-DOCSTART- -X- O
Lifelong -X- _ B-TaskName
learning -X- _ I-TaskName
( -X- _ I-TaskName
LL -X- _ I-TaskName
) -X- _ I-TaskName
aims -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
on -X- _ O
a -X- _ O
stream -X- _ O
of -X- _ O
tasks -X- _ O
while -X- _ O
retaining -X- _ O
knowledge -X- _ O
from -X- _ O
previous -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
many -X- _ O
prior -X- _ O
attempts -X- _ O
in -X- _ O
NLP -X- _ O
still -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
issue -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
completely -X- _ O
forgets -X- _ O
what -X- _ O
it -X- _ O
just -X- _ O
learned -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
, -X- _ O
a -X- _ O
novel -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
LL -X- _ B-TaskName
framework -X- _ O
for -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
alleviate -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
, -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
enhances -X- _ O
LAMOL -X- _ B-MethodName
, -X- _ O
a -X- _ O
recent -X- _ O
LL -X- _ B-TaskName
model -X- _ O
, -X- _ O
by -X- _ O
applying -X- _ O
critical -X- _ O
freezing -X- _ O
guided -X- _ O
by -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
human -X- _ O
rationales -X- _ O
are -X- _ O
not -X- _ O
available -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
exploiting -X- _ O
unsupervised -X- _ O
generated -X- _ O
rationales -X- _ O
as -X- _ O
substitutions -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
tested -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
on -X- _ O
permutations -X- _ O
of -X- _ O
three -X- _ O
datasets -X- _ O
from -X- _ O
the -X- _ O
ERASER -X- _ O
benchmark -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
outperformed -X- _ O
vanilla -X- _ O
LAMOL -X- _ B-MethodName
on -X- _ O
most -X- _ O
permutations -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
unsupervised -X- _ O
rationale -X- _ O
generation -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
consistently -X- _ O
improve -X- _ O
the -X- _ O
overall -X- _ O
LL -X- _ B-TaskName
performance -X- _ O
from -X- _ O
the -X- _ O
baseline -X- _ O
without -X- _ O
relying -X- _ O
on -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
rationales -X- _ O
. -X- _ O
We -X- _ O
made -X- _ O
our -X- _ O
code -X- _ O
publicly -X- _ O
available -X- _ O
at -X- _ O
https://github -X- _ O
. -X- _ O
com -X- _ O
/ -X- _ O
kanwatchara -X- _ O
- -X- _ O
k -X- _ O
/ -X- _ O
r_lamol -X- _ O
. -X- _ O
The -X- _ O
grounds -X- _ O
of -X- _ O
lifelong -X- _ B-TaskName
learning -X- _ I-TaskName
( -X- _ O
LL -X- _ B-TaskName
) -X- _ O
stem -X- _ O
from -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
humans -X- _ O
to -X- _ O
continually -X- _ O
acquire -X- _ O
, -X- _ O
consolidate -X- _ O
, -X- _ O
and -X- _ O
transfer -X- _ O
knowledge -X- _ O
and -X- _ O
skills -X- _ O
throughout -X- _ O
their -X- _ O
lifespan -X- _ O
. -X- _ O
This -X- _ O
ability -X- _ O
is -X- _ O
also -X- _ O
important -X- _ O
for -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
applications -X- _ O
, -X- _ O
where -X- _ O
autonomous -X- _ O
agents -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
interact -X- _ O
with -X- _ O
users -X- _ O
from -X- _ O
various -X- _ O
domains -X- _ O
through -X- _ O
continuous -X- _ O
streams -X- _ O
of -X- _ O
information -X- _ O
and -X- _ O
language -X- _ O
semantic -X- _ O
drifts -X- _ O
occur -X- _ O
over -X- _ O
time -X- _ O
. -X- _ O
The -X- _ O
existing -X- _ O
dominant -X- _ O
paradigm -X- _ O
for -X- _ O
machine -X- _ O
learning -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
is -X- _ O
isolated -X- _ O
learning -X- _ O
( -X- _ O
Chen -X- _ O
and -X- _ O
Liu -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
isolated -X- _ O
learning -X- _ O
has -X- _ O
shown -X- _ O
some -X- _ O
successes -X- _ O
in -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
domains -X- _ O
, -X- _ O
their -X- _ O
applicability -X- _ O
remains -X- _ O
limited -X- _ O
to -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
all -X- _ O
samples -X- _ O
are -X- _ O
available -X- _ O
during -X- _ O
the -X- _ O
learning -X- _ O
phase -X- _ O
. -X- _ O
When -X- _ O
a -X- _ O
stream -X- _ O
of -X- _ O
tasks -X- _ O
are -X- _ O
trained -X- _ O
sequentially -X- _ O
, -X- _ O
machine -X- _ O
learning -X- _ O
and -X- _ O
neural -X- _ O
network -X- _ O
models -X- _ O
face -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
or -X- _ O
interference -X- _ O
( -X- _ O
McCloskey -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
1989 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
occurs -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
stationary -X- _ O
data -X- _ O
distribution -X- _ O
that -X- _ O
biases -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
focus -X- _ O
on -X- _ O
lifelong -X- _ B-TaskName
language -X- _ I-TaskName
learning -X- _ I-TaskName
( -X- _ O
LLL -X- _ B-TaskName
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
lifelong -X- _ B-TaskName
learning -X- _ I-TaskName
on -X- _ O
a -X- _ O
stream -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
the -X- _ O
grounds -X- _ O
of -X- _ O
LLL -X- _ B-TaskName
are -X- _ O
left -X- _ O
largely -X- _ O
underexplored -X- _ O
. -X- _ O
LAMOL -X- _ B-MethodName
is -X- _ O
an -X- _ O
LLL -X- _ B-TaskName
general -X- _ O
framework -X- _ O
that -X- _ O
has -X- _ O
garnered -X- _ O
recent -X- _ O
interest -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
simplicity -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
LAMOL -X- _ B-MethodName
transforms -X- _ O
all -X- _ O
NLP -X- _ O
tasks -X- _ O
into -X- _ O
the -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
QA -X- _ O
) -X- _ O
format -X- _ O
according -X- _ O
to -X- _ O
McCann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
generates -X- _ O
pseudo -X- _ O
- -X- _ O
samples -X- _ O
of -X- _ O
old -X- _ O
tasks -X- _ O
using -X- _ O
its -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O
capability -X- _ O
to -X- _ O
refresh -X- _ O
the -X- _ O
learned -X- _ O
knowledge -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
LAMOL -X- _ B-MethodName
and -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
task -X- _ I-TaskName
learning -X- _ I-TaskName
which -X- _ O
is -X- _ O
generally -X- _ O
considered -X- _ O
as -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
LLL -X- _ B-TaskName
performance -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
only -X- _ O
pseudo -X- _ O
- -X- _ O
samples -X- _ O
generation -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
sufficient -X- _ O
to -X- _ O
prevent -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
improve -X- _ O
existing -X- _ O
LLL -X- _ B-TaskName
strategies -X- _ O
by -X- _ O
proposing -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
, -X- _ O
a -X- _ O
rationale -X- _ O
- -X- _ O
based -X- _ O
lifelong -X- _ O
learning -X- _ O
framework -X- _ O
which -X- _ O
equips -X- _ O
the -X- _ O
original -X- _ O
LAMOL -X- _ B-MethodName
with -X- _ O
critical -X- _ O
freezing -X- _ O
( -X- _ O
Nguyen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
further -X- _ O
prevent -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
we -X- _ O
devise -X- _ O
an -X- _ O
algorithm -X- _ O
to -X- _ O
identify -X- _ O
critical -X- _ O
components -X- _ O
in -X- _ O
transformer -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
language -X- _ I-MethodName
models -X- _ I-MethodName
using -X- _ O
rationales -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
selected -X- _ O
compo -X- _ O
- -X- _ O
nents -X- _ O
will -X- _ O
be -X- _ O
frozen -X- _ O
to -X- _ O
maintain -X- _ O
learned -X- _ O
knowledge -X- _ O
while -X- _ O
being -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
. -X- _ O
The -X- _ O
contributions -X- _ O
of -X- _ O
our -X- _ O
paper -X- _ O
are -X- _ O
listed -X- _ O
below:• -X- _ O
We -X- _ O
demonstrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
freezing -X- _ O
plastic -X- _ O
components -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
components -X- _ O
that -X- _ O
are -X- _ O
most -X- _ O
susceptible -X- _ O
to -X- _ O
change -X- _ O
) -X- _ O
in -X- _ O
transformerbased -X- _ B-MethodName
models -X- _ I-MethodName
to -X- _ O
strengthen -X- _ O
memories -X- _ O
of -X- _ O
the -X- _ O
previously -X- _ O
learned -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
LLL -X- _ B-TaskName
setting.• -X- _ O
We -X- _ O
propose -X- _ O
critical -X- _ O
component -X- _ O
identification -X- _ O
algorithm -X- _ O
which -X- _ O
analyzes -X- _ O
the -X- _ O
transformerbased -X- _ B-MethodName
LLL -X- _ I-MethodName
model -X- _ I-MethodName
with -X- _ O
rationales -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
most -X- _ O
plastic -X- _ O
component -X- _ O
to -X- _ O
freeze -X- _ O
. -X- _ O
This -X- _ O
step -X- _ O
is -X- _ O
so -X- _ O
called -X- _ O
critical -X- _ O
freezing -X- _ O
, -X- _ O
firstly -X- _ O
devised -X- _ O
in -X- _ O
computer -X- _ O
vision -X- _ O
( -X- _ O
Nguyen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
but -X- _ O
we -X- _ O
adapted -X- _ O
it -X- _ O
to -X- _ O
NLP.• -X- _ O
We -X- _ O
propose -X- _ O
that -X- _ O
unsupervised -X- _ O
generated -X- _ O
rationales -X- _ O
by -X- _ O
InvRat -X- _ B-MethodName
( -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
effectively -X- _ O
used -X- _ O
as -X- _ O
substitutions -X- _ O
of -X- _ O
human -X- _ O
rationales -X- _ O
, -X- _ O
allowing -X- _ O
our -X- _ O
framework -X- _ O
to -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
generic -X- _ O
NLP -X- _ O
datasets -X- _ O
. -X- _ O
We -X- _ O
evaluated -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
on -X- _ O
six -X- _ O
task -X- _ O
order -X- _ O
permutations -X- _ O
of -X- _ O
three -X- _ O
datasets -X- _ O
from -X- _ O
the -X- _ O
ERASER -X- _ O
benchmark -X- _ O
( -X- _ O
DeYoung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
outperformed -X- _ O
the -X- _ O
original -X- _ O
LAMOL -X- _ B-MethodName
on -X- _ O
five -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
six -X- _ O
permutations -X- _ O
, -X- _ O
achieving -X- _ O
average -X- _ O
improvements -X- _ O
of -X- _ O
1.83 -X- _ B-MetricValue
% -X- _ I-MetricValue
with -X- _ O
a -X- _ O
lower -X- _ O
standard -X- _ O
deviation -X- _ O
of -X- _ O
4.57 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Moreover -X- _ O
, -X- _ O
using -X- _ O
unsupervised -X- _ O
rationale -X- _ O
generation -X- _ O
instead -X- _ O
of -X- _ O
human -X- _ O
rationales -X- _ O
also -X- _ O
yielded -X- _ O
competitive -X- _ O
performance -X- _ O
, -X- _ O
achieving -X- _ O
average -X- _ O
improvements -X- _ O
of -X- _ O
2.67 -X- _ B-MetricValue
% -X- _ I-MetricValue
from -X- _ O
original -X- _ O
LAMOL -X- _ B-MethodName
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
briefly -X- _ O
introduce -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
lifelong -X- _ B-TaskName
learning -X- _ I-TaskName
, -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
, -X- _ O
and -X- _ O
component -X- _ O
freezing -X- _ O
which -X- _ O
are -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
core -X- _ O
idea -X- _ O
of -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
. -X- _ O
We -X- _ O
also -X- _ O
briefly -X- _ O
summarize -X- _ O
prominent -X- _ O
researches -X- _ O
related -X- _ O
to -X- _ O
rationales -X- _ O
. -X- _ O
While -X- _ O
people -X- _ O
fine -X- _ O
tune -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
single -X- _ O
task -X- _ O
, -X- _ O
lifelong -X- _ B-TaskName
learning -X- _ I-TaskName
( -X- _ O
LL -X- _ B-TaskName
) -X- _ O
is -X- _ O
a -X- _ O
setting -X- _ O
in -X- _ O
which -X- _ O
a -X- _ O
learner -X- _ O
performs -X- _ O
sequential -X- _ O
learning -X- _ O
of -X- _ O
infinitely -X- _ O
incoming -X- _ O
tasks -X- _ O
τ -X- _ O
= -X- _ O
{ -X- _ O
τ -X- _ O
1 -X- _ O
, -X- _ O
τ -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
τ -X- _ O
i -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
τ -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
task -X- _ O
to -X- _ O
learn -X- _ O
at -X- _ O
a -X- _ O
particular -X- _ O
point -X- _ O
in -X- _ O
time -X- _ O
. -X- _ O
The -X- _ O
objective -X- _ O
of -X- _ O
the -X- _ O
LL -X- _ B-TaskName
learner -X- _ O
is -X- _ O
to -X- _ O
ideally -X- _ O
both -X- _ O
optimize -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
new -X- _ O
task -X- _ O
and -X- _ O
maintain -X- _ O
optimal -X- _ O
performance -X- _ O
on -X- _ O
previous -X- _ O
tasks -X- _ O
τ -X- _ O
t -X- _ O
for -X- _ O
t -X- _ O
= -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
i. -X- _ O
Moreover -X- _ O
, -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
transfer -X- _ O
knowledge -X- _ O
across -X- _ O
different -X- _ O
tasks -X- _ O
is -X- _ O
also -X- _ O
desired -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
naively -X- _ O
training -X- _ O
on -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
tasks -X- _ O
without -X- _ O
accounting -X- _ O
for -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
data -X- _ O
distributions -X- _ O
would -X- _ O
result -X- _ O
in -X- _ O
an -X- _ O
abrupt -X- _ O
decrease -X- _ O
in -X- _ O
old -X- _ O
tasks -X- _ O
performance -X- _ O
. -X- _ O
This -X- _ O
phenomenon -X- _ O
is -X- _ O
known -X- _ O
as -X- _ O
Catastrophic -X- _ O
Forgetting -X- _ O
( -X- _ O
McCloskey -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
1989 -X- _ O
) -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
multiple -X- _ O
existing -X- _ O
works -X- _ O
that -X- _ O
aim -X- _ O
to -X- _ O
mitigate -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
in -X- _ O
LL -X- _ B-TaskName
. -X- _ O
They -X- _ O
can -X- _ O
be -X- _ O
categorized -X- _ O
into -X- _ O
three -X- _ O
major -X- _ O
approaches -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
regularization -X- _ O
methods -X- _ O
use -X- _ O
a -X- _ O
regularization -X- _ O
term -X- _ O
to -X- _ O
constrain -X- _ O
changes -X- _ O
when -X- _ O
updating -X- _ O
weights -X- _ O
in -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
( -X- _ O
Kirkpatrick -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Aljundi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
data -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
disallow -X- _ O
significant -X- _ O
deviation -X- _ O
of -X- _ O
weights -X- _ O
from -X- _ O
previous -X- _ O
tasks -X- _ O
by -X- _ O
keeping -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
tasks -X- _ O
or -X- _ O
generating -X- _ O
pseudo -X- _ O
- -X- _ O
data -X- _ O
to -X- _ O
refresh -X- _ O
the -X- _ O
learned -X- _ O
knowledge -X- _ O
( -X- _ O
Lopez -X- _ O
- -X- _ O
Paz -X- _ O
and -X- _ O
Ranzato -X- _ O
, -X- _ O
2017;Chaudhry -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;de -X- _ O
Masson -X- _ O
d'Autume -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Li -X- _ O
and -X- _ O
Hoiem -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
architecture -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
dynamically -X- _ O
transform -X- _ O
the -X- _ O
neural -X- _ O
network -X- _ O
architectures -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
accommodate -X- _ O
new -X- _ O
knowledge -X- _ O
( -X- _ O
Rusu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;.Lifelong -X- _ B-TaskName
Language -X- _ I-TaskName
Learning -X- _ I-TaskName
or -X- _ O
LLL -X- _ B-TaskName
is -X- _ O
a -X- _ O
scenario -X- _ O
where -X- _ O
a -X- _ O
model -X- _ O
sequentially -X- _ O
learns -X- _ O
from -X- _ O
a -X- _ O
stream -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
in -X- _ O
an -X- _ O
LL -X- _ B-TaskName
manner -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
LLL -X- _ B-TaskName
has -X- _ O
rarely -X- _ O
been -X- _ O
studied -X- _ O
and -X- _ O
previous -X- _ O
works -X- _ O
usually -X- _ O
target -X- _ O
a -X- _ O
single -X- _ O
type -X- _ O
of -X- _ O
NLP -X- _ O
tasks -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;de -X- _ O
Masson -X- _ O
d'Autume -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
go -X- _ O
beyond -X- _ O
this -X- _ O
limitation -X- _ O
, -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
LAMOL -X- _ B-MethodName
, -X- _ O
a -X- _ O
learning -X- _ O
framework -X- _ O
that -X- _ O
utilizes -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
simultaneously -X- _ O
predict -X- _ O
outputs -X- _ O
and -X- _ O
learn -X- _ O
to -X- _ O
generate -X- _ O
pseudo -X- _ O
- -X- _ O
training -X- _ O
examples -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
exploited -X- _ O
to -X- _ O
alleviate -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
LAMOL -X- _ B-MethodName
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
our -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
, -X- _ O
naturally -X- _ O
falls -X- _ O
into -X- _ O
the -X- _ O
data -X- _ O
- -X- _ O
based -X- _ O
LL -X- _ B-TaskName
approach -X- _ O
since -X- _ O
data -X- _ O
from -X- _ O
previous -X- _ O
tasks -X- _ O
, -X- _ O
albeit -X- _ O
generated -X- _ O
, -X- _ O
is -X- _ O
utilized -X- _ O
to -X- _ O
constrain -X- _ O
a -X- _ O
model -X- _ O
. -X- _ O
Component -X- _ O
Freezing -X- _ O
While -X- _ O
component -X- _ O
freezing -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
common -X- _ O
practice -X- _ O
in -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
process -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
done -X- _ O
to -X- _ O
prevent -X- _ O
loss -X- _ O
in -X- _ O
general -X- _ O
knowledge -X- _ O
in -X- _ O
lower -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
( -X- _ O
Raganato -X- _ O
and -X- _ O
Tiedemann -X- _ O
, -X- _ O
2018).By -X- _ O
contrast -X- _ O
, -X- _ O
many -X- _ O
architecture -X- _ O
- -X- _ O
based -X- _ O
LL -X- _ B-TaskName
methods -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
Rusu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
utilize -X- _ O
component -X- _ O
freezing -X- _ O
to -X- _ O
prevent -X- _ O
changes -X- _ O
to -X- _ O
learned -X- _ O
knowledge -X- _ O
from -X- _ O
previous -X- _ O
tasks -X- _ O
and -X- _ O
enlarge -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
accommodate -X- _ O
new -X- _ O
tasks -X- _ O
, -X- _ O
thereby -X- _ O
making -X- _ O
the -X- _ O
model -X- _ O
immune -X- _ O
to -X- _ O
forgetting -X- _ O
. -X- _ O
Our -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
also -X- _ O
uses -X- _ O
component -X- _ O
freezing -X- _ O
, -X- _ O
but -X- _ O
unlike -X- _ O
architecturebased -X- _ O
methods -X- _ O
, -X- _ O
only -X- _ O
a -X- _ O
small -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
frozen -X- _ O
and -X- _ O
its -X- _ O
size -X- _ O
is -X- _ O
constant -X- _ O
throughout -X- _ O
the -X- _ O
learning -X- _ O
process -X- _ O
. -X- _ O
Rationales -X- _ O
Rationales -X- _ O
are -X- _ O
reasons -X- _ O
for -X- _ O
labels -X- _ O
or -X- _ O
predictions -X- _ O
. -X- _ O
In -X- _ O
NLP -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
usually -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
texts -X- _ O
which -X- _ O
support -X- _ O
or -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
class -X- _ O
labels -X- _ O
. -X- _ O
Rationales -X- _ O
could -X- _ O
be -X- _ O
either -X- _ O
annotated -X- _ O
by -X- _ O
humans -X- _ O
or -X- _ O
generated -X- _ O
by -X- _ O
machine -X- _ O
learning -X- _ O
models -X- _ O
. -X- _ O
Human -X- _ O
rationales -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
enhance -X- _ O
machine -X- _ O
learning -X- _ O
in -X- _ O
multiple -X- _ O
studies -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
Rajani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
used -X- _ O
the -X- _ O
rationales -X- _ O
to -X- _ O
guide -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
toward -X- _ O
better -X- _ O
reasoning -X- _ O
. -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
utilized -X- _ O
rationales -X- _ O
as -X- _ O
auxiliary -X- _ O
information -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
model -X- _ O
, -X- _ O
reducing -X- _ O
training -X- _ O
examples -X- _ O
required -X- _ O
to -X- _ O
achieve -X- _ O
good -X- _ O
results -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
DeYoung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
introduced -X- _ O
the -X- _ O
ERASER -X- _ O
benchmark -X- _ O
consisting -X- _ O
of -X- _ O
multiple -X- _ O
datasets -X- _ O
, -X- _ O
all -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
annotated -X- _ O
with -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O
This -X- _ O
facilitates -X- _ O
the -X- _ O
advancement -X- _ O
of -X- _ O
research -X- _ O
on -X- _ O
interpretable -X- _ O
NLP -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
human -X- _ O
rationales -X- _ O
from -X- _ O
ERASER -X- _ O
in -X- _ O
the -X- _ O
critical -X- _ O
component -X- _ O
identification -X- _ O
step -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
most -X- _ O
plastic -X- _ O
component -X- _ O
to -X- _ O
be -X- _ O
frozen -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
some -X- _ O
researchers -X- _ O
attempt -X- _ O
to -X- _ O
design -X- _ O
architectures -X- _ O
to -X- _ O
predict -X- _ O
rationales -X- _ O
from -X- _ O
labelled -X- _ O
data -X- _ O
. -X- _ O
Existing -X- _ O
rationalization -X- _ O
techniques -X- _ O
commonly -X- _ O
use -X- _ O
the -X- _ O
maximum -X- _ O
mutual -X- _ O
information -X- _ O
( -X- _ O
MMI -X- _ O
) -X- _ O
criterion -X- _ O
to -X- _ O
select -X- _ O
rationales -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
prone -X- _ O
to -X- _ O
choosing -X- _ O
spurious -X- _ O
correlation -X- _ O
between -X- _ O
input -X- _ O
features -X- _ O
and -X- _ O
outputs -X- _ O
as -X- _ O
rationales -X- _ O
( -X- _ O
Lei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
fix -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
Invariant -X- _ O
Rationalization -X- _ O
( -X- _ O
InvRat -X- _ O
) -X- _ O
( -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
follows -X- _ O
the -X- _ O
invariant -X- _ O
risk -X- _ O
minimization -X- _ O
( -X- _ O
IRM -X- _ O
) -X- _ O
paradigm -X- _ O
, -X- _ O
as -X- _ O
introduced -X- _ O
by -X- _ O
Arjovsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
utilizes -X- _ O
the -X- _ O
environment -X- _ O
variable -X- _ O
to -X- _ O
isolate -X- _ O
and -X- _ O
select -X- _ O
the -X- _ O
causal -X- _ O
features -X- _ O
that -X- _ O
faithfully -X- _ O
explain -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
allow -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
to -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
NLP -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
to -X- _ O
leverage -X- _ O
InvRat -X- _ O
to -X- _ O
automatically -X- _ O
produce -X- _ O
rationales -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
superior -X- _ O
performance -X- _ O
and -X- _ O
straightforward -X- _ O
application -X- _ O
, -X- _ O
removing -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
and -X- _ O
its -X- _ O
detailed -X- _ O
implementation -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O
As -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
is -X- _ O
based -X- _ O
from -X- _ O
LAMOL -X- _ B-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
briefly -X- _ O
explain -X- _ O
LAMOL -X- _ B-MethodName
in -X- _ O
Section -X- _ O
3.1 -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
core -X- _ O
lifelong -X- _ B-TaskName
learning -X- _ I-TaskName
framework -X- _ O
of -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
followed -X- _ O
by -X- _ O
two -X- _ O
proposed -X- _ O
enhancements -X- _ O
including -X- _ O
critical -X- _ O
component -X- _ O
identification -X- _ O
and -X- _ O
unsupervised -X- _ O
rationale -X- _ O
generation -X- _ O
, -X- _ O
detailed -X- _ O
in -X- _ O
Section -X- _ O
3.3 -X- _ O
and -X- _ O
3.4 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Language -X- _ B-MethodName
Modeling -X- _ I-MethodName
for -X- _ I-MethodName
Lifelong -X- _ I-MethodName
Language -X- _ I-MethodName
Learning -X- _ I-MethodName
( -X- _ O
LAMOL -X- _ B-MethodName
) -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
utilizes -X- _ O
a -X- _ O
single -X- _ O
language -X- _ O
model -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
multipurpose -X- _ O
model -X- _ O
. -X- _ O
Framing -X- _ O
all -X- _ O
tasks -X- _ O
as -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
QA -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
LM -X- _ O
now -X- _ O
poses -X- _ O
as -X- _ O
a -X- _ O
generic -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
LAMOL -X- _ B-MethodName
trains -X- _ O
the -X- _ O
LM -X- _ O
as -X- _ O
a -X- _ O
generative -X- _ O
model -X- _ O
upon -X- _ O
receiving -X- _ O
a -X- _ O
special -X- _ O
generation -X- _ O
token -X- _ O
. -X- _ O
Using -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
for -X- _ O
both -X- _ O
providing -X- _ O
answers -X- _ O
and -X- _ O
generating -X- _ O
pseudo -X- _ O
- -X- _ O
samples -X- _ O
, -X- _ O
LAMOL -X- _ B-MethodName
truly -X- _ O
exhibits -X- _ O
a -X- _ O
model -X- _ O
of -X- _ O
LM -X- _ O
and -X- _ O
QA -X- _ O
duality -X- _ O
. -X- _ O
The -X- _ O
benefit -X- _ O
that -X- _ O
comes -X- _ O
with -X- _ O
the -X- _ O
generative -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
tackles -X- _ O
the -X- _ O
long -X- _ O
- -X- _ O
standing -X- _ O
issue -X- _ O
of -X- _ O
LLcatastrophic -X- _ B-TaskName
forgetting -X- _ O
. -X- _ O
While -X- _ O
other -X- _ O
methods -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
extra -X- _ O
memory -X- _ O
or -X- _ O
model -X- _ O
capacity -X- _ O
to -X- _ O
preserve -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
real -X- _ O
samples -X- _ O
( -X- _ O
Lopez -X- _ O
- -X- _ O
Paz -X- _ O
and -X- _ O
Ranzato -X- _ O
, -X- _ O
2017;Chaudhry -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
to -X- _ O
accomodate -X- _ O
a -X- _ O
separate -X- _ O
generator -X- _ O
( -X- _ O
Shin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Kemker -X- _ O
and -X- _ O
Kanan -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
LAMOL -X- _ B-MethodName
transfers -X- _ O
all -X- _ O
the -X- _ O
responsibilities -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
. -X- _ O
It -X- _ O
learns -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
select -X- _ O
potentially -X- _ O
prominent -X- _ O
features -X- _ O
befitting -X- _ O
learning -X- _ O
by -X- _ O
modeling -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
replay -X- _ O
meaningful -X- _ O
pseudo -X- _ O
- -X- _ O
samples -X- _ O
from -X- _ O
previous -X- _ O
tasks -X- _ O
while -X- _ O
forcing -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
memorize -X- _ O
knowledge -X- _ O
acquired -X- _ O
from -X- _ O
previous -X- _ O
tasks -X- _ O
tied -X- _ O
to -X- _ O
the -X- _ O
generation -X- _ O
token -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
exploiting -X- _ O
rationales -X- _ O
with -X- _ O
LAMOL -X- _ B-MethodName
to -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
LLL -X- _ B-TaskName
performance -X- _ O
, -X- _ O
discussed -X- _ O
next -X- _ O
. -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
, -X- _ O
illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
( -X- _ O
right -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
learning -X- _ O
framework -X- _ O
revolving -X- _ O
around -X- _ O
the -X- _ O
original -X- _ O
methodologies -X- _ O
of -X- _ O
LAMOL -X- _ B-MethodName
. -X- _ O
We -X- _ O
consider -X- _ O
an -X- _ O
LL -X- _ B-TaskName
setting -X- _ O
where -X- _ O
τ -X- _ O
= -X- _ O
{ -X- _ O
τ -X- _ O
1 -X- _ O
, -X- _ O
τ -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
τ -X- _ O
i -X- _ O
, -X- _ O
... -X- _ O
} -X- _ O
is -X- _ O
a -X- _ O
stream -X- _ O
of -X- _ O
learning -X- _ O
tasks -X- _ O
and -X- _ O
τ -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
task -X- _ O
to -X- _ O
train -X- _ O
at -X- _ O
a -X- _ O
particular -X- _ O
point -X- _ O
in -X- _ O
time -X- _ O
. -X- _ O
Let -X- _ O
M -X- _ O
i -X- _ O
denote -X- _ O
the -X- _ O
model -X- _ O
M -X- _ O
after -X- _ O
being -X- _ O
trained -X- _ O
for -X- _ O
task -X- _ O
i -X- _ O
, -X- _ O
where -X- _ O
M -X- _ O
0 -X- _ O
is -X- _ O
the -X- _ O
initialized -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
. -X- _ O
Using -X- _ O
these -X- _ O
notations -X- _ O
and -X- _ O
starting -X- _ O
from -X- _ O
M -X- _ O
0 -X- _ O
, -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
works -X- _ O
iteratively -X- _ O
in -X- _ O
four -X- _ O
steps -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
model -X- _ O
M -X- _ O
i -X- _ O
, -X- _ O
it -X- _ O
trains -X- _ O
M -X- _ O
i -X- _ O
with -X- _ O
the -X- _ O
task -X- _ O
τ -X- _ O
i+1 -X- _ O
using -X- _ O
LAMOL -X- _ B-MethodName
's -X- _ O
training -X- _ O
procedure -X- _ O
to -X- _ O
obtainM -X- _ O
i+1 -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
for -X- _ O
i -X- _ O
> -X- _ O
0 -X- _ O
, -X- _ O
it -X- _ O
applies -X- _ O
critical -X- _ O
component -X- _ O
identification -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.3 -X- _ O
, -X- _ O
on -X- _ O
M -X- _ O
i -X- _ O
andM -X- _ O
i+1 -X- _ O
with -X- _ O
the -X- _ O
rationales -X- _ O
of -X- _ O
task -X- _ O
τ -X- _ O
i -X- _ O
to -X- _ O
dissect -X- _ O
the -X- _ O
most -X- _ O
plastic -X- _ O
layers -X- _ O
or -X- _ O
blocks -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
a -X- _ O
step -X- _ O
back -X- _ O
to -X- _ O
work -X- _ O
at -X- _ O
M -X- _ O
i -X- _ O
and -X- _ O
apply -X- _ O
critical -X- _ O
freezing -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
freezing -X- _ O
the -X- _ O
most -X- _ O
plastic -X- _ O
components -X- _ O
, -X- _ O
The -X- _ O
input -X- _ O
is -X- _ O
fed -X- _ O
through -X- _ O
each -X- _ O
attention -X- _ O
block -X- _ O
AT -X- _ O
j -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
block -X- _ O
j -X- _ O
has -X- _ O
multiple -X- _ O
heads -X- _ O
. -X- _ O
B -X- _ O
: -X- _ O
A -X- _ O
single -X- _ O
attention -X- _ O
head -X- _ O
AT -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
consists -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
in -X- _ O
relation -X- _ O
to -X- _ O
all -X- _ O
other -X- _ O
tokens -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
C. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
IoU -X- _ O
calculation -X- _ O
F -X- _ O
is -X- _ O
applied -X- _ O
on -X- _ O
the -X- _ O
hard -X- _ O
selection -X- _ O
of -X- _ O
attention -X- _ O
token -X- _ O
with -X- _ O
percentiles -X- _ O
D -X- _ O
and -X- _ O
the -X- _ O
rationale -X- _ O
ground -X- _ O
truth -X- _ O
in -X- _ O
E.to -X- _ O
obtain -X- _ O
M -X- _ O
CF -X- _ O
i -X- _ O
. -X- _ O
Lastly -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
M -X- _ O
CF -X- _ O
i -X- _ O
through -X- _ O
the -X- _ O
task -X- _ O
τ -X- _ O
i+1 -X- _ O
again -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
new -X- _ O
model -X- _ O
M -X- _ O
i+1 -X- _ O
that -X- _ O
retains -X- _ O
the -X- _ O
most -X- _ O
plastic -X- _ O
memories -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
despite -X- _ O
the -X- _ O
unique -X- _ O
nature -X- _ O
of -X- _ O
LAMOL -X- _ B-MethodName
, -X- _ O
our -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
does -X- _ O
not -X- _ O
limit -X- _ O
its -X- _ O
usage -X- _ O
to -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
architecture -X- _ O
. -X- _ O
It -X- _ O
has -X- _ O
potential -X- _ O
applications -X- _ O
to -X- _ O
general -X- _ O
attention -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
suffering -X- _ O
from -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
through -X- _ O
domain -X- _ O
shifts -X- _ O
across -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
the -X- _ O
Critical -X- _ O
Component -X- _ O
Identification -X- _ O
( -X- _ O
CCI -X- _ O
) -X- _ O
algorithm -X- _ O
, -X- _ O
pointing -X- _ O
out -X- _ O
the -X- _ O
most -X- _ O
plastic -X- _ O
block -X- _ O
of -X- _ O
our -X- _ O
transformer -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
LL -X- _ I-MethodName
model -X- _ I-MethodName
before -X- _ O
moving -X- _ O
on -X- _ O
to -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
completely -X- _ O
. -X- _ O
( -X- _ O
This -X- _ O
shares -X- _ O
the -X- _ O
same -X- _ O
spirit -X- _ O
as -X- _ O
Nguyen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
proposing -X- _ O
Auto -X- _ O
DeepVis -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
most -X- _ O
plastic -X- _ O
blocks -X- _ O
of -X- _ O
CNN -X- _ O
models -X- _ O
for -X- _ O
image -X- _ O
classification -X- _ O
. -X- _ O
) -X- _ O
The -X- _ O
chosen -X- _ O
block -X- _ O
is -X- _ O
the -X- _ O
one -X- _ O
that -X- _ O
forgets -X- _ O
what -X- _ O
it -X- _ O
has -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
recent -X- _ O
task -X- _ O
the -X- _ O
most -X- _ O
when -X- _ O
being -X- _ O
introduced -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
will -X- _ O
freeze -X- _ O
the -X- _ O
block -X- _ O
to -X- _ O
prevent -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
in -X- _ O
Rational -X- _ B-MethodName
LAMOL.As -X- _ I-MethodName
shown -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
validation -X- _ O
sample -X- _ O
x -X- _ O
∈ -X- _ O
X -X- _ O
of -X- _ O
task -X- _ O
i -X- _ O
, -X- _ O
the -X- _ O
CCI -X- _ O
compares -X- _ O
the -X- _ O
attention -X- _ O
maps -X- _ O
AT -X- _ O
produced -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
M -X- _ O
i -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
old -X- _ O
model -X- _ O
M -X- _ O
O -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
) -X- _ O
andM -X- _ O
i+1 -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
new -X- _ O
model -X- _ O
M -X- _ O
N -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
) -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
most -X- _ O
plastic -X- _ O
block -X- _ O
b -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
this -X- _ O
sample -X- _ O
. -X- _ O
Then -X- _ O
it -X- _ O
returns -X- _ O
the -X- _ O
block -X- _ O
F -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
mode -X- _ O
of -X- _ O
all -X- _ O
b -X- _ O
, -X- _ O
voted -X- _ O
by -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
samples -X- _ O
in -X- _ O
X. -X- _ O
Note -X- _ O
that -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
variable -X- _ O
names -X- _ O
are -X- _ O
preserved -X- _ O
similar -X- _ O
to -X- _ O
Nguyen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
ease -X- _ O
of -X- _ O
reference -X- _ O
, -X- _ O
and -X- _ O
some -X- _ O
sections -X- _ O
are -X- _ O
refactored -X- _ O
for -X- _ O
readability -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
to -X- _ O
find -X- _ O
b -X- _ O
for -X- _ O
the -X- _ O
sample -X- _ O
x -X- _ O
, -X- _ O
we -X- _ O
iterate -X- _ O
over -X- _ O
all -X- _ O
blocks -X- _ O
j -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
K -X- _ O
and -X- _ O
perform -X- _ O
two -X- _ O
steps -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
representative -X- _ O
map -X- _ O
of -X- _ O
the -X- _ O
block -X- _ O
j -X- _ O
in -X- _ O
M -X- _ O
O -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
GT -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
RM -X- _ O
M -X- _ O
O -X- _ O
, -X- _ O
GT -X- _ O
( -X- _ O
j -X- _ O
) -X- _ O
) -X- _ O
by -X- _ O
selecting -X- _ O
the -X- _ O
attention -X- _ O
map -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
head -X- _ O
a -X- _ O
* -X- _ O
and -X- _ O
the -X- _ O
token -X- _ O
s -X- _ O
* -X- _ O
in -X- _ O
x -X- _ O
from -X- _ O
the -X- _ O
block -X- _ O
j -X- _ O
that -X- _ O
is -X- _ O
most -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
human -X- _ O
rationale -X- _ O
for -X- _ O
the -X- _ O
sample -X- _ O
x -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
ground -X- _ O
truth -X- _ O
GT -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
interpretable -X- _ O
NLP -X- _ O
stands -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
nascent -X- _ O
subfield -X- _ O
for -X- _ O
exploration -X- _ O
( -X- _ O
DeYoung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
elementary -X- _ O
visualization -X- _ O
of -X- _ O
attentions -X- _ O
are -X- _ O
possible -X- _ O
in -X- _ O
Transformers -X- _ B-MethodName
( -X- _ O
Vig -X- _ O
, -X- _ O
2019;Hoover -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanisms -X- _ O
associate -X- _ O
distant -X- _ O
positions -X- _ O
of -X- _ O
a -X- _ O
single -X- _ O
sequence -X- _ O
and -X- _ O
many -X- _ O
appear -X- _ O
to -X- _ O
exhibit -X- _ O
behavior -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
sentences -X- _ O
' -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
structure -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
semantic -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanisms -X- _ O
would -X- _ O
opt -X- _ O
for -X- _ O
tokens -X- _ O
most -X- _ O
relating -X- _ O
to -X- _ O
positive -X- _ O
evidence -X- _ O
vital -X- _ O
for -X- _ O
predictions -X- _ O
, -X- _ O
being -X- _ O
analogous -X- _ O
to -X- _ O
rationales -X- _ O
- -X- _ O
snippets -X- _ O
thatAlgorithm -X- _ O
1 -X- _ O
Critical -X- _ O
Component -X- _ O
Identification -X- _ O
Input -X- _ O
: -X- _ O
Validation -X- _ O
set -X- _ O
X -X- _ O
, -X- _ O
ground -X- _ O
truth -X- _ O
rationale -X- _ O
GT -X- _ O
, -X- _ O
old -X- _ O
model -X- _ O
M -X- _ O
O -X- _ O
, -X- _ O
new -X- _ O
model -X- _ O
M -X- _ O
N -X- _ O
, -X- _ O
number -X- _ O
of -X- _ O
blocks -X- _ O
K -X- _ O
Output -X- _ O
: -X- _ O
Critical -X- _ O
block -X- _ O
F -X- _ O
Ł← -X- _ O
∅ -X- _ O
for -X- _ O
all -X- _ O
validation -X- _ O
sample -X- _ O
x -X- _ O
∈ -X- _ O
X -X- _ O
do -X- _ O
: -X- _ O
IoUs -X- _ O
← -X- _ O
∅ -X- _ O
AT -X- _ O
O -X- _ O
, -X- _ O
AT -X- _ O
N -X- _ O
← -X- _ O
[ -X- _ O
M -X- _ O
O -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
, -X- _ O
M -X- _ O
N -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
] -X- _ O
for -X- _ O
j -X- _ O
= -X- _ O
1 -X- _ O
, -X- _ O
K -X- _ O
do -X- _ O
: -X- _ O
RM -X- _ O
M -X- _ O
O -X- _ O
, -X- _ O
GT -X- _ O
← -X- _ O
AT -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
* -X- _ O
, -X- _ O
s -X- _ O
* -X- _ O
with -X- _ O
highest -X- _ O
IoU -X- _ O
M -X- _ O
O -X- _ O
, -X- _ O
GT -X- _ O
RM -X- _ O
M -X- _ O
N -X- _ O
, -X- _ O
M -X- _ O
O -X- _ O
← -X- _ O
AT -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
* -X- _ O
, -X- _ O
s -X- _ O
* -X- _ O
with -X- _ O
highest -X- _ O
IoU -X- _ O
M -X- _ O
N -X- _ O
, -X- _ O
M -X- _ O
O -X- _ O
APPEND(IoUs -X- _ O
, -X- _ O
max(IoU -X- _ O
M -X- _ O
N -X- _ O
, -X- _ O
M -X- _ O
O -X- _ O
) -X- _ O
) -X- _ O
end -X- _ O
for -X- _ O
b -X- _ O
← -X- _ O
arg -X- _ O
min -X- _ O
j -X- _ O
IoUs -X- _ O
APPEND(Ł -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
end -X- _ O
for -X- _ O
F -X- _ O
= -X- _ O
MODE(Ł -X- _ O
) -X- _ O
return -X- _ O
Fsupport -X- _ O
outputs -X- _ O
. -X- _ O
To -X- _ O
compute -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
attention -X- _ O
maps -X- _ O
and -X- _ O
human -X- _ O
rationales -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Intersection -X- _ O
over -X- _ O
Union -X- _ O
( -X- _ O
IoU -X- _ O
) -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
the -X- _ O
following -X- _ O
equations -X- _ O
explain -X- _ O
this -X- _ O
step -X- _ O
. -X- _ O
RM -X- _ O
M -X- _ O
, -X- _ O
GT -X- _ O
( -X- _ O
j -X- _ O
) -X- _ O
= -X- _ O
AT -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
* -X- _ O
, -X- _ O
s -X- _ O
* -X- _ O
( -X- _ O
1)where -X- _ O
( -X- _ O
a -X- _ O
* -X- _ O
, -X- _ O
s -X- _ O
* -X- _ O
) -X- _ O
= -X- _ O
arg -X- _ O
max -X- _ O
a∈A -X- _ O
, -X- _ O
s∈S -X- _ O
( -X- _ O
IoU -X- _ O
M -X- _ O
, -X- _ O
GT -X- _ O
( -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
s))andIoU -X- _ O
M -X- _ O
, -X- _ O
GT -X- _ O
( -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
= -X- _ O
P -X- _ O
β -X- _ O
( -X- _ O
AT -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
∩ -X- _ O
GT -X- _ O
P -X- _ O
β -X- _ O
( -X- _ O
AT -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
∪ -X- _ O
GT(3)A -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
attention -X- _ O
heads -X- _ O
in -X- _ O
the -X- _ O
block -X- _ O
, -X- _ O
and -X- _ O
S -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
tokens -X- _ O
in -X- _ O
x. -X- _ O
IoU -X- _ O
M -X- _ O
, -X- _ O
GT -X- _ O
( -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
reflects -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
and -X- _ O
the -X- _ O
attention -X- _ O
map -X- _ O
of -X- _ O
the -X- _ O
block -X- _ O
j -X- _ O
, -X- _ O
head -X- _ O
a -X- _ O
, -X- _ O
and -X- _ O
token -X- _ O
s -X- _ O
in -X- _ O
x. -X- _ O
Since -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
contains -X- _ O
binary -X- _ O
labels -X- _ O
indicating -X- _ O
whether -X- _ O
a -X- _ O
token -X- _ O
is -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
rationale -X- _ O
or -X- _ O
not -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
convert -X- _ O
the -X- _ O
attention -X- _ O
map -X- _ O
AT -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
s -X- _ O
into -X- _ O
binary -X- _ O
labels -X- _ O
using -X- _ O
P -X- _ O
β -X- _ O
-a -X- _ O
simple -X- _ O
binary -X- _ O
thresholding -X- _ O
which -X- _ O
returns -X- _ O
1 -X- _ O
for -X- _ O
the -X- _ O
value -X- _ O
greater -X- _ O
than -X- _ O
the -X- _ O
β -X- _ O
- -X- _ O
th -X- _ O
percentile -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
sequence -X- _ O
( -X- _ O
otherwise -X- _ O
, -X- _ O
0 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
required -X- _ O
as -X- _ O
IoU -X- _ O
works -X- _ O
for -X- _ O
comparing -X- _ O
two -X- _ O
binary -X- _ O
masks -X- _ O
. -X- _ O
Actually -X- _ O
, -X- _ O
transformer -X- _ O
blocks -X- _ O
are -X- _ O
not -X- _ O
the -X- _ O
finest -X- _ O
granularity -X- _ O
that -X- _ O
we -X- _ O
could -X- _ O
freeze -X- _ O
. -X- _ O
Since -X- _ O
each -X- _ O
block -X- _ O
contains -X- _ O
several -X- _ O
attention -X- _ O
heads -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
to -X- _ O
freeze -X- _ O
some -X- _ O
attention -X- _ O
heads -X- _ O
individually -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
another -X- _ O
algorithm -X- _ O
, -X- _ O
applying -X- _ O
to -X- _ O
heads -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
Algorithm -X- _ O
1 -X- _ O
, -X- _ O
but -X- _ O
instead -X- _ O
of -X- _ O
searching -X- _ O
for -X- _ O
blocks -X- _ O
with -X- _ O
lowest -X- _ O
maximum -X- _ O
IoU -X- _ O
, -X- _ O
the -X- _ O
algorithm -X- _ O
searches -X- _ O
using -X- _ O
both -X- _ O
the -X- _ O
attention -X- _ O
blocks -X- _ O
and -X- _ O
attention -X- _ O
heads -X- _ O
together -X- _ O
as -X- _ O
keys -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
IoU -X- _ O
stays -X- _ O
the -X- _ O
same -X- _ O
, -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
the -X- _ O
representative -X- _ O
map -X- _ O
will -X- _ O
be -X- _ O
at -X- _ O
a -X- _ O
higher -X- _ O
granularity -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
for -X- _ O
a -X- _ O
block -X- _ O
index -X- _ O
j -X- _ O
and -X- _ O
attention -X- _ O
head -X- _ O
a -X- _ O
, -X- _ O
RM -X- _ O
M -X- _ O
, -X- _ O
GT -X- _ O
will -X- _ O
be -X- _ O
computed -X- _ O
as -X- _ O
: -X- _ O
RM -X- _ O
M -X- _ O
, -X- _ O
GT -X- _ O
( -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
) -X- _ O
= -X- _ O
AT -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
s -X- _ O
* -X- _ O
( -X- _ O
4)where(s -X- _ O
* -X- _ O
) -X- _ O
= -X- _ O
arg -X- _ O
max -X- _ O
s∈S -X- _ O
( -X- _ O
IoU -X- _ O
M -X- _ O
, -X- _ O
GT -X- _ O
( -X- _ O
j -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
s))(5)and -X- _ O
we -X- _ O
can -X- _ O
freeze -X- _ O
top -X- _ O
n -X- _ O
heads -X- _ O
that -X- _ O
receives -X- _ O
most -X- _ O
votes -X- _ O
from -X- _ O
the -X- _ O
samples -X- _ O
in -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
X. -X- _ O
As -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
, -X- _ O
our -X- _ O
framework -X- _ O
requires -X- _ O
rationales -X- _ O
as -X- _ O
an -X- _ O
input -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
most -X- _ O
existing -X- _ O
NLP -X- _ O
datasets -X- _ O
are -X- _ O
not -X- _ O
annotated -X- _ O
with -X- _ O
rationales -X- _ O
. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
limitation -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
a -X- _ O
recent -X- _ O
unsupervised -X- _ O
rationale -X- _ O
generation -X- _ O
framework -X- _ O
, -X- _ O
In -X- _ B-MethodName
- -X- _ I-MethodName
vRat -X- _ I-MethodName
( -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
rationales -X- _ O
as -X- _ O
substitutions -X- _ O
. -X- _ O
Originally -X- _ O
, -X- _ O
InvRat -X- _ B-MethodName
was -X- _ O
designed -X- _ O
for -X- _ O
single -X- _ O
- -X- _ O
input -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
sentiment -X- _ O
analysis -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
since -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
we -X- _ O
experimented -X- _ O
with -X- _ O
are -X- _ O
text -X- _ O
- -X- _ O
pair -X- _ O
classification -X- _ O
, -X- _ O
we -X- _ O
append -X- _ O
the -X- _ O
query -X- _ O
( -X- _ O
or -X- _ O
question -X- _ O
) -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
each -X- _ O
sample -X- _ O
to -X- _ O
accommodate -X- _ O
these -X- _ O
tasks -X- _ O
. -X- _ O
4 -X- _ O
Experimental -X- _ O
Setup -X- _ O
To -X- _ O
evaluate -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
conducted -X- _ O
an -X- _ O
experiment -X- _ O
on -X- _ O
three -X- _ O
English -X- _ O
text -X- _ O
classification -X- _ O
datasets -X- _ O
, -X- _ O
curated -X- _ O
and -X- _ O
made -X- _ O
publicly -X- _ O
available -X- _ O
by -X- _ O
ERASER -X- _ O
1 -X- _ O
( -X- _ O
DeYoung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
datasets -X- _ O
, -X- _ O
as -X- _ O
listed -X- _ O
below -X- _ O
, -X- _ O
are -X- _ O
provided -X- _ O
with -X- _ O
rationales -X- _ O
marked -X- _ O
by -X- _ O
humans -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
contains -X- _ O
a -X- _ O
summary -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
dataset -X- _ O
sizes -X- _ O
, -X- _ O
and -X- _ O
metrics.• -X- _ O
BoolQ -X- _ B-DatasetName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
): -X- _ O
a -X- _ O
dataset -X- _ O
comprises -X- _ O
selected -X- _ O
passages -X- _ O
from -X- _ O
Wikipedia -X- _ O
and -X- _ O
naturally -X- _ O
occurring -X- _ O
yes -X- _ O
/ -X- _ O
no -X- _ O
questions -X- _ O
to -X- _ O
be -X- _ O
answered -X- _ O
by -X- _ O
the -X- _ O
model.• -X- _ O
Movie -X- _ B-DatasetName
Reviews -X- _ I-DatasetName
( -X- _ O
Zaidan -X- _ O
and -X- _ O
Eisner -X- _ O
, -X- _ O
2008 -X- _ O
): -X- _ O
a -X- _ O
dataset -X- _ O
composed -X- _ O
of -X- _ O
movie -X- _ O
reviews -X- _ O
. -X- _ O
It -X- _ O
contains -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
sentiment -X- _ O
labels -X- _ O
to -X- _ O
be -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
model.• -X- _ O
SciFact -X- _ B-DatasetName
( -X- _ O
Wadden -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
): -X- _ O
a -X- _ O
dataset -X- _ O
containing -X- _ O
expert -X- _ O
- -X- _ O
written -X- _ O
scientific -X- _ O
claims -X- _ O
coupled -X- _ O
with -X- _ O
evidence -X- _ O
- -X- _ O
containing -X- _ O
abstracts -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
claim -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
to -X- _ O
identify -X- _ O
if -X- _ O
the -X- _ O
abstract -X- _ O
supports -X- _ O
or -X- _ O
refutes -X- _ O
the -X- _ O
claim -X- _ O
. -X- _ O
We -X- _ O
ran -X- _ O
our -X- _ O
proposed -X- _ O
framework -X- _ O
on -X- _ O
all -X- _ O
six -X- _ O
permutations -X- _ O
of -X- _ O
task -X- _ O
order -X- _ O
for -X- _ O
three -X- _ O
times -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
results -X- _ O
are -X- _ O
then -X- _ O
reported -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
. -X- _ O
We -X- _ O
followed -X- _ O
the -X- _ O
best -X- _ O
LAMOL -X- _ B-MethodName
configuration -X- _ O
from -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
parameters -X- _ O
were -X- _ O
kept -X- _ O
at -X- _ O
the -X- _ O
default -X- _ O
values -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
methods -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
small -X- _ O
GPT-2 -X- _ O
model -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
Each -X- _ O
task -X- _ O
was -X- _ O
trained -X- _ O
for -X- _ O
five -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
applied -X- _ O
greedy -X- _ O
decoding -X- _ O
during -X- _ O
inference -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
instability -X- _ O
of -X- _ O
neural -X- _ O
network -X- _ O
, -X- _ O
in -X- _ O
each -X- _ O
task -X- _ O
order -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
first -X- _ O
task -X- _ O
model -X- _ O
M -X- _ O
1 -X- _ O
for -X- _ O
all -X- _ O
methods -X- _ O
in -X- _ O
each -X- _ O
run -X- _ O
for -X- _ O
fair -X- _ O
comparison -X- _ O
. -X- _ O
Critical -X- _ O
freezing -X- _ O
was -X- _ O
applied -X- _ O
to -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
two -X- _ O
different -X- _ O
levels -X- _ O
of -X- _ O
granularity -X- _ O
: -X- _ O
block -X- _ O
level -X- _ O
and -X- _ O
head -X- _ O
level -X- _ O
. -X- _ O
The -X- _ O
validation -X- _ O
set -X- _ O
of -X- _ O
each -X- _ O
task -X- _ O
was -X- _ O
used -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
Algorithm -X- _ O
1 -X- _ O
. -X- _ O
For -X- _ O
block -X- _ O
level -X- _ O
granularity -X- _ O
, -X- _ O
we -X- _ O
chose -X- _ O
to -X- _ O
freeze -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
block -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
algorithm -X- _ O
, -X- _ O
while -X- _ O
for -X- _ O
head -X- _ O
level -X- _ O
granularity -X- _ O
, -X- _ O
12 -X- _ O
heads -X- _ O
chosen -X- _ O
returned -X- _ O
by -X- _ O
the -X- _ O
algorithm -X- _ O
were -X- _ O
kept -X- _ O
frozen -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
β -X- _ B-HyperparameterName
= -X- _ O
80 -X- _ B-HyperparameterValue
, -X- _ O
i.e. -X- _ O
, -X- _ O
selecting -X- _ O
the -X- _ O
top -X- _ O
20 -X- _ O
percentile -X- _ O
of -X- _ O
attention -X- _ O
scores -X- _ O
to -X- _ O
compare -X- _ O
with -X- _ O
ground -X- _ O
truth -X- _ O
rationales -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
ERASER -X- _ O
benchmark -X- _ O
has -X- _ O
an -X- _ O
average -X- _ O
ratio -X- _ O
of -X- _ O
rationale -X- _ O
tokens -X- _ O
to -X- _ O
document -X- _ O
tokens -X- _ O
of -X- _ O
around -X- _ O
9.4 -X- _ O
% -X- _ O
, -X- _ O
we -X- _ O
allowed -X- _ O
rationale -X- _ B-HyperparameterName
selection -X- _ I-HyperparameterName
to -X- _ O
be -X- _ O
two -X- _ O
times -X- _ O
the -X- _ O
average -X- _ O
ratio -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
20%).For -X- _ B-HyperparameterValue
InvRat -X- _ B-MethodName
, -X- _ O
we -X- _ O
opted -X- _ O
for -X- _ O
300 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
dimensional -X- _ I-HyperparameterValue
GloVe -X- _ B-HyperparameterName
embeddings -X- _ I-HyperparameterName
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
generator -X- _ O
and -X- _ O
the -X- _ O
predictor -X- _ O
modules -X- _ O
of -X- _ O
InvRat -X- _ B-MethodName
were -X- _ O
based -X- _ O
on -X- _ O
1 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
layer -X- _ I-HyperparameterValue
bidirectional -X- _ B-HyperparameterName
gated -X- _ I-HyperparameterName
recurrent -X- _ I-HyperparameterName
units -X- _ I-HyperparameterName
( -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
with -X- _ O
256 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
as -X- _ O
in -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Maximum -X- _ B-HyperparameterName
model -X- _ I-HyperparameterName
input -X- _ I-HyperparameterName
was -X- _ O
set -X- _ O
to -X- _ O
1,024 -X- _ B-HyperparameterValue
tokens -X- _ I-HyperparameterValue
. -X- _ O
All -X- _ O
hyperparameters -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
were -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
This -X- _ O
section -X- _ O
reports -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
Rationale -X- _ B-MethodName
LAMOL -X- _ I-MethodName
and -X- _ O
compares -X- _ O
it -X- _ O
with -X- _ O
LAMOL -X- _ B-MethodName
as -X- _ O
the -X- _ O
baseline -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
multitask -X- _ B-TaskName
learning -X- _ I-TaskName
, -X- _ O
which -X- _ O
is -X- _ O
considered -X- _ O
as -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
LL -X- _ B-TaskName
. -X- _ O
We -X- _ O
also -X- _ O
analyze -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
in -X- _ O
the -X- _ O
proposed -X- _ O
framework -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
validate -X- _ O
if -X- _ O
component -X- _ O
freezing -X- _ O
truly -X- _ O
helps -X- _ O
reduce -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
, -X- _ O
we -X- _ O
performed -X- _ O
partial -X- _ O
brute -X- _ O
force -X- _ O
block -X- _ O
- -X- _ O
level -X- _ O
freezing -X- _ O
on -X- _ O
each -X- _ O
task -X- _ O
permutation -X- _ O
to -X- _ O
approximately -X- _ O
determine -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
our -X- _ O
Rationale -X- _ B-MethodName
LAMOL -X- _ I-MethodName
block -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
limited -X- _ O
computing -X- _ O
resources -X- _ O
, -X- _ O
we -X- _ O
compromised -X- _ O
with -X- _ O
searching -X- _ O
for -X- _ O
all -X- _ O
even -X- _ O
- -X- _ O
numbered -X- _ O
block -X- _ O
indices -X- _ O
, -X- _ O
and -X- _ O
choosing -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
maximum -X- _ O
average -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
tasks -X- _ O
to -X- _ O
do -X- _ O
the -X- _ O
brute -X- _ O
force -X- _ O
on -X- _ O
the -X- _ O
latter -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O
Since -X- _ O
brute -X- _ O
force -X- _ O
was -X- _ O
performed -X- _ O
on -X- _ O
a -X- _ O
per -X- _ O
- -X- _ O
task -X- _ O
basis -X- _ O
, -X- _ O
our -X- _ O
search -X- _ O
space -X- _ O
would -X- _ O
be -X- _ O
6 -X- _ O
+ -X- _ O
6 -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
six -X- _ O
being -X- _ O
the -X- _ O
six -X- _ O
blocks -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
latter -X- _ O
six -X- _ O
being -X- _ O
the -X- _ O
six -X- _ O
blocks -X- _ O
on -X- _ O
the -X- _ O
last -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O
Do -X- _ O
note -X- _ O
that -X- _ O
true -X- _ O
brute -X- _ O
force -X- _ O
would -X- _ O
be -X- _ O
12×12 -X- _ O
. -X- _ O
Although -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
our -X- _ O
partial -X- _ O
brute -X- _ O
force -X- _ O
is -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
good -X- _ O
compromise -X- _ O
due -X- _ O
to -X- _ O
limited -X- _ O
computing -X- _ O
resources -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
Brute -X- _ O
force -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
outperform -X- _ O
vanilla -X- _ O
LAMOL -X- _ B-MethodName
by -X- _ O
a -X- _ O
substantial -X- _ O
margin -X- _ O
of -X- _ O
3.68 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
only -X- _ O
1.36 -X- _ B-MetricValue
% -X- _ I-MetricValue
from -X- _ O
the -X- _ O
multitask -X- _ O
upper -X- _ O
bound -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
component -X- _ O
freezing -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
further -X- _ O
nullify -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
from -X- _ O
LAMOL -X- _ B-MethodName
. -X- _ O
It -X- _ O
also -X- _ O
achieved -X- _ O
a -X- _ O
standard -X- _ O
deviation -X- _ O
of -X- _ O
only -X- _ O
2.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
compared -X- _ O
with -X- _ O
LAMOL -X- _ B-MethodName
's -X- _ O
5.28 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
freezing -X- _ O
the -X- _ O
right -X- _ O
component -X- _ O
helps -X- _ O
with -X- _ O
task -X- _ O
order -X- _ O
resilience -X- _ O
. -X- _ O
A -X- _ O
sample -X- _ O
of -X- _ O
accuracy -X- _ B-MetricName
graphs -X- _ O
( -X- _ O
as -X- _ O
the -X- _ O
learning -X- _ O
progressed -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
compared -X- _ O
methods -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
BoolQ -X- _ B-DatasetName
→ -X- _ O
SciFact -X- _ B-DatasetName
→ -X- _ O
Movies -X- _ B-DatasetName
( -X- _ O
BSM -X- _ O
) -X- _ O
task -X- _ O
order -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
from -X- _ O
top -X- _ O
to -X- _ O
bottom -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
first -X- _ O
task -X- _ O
, -X- _ O
BoolQ -X- _ B-DatasetName
was -X- _ O
not -X- _ O
really -X- _ O
affected -X- _ O
by -X- _ O
SciFact -X- _ B-DatasetName
, -X- _ O
but -X- _ O
encountered -X- _ O
a -X- _ O
heavy -X- _ O
drop -X- _ O
during -X- _ O
the -X- _ O
third -X- _ O
task -X- _ O
of -X- _ O
Movies -X- _ B-DatasetName
. -X- _ O
In -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
BoolQ -X- _ B-DatasetName
dropped -X- _ O
from -X- _ O
61 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
a -X- _ O
mere -X- _ O
6 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
while -X- _ O
only -X- _ O
rebounding -X- _ O
up -X- _ O
to -X- _ O
26 -X- _ B-MetricValue
% -X- _ I-MetricValue
at -X- _ O
the -X- _ O
end -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
after -X- _ O
freezing -X- _ O
the -X- _ O
most -X- _ O
plastic -X- _ O
block -X- _ O
identified -X- _ O
by -X- _ O
partial -X- _ O
brute -X- _ O
forcing -X- _ O
, -X- _ O
BoolQ -X- _ B-DatasetName
dropped -X- _ O
from -X- _ O
62 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
15 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
and -X- _ O
rebounding -X- _ O
up -X- _ O
to -X- _ O
47 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Comparatively -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
task -X- _ O
, -X- _ O
SciFact -X- _ B-DatasetName
encountered -X- _ O
a -X- _ O
smaller -X- _ O
drop -X- _ O
during -X- _ O
the -X- _ O
third -X- _ O
task -X- _ O
from -X- _ O
63 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
55 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
and -X- _ O
then -X- _ O
Green -X- _ O
background -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
epochs -X- _ O
on -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
first -X- _ O
introduced -X- _ O
with -X- _ O
a -X- _ O
particular -X- _ O
task -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
figure -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
Bool -X- _ B-DatasetName
- -X- _ I-DatasetName
Q -X- _ I-DatasetName
and -X- _ O
evaluated -X- _ O
on -X- _ O
all -X- _ O
the -X- _ O
three -X- _ O
tasks -X- _ O
during -X- _ O
epoch -X- _ O
1 -X- _ O
- -X- _ O
5 -X- _ O
. -X- _ O
rebounded -X- _ O
back -X- _ O
to -X- _ O
65 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
As -X- _ O
the -X- _ O
last -X- _ O
task -X- _ O
, -X- _ O
movies -X- _ B-DatasetName
was -X- _ O
not -X- _ O
affected -X- _ O
by -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
. -X- _ O
Accuracy -X- _ B-MetricName
graphs -X- _ O
for -X- _ O
all -X- _ O
permutation -X- _ O
of -X- _ O
tasks -X- _ O
is -X- _ O
available -X- _ O
in -X- _ O
Appendix -X- _ O
6 -X- _ O
from -X- _ O
which -X- _ O
we -X- _ O
make -X- _ O
several -X- _ O
observations -X- _ O
concerning -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
task -X- _ O
orders -X- _ O
on -X- _ O
the -X- _ O
overall -X- _ O
performance:• -X- _ O
There -X- _ O
is -X- _ O
evidence -X- _ O
that -X- _ O
Movies -X- _ B-DatasetName
accelerate -X- _ O
the -X- _ O
forgetting -X- _ O
process -X- _ O
of -X- _ O
first -X- _ O
task -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
abrupt -X- _ O
change -X- _ O
in -X- _ O
data -X- _ O
distribution.• -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
Movies -X- _ B-DatasetName
itself -X- _ O
is -X- _ O
barely -X- _ O
affected -X- _ O
by -X- _ O
the -X- _ O
task -X- _ O
order -X- _ O
. -X- _ O
We -X- _ O
attribute -X- _ O
it -X- _ O
to -X- _ O
the -X- _ O
low -X- _ O
difficulty -X- _ O
of -X- _ O
the -X- _ O
task.• -X- _ O
There -X- _ O
is -X- _ O
usually -X- _ O
no -X- _ O
interference -X- _ O
between -X- _ O
the -X- _ O
tasks -X- _ O
Bool -X- _ B-DatasetName
- -X- _ I-DatasetName
Q -X- _ I-DatasetName
and -X- _ O
SciFact -X- _ B-DatasetName
when -X- _ O
these -X- _ O
tasks -X- _ O
are -X- _ O
trained -X- _ O
in -X- _ O
adjacency -X- _ O
since -X- _ O
they -X- _ O
are -X- _ O
similar -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
unrealistic -X- _ O
to -X- _ O
perform -X- _ O
brute -X- _ O
force -X- _ O
in -X- _ O
every -X- _ O
single -X- _ O
setting -X- _ O
. -X- _ O
So -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
crucial -X- _ O
that -X- _ O
our -X- _ O
algorithm -X- _ O
uses -X- _ O
reasonable -X- _ O
amount -X- _ O
of -X- _ O
time -X- _ O
while -X- _ O
still -X- _ O
maintaining -X- _ O
improvements -X- _ O
from -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O
The -X- _ O
CCI -X- _ O
algorithm -X- _ O
requires -X- _ O
each -X- _ O
task -X- _ O
except -X- _ O
task -X- _ O
1 -X- _ O
to -X- _ O
be -X- _ O
repeated -X- _ O
twice -X- _ O
. -X- _ O
This -X- _ O
doubles -X- _ O
the -X- _ O
time -X- _ O
needed -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
single -X- _ O
task -X- _ O
. -X- _ O
Combined -X- _ O
with -X- _ O
time -X- _ O
required -X- _ O
for -X- _ O
CCI -X- _ O
, -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
required -X- _ O
approximately -X- _ O
2.4 -X- _ O
times -X- _ O
more -X- _ O
time -X- _ O
than -X- _ O
vanilla -X- _ O
LAMOL -X- _ B-MethodName
to -X- _ O
completely -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
our -X- _ O
algorithm -X- _ O
used -X- _ O
only -X- _ O
approximately -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
it -X- _ O
took -X- _ O
to -X- _ O
train -X- _ O
in -X- _ O
the -X- _ O
partial -X- _ O
brute -X- _ O
force -X- _ O
fashion -X- _ O
. -X- _ O
Currently -X- _ O
, -X- _ O
CCI -X- _ O
only -X- _ O
measures -X- _ O
plasticity -X- _ O
in -X- _ O
between -X- _ O
two -X- _ O
models -X- _ O
( -X- _ O
M -X- _ O
i -X- _ O
andM -X- _ O
i+1 -X- _ O
) -X- _ O
. -X- _ O
Single -X- _ O
model -X- _ O
analysis -X- _ O
for -X- _ O
layer -X- _ O
plasticity -X- _ O
evaluation -X- _ O
is -X- _ O
left -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
From -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
block -X- _ O
outperformed -X- _ O
LAMOL -X- _ B-MethodName
by -X- _ O
1.83 -X- _ B-MetricValue
% -X- _ I-MetricValue
average -X- _ O
accuracy -X- _ B-MetricName
( -X- _ O
0.97 -X- _ B-MetricValue
% -X- _ I-MetricValue
average -X- _ O
Macro -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
) -X- _ O
over -X- _ O
all -X- _ O
permutations -X- _ O
while -X- _ O
having -X- _ O
smaller -X- _ O
standard -X- _ O
deviation -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
also -X- _ O
more -X- _ O
robust -X- _ O
to -X- _ O
task -X- _ O
orders -X- _ O
. -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
head -X- _ O
was -X- _ O
able -X- _ O
to -X- _ O
match -X- _ O
or -X- _ O
outperform -X- _ O
LAMOL -X- _ B-MethodName
in -X- _ O
five -X- _ O
out -X- _ O
of -X- _ O
six -X- _ O
task -X- _ O
orders -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
significant -X- _ O
decrease -X- _ O
in -X- _ O
the -X- _ O
SBM -X- _ O
order -X- _ O
lowered -X- _ O
the -X- _ O
average -X- _ O
to -X- _ O
a -X- _ O
0.43 -X- _ B-MetricValue
% -X- _ I-MetricValue
gain -X- _ O
( -X- _ O
and -X- _ O
a -X- _ O
slight -X- _ O
decrease -X- _ O
in -X- _ O
Macro -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
) -X- _ O
from -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O
Upon -X- _ O
further -X- _ O
inspection -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
samples -X- _ O
of -X- _ O
SciFact -X- _ B-DatasetName
contained -X- _ O
high -X- _ O
variance -X- _ O
in -X- _ O
quality -X- _ O
during -X- _ O
pseudodata -X- _ O
replay -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
generation -X- _ O
token -X- _ O
mismatch -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
a -X- _ O
situation -X- _ O
where -X- _ O
a -X- _ O
pseudo -X- _ O
- -X- _ O
sample -X- _ O
has -X- _ O
an -X- _ O
answer -X- _ O
token -X- _ O
from -X- _ O
a -X- _ O
wrong -X- _ O
task -X- _ O
, -X- _ O
the -X- _ O
low -X- _ O
volume -X- _ O
of -X- _ O
SciFact -X- _ B-DatasetName
training -X- _ O
data -X- _ O
affected -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
pseudo -X- _ O
- -X- _ O
samples -X- _ O
generated -X- _ O
. -X- _ O
So -X- _ O
, -X- _ O
this -X- _ O
accelerated -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
rather -X- _ O
than -X- _ O
alleviating -X- _ O
. -X- _ O
Without -X- _ O
the -X- _ O
SBM -X- _ O
drop -X- _ O
, -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
head -X- _ O
performed -X- _ O
comparatively -X- _ O
well -X- _ O
or -X- _ O
slightly -X- _ O
higher -X- _ O
with -X- _ O
the -X- _ O
block -X- _ O
- -X- _ O
level -X- _ O
. -X- _ O
Performing -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
tailed -X- _ O
paired -X- _ O
ttest -X- _ O
on -X- _ O
all -X- _ O
data -X- _ O
points -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
3 -X- _ O
random -X- _ O
seeds -X- _ O
, -X- _ O
we -X- _ O
observed -X- _ O
that -X- _ O
block -X- _ O
- -X- _ O
level -X- _ O
freezing -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
win -X- _ O
against -X- _ O
the -X- _ O
original -X- _ O
LAMOL -X- _ B-MethodName
with -X- _ O
statistical -X- _ O
significance -X- _ O
( -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
of -X- _ O
0.023 -X- _ O
and -X- _ O
0.042 -X- _ O
for -X- _ O
block -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
generated -X- _ O
block -X- _ O
- -X- _ O
level -X- _ O
respectively -X- _ O
) -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
SBM -X- _ O
result -X- _ O
neglected -X- _ O
as -X- _ O
an -X- _ O
outlier -X- _ O
, -X- _ O
both -X- _ O
block -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
head -X- _ O
- -X- _ O
level -X- _ O
significantly -X- _ O
improved -X- _ O
the -X- _ O
results -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
LAMOL -X- _ B-MethodName
( -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
of -X- _ O
0.015 -X- _ O
, -X- _ O
0.014 -X- _ O
, -X- _ O
0.010 -X- _ O
, -X- _ O
0.049 -X- _ O
for -X- _ O
block -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
generated -X- _ O
block -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
head -X- _ O
- -X- _ O
level -X- _ O
, -X- _ O
and -X- _ O
generated -X- _ O
headlevel -X- _ O
respectively -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
conclusive -X- _ O
evidence -X- _ O
of -X- _ O
which -X- _ O
method -X- _ O
( -X- _ O
head -X- _ O
- -X- _ O
level -X- _ O
or -X- _ O
blocklevel -X- _ O
freezing -X- _ O
) -X- _ O
being -X- _ O
significantly -X- _ O
better -X- _ O
( -X- _ O
p -X- _ O
- -X- _ O
value -X- _ O
of -X- _ O
0.133 -X- _ O
) -X- _ O
. -X- _ O
Even -X- _ O
though -X- _ O
our -X- _ O
Rationale -X- _ B-MethodName
LAMOL -X- _ I-MethodName
outperformed -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
there -X- _ O
was -X- _ O
still -X- _ O
a -X- _ O
gap -X- _ O
from -X- _ O
the -X- _ O
brute -X- _ O
force -X- _ O
upper -X- _ O
bound -X- _ O
. -X- _ O
This -X- _ O
could -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
many -X- _ O
incompatibilities -X- _ O
between -X- _ O
human -X- _ O
rationales -X- _ O
and -X- _ O
machine -X- _ O
attention -X- _ O
scores -X- _ O
, -X- _ O
as -X- _ O
mentioned -X- _ O
in -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
made -X- _ O
our -X- _ O
algorithm -X- _ O
choose -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
layers -X- _ O
/ -X- _ O
heads -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
difference -X- _ O
in -X- _ O
focus -X- _ O
between -X- _ O
human -X- _ O
and -X- _ O
machines -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
conceivable -X- _ O
that -X- _ O
the -X- _ O
rationales -X- _ O
generated -X- _ O
by -X- _ O
InvRat -X- _ B-MethodName
would -X- _ O
be -X- _ O
mostly -X- _ O
misaligned -X- _ O
with -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
of -X- _ O
InvRat -X- _ B-MethodName
are -X- _ O
quite -X- _ O
low -X- _ O
when -X- _ O
compared -X- _ O
with -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
generated -X- _ O
rationales -X- _ O
output -X- _ O
by -X- _ B-MethodName
InvRat -X- _ I-MethodName
compared -X- _ O
with -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O
Despite -X- _ O
that -X- _ O
, -X- _ O
Generated -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
block -X- _ O
outperformed -X- _ O
both -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
and -X- _ O
LAMOL -X- _ B-MethodName
baseline -X- _ O
by -X- _ O
0.84 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
( -X- _ O
0.31 -X- _ B-MetricValue
% -X- _ I-MetricValue
Macro -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
) -X- _ O
and -X- _ O
2.67 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
( -X- _ O
1.27 -X- _ B-MetricValue
% -X- _ I-MetricValue
Macro -X- _ B-MetricName
- -X- _ I-MetricName
F1 -X- _ I-MetricName
) -X- _ O
respectively -X- _ O
, -X- _ O
further -X- _ O
reducing -X- _ O
the -X- _ O
gap -X- _ O
to -X- _ O
Brute -X- _ O
Force -X- _ O
, -X- _ O
the -X- _ O
approximate -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
CCI -X- _ O
. -X- _ O
This -X- _ O
suggests -X- _ O
that -X- _ O
rationales -X- _ O
chosen -X- _ O
by -X- _ O
InvRat -X- _ B-MethodName
, -X- _ O
regardless -X- _ O
of -X- _ O
how -X- _ O
nonsensical -X- _ O
they -X- _ O
appear -X- _ O
, -X- _ O
still -X- _ O
carry -X- _ O
information -X- _ O
that -X- _ O
eliminates -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
Bao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
who -X- _ O
showed -X- _ O
that -X- _ O
significant -X- _ O
gains -X- _ O
are -X- _ O
achieved -X- _ O
when -X- _ O
using -X- _ O
machines -X- _ O
attention -X- _ O
scores -X- _ O
as -X- _ O
an -X- _ O
additional -X- _ O
supervision -X- _ O
signal -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
human -X- _ O
rationales -X- _ O
. -X- _ O
Last -X- _ O
but -X- _ O
not -X- _ O
least -X- _ O
, -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
generating -X- _ O
rationales -X- _ O
using -X- _ O
InvRat -X- _ B-MethodName
, -X- _ O
including -X- _ O
training -X- _ O
and -X- _ O
inference -X- _ O
, -X- _ O
contributed -X- _ O
only -X- _ O
marginally -X- _ O
, -X- _ O
about -X- _ O
15 -X- _ O
minutes -X- _ O
, -X- _ O
to -X- _ O
the -X- _ O
total -X- _ O
time -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
To -X- _ O
effectively -X- _ O
retain -X- _ O
learned -X- _ O
knowledge -X- _ O
in -X- _ O
LL -X- _ B-TaskName
for -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
proposed -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
, -X- _ O
a -X- _ O
learning -X- _ O
framework -X- _ O
that -X- _ O
uses -X- _ O
rationales -X- _ O
to -X- _ O
identify -X- _ O
and -X- _ O
freeze -X- _ O
the -X- _ O
most -X- _ O
critical -X- _ O
components -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
while -X- _ O
being -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
showed -X- _ O
that -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
outperform -X- _ O
LAMOL -X- _ B-MethodName
by -X- _ O
a -X- _ O
significant -X- _ O
margin -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
our -X- _ O
framework -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
any -X- _ O
NLP -X- _ O
datasets -X- _ O
by -X- _ O
leveraging -X- _ O
unsupervised -X- _ O
rationale -X- _ O
generation -X- _ O
, -X- _ O
eliminating -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
human -X- _ O
rationales -X- _ O
while -X- _ O
maintaining -X- _ O
comparable -X- _ O
improvements -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
Rational -X- _ B-MethodName
LAMOL -X- _ I-MethodName
bridges -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
LL -X- _ B-TaskName
in -X- _ O
NLP -X- _ O
with -X- _ O
model -X- _ O
understanding -X- _ O
through -X- _ O
rationales -X- _ O
, -X- _ O
exhibiting -X- _ O
potential -X- _ O
for -X- _ O
a -X- _ O
true -X- _ O
lifelong -X- _ B-TaskName
language -X- _ I-TaskName
learning -X- _ I-TaskName
as -X- _ O
well -X- _ O
as -X- _ O
limiting -X- _ O
catastrophic -X- _ O
forgetting -X- _ O
. -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
and -X- _ O
the -X- _ O
9th -X- _ O
International -X- _ O
Joint -X- _ O
Conference -X- _ O
on -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
EMNLP -X- _ O
- -X- _ O
IJCNLP -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
4094 -X- _ O
- -X- _ O
4103 -X- _ O
, -X- _ O
Hong -X- _ O
Kong -X- _ O
, -X- _ O
China -X- _ O
. -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O
A -X- _ O
Learning -X- _ O
Curves -X- _ O
of -X- _ O
All -X- _ O
Task -X- _ O
Permutations -X- _ O

Active -X- _ O
learning -X- _ O
promises -X- _ O
to -X- _ O
alleviate -X- _ O
the -X- _ O
massive -X- _ O
data -X- _ O
needs -X- _ O
of -X- _ O
supervised -X- _ O
machine -X- _ O
learning -X- _ O
: -X- _ O
it -X- _ O
has -X- _ O
successfully -X- _ O
improved -X- _ O
sample -X- _ O
efficiency -X- _ O
by -X- _ O
an -X- _ O
order -X- _ O
of -X- _ O
magnitude -X- _ O
on -X- _ O
traditional -X- _ O
tasks -X- _ O
like -X- _ O
topic -X- _ O
classification -X- _ O
and -X- _ O
object -X- _ O
recognition -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
uncover -X- _ O
a -X- _ O
striking -X- _ O
contrast -X- _ O
to -X- _ O
this -X- _ O
promise -X- _ O
: -X- _ O
across -X- _ O
5 -X- _ O
models -X- _ O
and -X- _ O
4 -X- _ O
datasets -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
visual -X- _ B-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
, -X- _ O
a -X- _ O
wide -X- _ O
variety -X- _ O
of -X- _ O
active -X- _ O
learning -X- _ O
approaches -X- _ O
fail -X- _ O
to -X- _ O
outperform -X- _ O
random -X- _ O
selection -X- _ O
. -X- _ O
To -X- _ O
understand -X- _ O
this -X- _ O
discrepancy -X- _ O
, -X- _ O
we -X- _ O
profile -X- _ O
8 -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
on -X- _ O
a -X- _ O
per -X- _ O
- -X- _ O
example -X- _ O
basis -X- _ O
, -X- _ O
and -X- _ O
identify -X- _ O
the -X- _ O
problem -X- _ O
as -X- _ O
collective -X- _ O
outliers -X- _ O
-groups -X- _ O
of -X- _ O
examples -X- _ O
that -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
prefer -X- _ O
to -X- _ O
acquire -X- _ O
but -X- _ O
models -X- _ O
fail -X- _ O
to -X- _ O
learn -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
questions -X- _ O
that -X- _ O
ask -X- _ O
about -X- _ O
text -X- _ O
in -X- _ O
images -X- _ O
or -X- _ O
require -X- _ O
external -X- _ O
knowledge -X- _ O
) -X- _ O
. -X- _ O
Through -X- _ O
systematic -X- _ O
ablation -X- _ O
experiments -X- _ O
and -X- _ O
qualitative -X- _ O
visualizations -X- _ O
, -X- _ O
we -X- _ O
verify -X- _ O
that -X- _ O
collective -X- _ O
outliers -X- _ O
are -X- _ O
a -X- _ O
general -X- _ O
phenomenon -X- _ O
responsible -X- _ O
for -X- _ O
degrading -X- _ O
pool -X- _ O
- -X- _ O
based -X- _ O
active -X- _ O
learning -X- _ O
. -X- _ O
Notably -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
active -X- _ O
learning -X- _ O
sample -X- _ O
efficiency -X- _ O
increases -X- _ O
significantly -X- _ O
as -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
collective -X- _ O
outliers -X- _ O
in -X- _ O
the -X- _ O
active -X- _ O
learning -X- _ O
pool -X- _ O
decreases -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
with -X- _ O
a -X- _ O
discussion -X- _ O
and -X- _ O
prescriptive -X- _ O
recommendations -X- _ O
for -X- _ O
mitigating -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
these -X- _ O
outliers -X- _ O
in -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Today -X- _ O
, -X- _ O
language -X- _ O
- -X- _ O
equipped -X- _ O
vision -X- _ O
systems -X- _ O
such -X- _ O
as -X- _ O
VizWiz -X- _ O
, -X- _ O
TapTapSee -X- _ O
, -X- _ O
BeMyEyes -X- _ O
, -X- _ O
and -X- _ O
CamFind -X- _ O
are -X- _ O
actively -X- _ O
being -X- _ O
deployed -X- _ O
across -X- _ O
a -X- _ O
broad -X- _ O
spectrum -X- _ O
of -X- _ O
users -X- _ O
. -X- _ O
1 -X- _ O
As -X- _ O
underlying -X- _ O
methods -X- _ O
improve -X- _ O
, -X- _ O
these -X- _ O
systems -X- _ O
will -X- _ O
be -X- _ O
expected -X- _ O
to -X- _ O
operate -X- _ O
over -X- _ O
diverse -X- _ O
visual -X- _ O
environments -X- _ O
and -X- _ O
understand -X- _ O
myriad -X- _ O
language -X- _ O
inputs -X- _ O
( -X- _ O
Bigham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010;Tellex -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011;Mei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Anderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b;Park -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Visual -X- _ B-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
( -X- _ O
VQA -X- _ B-TaskName
) -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
answering -X- _ O
questions -X- _ O
about -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
We -X- _ O
systematically -X- _ O
evaluate -X- _ O
active -X- _ O
learning -X- _ O
on -X- _ O
VQA -X- _ B-TaskName
datasets -X- _ O
and -X- _ O
isolate -X- _ O
their -X- _ O
inability -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
random -X- _ O
sampling -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
collective -X- _ O
outliers -X- _ O
. -X- _ O
Active -X- _ O
learning -X- _ O
methods -X- _ O
prefer -X- _ O
to -X- _ O
acquire -X- _ O
these -X- _ O
outliers -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
hard -X- _ O
and -X- _ O
often -X- _ O
impossible -X- _ O
for -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
Dataset -X- _ O
Maps -X- _ O
, -X- _ O
like -X- _ O
the -X- _ O
one -X- _ O
shown -X- _ O
here -X- _ O
, -X- _ O
can -X- _ O
heuristically -X- _ O
identify -X- _ O
these -X- _ O
collective -X- _ O
outliers -X- _ O
as -X- _ O
examples -X- _ O
assigned -X- _ O
low -X- _ O
model -X- _ O
confidence -X- _ O
and -X- _ O
prediction -X- _ O
variability -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
visual -X- _ O
inputs -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
popular -X- _ O
benchmark -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
progress -X- _ O
towards -X- _ O
such -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
systems -X- _ O
( -X- _ O
Agrawal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Gordon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Hudson -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
today -X- _ O
's -X- _ O
VQA -X- _ B-TaskName
models -X- _ O
are -X- _ O
data -X- _ O
hungry -X- _ O
: -X- _ O
Their -X- _ O
performance -X- _ O
scales -X- _ O
monotonically -X- _ O
with -X- _ O
more -X- _ O
train -X- _ O
- -X- _ O
ing -X- _ O
data -X- _ O
( -X- _ O
Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Lin -X- _ O
and -X- _ O
Parikh -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
motivating -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
data -X- _ O
acquisition -X- _ O
mechanisms -X- _ O
such -X- _ O
as -X- _ O
active -X- _ O
learning -X- _ O
, -X- _ O
which -X- _ O
maximize -X- _ O
performance -X- _ O
while -X- _ O
minimizing -X- _ O
expensive -X- _ O
data -X- _ O
labeling -X- _ O
. -X- _ O
While -X- _ O
active -X- _ O
learning -X- _ O
is -X- _ O
often -X- _ O
key -X- _ O
to -X- _ O
effective -X- _ O
data -X- _ O
acquisition -X- _ O
when -X- _ O
such -X- _ O
labeled -X- _ O
data -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
obtain -X- _ O
( -X- _ O
Lewis -X- _ O
and -X- _ O
Catlett -X- _ O
, -X- _ O
1994;Tong -X- _ O
and -X- _ O
Koller -X- _ O
, -X- _ O
2001;Culotta -X- _ O
and -X- _ O
McCallum -X- _ O
, -X- _ O
2005;Settles -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
8 -X- _ O
modern -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
Siddhant -X- _ O
and -X- _ O
Lipton -X- _ O
, -X- _ O
2018;Lowell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
show -X- _ O
little -X- _ O
to -X- _ O
no -X- _ O
improvement -X- _ O
in -X- _ O
sample -X- _ O
efficiency -X- _ O
across -X- _ O
5 -X- _ O
models -X- _ O
on -X- _ O
4 -X- _ O
VQA -X- _ B-TaskName
datasets -X- _ O
-indeed -X- _ O
, -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
performing -X- _ O
worse -X- _ O
than -X- _ O
randomly -X- _ O
selecting -X- _ O
data -X- _ O
to -X- _ O
label -X- _ O
. -X- _ O
This -X- _ O
finding -X- _ O
is -X- _ O
in -X- _ O
stark -X- _ O
contrast -X- _ O
to -X- _ O
the -X- _ O
successful -X- _ O
application -X- _ O
of -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
on -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
traditional -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
topic -X- _ O
classification -X- _ O
( -X- _ O
Siddhant -X- _ O
and -X- _ O
Lipton -X- _ O
, -X- _ O
2018;Lowell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
object -X- _ O
recognition -X- _ O
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
digit -X- _ O
classification -X- _ O
, -X- _ O
and -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
negative -X- _ O
results -X- _ O
hold -X- _ O
even -X- _ O
when -X- _ O
accounting -X- _ O
for -X- _ O
common -X- _ O
active -X- _ O
learning -X- _ O
ailments -X- _ O
: -X- _ O
cold -X- _ O
starts -X- _ O
, -X- _ O
correlated -X- _ O
sampling -X- _ O
, -X- _ O
and -X- _ O
uncalibrated -X- _ O
uncertainty -X- _ O
. -X- _ O
We -X- _ O
mitigate -X- _ O
the -X- _ O
cold -X- _ O
start -X- _ O
challenge -X- _ O
of -X- _ O
needing -X- _ O
a -X- _ O
representative -X- _ O
initial -X- _ O
dataset -X- _ O
by -X- _ O
varying -X- _ O
the -X- _ O
size -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
seed -X- _ I-HyperparameterName
set -X- _ I-HyperparameterName
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
We -X- _ O
account -X- _ O
for -X- _ O
sampling -X- _ O
correlated -X- _ O
data -X- _ O
within -X- _ O
a -X- _ O
given -X- _ O
batch -X- _ O
by -X- _ O
including -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
selection -X- _ O
( -X- _ O
Sener -X- _ O
and -X- _ O
Savarese -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
we -X- _ O
evaluate -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
deep -X- _ B-MethodName
Bayesian -X- _ I-MethodName
active -X- _ I-MethodName
learning -X- _ I-MethodName
to -X- _ O
calibrate -X- _ O
model -X- _ O
uncertainty -X- _ O
to -X- _ O
high -X- _ O
- -X- _ O
dimensional -X- _ O
data -X- _ O
( -X- _ O
Houlsby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011;Gal -X- _ O
and -X- _ O
Ghahramani -X- _ O
, -X- _ O
2016;.After -X- _ O
concluding -X- _ O
that -X- _ O
negative -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
across -X- _ O
all -X- _ O
experimental -X- _ O
conditions -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
active -X- _ O
learning -X- _ O
's -X- _ O
ineffectiveness -X- _ O
on -X- _ O
VQA -X- _ B-TaskName
as -X- _ O
a -X- _ O
data -X- _ O
problem -X- _ O
and -X- _ O
identify -X- _ O
the -X- _ O
existence -X- _ O
of -X- _ O
collective -X- _ O
outliers -X- _ O
( -X- _ O
Han -X- _ O
and -X- _ O
Kamber -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
the -X- _ O
problem -X- _ O
. -X- _ O
Leveraging -X- _ O
recent -X- _ O
advances -X- _ O
in -X- _ O
model -X- _ O
interpretability -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
Dataset -X- _ O
Maps -X- _ O
, -X- _ O
which -X- _ O
distinguish -X- _ O
between -X- _ O
collective -X- _ O
outliers -X- _ O
and -X- _ O
useful -X- _ O
data -X- _ O
that -X- _ O
improve -X- _ O
validation -X- _ O
set -X- _ O
performance -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
global -X- _ O
outliers -X- _ O
deviate -X- _ O
from -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
and -X- _ O
are -X- _ O
often -X- _ O
a -X- _ O
consequence -X- _ O
of -X- _ O
labeling -X- _ O
error -X- _ O
, -X- _ O
collective -X- _ O
outliers -X- _ O
cluster -X- _ O
together -X- _ O
; -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
individually -X- _ O
be -X- _ O
identifiable -X- _ O
as -X- _ O
outliers -X- _ O
but -X- _ O
collectively -X- _ O
deviate -X- _ O
from -X- _ O
other -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
VQA-2 -X- _ B-DatasetName
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
riddled -X- _ O
with -X- _ O
collections -X- _ O
of -X- _ O
hard -X- _ O
questions -X- _ O
that -X- _ O
require -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
answer -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
What -X- _ O
is -X- _ O
the -X- _ O
symbol -X- _ O
on -X- _ O
the -X- _ O
hood -X- _ O
often -X- _ O
associated -X- _ O
with -X- _ O
? -X- _ O
" -X- _ O
) -X- _ O
or -X- _ O
that -X- _ O
ask -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
read -X- _ O
text -X- _ O
in -X- _ O
the -X- _ O
images -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
What -X- _ O
is -X- _ O
the -X- _ O
word -X- _ O
on -X- _ O
the -X- _ O
wall -X- _ O
? -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
GQA -X- _ B-DatasetName
( -X- _ O
Hudson -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
asks -X- _ O
underspecified -X- _ O
questions -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
person -X- _ O
wearing -X- _ O
? -X- _ O
" -X- _ O
which -X- _ O
can -X- _ O
have -X- _ O
multiple -X- _ O
correct -X- _ O
answers -X- _ O
) -X- _ O
. -X- _ O
Collective -X- _ O
outliers -X- _ O
are -X- _ O
not -X- _ O
specific -X- _ O
to -X- _ O
VQA -X- _ B-TaskName
, -X- _ O
but -X- _ O
can -X- _ O
similarly -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
many -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
visual -X- _ O
navigation -X- _ O
( -X- _ O
Anderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
Go -X- _ O
to -X- _ O
the -X- _ O
grandfather -X- _ O
clock -X- _ O
" -X- _ O
requires -X- _ O
identifying -X- _ O
rare -X- _ O
grandfather -X- _ O
clocks -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
open -X- _ O
- -X- _ O
domain -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
Kwiatkowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
amongst -X- _ O
others -X- _ O
. -X- _ O
Using -X- _ O
Dataset -X- _ O
Maps -X- _ O
, -X- _ O
we -X- _ O
profile -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
they -X- _ O
prefer -X- _ O
acquiring -X- _ O
collective -X- _ O
outliers -X- _ O
that -X- _ O
models -X- _ O
are -X- _ O
unable -X- _ O
to -X- _ O
learn -X- _ O
, -X- _ O
explaining -X- _ O
their -X- _ O
poor -X- _ O
improvements -X- _ O
in -X- _ O
sample -X- _ O
efficiency -X- _ O
relative -X- _ O
to -X- _ O
random -X- _ O
sampling -X- _ O
. -X- _ O
Building -X- _ O
on -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
these -X- _ O
maps -X- _ O
to -X- _ O
perform -X- _ O
ablations -X- _ O
where -X- _ O
we -X- _ O
identify -X- _ O
and -X- _ O
remove -X- _ O
outliers -X- _ O
iteratively -X- _ O
from -X- _ O
the -X- _ O
active -X- _ O
learning -X- _ O
pool -X- _ O
, -X- _ O
observing -X- _ O
correlated -X- _ O
improvements -X- _ O
in -X- _ O
sample -X- _ O
efficiency -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
conclude -X- _ O
that -X- _ O
collective -X- _ O
outliers -X- _ O
are -X- _ O
, -X- _ O
indeed -X- _ O
, -X- _ O
responsible -X- _ O
for -X- _ O
the -X- _ O
ineffectiveness -X- _ O
of -X- _ O
active -X- _ O
learning -X- _ O
for -X- _ O
VQA -X- _ B-TaskName
. -X- _ O
We -X- _ O
end -X- _ O
with -X- _ O
prescriptive -X- _ O
suggestions -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
in -X- _ O
building -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
robust -X- _ O
to -X- _ O
these -X- _ O
types -X- _ O
of -X- _ O
outliers -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
tests -X- _ O
the -X- _ O
utility -X- _ O
of -X- _ O
multiple -X- _ O
recent -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
understanding -X- _ O
task -X- _ O
of -X- _ O
VQA -X- _ B-TaskName
. -X- _ O
We -X- _ O
draw -X- _ O
on -X- _ O
the -X- _ O
dataset -X- _ O
analysis -X- _ O
literature -X- _ O
to -X- _ O
identify -X- _ O
collective -X- _ O
outliers -X- _ O
as -X- _ O
the -X- _ O
bottleneck -X- _ O
hindering -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
in -X- _ O
this -X- _ O
setting -X- _ O
. -X- _ O
Active -X- _ O
Learning -X- _ O
. -X- _ O
Active -X- _ O
learning -X- _ O
strategies -X- _ O
have -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
to -X- _ O
image -X- _ O
recognition -X- _ O
( -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009;Sener -X- _ O
and -X- _ O
Savarese -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
information -X- _ O
extraction -X- _ O
( -X- _ O
Scheffer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2001;Finn -X- _ O
and -X- _ O
Kushmerick -X- _ O
, -X- _ O
2003;Jones -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003;Culotta -X- _ O
and -X- _ O
McCallum -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
( -X- _ O
Hachey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005;Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
semantic -X- _ O
parsing -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
text -X- _ O
categorization -X- _ O
( -X- _ O
Lewis -X- _ O
and -X- _ O
Gale -X- _ O
, -X- _ O
1994;Hoi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
same -X- _ O
methods -X- _ O
struggle -X- _ O
to -X- _ O
outperform -X- _ O
a -X- _ O
random -X- _ O
baseline -X- _ O
when -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
VQA -X- _ B-TaskName
( -X- _ O
Lin -X- _ O
and -X- _ O
Parikh -X- _ O
, -X- _ O
2017;Jedoui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
study -X- _ O
this -X- _ O
discrepancy -X- _ O
, -X- _ O
we -X- _ O
systematically -X- _ O
apply -X- _ O
8 -X- _ O
diverse -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
to -X- _ O
VQA -X- _ B-TaskName
, -X- _ O
including -X- _ O
methods -X- _ O
that -X- _ O
use -X- _ O
model -X- _ B-MethodName
uncertainty -X- _ I-MethodName
( -X- _ O
Abramson -X- _ O
and -X- _ O
Freund -X- _ O
, -X- _ O
2004;Collins -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008;Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
Bayesian -X- _ B-MethodName
uncertainty -X- _ I-MethodName
( -X- _ O
Gal -X- _ O
and -X- _ O
Ghahramani -X- _ O
, -X- _ O
2016;Kendall -X- _ O
and -X- _ O
Gal -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
disagreement -X- _ O
( -X- _ O
Houlsby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
, -X- _ O
and -X- _ O
Core -X- _ B-MethodName
- -X- _ I-MethodName
Set -X- _ I-MethodName
selection -X- _ O
( -X- _ O
Sener -X- _ O
and -X- _ O
Savarese -X- _ O
, -X- _ O
2018).Visual -X- _ B-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
. -X- _ O
Progress -X- _ O
on -X- _ O
VQA -X- _ B-TaskName
has -X- _ O
been -X- _ O
heralded -X- _ O
as -X- _ O
a -X- _ O
marker -X- _ O
for -X- _ O
progress -X- _ O
on -X- _ O
general -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
understanding -X- _ O
tasks -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
several -X- _ O
benchmarks -X- _ O
( -X- _ O
Agrawal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Malinowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015a;Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Suhr -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Hudson -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
models -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Fukui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Lu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Anderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a;Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019;Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
ensure -X- _ O
that -X- _ O
our -X- _ O
negative -X- _ O
results -X- _ O
are -X- _ O
not -X- _ O
dataset -X- _ O
or -X- _ O
model -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
we -X- _ O
sample -X- _ O
4 -X- _ O
datasets -X- _ O
and -X- _ O
5 -X- _ O
representative -X- _ O
models -X- _ O
, -X- _ O
each -X- _ O
utilizing -X- _ O
unique -X- _ O
visual -X- _ O
and -X- _ O
linguistic -X- _ O
features -X- _ O
and -X- _ O
employing -X- _ O
different -X- _ O
inductive -X- _ O
biases -X- _ O
. -X- _ O
Interpreting -X- _ O
and -X- _ O
Analyzing -X- _ O
Datasets -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
prevalence -X- _ O
of -X- _ O
large -X- _ O
datasets -X- _ O
in -X- _ O
modern -X- _ O
machine -X- _ O
learning -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
critical -X- _ O
to -X- _ O
assess -X- _ O
dataset -X- _ O
properties -X- _ O
to -X- _ O
remove -X- _ O
redundancies -X- _ O
( -X- _ O
Gururangan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Li -X- _ O
and -X- _ O
Vasconcelos -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
biases -X- _ O
( -X- _ O
Torralba -X- _ O
and -X- _ O
Efros -X- _ O
, -X- _ O
2011;Khosla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012;Bolukbasi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
both -X- _ O
of -X- _ O
which -X- _ O
negatively -X- _ O
impact -X- _ O
sample -X- _ O
efficiency -X- _ O
. -X- _ O
Prior -X- _ O
work -X- _ O
has -X- _ O
used -X- _ O
training -X- _ O
dynamics -X- _ O
to -X- _ O
find -X- _ O
examples -X- _ O
which -X- _ O
are -X- _ O
frequently -X- _ O
forgotten -X- _ O
( -X- _ O
Krymolowski -X- _ O
, -X- _ O
2002;Toneva -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
versus -X- _ O
those -X- _ O
that -X- _ O
are -X- _ O
easy -X- _ O
to -X- _ O
learn -X- _ O
( -X- _ O
Bras -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
suggests -X- _ O
using -X- _ O
two -X- _ O
model -X- _ O
- -X- _ O
specific -X- _ O
measures -X- _ O
confidence -X- _ O
and -X- _ O
prediction -X- _ O
variance -X- _ O
-as -X- _ O
indicators -X- _ O
of -X- _ O
a -X- _ O
training -X- _ O
example -X- _ O
's -X- _ O
" -X- _ O
learnability -X- _ O
" -X- _ O
( -X- _ O
Chang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
. -X- _ O
Dataset -X- _ O
Maps -X- _ O
, -X- _ O
a -X- _ O
recently -X- _ O
introduced -X- _ O
framework -X- _ O
uses -X- _ O
these -X- _ O
two -X- _ O
measures -X- _ O
to -X- _ O
profile -X- _ O
datasets -X- _ O
to -X- _ O
find -X- _ O
learnable -X- _ O
examples -X- _ O
. -X- _ O
Unlike -X- _ O
prior -X- _ O
datasets -X- _ O
analyzed -X- _ O
by -X- _ O
Dataset -X- _ O
Maps -X- _ O
that -X- _ O
have -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
global -X- _ O
outliers -X- _ O
as -X- _ O
hard -X- _ O
examples -X- _ O
, -X- _ O
we -X- _ O
discover -X- _ O
that -X- _ O
VQA -X- _ B-TaskName
datasets -X- _ O
contain -X- _ O
copious -X- _ O
amounts -X- _ O
of -X- _ O
collective -X- _ O
outliers -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
difficult -X- _ O
or -X- _ O
even -X- _ O
impossible -X- _ O
for -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
standard -X- _ O
pool -X- _ O
- -X- _ O
based -X- _ O
active -X- _ O
learning -X- _ O
setup -X- _ O
from -X- _ O
prior -X- _ O
work -X- _ O
( -X- _ O
Lewis -X- _ O
and -X- _ O
Gale -X- _ O
, -X- _ O
1994;Settles -X- _ O
, -X- _ O
2009;Lin -X- _ O
and -X- _ O
Parikh -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
consisting -X- _ O
of -X- _ O
a -X- _ O
model -X- _ O
M -X- _ O
, -X- _ O
initial -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
of -X- _ O
labeled -X- _ O
examples -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
y -X- _ O
i -X- _ O
) -X- _ O
∈ -X- _ O
D -X- _ O
seed -X- _ O
used -X- _ O
to -X- _ O
initialize -X- _ O
M -X- _ O
, -X- _ O
an -X- _ O
unlabeled -X- _ O
pool -X- _ O
of -X- _ O
data -X- _ O
D -X- _ O
pool -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
acquisition -X- _ O
function -X- _ O
A(x -X- _ O
, -X- _ O
M -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
run -X- _ O
active -X- _ O
learning -X- _ O
over -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
acquisition -X- _ O
iterations -X- _ O
T -X- _ O
where -X- _ O
at -X- _ O
each -X- _ O
iteration -X- _ O
we -X- _ O
acquire -X- _ O
a -X- _ O
batch -X- _ O
of -X- _ O
B -X- _ O
new -X- _ O
examples -X- _ O
per -X- _ O
:x -X- _ O
∈ -X- _ O
D -X- _ O
pool -X- _ O
to -X- _ O
label -X- _ O
per -X- _ O
x -X- _ O
= -X- _ O
arg -X- _ O
max -X- _ O
x∈D -X- _ O
pool -X- _ O
A(x -X- _ O
, -X- _ O
M).Acquiring -X- _ O
an -X- _ O
example -X- _ O
often -X- _ O
refers -X- _ O
to -X- _ O
using -X- _ O
an -X- _ O
oracle -X- _ O
or -X- _ O
human -X- _ O
expert -X- _ O
to -X- _ O
annotate -X- _ O
a -X- _ O
new -X- _ O
example -X- _ O
with -X- _ O
a -X- _ O
correct -X- _ O
label -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
prior -X- _ O
work -X- _ O
to -X- _ O
simulate -X- _ O
an -X- _ O
oracle -X- _ O
using -X- _ O
existing -X- _ O
datasets -X- _ O
, -X- _ O
forming -X- _ O
D -X- _ O
seed -X- _ O
from -X- _ O
a -X- _ O
fixed -X- _ O
percentage -X- _ O
of -X- _ O
the -X- _ O
full -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
using -X- _ O
the -X- _ O
remainder -X- _ O
as -X- _ O
D -X- _ O
pool -X- _ O
Lin -X- _ O
and -X- _ O
Parikh -X- _ O
, -X- _ O
2017;Siddhant -X- _ O
and -X- _ O
Lipton -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
re -X- _ O
- -X- _ O
train -X- _ O
M -X- _ O
after -X- _ O
each -X- _ O
acquisition -X- _ O
iteration -X- _ O
. -X- _ O
Prior -X- _ O
work -X- _ O
has -X- _ O
noted -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
on -X- _ O
active -X- _ O
learning -X- _ O
performance -X- _ O
( -X- _ O
Lin -X- _ O
and -X- _ O
Parikh -X- _ O
, -X- _ O
2017;Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Jedoui -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
run -X- _ O
multiple -X- _ O
active -X- _ O
learning -X- _ O
evaluations -X- _ O
with -X- _ O
varying -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
sizes -X- _ I-HyperparameterName
( -X- _ O
ranging -X- _ O
from -X- _ O
5 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
to -X- _ I-HyperparameterValue
50 -X- _ I-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
full -X- _ I-HyperparameterValue
pool -X- _ I-HyperparameterValue
size -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O
We -X- _ O
keep -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
each -X- _ O
acquisition -X- _ O
batch -X- _ B-HyperparameterName
B -X- _ I-HyperparameterName
to -X- _ O
a -X- _ O
constant -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
overall -X- _ I-HyperparameterValue
pool -X- _ I-HyperparameterValue
size -X- _ I-HyperparameterValue
. -X- _ O
Visual -X- _ B-TaskName
Question -X- _ I-TaskName
Answering -X- _ I-TaskName
( -X- _ O
VQA -X- _ B-TaskName
) -X- _ O
requires -X- _ O
reasoning -X- _ O
over -X- _ O
two -X- _ O
modalities -X- _ O
: -X- _ O
images -X- _ O
and -X- _ O
text -X- _ O
. -X- _ O
Most -X- _ O
models -X- _ O
use -X- _ O
feature -X- _ O
" -X- _ O
backbones -X- _ O
" -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
features -X- _ O
from -X- _ O
object -X- _ O
recognition -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
Ima -X- _ O
- -X- _ O
geNet -X- _ O
, -X- _ O
and -X- _ O
pretrained -X- _ O
word -X- _ O
vectors -X- _ O
for -X- _ O
text -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
image -X- _ O
features -X- _ O
we -X- _ O
use -X- _ O
grid -X- _ O
- -X- _ O
based -X- _ O
features -X- _ O
from -X- _ O
ResNet-101 -X- _ O
, -X- _ O
or -X- _ O
object -X- _ O
- -X- _ O
based -X- _ O
features -X- _ O
from -X- _ O
Faster -X- _ O
R -X- _ O
- -X- _ O
CNN -X- _ O
( -X- _ O
Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015b -X- _ O
) -X- _ O
finetuned -X- _ O
on -X- _ O
Visual -X- _ O
Genome -X- _ O
( -X- _ O
Anderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
with -X- _ O
a -X- _ O
representative -X- _ O
sample -X- _ O
of -X- _ O
existing -X- _ O
VQA -X- _ B-TaskName
models -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
following -X- _ O
: -X- _ O
2LogReg -X- _ B-MethodName
is -X- _ O
a -X- _ O
logistic -X- _ O
regression -X- _ O
model -X- _ O
that -X- _ O
uses -X- _ O
either -X- _ O
ResNet-101 -X- _ O
or -X- _ O
Faster -X- _ O
R -X- _ O
- -X- _ O
CNN -X- _ O
image -X- _ O
features -X- _ O
with -X- _ O
mean -X- _ O
- -X- _ O
pooled -X- _ O
GloVe -X- _ O
question -X- _ O
embeddings -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
these -X- _ O
models -X- _ O
are -X- _ O
not -X- _ O
as -X- _ O
performant -X- _ O
as -X- _ O
the -X- _ O
subsequent -X- _ O
models -X- _ O
, -X- _ O
logistic -X- _ O
regression -X- _ O
has -X- _ O
been -X- _ O
effective -X- _ O
on -X- _ O
VQA -X- _ B-TaskName
( -X- _ O
Suhr -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
pervasive -X- _ O
in -X- _ O
the -X- _ O
active -X- _ O
learning -X- _ O
literature -X- _ O
( -X- _ O
Schein -X- _ O
and -X- _ O
Ungar -X- _ O
, -X- _ O
2007;Yang -X- _ O
and -X- _ O
Loog -X- _ O
, -X- _ O
2018;Mussmann -X- _ O
and -X- _ O
Liang -X- _ O
, -X- _ O
2018).LSTM -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
is -X- _ O
a -X- _ O
standard -X- _ O
model -X- _ O
introduced -X- _ O
with -X- _ O
VQA-1 -X- _ B-TaskName
( -X- _ O
Agrawal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
more -X- _ O
performant -X- _ O
ResNet-101 -X- _ O
features -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
VGGNet -X- _ O
features -X- _ O
as -X- _ O
our -X- _ O
visual -X- _ O
backbone -X- _ O
. -X- _ O
BUTD -X- _ B-MethodName
( -X- _ B-MethodName
Bottom -X- _ I-MethodName
- -X- _ I-MethodName
Up -X- _ I-MethodName
Top -X- _ I-MethodName
- -X- _ I-MethodName
Down -X- _ I-MethodName
Attention -X- _ I-MethodName
) -X- _ O
uses -X- _ O
object -X- _ O
- -X- _ O
based -X- _ O
features -X- _ O
in -X- _ O
tandem -X- _ O
with -X- _ O
attention -X- _ O
over -X- _ O
objects -X- _ O
( -X- _ O
Anderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
BUTD -X- _ B-MethodName
won -X- _ O
the -X- _ O
2017 -X- _ O
VQA -X- _ B-TaskName
Challenge -X- _ O
( -X- _ O
Teney -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
consistent -X- _ O
baseline -X- _ O
for -X- _ O
recent -X- _ O
work -X- _ O
in -X- _ O
VQA.LXMERT -X- _ B-TaskName
is -X- _ O
a -X- _ O
large -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
transformer -X- _ O
model -X- _ O
that -X- _ O
uses -X- _ O
BUTD -X- _ B-MethodName
's -X- _ O
object -X- _ O
features -X- _ O
and -X- _ O
contextualized -X- _ O
BERT -X- _ O
language -X- _ O
features -X- _ O
( -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
LXMERT -X- _ B-MethodName
is -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
aligned -X- _ O
image -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
textual -X- _ O
data -X- _ O
spanning -X- _ O
MS -X- _ O
COCO -X- _ O
, -X- _ O
Visual -X- _ O
Genome -X- _ O
, -X- _ O
VQA-2 -X- _ B-DatasetName
, -X- _ O
NLVR-2 -X- _ O
, -X- _ O
and -X- _ O
GQA -X- _ B-DatasetName
( -X- _ O
Lin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Suhr -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Hudson -X- _ O
and -X- _ O
Manning -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
initializing -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
modal -X- _ O
representation -X- _ O
space -X- _ O
conducive -X- _ O
to -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
3 -X- _ O
Several -X- _ O
active -X- _ B-MethodName
learning -X- _ I-MethodName
methods -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
different -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
machine -X- _ O
learning -X- _ O
training -X- _ O
pipeline -X- _ O
: -X- _ O
while -X- _ O
some -X- _ O
acquire -X- _ O
examples -X- _ O
with -X- _ O
high -X- _ O
aleotoric -X- _ O
uncertainty -X- _ O
( -X- _ O
Settles -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
( -X- _ O
having -X- _ O
to -X- _ O
do -X- _ O
with -X- _ O
the -X- _ O
natural -X- _ O
uncertainty -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
) -X- _ O
or -X- _ O
epistemic -X- _ O
uncertainty -X- _ O
( -X- _ O
having -X- _ O
to -X- _ O
do -X- _ O
with -X- _ O
the -X- _ O
uncertainty -X- _ O
in -X- _ O
the -X- _ O
modeling -X- _ O
/ -X- _ O
learning -X- _ O
process -X- _ O
) -X- _ O
, -X- _ O
others -X- _ O
attempt -X- _ O
to -X- _ O
acquire -X- _ O
examples -X- _ O
that -X- _ O
reflect -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
pool -X- _ O
( -X- _ O
Sener -X- _ O
and -X- _ O
Savarese -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
sample -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
: -X- _ O
Random -X- _ B-MethodName
Sampling -X- _ I-MethodName
serves -X- _ O
as -X- _ O
our -X- _ O
baseline -X- _ O
passive -X- _ O
approach -X- _ O
for -X- _ O
acquiring -X- _ O
examples -X- _ O
. -X- _ O
Least -X- _ B-MethodName
Confidence -X- _ I-MethodName
acquires -X- _ O
examples -X- _ O
with -X- _ O
lowest -X- _ O
model -X- _ O
prediction -X- _ O
probability -X- _ O
( -X- _ O
Settles -X- _ O
, -X- _ O
2009).Entropy -X- _ B-MethodName
acquires -X- _ O
examples -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
entropy -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
output -X- _ O
( -X- _ O
Settles -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O
MC -X- _ B-MethodName
- -X- _ I-MethodName
Dropout -X- _ I-MethodName
Entropy -X- _ I-MethodName
( -X- _ O
Monte -X- _ B-MethodName
- -X- _ I-MethodName
Carlo -X- _ I-MethodName
Dropout -X- _ I-MethodName
with -X- _ I-MethodName
Entropy -X- _ I-MethodName
acquisition -X- _ I-MethodName
) -X- _ O
acquires -X- _ O
examples -X- _ O
with -X- _ O
high -X- _ O
entropy -X- _ O
in -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
output -X- _ O
averaged -X- _ O
over -X- _ O
multiple -X- _ O
passes -X- _ O
through -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
with -X- _ O
different -X- _ O
dropout -X- _ O
masks -X- _ O
( -X- _ O
Gal -X- _ O
and -X- _ O
Ghahramani -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
process -X- _ O
is -X- _ O
a -X- _ O
consequence -X- _ O
of -X- _ O
a -X- _ O
theoretical -X- _ O
casting -X- _ O
of -X- _ O
dropout -X- _ O
as -X- _ O
approximate -X- _ O
Bayesian -X- _ O
inference -X- _ O
in -X- _ O
deep -X- _ O
Gaussian -X- _ O
processes -X- _ O
. -X- _ O
BALD -X- _ B-MethodName
( -X- _ O
Bayesian -X- _ B-MethodName
Active -X- _ I-MethodName
Learning -X- _ I-MethodName
by -X- _ I-MethodName
Disagreement -X- _ I-MethodName
) -X- _ O
builds -X- _ O
upon -X- _ O
Monte -X- _ B-MethodName
- -X- _ I-MethodName
Carlo -X- _ I-MethodName
Dropout -X- _ I-MethodName
by -X- _ O
proposing -X- _ O
a -X- _ O
decision -X- _ O
theoretic -X- _ O
objective -X- _ O
; -X- _ O
it -X- _ O
acquires -X- _ O
examples -X- _ O
that -X- _ O
maximise -X- _ O
the -X- _ O
decrease -X- _ O
in -X- _ O
expected -X- _ O
posterior -X- _ O
entropy -X- _ O
( -X- _ O
Houlsby -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011;Siddhant -X- _ O
and -X- _ O
Lipton -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
-capturing -X- _ O
" -X- _ O
disagreement -X- _ O
" -X- _ O
across -X- _ O
different -X- _ O
dropout -X- _ O
masks -X- _ O
. -X- _ O
Selection -X- _ O
samples -X- _ O
examples -X- _ O
that -X- _ O
capture -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
pool -X- _ O
( -X- _ O
Sener -X- _ O
and -X- _ O
Savarese -X- _ O
, -X- _ O
2018;Coleman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
acquires -X- _ O
examples -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
an -X- _ O
example -X- _ O
in -X- _ O
the -X- _ O
unlabeled -X- _ O
pool -X- _ O
to -X- _ O
its -X- _ O
closest -X- _ O
labeled -X- _ O
example -X- _ O
. -X- _ O
Since -X- _ O
Core -X- _ B-MethodName
- -X- _ I-MethodName
Set -X- _ I-MethodName
selection -X- _ O
operates -X- _ O
over -X- _ O
a -X- _ O
representation -X- _ O
space -X- _ O
( -X- _ O
and -X- _ O
not -X- _ O
an -X- _ O
output -X- _ O
distribution -X- _ O
, -X- _ O
like -X- _ O
prior -X- _ O
strategies -X- _ O
) -X- _ O
and -X- _ O
VQA -X- _ B-TaskName
models -X- _ O
operate -X- _ O
over -X- _ O
two -X- _ O
modalities -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
three -X- _ O
Core -X- _ B-MethodName
- -X- _ I-MethodName
Set -X- _ I-MethodName
variants -X- _ O
: -X- _ O
Core -X- _ B-MethodName
- -X- _ I-MethodName
Set -X- _ I-MethodName
( -X- _ O
Language -X- _ O
) -X- _ O
and -X- _ O
Core -X- _ B-MethodName
- -X- _ I-MethodName
Set -X- _ I-MethodName
( -X- _ O
Vision -X- _ O
) -X- _ O
operate -X- _ O
over -X- _ O
their -X- _ O
respective -X- _ O
representation -X- _ O
spaces -X- _ O
while -X- _ O
Core -X- _ B-MethodName
- -X- _ I-MethodName
Set -X- _ I-MethodName
( -X- _ O
Fused -X- _ O
) -X- _ O
operates -X- _ O
over -X- _ O
the -X- _ O
" -X- _ O
fused -X- _ O
" -X- _ O
vision -X- _ O
and -X- _ O
language -X- _ O
representation -X- _ O
space -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
8 -X- _ O
active -X- _ O
learning -X- _ O
strategies -X- _ O
across -X- _ O
the -X- _ O
5 -X- _ O
models -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
. -X- _ O
Figures -X- _ O
2 -X- _ O
- -X- _ O
5 -X- _ O
show -X- _ O
a -X- _ O
representative -X- _ O
sample -X- _ O
of -X- _ O
active -X- _ O
learning -X- _ O
results -X- _ O
across -X- _ O
datasets -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
space -X- _ O
constraints -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
visualize -X- _ O
4 -X- _ O
active -X- _ O
learning -X- _ O
strategies -X- _ O
-Least -X- _ B-MethodName
- -X- _ I-MethodName
Confidence -X- _ I-MethodName
, -X- _ O
BALD -X- _ B-MethodName
, -X- _ O
CoreSet -X- _ B-MethodName
- -X- _ O
Fused -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Random -X- _ B-MethodName
Baseline -X- _ I-MethodName
-using -X- _ O
3 -X- _ O
models -X- _ O
( -X- _ O
LSTM -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
, -X- _ O
BUTD -X- _ B-MethodName
, -X- _ O
LXMERT -X- _ B-MethodName
) -X- _ O
. -X- _ O
4 -X- _ O
Results -X- _ O
and -X- _ O
trends -X- _ O
are -X- _ O
consistent -X- _ O
across -X- _ O
the -X- _ O
different -X- _ O
acquisition -X- _ O
functions -X- _ O
, -X- _ O
models -X- _ O
and -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
sizes -X- _ I-HyperparameterName
( -X- _ O
see -X- _ O
the -X- _ O
appendix -X- _ O
for -X- _ O
results -X- _ O
with -X- _ O
other -X- _ O
models -X- _ O
, -X- _ O
acquisition -X- _ O
functions -X- _ O
, -X- _ O
and -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
sizes -X- _ I-HyperparameterName
) -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
go -X- _ O
on -X- _ O
to -X- _ O
provide -X- _ O
descriptions -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
we -X- _ O
evaluate -X- _ O
against -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
results -X- _ O
. -X- _ O
Strategies -X- _ O
perform -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
or -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
random -X- _ O
baseline -X- _ O
, -X- _ O
when -X- _ O
using -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
full -X- _ I-HyperparameterValue
dataset -X- _ I-HyperparameterValue
as -X- _ O
the -X- _ O
seed -X- _ B-HyperparameterName
set.4 -X- _ I-HyperparameterName
0 -X- _ O
K -X- _ O
8 -X- _ O
0 -X- _ O
K -X- _ O
1 -X- _ O
2 -X- _ O
0 -X- _ O
K -X- _ O
1 -X- _ O
6 -X- _ O
0 -X- _ O
K -X- _ O
2 -X- _ O
0 -X- _ O
0 -X- _ O
K -X- _ O
2 -X- _ O
4 -X- _ O
0 -X- _ O
K -X- _ O
2 -X- _ O
8 -X- _ O
0 -X- _ O
K -X- _ O
3 -X- _ O
2 -X- _ O
0 -X- _ O
K -X- _ O
3 -X- _ O
6 -X- _ O
0 -X- _ O
K -X- _ O
4 -X- _ O
0 -X- _ O
0 -X- _ O
K -X- _ O
Number -X- _ O
of -X- _ O
Training -X- _ O
Examples -X- _ O
0.2 -X- _ O
0.3 -X- _ O
0.4 -X- _ O
0.5 -X- _ O
0.6 -X- _ O
0.7 -X- _ O
0.8 -X- _ O
0.9 -X- _ O
1.0 -X- _ O
Validation -X- _ O
Accuracy -X- _ B-MetricName
LSTM -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
-VQA-2 -X- _ B-DatasetName
Random -X- _ O
Baseline -X- _ O
Least -X- _ O
- -X- _ O
Confidence -X- _ O
BALD -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
( -X- _ O
Fused -X- _ O
) -X- _ O
4 -X- _ O
0 -X- _ O
K -X- _ O
8 -X- _ O
0 -X- _ O
K -X- _ O
1 -X- _ O
2 -X- _ O
0 -X- _ O
K -X- _ O
1 -X- _ O
6 -X- _ O
0 -X- _ O
K -X- _ O
2 -X- _ O
0 -X- _ O
0 -X- _ O
K -X- _ O
2 -X- _ O
4 -X- _ O
0 -X- _ O
K -X- _ O
2 -X- _ O
8 -X- _ O
0 -X- _ O
K -X- _ O
3 -X- _ O
2 -X- _ O
0 -X- _ O
K -X- _ O
3 -X- _ O
6 -X- _ O
0 -X- _ O
K -X- _ O
4 -X- _ O
0 -X- _ O
0 -X- _ O
K -X- _ O
Number -X- _ O
of -X- _ O
Training -X- _ O
Examples -X- _ O
0.2 -X- _ O
0.3 -X- _ O
0.4 -X- _ O
0.5 -X- _ O
0.6 -X- _ O
0.7 -X- _ O
0.8 -X- _ O
0.9 -X- _ O
1.0 -X- _ O
Validation -X- _ O
Accuracy -X- _ B-MetricName
BUTD -X- _ B-MethodName
-VQA-2 -X- _ B-DatasetName
4 -X- _ O
0 -X- _ O
K -X- _ O
8 -X- _ O
0 -X- _ O
K -X- _ O
1 -X- _ O
2 -X- _ O
0 -X- _ O
K -X- _ O
1 -X- _ O
6 -X- _ O
0 -X- _ O
K -X- _ O
2 -X- _ O
0 -X- _ O
0 -X- _ O
K -X- _ O
2 -X- _ O
4 -X- _ O
0 -X- _ O
K -X- _ O
2 -X- _ O
8 -X- _ O
0 -X- _ O
K -X- _ O
3 -X- _ O
2 -X- _ O
0 -X- _ O
K -X- _ O
3 -X- _ O
6 -X- _ O
0 -X- _ O
K -X- _ O
4 -X- _ O
0 -X- _ O
0 -X- _ O
K -X- _ O
Number -X- _ O
of -X- _ O
Training -X- _ O
Examples -X- _ O
0.2 -X- _ O
0.3 -X- _ O
0.4 -X- _ O
0.5 -X- _ O
0.6 -X- _ O
0.7 -X- _ O
0.8 -X- _ O
0.9 -X- _ O
1.0 -X- _ O
Validation -X- _ O
Accuracy -X- _ B-MetricName
LXMERT -X- _ B-MethodName
-VQA-2Figure -X- _ B-DatasetName
3 -X- _ O
: -X- _ O
Results -X- _ O
for -X- _ O
the -X- _ O
full -X- _ O
VQA-2 -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
also -X- _ O
using -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
full -X- _ I-HyperparameterValue
dataset -X- _ I-HyperparameterValue
as -X- _ O
a -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
plot -X- _ O
above -X- _ O
, -X- _ O
all -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
perform -X- _ O
similar -X- _ O
to -X- _ O
a -X- _ O
random -X- _ O
baseline -X- _ O
. -X- _ O
One -X- _ O
complexity -X- _ O
of -X- _ O
VQA -X- _ B-TaskName
is -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
space -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
present -X- _ O
( -X- _ O
Agrawal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
; -X- _ O
VQA-2 -X- _ B-DatasetName
has -X- _ O
400k -X- _ O
training -X- _ O
examples -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
excess -X- _ O
of -X- _ O
3k -X- _ O
possible -X- _ O
answers -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
prior -X- _ O
work -X- _ O
in -X- _ O
active -X- _ O
learning -X- _ O
focuses -X- _ O
on -X- _ O
smaller -X- _ O
datasets -X- _ O
like -X- _ O
the -X- _ O
10 -X- _ O
- -X- _ O
class -X- _ O
MNIST -X- _ O
dataset -X- _ O
, -X- _ O
binary -X- _ O
classification -X- _ O
( -X- _ O
Siddhant -X- _ O
and -X- _ O
Lipton -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
small -X- _ O
- -X- _ O
cardinality -X- _ O
( -X- _ O
≤ -X- _ O
20 -X- _ O
classes -X- _ O
) -X- _ O
text -X- _ O
categorization -X- _ O
( -X- _ O
Lowell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
ensure -X- _ O
our -X- _ O
results -X- _ O
and -X- _ O
conclusions -X- _ O
are -X- _ O
not -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
space -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
two -X- _ O
meaningful -X- _ O
, -X- _ O
but -X- _ O
narrow -X- _ O
- -X- _ O
domain -X- _ O
VQA -X- _ B-TaskName
datasets -X- _ O
from -X- _ O
subsets -X- _ O
of -X- _ O
VQA-2 -X- _ B-DatasetName
. -X- _ O
These -X- _ O
simplified -X- _ O
datasets -X- _ O
reduce -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
the -X- _ O
underlying -X- _ O
learning -X- _ O
problem -X- _ O
and -X- _ O
provide -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
to -X- _ O
existing -X- _ O
active -X- _ O
learning -X- _ O
literature -X- _ O
. -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Sports -X- _ I-DatasetName
. -X- _ O
We -X- _ O
generate -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Sports -X- _ I-DatasetName
by -X- _ O
compiling -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
20 -X- _ O
popular -X- _ O
sports -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
soccer -X- _ O
, -X- _ O
football -X- _ O
, -X- _ O
tennis -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
) -X- _ O
in -X- _ O
VQA-2 -X- _ B-DatasetName
, -X- _ O
and -X- _ O
restricting -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
questions -X- _ O
to -X- _ O
those -X- _ O
with -X- _ O
answers -X- _ O
in -X- _ O
this -X- _ O
list -X- _ O
. -X- _ O
We -X- _ O
picked -X- _ O
the -X- _ O
sports -X- _ O
categories -X- _ O
by -X- _ O
ranking -X- _ O
the -X- _ O
GloVe -X- _ O
vector -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
word -X- _ O
" -X- _ O
sports -X- _ O
" -X- _ O
to -X- _ O
answers -X- _ O
in -X- _ O
VQA-2 -X- _ B-DatasetName
, -X- _ O
and -X- _ O
selected -X- _ O
the -X- _ O
20 -X- _ O
most -X- _ O
commonly -X- _ O
occurring -X- _ O
answers -X- _ O
. -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Food -X- _ I-DatasetName
. -X- _ O
We -X- _ O
generate -X- _ O
the -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Food -X- _ I-DatasetName
dataset -X- _ O
similarly -X- _ O
, -X- _ O
compiling -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
the -X- _ O
20 -X- _ O
commonly -X- _ O
occurring -X- _ O
food -X- _ O
categories -X- _ O
by -X- _ O
GloVe -X- _ O
vector -X- _ O
similarity -X- _ O
to -X- _ O
the -X- _ O
word -X- _ O
" -X- _ O
food -X- _ O
. -X- _ O
"Results -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
presents -X- _ O
results -X- _ O
for -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Sports -X- _ I-DatasetName
, -X- _ O
with -X- _ O
an -X- _ O
initial -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
restricted -X- _ O
to -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
total -X- _ I-HyperparameterValue
pool -X- _ I-HyperparameterValue
( -X- _ O
500 -X- _ B-HyperparameterValue
examples -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O
The -X- _ O
appendix -X- _ O
reports -X- _ O
similar -X- _ O
results -X- _ O
on -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Food -X- _ I-DatasetName
. -X- _ O
For -X- _ O
LSTM -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
, -X- _ O
Least -X- _ O
- -X- _ O
Confidence -X- _ O
appears -X- _ O
to -X- _ O
be -X- _ O
slightly -X- _ O
more -X- _ O
sample -X- _ O
efficient -X- _ O
, -X- _ O
while -X- _ O
all -X- _ O
other -X- _ O
strategies -X- _ O
perform -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
or -X- _ O
worse -X- _ O
than -X- _ O
random -X- _ O
. -X- _ O
For -X- _ O
BUTD -X- _ B-MethodName
, -X- _ O
all -X- _ O
methods -X- _ O
are -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
random -X- _ O
; -X- _ O
for -X- _ O
LXMERT -X- _ B-MethodName
, -X- _ O
they -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
random -X- _ O
. -X- _ O
Generally -X- _ O
on -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Sports -X- _ I-DatasetName
, -X- _ O
active -X- _ O
learning -X- _ O
performance -X- _ O
varies -X- _ O
, -X- _ O
but -X- _ O
fails -X- _ O
to -X- _ O
outperform -X- _ O
random -X- _ O
acquisition -X- _ O
. -X- _ O
VQA-2 -X- _ B-DatasetName
is -X- _ O
the -X- _ O
canonical -X- _ O
dataset -X- _ O
for -X- _ O
evaluating -X- _ O
VQA -X- _ O
models -X- _ O
( -X- _ O
Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
keeping -X- _ O
with -X- _ O
prior -X- _ O
work -X- _ O
( -X- _ O
Anderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a;Tan -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
filter -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
to -X- _ O
only -X- _ O
include -X- _ O
answers -X- _ O
that -X- _ O
appear -X- _ O
at -X- _ O
least -X- _ O
9 -X- _ O
times -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
3130 -X- _ O
unique -X- _ O
answers -X- _ O
. -X- _ O
Unlike -X- _ O
traditional -X- _ O
VQA-2 -X- _ B-DatasetName
evaluation -X- _ O
, -X- _ O
which -X- _ O
treats -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
label -X- _ O
binary -X- _ O
classification -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
prior -X- _ O
active -X- _ O
learning -X- _ O
work -X- _ O
on -X- _ O
VQA -X- _ O
( -X- _ O
Lin -X- _ O
and -X- _ O
Parikh -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
formulates -X- _ O
it -X- _ O
as -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
class -X- _ O
classification -X- _ O
problem -X- _ O
, -X- _ O
enabling -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
acquisition -X- _ O
functions -X- _ O
such -X- _ O
as -X- _ O
uncertainty -X- _ O
sampling -X- _ O
and -X- _ O
BALD -X- _ O
. -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
? -X- _ O
" -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
standard -X- _ O
GQA -X- _ B-DatasetName
training -X- _ O
set -X- _ O
of -X- _ O
943k -X- _ O
questions -X- _ O
, -X- _ O
900k -X- _ O
of -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
for -X- _ O
the -X- _ O
active -X- _ O
learning -X- _ O
pool -X- _ O
. -X- _ O
Results -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
results -X- _ O
on -X- _ O
GQA -X- _ B-DatasetName
using -X- _ O
a -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
full -X- _ I-HyperparameterValue
pool -X- _ I-HyperparameterValue
( -X- _ O
90k -X- _ B-HyperparameterValue
examples -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O
Despite -X- _ O
its -X- _ O
notable -X- _ O
differences -X- _ O
in -X- _ O
question -X- _ O
structure -X- _ O
to -X- _ O
VQA-2 -X- _ B-DatasetName
, -X- _ O
active -X- _ O
learning -X- _ O
still -X- _ O
performs -X- _ O
on -X- _ O
par -X- _ O
with -X- _ O
or -X- _ O
slightly -X- _ O
worse -X- _ O
than -X- _ O
random -X- _ O
. -X- _ O
The -X- _ O
previous -X- _ O
section -X- _ O
shows -X- _ O
that -X- _ O
active -X- _ O
learning -X- _ O
fails -X- _ O
to -X- _ O
improve -X- _ O
over -X- _ O
random -X- _ O
acquisition -X- _ O
on -X- _ O
VQA -X- _ O
across -X- _ O
models -X- _ O
and -X- _ O
datasets -X- _ O
. -X- _ O
A -X- _ O
simple -X- _ O
question -X- _ O
remains -X- _ O
-why -X- _ O
? -X- _ O
One -X- _ O
hypothesis -X- _ O
is -X- _ O
that -X- _ O
sample -X- _ O
inefficiency -X- _ O
stems -X- _ O
from -X- _ O
the -X- _ O
data -X- _ O
itself -X- _ O
: -X- _ O
there -X- _ O
is -X- _ O
only -X- _ O
a -X- _ O
2 -X- _ B-MetricValue
% -X- _ I-MetricValue
gain -X- _ O
in -X- _ O
validation -X- _ O
accuracy -X- _ B-MetricName
when -X- _ O
training -X- _ O
on -X- _ O
half -X- _ O
versus -X- _ O
the -X- _ O
whole -X- _ O
dataset -X- _ O
. -X- _ O
Working -X- _ O
from -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
characterize -X- _ O
the -X- _ O
underlying -X- _ O
datasets -X- _ O
using -X- _ O
Dataset -X- _ O
Maps -X- _ O
and -X- _ O
discover -X- _ O
that -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
prefer -X- _ O
sampling -X- _ O
" -X- _ O
hard -X- _ O
- -X- _ O
tolearn -X- _ O
" -X- _ O
examples -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
poor -X- _ O
performance -X- _ O
. -X- _ O
( -X- _ O
Han -X- _ O
and -X- _ O
Kamber -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
-they -X- _ O
often -X- _ O
present -X- _ O
as -X- _ O
fundamental -X- _ O
subproblems -X- _ O
of -X- _ O
a -X- _ O
broader -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
( -X- _ O
Figure -X- _ O
7 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
VQA-2 -X- _ B-DatasetName
, -X- _ O
we -X- _ O
identify -X- _ O
clusters -X- _ O
of -X- _ O
hard -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
learn -X- _ O
examples -X- _ O
that -X- _ O
require -X- _ O
optical -X- _ O
character -X- _ O
recognition -X- _ O
( -X- _ O
OCR -X- _ O
) -X- _ O
for -X- _ O
reasoning -X- _ O
about -X- _ O
text -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
What -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
word -X- _ O
on -X- _ O
the -X- _ O
black -X- _ O
car -X- _ O
? -X- _ O
" -X- _ O
) -X- _ O
; -X- _ O
another -X- _ O
cluster -X- _ O
requires -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
answer -X- _ O
( -X- _ O
" -X- _ O
What -X- _ O
is -X- _ O
the -X- _ O
symbol -X- _ O
on -X- _ O
the -X- _ O
hood -X- _ O
often -X- _ O
associated -X- _ O
with -X- _ O
? -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
GQA -X- _ B-DatasetName
, -X- _ O
we -X- _ O
identify -X- _ O
different -X- _ O
clusters -X- _ O
of -X- _ O
collective -X- _ O
outliers -X- _ O
; -X- _ O
one -X- _ O
cluster -X- _ O
stems -X- _ O
from -X- _ O
innate -X- _ O
underspecification -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
what -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
shelf -X- _ O
? -X- _ O
" -X- _ O
with -X- _ O
multiple -X- _ O
objects -X- _ O
present -X- _ O
on -X- _ O
the -X- _ O
shelf -X- _ O
) -X- _ O
; -X- _ O
another -X- _ O
cluster -X- _ O
requires -X- _ O
multiple -X- _ O
reasoning -X- _ O
hops -X- _ O
difficult -X- _ O
for -X- _ O
current -X- _ O
models -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
" -X- _ O
What -X- _ O
is -X- _ O
the -X- _ O
vehicle -X- _ O
that -X- _ O
is -X- _ O
driving -X- _ O
down -X- _ O
the -X- _ O
road -X- _ O
the -X- _ O
box -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
side -X- _ O
of -X- _ O
? -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
sample -X- _ O
100 -X- _ O
random -X- _ O
" -X- _ O
hard -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
learn -X- _ O
" -X- _ O
examples -X- _ O
from -X- _ O
both -X- _ O
VQA-2 -X- _ B-DatasetName
and -X- _ O
GQA -X- _ B-DatasetName
and -X- _ O
find -X- _ O
that -X- _ O
100 -X- _ O
% -X- _ O
Ablating -X- _ O
Outliers -X- _ O
. -X- _ O
To -X- _ O
verify -X- _ O
that -X- _ O
collective -X- _ O
outliers -X- _ O
are -X- _ O
responsible -X- _ O
for -X- _ O
the -X- _ O
degradation -X- _ O
of -X- _ O
active -X- _ O
learning -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
re -X- _ O
- -X- _ O
run -X- _ O
our -X- _ O
experiments -X- _ O
using -X- _ O
active -X- _ O
learning -X- _ O
pools -X- _ O
with -X- _ O
varying -X- _ O
numbers -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
outliers -X- _ I-HyperparameterName
removed -X- _ I-HyperparameterName
. -X- _ O
To -X- _ O
remove -X- _ O
these -X- _ O
outliers -X- _ O
, -X- _ O
we -X- _ O
sort -X- _ O
and -X- _ O
remove -X- _ O
all -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
pool -X- _ O
using -X- _ O
the -X- _ O
product -X- _ O
of -X- _ O
their -X- _ O
model -X- _ O
confidence -X- _ O
and -X- _ O
prediction -X- _ O
variability -X- _ O
( -X- _ O
x -X- _ O
and -X- _ O
y -X- _ O
- -X- _ O
axis -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
Dataset -X- _ O
Maps -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
systematically -X- _ O
remove -X- _ O
examples -X- _ O
with -X- _ O
a -X- _ O
low -X- _ O
product -X- _ O
value -X- _ O
and -X- _ O
observe -X- _ O
how -X- _ O
active -X- _ O
learning -X- _ O
performance -X- _ O
changes -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
8).We -X- _ O
observe -X- _ O
a -X- _ O
2 -X- _ O
- -X- _ O
3x -X- _ O
improvement -X- _ O
in -X- _ O
sample -X- _ O
efficiency -X- _ O
when -X- _ O
removing -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
entire -X- _ I-HyperparameterValue
data -X- _ I-HyperparameterValue
pool -X- _ I-HyperparameterValue
, -X- _ O
consisting -X- _ O
mainly -X- _ O
of -X- _ O
collective -X- _ O
outliers -X- _ O
( -X- _ O
Figure -X- _ O
8c -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
improvement -X- _ O
decreases -X- _ O
if -X- _ O
we -X- _ O
only -X- _ O
remove -X- _ O
25 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
full -X- _ I-HyperparameterValue
pool -X- _ I-HyperparameterValue
( -X- _ O
Figure -X- _ O
8b -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
further -X- _ O
degrades -X- _ O
if -X- _ O
we -X- _ O
remove -X- _ O
only -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
( -X- _ O
Figure -X- _ O
8a -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
ablation -X- _ O
demonstrates -X- _ O
that -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
are -X- _ O
more -X- _ O
sample -X- _ O
efficient -X- _ O
than -X- _ O
the -X- _ O
random -X- _ O
baseline -X- _ O
when -X- _ O
collective -X- _ O
outliers -X- _ O
are -X- _ O
absent -X- _ O
from -X- _ O
the -X- _ O
unlabelled -X- _ O
pool -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
asks -X- _ O
a -X- _ O
simple -X- _ O
question -X- _ O
-why -X- _ O
does -X- _ O
the -X- _ O
modern -X- _ O
neural -X- _ O
active -X- _ O
learning -X- _ O
toolkit -X- _ O
fail -X- _ O
when -X- _ O
applied -X- _ O
to -X- _ O
complex -X- _ O
, -X- _ O
open -X- _ O
ended -X- _ O
tasks -X- _ O
? -X- _ O
While -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
VQA -X- _ B-TaskName
, -X- _ O
collective -X- _ O
outliers -X- _ O
are -X- _ O
abundant -X- _ O
in -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
opendomain -X- _ O
question -X- _ O
answering -X- _ O
( -X- _ O
Kwiatkowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
amongst -X- _ O
others -X- _ O
. -X- _ O
More -X- _ O
insidious -X- _ O
is -X- _ O
their -X- _ O
nature -X- _ O
; -X- _ O
collective -X- _ O
outliers -X- _ O
can -X- _ O
take -X- _ O
multiple -X- _ O
forms -X- _ O
, -X- _ O
requiring -X- _ O
external -X- _ O
domain -X- _ O
knowledge -X- _ O
or -X- _ O
" -X- _ O
commonsense -X- _ O
" -X- _ O
reasoning -X- _ O
, -X- _ O
containing -X- _ O
underspecification -X- _ O
, -X- _ O
or -X- _ O
requiring -X- _ O
capabilities -X- _ O
beyond -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
model -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
requiring -X- _ O
OCR -X- _ O
ability -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
perform -X- _ O
ablations -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
removing -X- _ O
collective -X- _ O
outliers -X- _ O
, -X- _ O
demonstrating -X- _ O
that -X- _ O
active -X- _ O
learning -X- _ O
fails -X- _ O
as -X- _ O
collective -X- _ O
outliers -X- _ O
take -X- _ O
up -X- _ O
larger -X- _ O
portions -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
only -X- _ O
an -X- _ O
analytical -X- _ O
tool -X- _ O
; -X- _ O
these -X- _ O
outliers -X- _ O
are -X- _ O
, -X- _ O
and -X- _ O
will -X- _ O
continue -X- _ O
to -X- _ O
be -X- _ O
, -X- _ O
pervasive -X- _ O
in -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
datasets -X- _ O
-and -X- _ O
as -X- _ O
such -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
need -X- _ O
to -X- _ O
develop -X- _ O
better -X- _ O
tools -X- _ O
for -X- _ O
learning -X- _ O
( -X- _ O
and -X- _ O
performing -X- _ O
active -X- _ O
learning -X- _ O
) -X- _ O
in -X- _ O
their -X- _ O
presence -X- _ O
. -X- _ O
Selective -X- _ O
Classification -X- _ O
. -X- _ O
One -X- _ O
potential -X- _ O
direction -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
is -X- _ O
to -X- _ O
develop -X- _ O
systems -X- _ O
that -X- _ O
abstain -X- _ O
when -X- _ O
they -X- _ O
encounter -X- _ O
collective -X- _ O
outliers -X- _ O
. -X- _ O
Historical -X- _ O
artificial -X- _ O
intelligence -X- _ O
systems -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
SHRDLU -X- _ O
( -X- _ O
Winograd -X- _ O
, -X- _ O
1972 -X- _ O
) -X- _ O
and -X- _ O
QUALM -X- _ O
( -X- _ O
Lehnert -X- _ O
, -X- _ O
1977 -X- _ O
) -X- _ O
, -X- _ O
were -X- _ O
designed -X- _ O
to -X- _ O
flag -X- _ O
input -X- _ O
sequences -X- _ O
that -X- _ O
they -X- _ O
were -X- _ O
not -X- _ O
designed -X- _ O
to -X- _ O
parse -X- _ O
. -X- _ O
Ideas -X- _ O
from -X- _ O
those -X- _ O
methods -X- _ O
can -X- _ O
and -X- _ O
should -X- _ O
be -X- _ O
resurrected -X- _ O
using -X- _ O
modern -X- _ O
techniques -X- _ O
; -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
recent -X- _ O
work -X- _ O
suggests -X- _ O
that -X- _ O
a -X- _ O
simple -X- _ O
classifier -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
to -X- _ O
identify -X- _ O
out -X- _ O
- -X- _ O
ofdomain -X- _ O
data -X- _ O
inputs -X- _ O
, -X- _ O
provided -X- _ O
a -X- _ O
seed -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
dataset -X- _ O
( -X- _ O
Kamath -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Active -X- _ O
learning -X- _ O
methods -X- _ O
can -X- _ O
be -X- _ O
augmented -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
classifier -X- _ O
, -X- _ O
which -X- _ O
re -X- _ O
- -X- _ O
calibrates -X- _ O
active -X- _ O
learning -X- _ O
uncertainty -X- _ O
scores -X- _ O
with -X- _ O
this -X- _ O
classifier -X- _ O
's -X- _ O
predictions -X- _ O
. -X- _ O
Other -X- _ O
work -X- _ O
learns -X- _ O
to -X- _ O
identify -X- _ O
novel -X- _ O
utterances -X- _ O
by -X- _ O
learning -X- _ O
to -X- _ O
intelligently -X- _ O
set -X- _ O
thresholds -X- _ O
in -X- _ O
representation -X- _ O
space -X- _ O
( -X- _ O
Karamcheti -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
powerful -X- _ O
idea -X- _ O
especially -X- _ O
if -X- _ O
combined -X- _ O
with -X- _ O
other -X- _ O
representation -X- _ O
- -X- _ O
centric -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
like -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
Sampling -X- _ O
( -X- _ O
Sener -X- _ O
and -X- _ O
Savarese -X- _ O
, -X- _ O
2018).Active -X- _ O
Learning -X- _ O
with -X- _ O
Global -X- _ O
Reasoning -X- _ O
. -X- _ O
Another -X- _ O
direction -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
to -X- _ O
explore -X- _ O
is -X- _ O
to -X- _ O
leverage -X- _ O
Dataset -X- _ O
Maps -X- _ O
to -X- _ O
perform -X- _ O
more -X- _ O
global -X- _ O
, -X- _ O
holistic -X- _ O
reasoning -X- _ O
over -X- _ O
datasets -X- _ O
, -X- _ O
to -X- _ O
intelligently -X- _ O
identify -X- _ O
promising -X- _ O
examples -X- _ O
-in -X- _ O
a -X- _ O
sense -X- _ O
, -X- _ O
baking -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
analysis -X- _ O
done -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
directly -X- _ O
into -X- _ O
the -X- _ O
active -X- _ O
learning -X- _ O
algorithms -X- _ O
. -X- _ O
A -X- _ O
possible -X- _ O
instantiation -X- _ O
of -X- _ O
this -X- _ O
idea -X- _ O
would -X- _ O
be -X- _ O
in -X- _ O
training -X- _ O
a -X- _ O
discriminator -X- _ O
to -X- _ O
differentiate -X- _ O
between -X- _ O
" -X- _ O
learnable -X- _ O
" -X- _ O
examples -X- _ O
( -X- _ O
upper -X- _ O
half -X- _ O
of -X- _ O
each -X- _ O
Dataset -X- _ O
Map -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
" -X- _ O
unlearnable -X- _ O
" -X- _ O
, -X- _ O
collective -X- _ O
outliers -X- _ O
with -X- _ O
low -X- _ O
confidence -X- _ O
and -X- _ O
low -X- _ O
variability -X- _ O
. -X- _ O
Between -X- _ O
each -X- _ O
active -X- _ O
learning -X- _ O
acquisition -X- _ O
iteration -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
generate -X- _ O
an -X- _ O
updated -X- _ O
Dataset -X- _ O
Map -X- _ O
, -X- _ O
thereby -X- _ O
reflecting -X- _ O
what -X- _ O
models -X- _ O
are -X- _ O
learning -X- _ O
as -X- _ O
they -X- _ O
obtain -X- _ O
new -X- _ O
labeled -X- _ O
examples -X- _ O
. -X- _ O
Machine -X- _ O
learning -X- _ O
systems -X- _ O
deployed -X- _ O
in -X- _ O
realworld -X- _ O
settings -X- _ O
will -X- _ O
inevitably -X- _ O
encounter -X- _ O
open -X- _ O
- -X- _ O
world -X- _ O
datasets -X- _ O
, -X- _ O
ones -X- _ O
that -X- _ O
contain -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
learnable -X- _ O
and -X- _ O
unlearnable -X- _ O
inputs -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
provides -X- _ O
a -X- _ O
framework -X- _ O
to -X- _ O
study -X- _ O
when -X- _ O
models -X- _ O
encounter -X- _ O
such -X- _ O
inputs -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
we -X- _ O
hope -X- _ O
that -X- _ O
our -X- _ O
experiments -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
catalyst -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
on -X- _ O
evaluating -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
with -X- _ O
inputs -X- _ O
drawn -X- _ O
from -X- _ O
open -X- _ O
- -X- _ O
world -X- _ O
datasets -X- _ O
. -X- _ O
All -X- _ O
code -X- _ O
for -X- _ O
data -X- _ O
preprocessing -X- _ O
, -X- _ O
model -X- _ O
implementation -X- _ O
, -X- _ O
and -X- _ O
active -X- _ O
learning -X- _ O
algorithms -X- _ O
is -X- _ O
made -X- _ O
available -X- _ O
at -X- _ O
https://github.com/siddk/vqa-outliers -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
this -X- _ O
repository -X- _ O
also -X- _ O
contains -X- _ O
the -X- _ O
full -X- _ O
set -X- _ O
of -X- _ O
results -X- _ O
and -X- _ O
dataset -X- _ O
maps -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
broad -X- _ O
scope -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
and -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
were -X- _ O
unable -X- _ O
to -X- _ O
fit -X- _ O
all -X- _ O
our -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
body -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
limited -X- _ O
length -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
appendix -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
only -X- _ O
salient -X- _ O
implementation -X- _ O
details -X- _ O
and -X- _ O
other -X- _ O
representative -X- _ O
results -X- _ O
here -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
all -X- _ O
code -X- _ O
, -X- _ O
models -X- _ O
, -X- _ O
data -X- _ O
, -X- _ O
results -X- _ O
, -X- _ O
active -X- _ O
learning -X- _ O
implementations -X- _ O
available -X- _ O
at -X- _ O
this -X- _ O
link -X- _ O
: -X- _ O
https -X- _ O
: -X- _ O
//github.com -X- _ O
/ -X- _ O
siddk -X- _ O
/ -X- _ O
vqa -X- _ O
- -X- _ O
outliers -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
any -X- _ O
combination -X- _ O
of -X- _ O
{ -X- _ O
active -X- _ O
learning -X- _ O
strategy -X- _ O
× -X- _ O
model -X- _ O
× -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
× -X- _ O
analysis -X- _ O
/ -X- _ O
acquisition -X- _ O
plot -X- _ O
} -X- _ O
is -X- _ O
present -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
public -X- _ O
code -X- _ O
repository -X- _ O
. -X- _ O
Where -X- _ O
applicable -X- _ O
, -X- _ O
we -X- _ O
implement -X- _ O
our -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
publicly -X- _ O
available -X- _ O
PyTorch -X- _ O
implementations -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
model -X- _ O
, -X- _ O
we -X- _ O
base -X- _ O
our -X- _ O
implementation -X- _ O
off -X- _ O
of -X- _ O
this -X- _ O
repository -X- _ O
: -X- _ O
https://github.com/ -X- _ O
Shivanshu -X- _ O
- -X- _ O
Gupta -X- _ O
/ -X- _ O
Visual -X- _ B-TaskName
- -X- _ I-TaskName
Question -X- _ I-TaskName
- -X- _ I-TaskName
Answering -X- _ I-TaskName
, -X- _ O
while -X- _ O
for -X- _ O
the -X- _ O
Bottom -X- _ O
- -X- _ O
Up -X- _ O
Top -X- _ O
- -X- _ O
Down -X- _ O
Attention -X- _ O
Model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
this -X- _ O
repository -X- _ O
: -X- _ O
https://github.com/ -X- _ O
hengyuan -X- _ O
- -X- _ O
hu -X- _ O
/ -X- _ O
bottom -X- _ O
- -X- _ O
up -X- _ O
- -X- _ O
attention -X- _ O
- -X- _ O
vqa -X- _ O
, -X- _ O
keeping -X- _ O
default -X- _ O
hyperparameters -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O
Logistic -X- _ O
Regression -X- _ O
. -X- _ O
When -X- _ O
implementing -X- _ O
Logistic -X- _ O
Regression -X- _ O
, -X- _ O
we -X- _ O
base -X- _ O
our -X- _ O
PyTorch -X- _ O
implementation -X- _ O
on -X- _ O
the -X- _ O
broadly -X- _ O
used -X- _ O
Scikit -X- _ O
- -X- _ O
Learn -X- _ O
( -X- _ O
https -X- _ O
: -X- _ O
//scikit -X- _ O
- -X- _ O
learn.org -X- _ O
) -X- _ O
implementation -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
default -X- _ O
parameters -X- _ O
( -X- _ O
including -X- _ O
L2 -X- _ O
weight -X- _ O
decay -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
optimize -X- _ O
our -X- _ O
models -X- _ O
via -X- _ O
stochastic -X- _ O
gradient -X- _ O
descent -X- _ O
. -X- _ O
LXMERT -X- _ B-MethodName
. -X- _ O
As -X- _ O
mentioned -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
the -X- _ O
default -X- _ O
LXMERT -X- _ B-MethodName
checkpoint -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
code -X- _ O
made -X- _ O
publicly -X- _ O
available -X- _ O
in -X- _ O
Tan -X- _ O
and -X- _ O
Bansal -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
associated -X- _ O
code -X- _ O
repository -X- _ O
: -X- _ O
https://github.com/ -X- _ O
airsplay -X- _ O
/ -X- _ O
lxmert -X- _ O
) -X- _ O
is -X- _ O
pretrained -X- _ O
on -X- _ O
data -X- _ O
from -X- _ O
VQA-2 -X- _ B-DatasetName
and -X- _ O
GQA -X- _ B-DatasetName
, -X- _ O
leaking -X- _ O
information -X- _ O
that -X- _ O
could -X- _ O
substantially -X- _ O
affect -X- _ O
our -X- _ O
active -X- _ O
learning -X- _ O
results -X- _ O
. -X- _ O
To -X- _ O
mitigate -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
contacted -X- _ O
the -X- _ O
authors -X- _ O
, -X- _ O
who -X- _ O
kindly -X- _ O
provided -X- _ O
us -X- _ O
with -X- _ O
a -X- _ O
checkpoint -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
without -X- _ O
VQA -X- _ B-TaskName
pretraining -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
this -X- _ O
model -X- _ O
obtaining -X- _ O
different -X- _ O
results -X- _ O
from -X- _ O
those -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
work -X- _ O
, -X- _ O
the -X- _ O
provided -X- _ O
pretrained -X- _ O
checkpoint -X- _ O
behaves -X- _ O
slightly -X- _ O
differently -X- _ O
during -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
requiring -X- _ O
different -X- _ O
hyperparameters -X- _ O
than -X- _ O
provided -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
repository -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
a -X- _ O
coarse -X- _ O
grid -X- _ O
search -X- _ O
over -X- _ O
hyperparameters -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
LXMERT -X- _ B-MethodName
implementation -X- _ O
provided -X- _ O
by -X- _ O
HuggingFace -X- _ O
Transformers -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
find -X- _ O
that -X- _ O
using -X- _ O
an -X- _ O
AdamW -X- _ O
optimizer -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
BERT -X- _ O
- -X- _ O
Adam -X- _ O
Optimizer -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
work -X- _ O
without -X- _ O
any -X- _ O
special -X- _ O
learning -X- _ O
rate -X- _ O
scheduling -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
best -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
standard -X- _ O
implementations -X- _ O
of -X- _ O
the -X- _ O
8 -X- _ O
active -X- _ O
learning -X- _ O
strategies -X- _ O
described -X- _ O
, -X- _ O
borrowing -X- _ O
from -X- _ O
prior -X- _ O
implementations -X- _ O
( -X- _ O
Mussmann -X- _ O
and -X- _ O
Liang -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
existing -X- _ O
code -X- _ O
repositories -X- _ O
( -X- _ O
https://github.com/ -X- _ O
google -X- _ O
/ -X- _ O
active -X- _ O
- -X- _ O
learning -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
additional -X- _ O
details -X- _ O
below -X- _ O
. -X- _ O
Monte -X- _ O
- -X- _ O
Carlo -X- _ O
Dropout -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
implementations -X- _ O
of -X- _ O
the -X- _ O
deep -X- _ O
Bayesian -X- _ O
active -X- _ O
learning -X- _ O
methods -X- _ O
( -X- _ O
Monte -X- _ B-MethodName
- -X- _ I-MethodName
Carlo -X- _ I-MethodName
Dropout -X- _ I-MethodName
w/ -X- _ I-MethodName
Entropy -X- _ I-MethodName
, -X- _ O
BALD -X- _ B-MethodName
) -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
Gal -X- _ O
and -X- _ O
Ghahramani -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
estimate -X- _ O
a -X- _ O
Dropout -X- _ O
distribution -X- _ O
via -X- _ O
test -X- _ O
- -X- _ O
time -X- _ O
dropout -X- _ O
, -X- _ O
running -X- _ O
multiple -X- _ O
forward -X- _ O
passes -X- _ O
through -X- _ O
our -X- _ O
neural -X- _ O
networks -X- _ O
, -X- _ O
with -X- _ O
different -X- _ O
, -X- _ O
randomly -X- _ O
sampled -X- _ O
Dropout -X- _ O
masks -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
value -X- _ O
of -X- _ O
k -X- _ O
= -X- _ O
10 -X- _ O
forward -X- _ O
passes -X- _ O
to -X- _ O
form -X- _ O
our -X- _ O
Dropout -X- _ O
distribution -X- _ O
. -X- _ O
Amortized -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
Selection -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
original -X- _ O
Core -X- _ B-MethodName
- -X- _ I-MethodName
Set -X- _ I-MethodName
selection -X- _ O
active -X- _ O
learning -X- _ O
work -X- _ O
introduced -X- _ O
by -X- _ O
Sener -X- _ O
and -X- _ O
Savarese -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
shown -X- _ O
that -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
selection -X- _ O
for -X- _ O
active -X- _ O
learning -X- _ O
can -X- _ O
be -X- _ O
reduced -X- _ O
to -X- _ O
a -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
centers -X- _ O
problem -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
solved -X- _ O
approximately -X- _ O
( -X- _ O
2 -X- _ O
- -X- _ O
OPT -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
greedy -X- _ O
algorithm -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
running -X- _ O
this -X- _ O
algorithm -X- _ O
on -X- _ O
highdimensional -X- _ O
representations -X- _ O
, -X- _ O
across -X- _ O
large -X- _ O
pools -X- _ O
can -X- _ O
be -X- _ O
prohibitive -X- _ O
; -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
selection -X- _ O
is -X- _ O
batch -X- _ O
- -X- _ O
aware -X- _ O
, -X- _ O
requiring -X- _ O
recomputing -X- _ O
distances -X- _ O
from -X- _ O
each -X- _ O
" -X- _ O
clustercenter -X- _ O
" -X- _ O
( -X- _ O
points -X- _ O
in -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
acquired -X- _ O
examples -X- _ O
) -X- _ O
to -X- _ O
all -X- _ O
points -X- _ O
in -X- _ O
the -X- _ O
active -X- _ O
learning -X- _ O
pool -X- _ O
after -X- _ O
each -X- _ O
acquisition -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
can -X- _ O
run -X- _ O
this -X- _ O
out -X- _ O
completely -X- _ O
for -X- _ O
smaller -X- _ O
datasets -X- _ O
( -X- _ O
and -X- _ O
indeed -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
what -X- _ O
we -X- _ O
do -X- _ O
for -X- _ O
our -X- _ O
small -X- _ O
datasets -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Sports -X- _ I-DatasetName
and -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Food -X- _ I-DatasetName
) -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
acquisition -X- _ O
iteration -X- _ O
for -X- _ O
a -X- _ O
large -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
full -X- _ O
VQA-2 -X- _ B-DatasetName
dataset -X- _ O
takes -X- _ O
approximately -X- _ O
20 -X- _ O
GPU -X- _ O
- -X- _ O
hours -X- _ O
on -X- _ O
the -X- _ O
resources -X- _ O
we -X- _ O
have -X- _ O
available -X- _ O
, -X- _ O
or -X- _ O
up -X- _ O
to -X- _ O
9 -X- _ O
days -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
selection -X- _ O
run -X- _ O
. -X- _ O
For -X- _ O
GQA -X- _ B-DatasetName
, -X- _ O
performing -X- _ O
exact -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
selection -X- _ O
takes -X- _ O
at -X- _ O
least -X- _ O
twice -X- _ O
as -X- _ O
long -X- _ O
. -X- _ O
To -X- _ O
still -X- _ O
capture -X- _ O
the -X- _ O
spirit -X- _ O
of -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
diversitybased -X- _ O
selection -X- _ O
in -X- _ O
our -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
instead -X- _ O
introduce -X- _ O
an -X- _ O
amortized -X- _ O
implementation -X- _ O
of -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
selection -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
comprised -X- _ O
of -X- _ O
two -X- _ O
steps -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
downsample -X- _ O
the -X- _ O
high -X- _ O
- -X- _ O
dimensional -X- _ O
representations -X- _ O
( -X- _ O
of -X- _ O
either -X- _ O
the -X- _ O
fused -X- _ O
language -X- _ O
and -X- _ O
text -X- _ O
, -X- _ O
or -X- _ O
either -X- _ O
unimodal -X- _ O
representations -X- _ O
) -X- _ O
via -X- _ O
Principal -X- _ O
Component -X- _ O
Analysis -X- _ O
( -X- _ O
PCA -X- _ O
) -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
distance -X- _ O
computation -X- _ O
faster -X- _ O
by -X- _ O
an -X- _ O
order -X- _ O
of -X- _ O
magnitude -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
updating -X- _ O
distances -X- _ O
from -X- _ O
examples -X- _ O
in -X- _ O
our -X- _ O
acquired -X- _ O
set -X- _ O
to -X- _ O
points -X- _ O
in -X- _ O
our -X- _ O
pool -X- _ O
after -X- _ O
each -X- _ O
acquisitionx -X- _ O
, -X- _ O
we -X- _ O
delay -X- _ O
updates -X- _ O
, -X- _ O
instead -X- _ O
only -X- _ O
refreshing -X- _ O
the -X- _ O
distance -X- _ O
computation -X- _ O
every -X- _ O
2000 -X- _ O
acquisitions -X- _ O
( -X- _ O
roughly -X- _ O
5 -X- _ O
% -X- _ O
of -X- _ O
an -X- _ O
acquisition -X- _ O
batch -X- _ O
for -X- _ O
VQA-2 -X- _ B-DatasetName
) -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
report -X- _ O
results -X- _ O
for -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
selection -X- _ O
with -X- _ O
the -X- _ O
three -X- _ O
different -X- _ O
proposed -X- _ O
representations -X- _ O
( -X- _ O
Fused -X- _ O
, -X- _ O
Language -X- _ O
- -X- _ O
Only -X- _ O
, -X- _ O
Vision -X- _ O
- -X- _ O
Only -X- _ O
) -X- _ O
for -X- _ O
VQA-2 -X- _ B-DatasetName
; -X- _ O
unfortunately -X- _ O
, -X- _ O
for -X- _ O
GQA -X- _ B-DatasetName
and -X- _ O
LXMERT -X- _ B-MethodName
( -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
high -X- _ O
cost -X- _ O
of -X- _ O
training -X- _ O
) -X- _ O
, -X- _ O
even -X- _ O
running -X- _ O
this -X- _ O
amortized -X- _ O
version -X- _ O
of -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
selection -X- _ O
is -X- _ O
prohibitive -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
report -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
results -X- _ O
, -X- _ O
and -X- _ O
omit -X- _ O
the -X- _ O
rest -X- _ O
. -X- _ O
We -X- _ O
include -X- _ O
further -X- _ O
results -X- _ O
from -X- _ O
our -X- _ O
study -X- _ O
of -X- _ O
active -X- _ O
learning -X- _ O
applied -X- _ O
to -X- _ O
VQA -X- _ B-TaskName
, -X- _ O
including -X- _ O
results -X- _ O
on -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Food -X- _ I-DatasetName
( -X- _ O
not -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
body -X- _ O
) -X- _ O
, -X- _ O
active -X- _ O
learning -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
logistic -X- _ O
regression -X- _ O
models -X- _ O
-Log -X- _ O
- -X- _ O
Reg -X- _ O
( -X- _ O
ResNet-101 -X- _ O
) -X- _ O
and -X- _ O
Log -X- _ O
- -X- _ O
Reg -X- _ O
( -X- _ O
Faster -X- _ O
R -X- _ O
- -X- _ O
CNN -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
with -X- _ O
the -X- _ O
4 -X- _ O
acquisition -X- _ O
strategies -X- _ O
not -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
body -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
-Entropy -X- _ O
, -X- _ O
Monte -X- _ O
- -X- _ O
Carlo -X- _ O
Dropout -X- _ O
w/ -X- _ O
Entropy -X- _ O
, -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
( -X- _ O
Language -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
( -X- _ O
Vision -X- _ O
) -X- _ O
. -X- _ O
Figure -X- _ O
9 -X- _ O
shows -X- _ O
results -X- _ O
on -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Food -X- _ I-DatasetName
with -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
, -X- _ O
BUTD -X- _ B-MethodName
, -X- _ O
and -X- _ O
LXMERT -X- _ B-MethodName
models -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
comprised -X- _ O
of -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
of -X- _ I-HyperparameterValue
the -X- _ I-HyperparameterValue
total -X- _ I-HyperparameterValue
pool -X- _ I-HyperparameterValue
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
mostly -X- _ O
similar -X- _ O
to -X- _ O
those -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
; -X- _ O
strategies -X- _ O
track -X- _ O
or -X- _ O
underperform -X- _ O
random -X- _ O
sampling -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
Least -X- _ O
- -X- _ O
Confidence -X- _ O
for -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
model -X- _ O
-however -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
sole -X- _ O
exception -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
LSTM -X- _ B-MethodName
- -X- _ I-MethodName
CNN -X- _ I-MethodName
has -X- _ O
the -X- _ O
highest -X- _ O
training -X- _ O
variance -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
we -X- _ O
try -X- _ O
. -X- _ O
Figure -X- _ O
10 -X- _ O
shows -X- _ O
active -X- _ O
learning -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
Lo -X- _ O
- -X- _ O
gReg -X- _ O
( -X- _ O
ResNet-101 -X- _ O
) -X- _ O
model -X- _ O
on -X- _ O
VQA -X- _ O
- -X- _ O
Sports -X- _ O
( -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
and -X- _ O
VQA-2 -X- _ B-DatasetName
( -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
similar -X- _ O
to -X- _ O
those -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
with -X- _ O
active -X- _ O
learning -X- _ O
failing -X- _ O
to -X- _ O
outperform -X- _ O
random -X- _ O
acqusition -X- _ O
. -X- _ O
Figure -X- _ O
11 -X- _ O
presents -X- _ O
the -X- _ O
same -X- _ O
set -X- _ O
of -X- _ O
experiments -X- _ O
as -X- _ O
the -X- _ O
prior -X- _ O
section -X- _ O
, -X- _ O
except -X- _ O
with -X- _ O
the -X- _ O
LogReg -X- _ B-MethodName
( -X- _ O
Faster -X- _ O
R -X- _ O
- -X- _ O
CNN -X- _ O
) -X- _ O
model -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
object -X- _ O
- -X- _ O
based -X- _ O
Faster -X- _ O
R -X- _ O
- -X- _ O
CNN -X- _ O
representation -X- _ O
enables -X- _ O
much -X- _ O
higher -X- _ O
performance -X- _ O
than -X- _ O
the -X- _ O
ResNet-101 -X- _ O
representation -X- _ O
, -X- _ O
active -X- _ O
learning -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
those -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O
Figure -X- _ O
12 -X- _ O
presents -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
four -X- _ O
other -X- _ O
active -X- _ O
learning -X- _ O
strategies -X- _ O
we -X- _ O
implement -X- _ O
-Entropy -X- _ O
, -X- _ O
Monte -X- _ O
Carlo -X- _ O
Dropout -X- _ O
w/ -X- _ O
Entropy -X- _ O
, -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
( -X- _ O
Language -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Core -X- _ O
- -X- _ O
Set -X- _ O
( -X- _ O
Vision -X- _ O
) -X- _ O
-for -X- _ O
the -X- _ O
BUTD -X- _ B-MethodName
model -X- _ O
. -X- _ O
Results -X- _ O
are -X- _ O
across -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Sports -X- _ I-DatasetName
( -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
, -X- _ O
and -X- _ O
VQA-2 -X- _ B-DatasetName
( -X- _ O
seed -X- _ B-HyperparameterName
set -X- _ I-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
, -X- _ O
50 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
-despite -X- _ O
the -X- _ O
unique -X- _ O
features -X- _ O
of -X- _ O
each -X- _ O
strategy -X- _ O
, -X- _ O
the -X- _ O
trends -X- _ O
remain -X- _ O
consistent -X- _ O
with -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O
Figure -X- _ O
12 -X- _ O
: -X- _ O
Results -X- _ O
with -X- _ O
the -X- _ O
BUTD -X- _ B-MethodName
on -X- _ O
VQA -X- _ B-DatasetName
- -X- _ I-DatasetName
Sports -X- _ I-DatasetName
, -X- _ O
VQA-2 -X- _ B-DatasetName
and -X- _ O
GQA -X- _ O
using -X- _ O
the -X- _ O
alternative -X- _ O
4 -X- _ O
acquisition -X- _ O
strategies -X- _ O
not -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
body -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O
Unsurprisingly -X- _ O
, -X- _ O
results -X- _ O
are -X- _ O
consistent -X- _ O
with -X- _ O
those -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O
Given -X- _ O
that -X- _ O
the -X- _ O
map -X- _ O
for -X- _ O
GQA -X- _ B-DatasetName
is -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
map -X- _ O
for -X- _ O
VQA-2 -X- _ B-DatasetName
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
surprising -X- _ O
that -X- _ O
the -X- _ O
active -X- _ O
learning -X- _ O
acquisitions -X- _ O
follow -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
, -X- _ O
preferring -X- _ O
to -X- _ O
select -X- _ O
" -X- _ O
hard -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
learn -X- _ O
" -X- _ O
examples -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
are -X- _ O
fully -X- _ O
committed -X- _ O
to -X- _ O
maintaining -X- _ O
this -X- _ O
repository -X- _ O
, -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
both -X- _ O
functionality -X- _ O
and -X- _ O
ease -X- _ O
of -X- _ O
use -X- _ O
, -X- _ O
and -X- _ O
will -X- _ O
actively -X- _ O
monitor -X- _ O
both -X- _ O
email -X- _ O
and -X- _ O
Github -X- _ O
Issues -X- _ O
should -X- _ O
there -X- _ O
be -X- _ O
problems -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
Kaylee -X- _ O
Burns -X- _ O
, -X- _ O
Eric -X- _ O
Mitchell -X- _ O
, -X- _ O
Stephen -X- _ O
Mussman -X- _ O
, -X- _ O
Dorsa -X- _ O
Sadigh -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
anonymous -X- _ O
ACL -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
useful -X- _ O
feedback -X- _ O
on -X- _ O
earlier -X- _ O
versions -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
also -X- _ O
grateful -X- _ O
to -X- _ O
Hao -X- _ O
Tan -X- _ O
for -X- _ O
providing -X- _ O
us -X- _ O
with -X- _ O
the -X- _ O
LXMERT -X- _ B-MethodName
checkpoint -X- _ O
trained -X- _ O
without -X- _ O
access -X- _ O
to -X- _ O
VQA -X- _ B-TaskName
datasets -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
for -X- _ O
general -X- _ O
LXMERT -X- _ B-MethodName
fine -X- _ O
- -X- _ O
tuning -X- _ O
pointers -X- _ O
. -X- _ O
Siddharth -X- _ O
Karamcheti -X- _ O
is -X- _ O
graciously -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Open -X- _ O
Philanthropy -X- _ O
Project -X- _ O
AI -X- _ O
Fellowship -X- _ O
. -X- _ O
Christopher -X- _ O
D. -X- _ O
Manning -X- _ O
is -X- _ O
a -X- _ O
CIFAR -X- _ O
Fellow -X- _ O
. -X- _ O

Contrastive -X- _ O
learning -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
image -X- _ O
in -X- _ O
computer -X- _ O
vision -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
contrastive -X- _ O
learning -X- _ O
is -X- _ O
not -X- _ O
widely -X- _ O
utilized -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
a -X- _ O
general -X- _ O
method -X- _ O
of -X- _ O
data -X- _ O
augmentation -X- _ O
for -X- _ O
text -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
method -X- _ O
of -X- _ O
employing -X- _ O
contrastive -X- _ O
learning -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
text -X- _ O
representation -X- _ O
from -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
for -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
. -X- _ O
The -X- _ O
key -X- _ O
knob -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
is -X- _ O
a -X- _ O
unique -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
step -X- _ O
tailored -X- _ O
for -X- _ O
the -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
tasks -X- _ O
by -X- _ O
seamlessly -X- _ O
integrating -X- _ O
linguistic -X- _ O
knowledge -X- _ O
into -X- _ O
the -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
how -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
data -X- _ O
constructed -X- _ O
from -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
bases -X- _ O
can -X- _ O
enhance -X- _ O
the -X- _ O
generality -X- _ O
of -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
three -X- _ O
relation -X- _ O
extraction -X- _ O
benchmark -X- _ O
datasets -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
representation -X- _ O
and -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
interpretability -X- _ O
of -X- _ O
models -X- _ O
by -X- _ O
showing -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
relies -X- _ O
more -X- _ O
on -X- _ O
rationales -X- _ O
for -X- _ O
prediction -X- _ O
. -X- _ O
Our -X- _ O
code -X- _ O
and -X- _ O
data -X- _ O
are -X- _ O
publicly -X- _ O
available -X- _ O
at -X- _ O
: -X- _ O
https://github -X- _ O
. -X- _ O
com -X- _ O
/ -X- _ O
udel -X- _ O
- -X- _ O
biotm -X- _ O
- -X- _ O
lab -X- _ O
/ -X- _ O
BERT -X- _ O
- -X- _ O
CLRE -X- _ O
. -X- _ O
Contrastive -X- _ O
learning -X- _ O
is -X- _ O
a -X- _ O
family -X- _ O
of -X- _ O
methods -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
discriminative -X- _ O
model -X- _ O
by -X- _ O
comparing -X- _ O
input -X- _ O
pairs -X- _ O
( -X- _ O
Le -X- _ O
- -X- _ O
Khac -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
comparison -X- _ O
is -X- _ O
performed -X- _ O
between -X- _ O
positive -X- _ O
pairs -X- _ O
of -X- _ O
" -X- _ O
similar -X- _ O
" -X- _ O
inputs -X- _ O
and -X- _ O
negative -X- _ O
pairs -X- _ O
of -X- _ O
" -X- _ O
dissimilar -X- _ O
" -X- _ O
inputs -X- _ O
. -X- _ O
The -X- _ O
positive -X- _ O
pairs -X- _ O
can -X- _ O
be -X- _ O
generated -X- _ O
in -X- _ O
an -X- _ O
automatic -X- _ O
way -X- _ O
by -X- _ O
transforming -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
to -X- _ O
variants -X- _ O
without -X- _ O
changing -X- _ O
the -X- _ O
key -X- _ O
information -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
rotate -X- _ O
an -X- _ O
image -X- _ O
) -X- _ O
. -X- _ O
Contrastive -X- _ O
learning -X- _ O
can -X- _ O
encode -X- _ O
general -X- _ O
properties -X- _ O
( -X- _ O
e.g. -X- _ O
invariance -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
learned -X- _ O
representation -X- _ O
while -X- _ O
it -X- _ O
is -X- _ O
relatively -X- _ O
hard -X- _ O
for -X- _ O
other -X- _ O
representation -X- _ O
learning -X- _ O
methods -X- _ O
to -X- _ O
achieve -X- _ O
( -X- _ O
Bengio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
,1 -X- _ O
These -X- _ O
authors -X- _ O
contributed -X- _ O
equally -X- _ O
. -X- _ O
2013 -X- _ O
; -X- _ O
Le -X- _ O
- -X- _ O
Khac -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
contrastive -X- _ O
learning -X- _ O
provides -X- _ O
a -X- _ O
powerful -X- _ O
approach -X- _ O
to -X- _ O
learn -X- _ O
representations -X- _ O
in -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
manner -X- _ O
and -X- _ O
has -X- _ O
shown -X- _ O
great -X- _ O
promise -X- _ O
and -X- _ O
achieved -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).Despite -X- _ O
its -X- _ O
advancement -X- _ O
, -X- _ O
contrastive -X- _ O
learning -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
well -X- _ O
studied -X- _ O
in -X- _ O
biomedical -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
BioNLP -X- _ O
) -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
( -X- _ O
RE -X- _ B-TaskName
) -X- _ O
tasks -X- _ O
. -X- _ O
One -X- _ O
obstacle -X- _ O
lies -X- _ O
in -X- _ O
the -X- _ O
discrete -X- _ O
characteristics -X- _ O
of -X- _ O
text -X- _ O
data -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
computer -X- _ O
vision -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
more -X- _ O
challenging -X- _ O
to -X- _ O
design -X- _ O
a -X- _ O
general -X- _ O
and -X- _ O
efficient -X- _ O
data -X- _ O
augmentation -X- _ O
method -X- _ O
to -X- _ O
construct -X- _ O
positive -X- _ O
pairs -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
there -X- _ O
have -X- _ O
been -X- _ O
significant -X- _ O
advances -X- _ O
in -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
facilitate -X- _ O
downstream -X- _ O
BioNLP -X- _ O
tasks -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
leveraging -X- _ O
contrastive -X- _ O
learning -X- _ O
in -X- _ O
the -X- _ O
large -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
more -X- _ O
general -X- _ O
representation -X- _ O
for -X- _ O
RE -X- _ B-TaskName
tasks -X- _ O
remains -X- _ O
unexplored -X- _ O
. -X- _ O
To -X- _ O
bridge -X- _ O
this -X- _ O
gap -X- _ O
, -X- _ O
this -X- _ O
paper -X- _ O
presents -X- _ O
an -X- _ O
innovative -X- _ O
method -X- _ O
of -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
representation -X- _ O
for -X- _ O
biomedical -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
. -X- _ O
As -X- _ O
the -X- _ O
main -X- _ O
difference -X- _ O
from -X- _ O
the -X- _ O
existing -X- _ O
contrastive -X- _ O
learning -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
augment -X- _ O
the -X- _ O
datasets -X- _ O
for -X- _ O
RE -X- _ B-TaskName
tasks -X- _ O
by -X- _ O
randomly -X- _ O
changing -X- _ O
the -X- _ O
words -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
affect -X- _ O
the -X- _ O
relation -X- _ O
expression -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
shortest -X- _ O
dependency -X- _ O
path -X- _ O
( -X- _ O
SDP -X- _ O
) -X- _ O
between -X- _ O
two -X- _ O
entities -X- _ O
captures -X- _ O
the -X- _ O
required -X- _ O
knowledge -X- _ O
for -X- _ O
the -X- _ O
relation -X- _ O
expression -X- _ O
. -X- _ O
We -X- _ O
hence -X- _ O
keep -X- _ O
words -X- _ O
on -X- _ O
SDP -X- _ O
fixed -X- _ O
during -X- _ O
the -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
external -X- _ O
knowledge -X- _ O
bases -X- _ O
to -X- _ O
construct -X- _ O
more -X- _ O
data -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
learned -X- _ O
representation -X- _ O
generalize -X- _ O
better -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
method -X- _ O
that -X- _ O
is -X- _ O
frequently -X- _ O
used -X- _ O
in -X- _ O
distant -X- _ O
supervision -X- _ O
( -X- _ O
Mintz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009;Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016).To -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
as -X- _ O
a -X- _ O
backbone -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
three -X- _ O
widely -X- _ O
studied -X- _ O
RE -X- _ B-TaskName
tasks -X- _ O
in -X- _ O
the -X- _ O
biomedical -X- _ O
domain -X- _ O
: -X- _ O
the -X- _ O
chemical -X- _ B-TaskName
- -X- _ I-TaskName
protein -X- _ I-TaskName
interactions -X- _ I-TaskName
( -X- _ O
ChemProt -X- _ B-TaskName
) -X- _ O
( -X- _ O
Krallinger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
drug -X- _ B-TaskName
- -X- _ I-TaskName
drug -X- _ I-TaskName
interactions -X- _ I-TaskName
( -X- _ O
DDI -X- _ B-TaskName
) -X- _ O
( -X- _ O
Herrero -X- _ O
- -X- _ O
Zazo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
protein -X- _ B-TaskName
- -X- _ I-TaskName
protein -X- _ I-TaskName
interactions -X- _ I-TaskName
( -X- _ O
PPI -X- _ B-TaskName
) -X- _ O
( -X- _ O
Krallinger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
boosts -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
performance -X- _ O
and -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
tasks -X- _ O
. -X- _ O
Interest -X- _ O
has -X- _ O
also -X- _ O
grown -X- _ O
in -X- _ O
designing -X- _ O
interpretable -X- _ O
BioNLP -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
both -X- _ O
plausible -X- _ O
( -X- _ O
accurate -X- _ O
) -X- _ O
and -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
( -X- _ O
faithful -X- _ O
rationales -X- _ O
) -X- _ O
( -X- _ O
DeYoung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Lei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016).Here -X- _ O
rationale -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
supporting -X- _ O
evidence -X- _ O
in -X- _ O
the -X- _ O
inputs -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
make -X- _ O
correct -X- _ O
predictions -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
direction -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
metric -X- _ O
, -X- _ O
" -X- _ O
prediction -X- _ O
shift -X- _ O
" -X- _ O
, -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
sensitivity -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
the -X- _ O
small -X- _ O
changes -X- _ O
( -X- _ O
out -X- _ O
of -X- _ O
the -X- _ O
SDP -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
inputs -X- _ O
will -X- _ O
make -X- _ O
model -X- _ O
change -X- _ O
its -X- _ O
predictions -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
contrastively -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
is -X- _ O
more -X- _ O
robust -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
model -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
make -X- _ O
predictions -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
rationales -X- _ O
of -X- _ O
the -X- _ O
inputs -X- _ O
. -X- _ O
In -X- _ O
sum -X- _ O
, -X- _ O
the -X- _ O
contribution -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
fourfold -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
method -X- _ O
that -X- _ O
utilizes -X- _ O
contrastive -X- _ O
learning -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
on -X- _ O
biomedical -X- _ B-TaskName
relation -X- _ I-TaskName
extraction -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
utilize -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
generate -X- _ O
more -X- _ O
data -X- _ O
for -X- _ O
learning -X- _ O
more -X- _ O
generalized -X- _ O
text -X- _ O
representation.(3 -X- _ O
) -X- _ O
We -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
three -X- _ O
benchmark -X- _ O
datasets -X- _ O
of -X- _ O
relation -X- _ O
extraction -X- _ O
tasks -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
metric -X- _ O
that -X- _ O
aims -X- _ O
to -X- _ O
reveal -X- _ O
the -X- _ O
rationales -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
uses -X- _ O
for -X- _ O
predicting -X- _ O
relations -X- _ O
. -X- _ O
The -X- _ O
code -X- _ O
and -X- _ O
the -X- _ O
new -X- _ O
rationale -X- _ O
test -X- _ O
datasets -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https://github -X- _ O
. -X- _ O
com -X- _ O
/ -X- _ O
udel -X- _ O
- -X- _ O
biotm -X- _ O
- -X- _ O
lab -X- _ O
/ -X- _ O
BERT -X- _ O
- -X- _ O
CLRE -X- _ O
. -X- _ O
The -X- _ O
history -X- _ O
of -X- _ O
contrastive -X- _ O
representation -X- _ O
learning -X- _ O
can -X- _ O
be -X- _ O
traced -X- _ O
back -X- _ O
to -X- _ O
( -X- _ O
Hadsell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
authors -X- _ O
explore -X- _ O
the -X- _ O
method -X- _ O
of -X- _ O
representation -X- _ O
learning -X- _ O
that -X- _ O
similar -X- _ O
inputs -X- _ O
are -X- _ O
mapped -X- _ O
to -X- _ O
nearby -X- _ O
points -X- _ O
in -X- _ O
the -X- _ O
representation -X- _ O
space -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
data -X- _ O
augmentation -X- _ O
techniques -X- _ O
, -X- _ O
deep -X- _ O
neural -X- _ O
network -X- _ O
architectures -X- _ O
, -X- _ O
contrastive -X- _ O
learning -X- _ O
regains -X- _ O
attention -X- _ O
and -X- _ O
achieves -X- _ O
superior -X- _ O
performance -X- _ O
on -X- _ O
visual -X- _ O
representation -X- _ O
learning -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
Momentum -X- _ O
Contrast -X- _ O
( -X- _ O
MoCo -X- _ O
) -X- _ O
framework -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
learn -X- _ O
representation -X- _ O
using -X- _ O
the -X- _ O
mechanism -X- _ O
of -X- _ O
dictionary -X- _ O
look -X- _ O
- -X- _ O
up -X- _ O
: -X- _ O
an -X- _ O
encoded -X- _ O
example -X- _ O
( -X- _ O
the -X- _ O
query -X- _ O
) -X- _ O
should -X- _ O
be -X- _ O
similar -X- _ O
to -X- _ O
its -X- _ O
matching -X- _ O
key -X- _ O
( -X- _ O
augmented -X- _ O
sample -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
example -X- _ O
) -X- _ O
and -X- _ O
dissimilar -X- _ O
to -X- _ O
others -X- _ O
. -X- _ O
In -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
authors -X- _ O
propose -X- _ O
the -X- _ O
SimCLR -X- _ O
frame -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
representations -X- _ O
by -X- _ O
maximizing -X- _ O
the -X- _ O
agreement -X- _ O
between -X- _ O
augmented -X- _ O
views -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
point -X- _ O
. -X- _ O
The -X- _ O
contrastive -X- _ O
representation -X- _ O
has -X- _ O
all -X- _ O
the -X- _ O
properties -X- _ O
that -X- _ O
a -X- _ O
good -X- _ O
representation -X- _ O
should -X- _ O
have -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
Distributed -X- _ O
property -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
Abstraction -X- _ O
and -X- _ O
invariant -X- _ O
property -X- _ O
; -X- _ O
3 -X- _ O
) -X- _ O
Disentangled -X- _ O
representation -X- _ O
( -X- _ O
Bengio -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013;Le -X- _ O
- -X- _ O
Khac -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
distributed -X- _ O
property -X- _ O
emphasizes -X- _ O
the -X- _ O
expressive -X- _ O
aspect -X- _ O
of -X- _ O
the -X- _ O
representation -X- _ O
( -X- _ O
different -X- _ O
data -X- _ O
points -X- _ O
should -X- _ O
have -X- _ O
distinguishable -X- _ O
representations -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
capture -X- _ O
of -X- _ O
abstract -X- _ O
concepts -X- _ O
and -X- _ O
the -X- _ O
invariance -X- _ O
to -X- _ O
small -X- _ O
and -X- _ O
local -X- _ O
changes -X- _ O
are -X- _ O
concerned -X- _ O
in -X- _ O
the -X- _ O
abstraction -X- _ O
and -X- _ O
invariant -X- _ O
property -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
disentangled -X- _ O
representation -X- _ O
's -X- _ O
perspective -X- _ O
, -X- _ O
it -X- _ O
should -X- _ O
encode -X- _ O
as -X- _ O
much -X- _ O
information -X- _ O
as -X- _ O
possible -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
contrastive -X- _ O
learning -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
invariant -X- _ O
aspect -X- _ O
of -X- _ O
the -X- _ O
representation -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
field -X- _ O
, -X- _ O
several -X- _ O
works -X- _ O
have -X- _ O
utilized -X- _ O
the -X- _ O
contrastive -X- _ O
learning -X- _ O
technique -X- _ O
. -X- _ O
Fang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
representation -X- _ O
model -X- _ O
( -X- _ O
CERT -X- _ B-MethodName
) -X- _ O
using -X- _ O
contrastive -X- _ O
learning -X- _ O
at -X- _ O
the -X- _ O
sentence -X- _ O
level -X- _ O
to -X- _ O
benefit -X- _ O
the -X- _ O
language -X- _ O
understanding -X- _ O
tasks -X- _ O
. -X- _ O
Klein -X- _ O
and -X- _ O
Nabi -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
employ -X- _ O
contrastive -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
commonsense -X- _ O
reasoning -X- _ O
problem -X- _ O
. -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
pretraining -X- _ O
framework -X- _ O
for -X- _ O
relation -X- _ O
extraction -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
encoded -X- _ O
information -X- _ O
for -X- _ O
the -X- _ O
textual -X- _ O
context -X- _ O
and -X- _ O
entity -X- _ O
type -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
previous -X- _ O
works -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
different -X- _ O
data -X- _ O
augmentation -X- _ O
techniques -X- _ O
and -X- _ O
utilize -X- _ O
data -X- _ O
from -X- _ O
external -X- _ O
knowledge -X- _ O
bases -X- _ O
in -X- _ O
contrastive -X- _ O
learning -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
relation -X- _ O
extraction -X- _ O
tasks -X- _ O
. -X- _ O
Relation -X- _ O
extraction -X- _ O
is -X- _ O
usually -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
classification -X- _ O
problem -X- _ O
when -X- _ O
the -X- _ O
entity -X- _ O
mentions -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
Many -X- _ O
different -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
to -X- _ O
solve -X- _ O
the -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
problem -X- _ O
( -X- _ O
Culotta -X- _ O
and -X- _ O
Sorensen -X- _ O
, -X- _ O
2004;Sierra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008;Sahu -X- _ O
and -X- _ O
Anand -X- _ O
, -X- _ O
2018;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Su -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
methods -X- _ O
redefine -X- _ O
this -X- _ O
field -X- _ O
with -X- _ O
their -X- _ O
superior -X- _ O
performance -X- _ O
( -X- _ O
Dai -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2015;Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Su -X- _ O
and -X- _ O
Vijay -X- _ O
- -X- _ O
Shanker -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Among -X- _ O
all -X- _ O
the -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
-a -X- _ O
language -X- _ O
representation -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
bidirectional -X- _ O
Transformer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
attracts -X- _ O
lots -X- _ O
of -X- _ O
attention -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
framework -X- _ O
of -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
data -X- _ O
augmentation -X- _ O
of -X- _ O
relation -X- _ O
extraction -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
replace -X- _ O
some -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
not -X- _ O
affecting -X- _ O
the -X- _ O
relation -X- _ O
expression -X- _ O
( -X- _ O
w -X- _ O
i -X- _ O
→ -X- _ O
w -X- _ O
i -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
sample -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
→ -X- _ O
w -X- _ O
j -X- _ O
in -X- _ O
the -X- _ O
right -X- _ O
sample -X- _ O
) -X- _ O
. -X- _ O
different -X- _ O
fields -X- _ O
. -X- _ O
Several -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
have -X- _ O
been -X- _ O
adapted -X- _ O
for -X- _ O
biomedical -X- _ O
domain -X- _ O
: -X- _ O
BioBERT -X- _ B-MethodName
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
SciBERT -X- _ B-MethodName
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Blue -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Peng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
PubMedBERT -X- _ B-MethodName
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
BioBERT -X- _ B-MethodName
, -X- _ O
SciBERT -X- _ B-MethodName
and -X- _ O
BlueBERT -X- _ B-MethodName
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
general -X- _ O
- -X- _ O
domain -X- _ O
BERT -X- _ B-MethodName
using -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
Pub -X- _ B-MethodName
- -X- _ I-MethodName
MedBERT -X- _ I-MethodName
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
is -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
from -X- _ O
scratch -X- _ O
using -X- _ O
PubMed -X- _ O
abstracts -X- _ O
. -X- _ O
In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
increasing -X- _ O
interest -X- _ O
in -X- _ O
designing -X- _ O
more -X- _ O
interpretable -X- _ O
NLP -X- _ O
models -X- _ O
that -X- _ O
reveal -X- _ O
the -X- _ O
logic -X- _ O
behind -X- _ O
model -X- _ O
predictions -X- _ O
. -X- _ O
In -X- _ O
( -X- _ O
DeYoung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
multiple -X- _ O
datasets -X- _ O
of -X- _ O
rationales -X- _ O
( -X- _ O
from -X- _ O
human -X- _ O
experts -X- _ O
) -X- _ O
are -X- _ O
collected -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
research -X- _ O
on -X- _ O
interpretable -X- _ O
models -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O
In -X- _ O
( -X- _ O
Lei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
authors -X- _ O
propose -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
generator -X- _ O
framework -X- _ O
to -X- _ O
automatically -X- _ O
generate -X- _ O
candidate -X- _ O
rationales -X- _ O
to -X- _ O
justify -X- _ O
the -X- _ O
predictions -X- _ O
of -X- _ O
neural -X- _ O
network -X- _ O
models -X- _ O
. -X- _ O
Our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
text -X- _ O
representation -X- _ O
by -X- _ O
maximizing -X- _ O
agreement -X- _ O
between -X- _ O
inputs -X- _ O
from -X- _ O
positive -X- _ O
pairs -X- _ O
via -X- _ O
a -X- _ O
contrastive -X- _ O
loss -X- _ O
in -X- _ O
the -X- _ O
latent -X- _ O
space -X- _ O
and -X- _ O
the -X- _ O
learned -X- _ O
representation -X- _ O
can -X- _ O
then -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
relation -X- _ O
extraction -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
our -X- _ O
framework -X- _ O
of -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
sentence -X- _ O
s -X- _ O
= -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
w -X- _ O
n -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
produce -X- _ O
two -X- _ O
augmented -X- _ O
views -X- _ O
( -X- _ O
a -X- _ O
positive -X- _ O
pair -X- _ O
) -X- _ O
v -X- _ O
= -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
w -X- _ O
i -X- _ O
, -X- _ O
... -X- _ O
w -X- _ O
n -X- _ O
and -X- _ O
v -X- _ O
= -X- _ O
w -X- _ O
1 -X- _ O
... -X- _ O
, -X- _ O
w -X- _ O
j -X- _ O
, -X- _ O
... -X- _ O
w -X- _ O
n -X- _ O
( -X- _ O
i -X- _ O
= -X- _ O
j -X- _ O
) -X- _ O
from -X- _ O
s -X- _ O
by -X- _ O
applying -X- _ O
text -X- _ O
augmentation -X- _ O
technique -X- _ O
( -X- _ O
Section -X- _ O
3.1.1).Our -X- _ O
framework -X- _ O
then -X- _ O
uses -X- _ O
one -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
two -X- _ O
inputs -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
encoder -X- _ O
f -X- _ O
( -X- _ O
Section -X- _ O
3.1.2 -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
projection -X- _ O
head -X- _ O
g -X- _ O
( -X- _ O
Section -X- _ O
3.1.3 -X- _ O
) -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
first -X- _ O
augmented -X- _ O
view -X- _ O
v -X- _ O
, -X- _ O
we -X- _ O
output -X- _ O
a -X- _ O
representation -X- _ O
h -X- _ O
f -X- _ O
( -X- _ O
v -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
projection -X- _ O
z -X- _ O
g(h -X- _ O
) -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
second -X- _ O
augmented -X- _ O
view -X- _ O
v -X- _ O
, -X- _ O
we -X- _ O
output -X- _ O
h -X- _ O
f -X- _ O
( -X- _ O
v -X- _ O
) -X- _ O
and -X- _ O
another -X- _ O
projection -X- _ O
z -X- _ O
g(h -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
contrastive -X- _ O
learning -X- _ O
method -X- _ O
learns -X- _ O
the -X- _ O
representation -X- _ O
by -X- _ O
comparing -X- _ O
different -X- _ O
samples -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Section -X- _ O
3.1.4 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
comparison -X- _ O
is -X- _ O
performed -X- _ O
between -X- _ O
both -X- _ O
similar -X- _ O
inputs -X- _ O
and -X- _ O
dissimilar -X- _ O
inputs -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
similar -X- _ O
inputs -X- _ O
are -X- _ O
positive -X- _ O
pairs -X- _ O
and -X- _ O
the -X- _ O
dissimilar -X- _ O
inputs -X- _ O
are -X- _ O
negative -X- _ O
pairs -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
representations -X- _ O
are -X- _ O
learned -X- _ O
by -X- _ O
leading -X- _ O
the -X- _ O
positive -X- _ O
pairs -X- _ O
to -X- _ O
have -X- _ O
similar -X- _ O
representations -X- _ O
and -X- _ O
making -X- _ O
negative -X- _ O
pairs -X- _ O
have -X- _ O
dissimilar -X- _ O
representations -X- _ O
. -X- _ O
In -X- _ O
applications -X- _ O
, -X- _ O
the -X- _ O
positive -X- _ O
pairs -X- _ O
are -X- _ O
usually -X- _ O
from -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
sample -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
negative -X- _ O
pairs -X- _ O
are -X- _ O
generated -X- _ O
by -X- _ O
selecting -X- _ O
augmented -X- _ O
data -X- _ O
from -X- _ O
different -X- _ O
samples -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
keep -X- _ O
the -X- _ O
encoder -X- _ O
f -X- _ O
as -X- _ O
in -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
any -X- _ O
text -X- _ O
input -X- _ O
x -X- _ O
, -X- _ O
h -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
x -X- _ O
from -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
The -X- _ O
data -X- _ O
augmentation -X- _ O
module -X- _ O
is -X- _ O
a -X- _ O
key -X- _ O
component -X- _ O
of -X- _ O
contrastive -X- _ O
learning -X- _ O
, -X- _ O
which -X- _ O
needs -X- _ O
to -X- _ O
randomly -X- _ O
generate -X- _ O
two -X- _ O
correlated -X- _ O
views -X- _ O
for -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
point -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
the -X- _ O
generated -X- _ O
data -X- _ O
should -X- _ O
be -X- _ O
different -X- _ O
from -X- _ O
each -X- _ O
other -X- _ O
to -X- _ O
make -X- _ O
them -X- _ O
distinguishable -X- _ O
( -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
perspective -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
significantly -X- _ O
different -X- _ O
to -X- _ O
change -X- _ O
the -X- _ O
structure -X- _ O
and -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
especially -X- _ O
difficult -X- _ O
to -X- _ O
augment -X- _ O
the -X- _ O
text -X- _ O
data -X- _ O
of -X- _ O
relation -X- _ O
extraction -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
focus -X- _ O
on -X- _ O
binary -X- _ O
relations -X- _ O
. -X- _ O
Given -X- _ O
< -X- _ O
s -X- _ O
, -X- _ O
e -X- _ O
1 -X- _ O
, -X- _ O
e -X- _ O
2 -X- _ O
, -X- _ O
r -X- _ O
> -X- _ O
, -X- _ O
where -X- _ O
e -X- _ O
1 -X- _ O
and -X- _ O
e -X- _ O
2 -X- _ O
are -X- _ O
two -X- _ O
entity -X- _ O
mentions -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
s -X- _ O
with -X- _ O
the -X- _ O
relation -X- _ O
type -X- _ O
r -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
e -X- _ O
1 -X- _ O
and -X- _ O
e -X- _ O
2 -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
retain -X- _ O
the -X- _ O
relation -X- _ O
expression -X- _ O
between -X- _ O
e -X- _ O
1 -X- _ O
and -X- _ O
e -X- _ O
2 -X- _ O
in -X- _ O
the -X- _ O
augmented -X- _ O
views -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
data -X- _ O
augmentation -X- _ O
method -X- _ O
utilizing -X- _ O
the -X- _ O
shortest -X- _ O
dependency -X- _ O
path -X- _ O
( -X- _ O
SDP -X- _ O
) -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
shortest -X- _ O
dependency -X- _ O
path -X- _ O
captures -X- _ O
the -X- _ O
required -X- _ O
information -X- _ O
to -X- _ O
assert -X- _ O
the -X- _ O
relationship -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
entities -X- _ O
. -X- _ O
Therefore -X- _ O
we -X- _ O
fix -X- _ O
the -X- _ O
shortest -X- _ O
dependency -X- _ O
path -X- _ O
, -X- _ O
and -X- _ O
randomly -X- _ O
change -X- _ O
the -X- _ O
other -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
idea -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
( -X- _ O
Wei -X- _ O
and -X- _ O
Zou -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
We -X- _ O
further -X- _ O
show -X- _ O
that -X- _ O
@PROTEIN$ -X- _ O
directly -X- _ O
interacts -X- _ O
with -X- _ O
@PROTEIN$ -X- _ O
and -X- _ O
Rpn4 -X- _ O
. -X- _ O
After -X- _ O
SR -X- _ O
We -X- _ O
further -X- _ O
show -X- _ O
that -X- _ O
@PROTEIN$ -X- _ O
straight -X- _ O
interacts -X- _ O
with -X- _ O
@PROTEIN$ -X- _ O
and -X- _ O
Rpn4 -X- _ O
. -X- _ O
After -X- _ O
RS -X- _ O
Further -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
@PROTEIN$ -X- _ O
directly -X- _ O
interacts -X- _ O
with -X- _ O
@PROTEIN$ -X- _ O
and -X- _ O
Rpn4 -X- _ O
. -X- _ O
After -X- _ O
RD -X- _ O
We -X- _ O
further -X- _ O
show -X- _ O
that -X- _ O
@PROTEIN$ -X- _ O
interacts -X- _ O
with -X- _ O
@PROTEIN$ -X- _ O
and -X- _ O
Rpn4.Table -X- _ O
1 -X- _ O
: -X- _ O
Examples -X- _ O
after -X- _ O
the -X- _ O
three -X- _ O
operations -X- _ O
for -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O
The -X- _ O
shortest -X- _ O
dependency -X- _ O
path -X- _ O
between -X- _ O
two -X- _ O
proteins -X- _ O
is -X- _ O
" -X- _ O
@PROTEIN$ -X- _ O
interacts -X- _ O
@PROTEIN$ -X- _ O
" -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
marked -X- _ O
with -X- _ O
underline -X- _ O
in -X- _ O
the -X- _ O
examples -X- _ O
. -X- _ O
The -X- _ O
changed -X- _ O
words -X- _ O
are -X- _ O
also -X- _ O
marked -X- _ O
with -X- _ O
bold -X- _ O
font -X- _ O
. -X- _ O
employed -X- _ O
easy -X- _ O
data -X- _ O
augmentation -X- _ O
techniques -X- _ O
to -X- _ O
improve -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
text -X- _ O
classification -X- _ O
tasks -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
preliminary -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
three -X- _ O
techniques -X- _ O
to -X- _ O
randomly -X- _ O
replace -X- _ O
the -X- _ O
tokens -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
and -X- _ O
choose -X- _ O
the -X- _ O
best -X- _ O
one -X- _ O
for -X- _ O
our -X- _ O
contrastive -X- _ O
learning -X- _ O
method -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
Synonym -X- _ B-MethodName
replacement -X- _ I-MethodName
( -X- _ O
SR -X- _ B-MethodName
) -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
Random -X- _ B-MethodName
swap -X- _ I-MethodName
( -X- _ O
RS -X- _ B-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
3 -X- _ O
) -X- _ O
Random -X- _ B-MethodName
deletion -X- _ I-MethodName
( -X- _ O
RD).Table -X- _ B-MethodName
1 -X- _ O
gives -X- _ O
some -X- _ O
samples -X- _ O
after -X- _ O
applying -X- _ O
the -X- _ O
three -X- _ O
operations -X- _ O
on -X- _ O
a -X- _ O
sentence -X- _ O
from -X- _ O
the -X- _ O
PPI -X- _ B-TaskName
task -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
synonym -X- _ B-MethodName
replacement -X- _ I-MethodName
, -X- _ O
we -X- _ O
randomly -X- _ O
replace -X- _ O
n -X- _ O
words -X- _ O
with -X- _ O
their -X- _ O
synonyms -X- _ O
. -X- _ O
To -X- _ O
acquire -X- _ O
the -X- _ O
synonym -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
the -X- _ O
WordNet -X- _ O
database -X- _ O
( -X- _ O
Miller -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
to -X- _ O
extract -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
synonyms -X- _ O
and -X- _ O
randomly -X- _ O
choose -X- _ O
one -X- _ O
from -X- _ O
the -X- _ O
list -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
random -X- _ O
swap -X- _ O
, -X- _ O
we -X- _ O
swap -X- _ O
the -X- _ O
positions -X- _ O
of -X- _ O
two -X- _ O
words -X- _ O
and -X- _ O
repeat -X- _ O
this -X- _ O
operation -X- _ O
n -X- _ O
times -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
random -X- _ O
deletion -X- _ O
, -X- _ O
we -X- _ O
delete -X- _ O
some -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
probability -X- _ B-HyperparameterName
p. -X- _ I-HyperparameterName
The -X- _ O
probability -X- _ B-HyperparameterName
p -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.1 -X- _ B-HyperparameterValue
in -X- _ O
our -X- _ O
experiments -X- _ O
and -X- _ O
the -X- _ O
parameter -X- _ O
n -X- _ O
for -X- _ O
SR -X- _ B-MethodName
and -X- _ O
RS -X- _ B-MethodName
is -X- _ O
calculated -X- _ O
by -X- _ O
p -X- _ O
× -X- _ O
l -X- _ O
, -X- _ O
where -X- _ O
l -X- _ O
is -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
To -X- _ O
examine -X- _ O
which -X- _ O
operation -X- _ O
performs -X- _ O
better -X- _ O
for -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
three -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
using -X- _ O
the -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
augmented -X- _ O
data -X- _ O
( -X- _ O
combined -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
training -X- _ O
data -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
synonym -X- _ B-TaskName
replacement -X- _ I-TaskName
( -X- _ O
SR -X- _ B-TaskName
) -X- _ O
operation -X- _ O
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
tasks -X- _ O
and -X- _ O
we -X- _ O
will -X- _ O
employ -X- _ O
this -X- _ O
operation -X- _ O
in -X- _ O
our -X- _ O
data -X- _ O
augmentation -X- _ O
module -X- _ O
in -X- _ O
our -X- _ O
contrastive -X- _ O
learning -X- _ O
experiments -X- _ O
( -X- _ O
We -X- _ O
will -X- _ O
further -X- _ O
discuss -X- _ O
it -X- _ O
in -X- _ O
Section -X- _ O
5.2 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
our -X- _ O
encoder -X- _ O
for -X- _ O
the -X- _ O
text -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
classification -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
) -X- _ O
output -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
will -X- _ O
be -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
As -X- _ O
demonstrated -X- _ O
in -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
adding -X- _ O
a -X- _ O
nonlinear -X- _ O
projection -X- _ O
head -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
output -X- _ O
will -X- _ O
improve -X- _ O
the -X- _ O
representation -X- _ O
quality -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
same -X- _ O
idea -X- _ O
, -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
perceptron -X- _ O
( -X- _ O
MLP -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
output -X- _ O
h. -X- _ O
Formally -X- _ O
, -X- _ O
z -X- _ O
= -X- _ O
g(h -X- _ O
) -X- _ O
= -X- _ O
W -X- _ O
2 -X- _ O
φ(W -X- _ O
1 -X- _ O
h)and -X- _ O
φ -X- _ O
is -X- _ O
the -X- _ O
ReLU -X- _ O
activation -X- _ O
function -X- _ O
, -X- _ O
W -X- _ O
1 -X- _ O
and -X- _ O
W -X- _ O
2 -X- _ O
are -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
perceptron -X- _ O
in -X- _ O
the -X- _ O
hidden -X- _ O
layers -X- _ O
. -X- _ O
Contrastive -X- _ O
learning -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
make -X- _ O
similar -X- _ O
representations -X- _ O
be -X- _ O
learned -X- _ O
for -X- _ O
the -X- _ O
augmented -X- _ O
samples -X- _ O
( -X- _ O
positive -X- _ O
pairs -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
point -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
work -X- _ O
of -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
design -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
( -X- _ O
Algorithm -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
During -X- _ O
contrastive -X- _ O
learning -X- _ O
, -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
is -X- _ O
calculated -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
augmented -X- _ O
batch -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
batch -X- _ O
. -X- _ O
Given -X- _ O
N -X- _ O
sentences -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
employ -X- _ O
the -X- _ O
data -X- _ O
augmentation -X- _ O
technique -X- _ O
to -X- _ O
acquire -X- _ O
two -X- _ O
views -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
batch -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
2N -X- _ O
views -X- _ O
from -X- _ O
the -X- _ O
batch -X- _ O
. -X- _ O
Given -X- _ O
one -X- _ O
positive -X- _ O
pair -X- _ O
( -X- _ O
two -X- _ O
views -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
sentence -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
treat -X- _ O
the -X- _ O
other -X- _ O
2(N -X- _ O
− -X- _ O
1 -X- _ O
) -X- _ O
within -X- _ O
the -X- _ O
batch -X- _ O
as -X- _ O
negative -X- _ O
examples -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
loss -X- _ O
for -X- _ O
a -X- _ O
positive -X- _ O
pair -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O
l(z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
= -X- _ O
−log -X- _ O
exp(sim(z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
/τ -X- _ O
) -X- _ O
2N -X- _ O
k=1 -X- _ O
1 -X- _ O
[ -X- _ O
z -X- _ O
k -X- _ O
= -X- _ O
z -X- _ O
] -X- _ O
exp(sim(z -X- _ O
, -X- _ O
z -X- _ O
k -X- _ O
) -X- _ O
/τ -X- _ O
) -X- _ O
where -X- _ O
sim(• -X- _ O
, -X- _ O
• -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
function,1 -X- _ O
[ -X- _ O
z -X- _ O
k -X- _ O
= -X- _ O
z -X- _ O
] -X- _ O
is -X- _ O
the -X- _ O
indicator -X- _ O
function -X- _ O
and -X- _ O
τ -X- _ O
is -X- _ O
the -X- _ O
temperature -X- _ O
parameter -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
loss -X- _ O
L -X- _ O
is -X- _ O
computed -X- _ O
across -X- _ O
all -X- _ O
positive -X- _ O
pairs -X- _ O
, -X- _ O
both -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
z -X- _ O
, -X- _ O
z -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
a -X- _ O
batch -X- _ O
. -X- _ O
For -X- _ O
computation -X- _ O
convenience -X- _ O
, -X- _ O
we -X- _ O
arrange -X- _ O
the -X- _ O
( -X- _ O
2k -X- _ O
− -X- _ O
1)-th -X- _ O
example -X- _ O
and -X- _ O
the -X- _ O
2k -X- _ O
- -X- _ O
th -X- _ O
example -X- _ O
in -X- _ O
the -X- _ O
batch -X- _ O
are -X- _ O
generated -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
sentence -X- _ O
, -X- _ O
a.k.a -X- _ O
. -X- _ O
, -X- _ O
( -X- _ O
2k -X- _ O
− -X- _ O
1 -X- _ O
, -X- _ O
2k -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
positive -X- _ O
pair -X- _ O
. -X- _ O
Please -X- _ O
see -X- _ O
Algorithm -X- _ O
1 -X- _ O
for -X- _ O
calculating -X- _ O
the -X- _ O
contrastive -X- _ O
loss -X- _ O
in -X- _ O
one -X- _ O
batch -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
can -X- _ O
update -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
and -X- _ O
projection -X- _ O
head -X- _ O
g -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
loss -X- _ O
L. -X- _ O
Input -X- _ O
: -X- _ O
encoder -X- _ O
f -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
) -X- _ O
, -X- _ O
project -X- _ O
head -X- _ O
g -X- _ O
, -X- _ O
data -X- _ O
augmentation -X- _ O
module -X- _ O
, -X- _ O
data -X- _ O
batch -X- _ O
{ -X- _ O
s -X- _ O
k -X- _ O
} -X- _ O
N -X- _ O
k=1 -X- _ O
; -X- _ O
for -X- _ O
k=1, -X- _ O
... -X- _ O
,N -X- _ O
do -X- _ O
v -X- _ O
, -X- _ O
v -X- _ O
= -X- _ O
data_augment(s -X- _ O
k -X- _ O
) -X- _ O
; -X- _ O
z -X- _ O
2k−1 -X- _ O
= -X- _ O
g(f -X- _ O
( -X- _ O
v -X- _ O
) -X- _ O
) -X- _ O
; -X- _ O
z -X- _ O
2k -X- _ O
= -X- _ O
g(f -X- _ O
( -X- _ O
v -X- _ O
) -X- _ O
) -X- _ O
; -X- _ O
end -X- _ O
L -X- _ O
= -X- _ O
1 -X- _ O
2N -X- _ O
N -X- _ O
k=1 -X- _ O
[ -X- _ O
l(z -X- _ O
2k−1 -X- _ O
, -X- _ O
z -X- _ O
2k -X- _ O
) -X- _ O
+ -X- _ O
l(z -X- _ O
2k -X- _ O
, -X- _ O
z -X- _ O
2k−1 -X- _ O
) -X- _ O
] -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
training -X- _ O
procedure -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
. -X- _ O
It -X- _ O
consists -X- _ O
of -X- _ O
three -X- _ O
stages -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
pretrain -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
unlabeled -X- _ O
data -X- _ O
from -X- _ O
a -X- _ O
specific -X- _ O
domain(e.g -X- _ O
. -X- _ O
, -X- _ O
biomedical -X- _ O
domain -X- _ O
) -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
contrastive -X- _ O
pretraining -X- _ O
on -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
data -X- _ O
as -X- _ O
a -X- _ O
continual -X- _ O
pretraining -X- _ O
step -X- _ O
after -X- _ O
the -X- _ O
domain -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
retain -X- _ O
the -X- _ O
learned -X- _ O
knowledge -X- _ O
from -X- _ O
general -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
add -X- _ O
the -X- _ O
new -X- _ O
features -X- _ O
from -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
finetune -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
RE -X- _ B-TaskName
tasks -X- _ O
to -X- _ O
further -X- _ O
gain -X- _ O
taskspecific -X- _ O
knowledge -X- _ O
through -X- _ O
supervised -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
labeled -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
domain -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
follows -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
using -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
technique -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019).In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
two -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
versions -X- _ O
for -X- _ O
the -X- _ O
biomedical -X- _ O
domain -X- _ O
: -X- _ O
BioBERT -X- _ B-MethodName
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
PubMedBERT -X- _ B-MethodName
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
requires -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
dataset -X- _ O
to -X- _ O
generalize -X- _ O
the -X- _ O
representation -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
our -X- _ O
data -X- _ O
augmentation -X- _ O
for -X- _ O
contrastive -X- _ O
learning -X- _ O
needs -X- _ O
SDP -X- _ O
between -X- _ O
two -X- _ O
given -X- _ O
entities -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
construct -X- _ O
the -X- _ O
augmented -X- _ O
dataset -X- _ O
with -X- _ O
the -X- _ O
entities -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
. -X- _ O
For -X- _ O
these -X- _ O
purposes -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
external -X- _ O
databases -X- _ O
for -X- _ O
the -X- _ O
relations -X- _ O
to -X- _ O
acquire -X- _ O
extra -X- _ O
instances -X- _ O
for -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
assuming -X- _ O
a -X- _ O
curated -X- _ O
database -X- _ O
for -X- _ O
relation -X- _ O
r -X- _ O
contains -X- _ O
all -X- _ O
the -X- _ O
relevant -X- _ O
entities -X- _ O
and -X- _ O
text -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
every -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
entity -X- _ O
pairs -X- _ O
in -X- _ O
one -X- _ O
sentence -X- _ O
and -X- _ O
use -X- _ O
them -X- _ O
as -X- _ O
examples -X- _ O
for -X- _ O
this -X- _ O
relation -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
three -X- _ O
proteins -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
s -X- _ O
: -X- _ O
" -X- _ O
Thus -X- _ O
NIPP1 -X- _ O
works -X- _ O
as -X- _ O
a -X- _ O
molecular -X- _ O
sensor -X- _ O
for -X- _ O
PP1 -X- _ O
to -X- _ O
recognize -X- _ O
phosphorylated -X- _ O
Sap155 -X- _ O
. -X- _ O
" -X- _ O
We -X- _ O
will -X- _ O
generate -X- _ O
three -X- _ O
examples -X- _ O
for -X- _ O
PPI -X- _ O
task -X- _ O
from -X- _ O
this -X- _ O
sentence -X- _ O
: -X- _ O
< -X- _ O
s -X- _ O
, -X- _ O
NIPP1,PP1,PPI -X- _ O
> -X- _ O
, -X- _ O
< -X- _ O
s -X- _ O
, -X- _ O
NIPP1,Sap155,PPI -X- _ O
> -X- _ O
and -X- _ O
< -X- _ O
s -X- _ O
, -X- _ O
PP1,Sap155,PPI>.We -X- _ O
use -X- _ O
the -X- _ O
IntAct -X- _ O
database -X- _ O
( -X- _ O
Orchard -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
interacting -X- _ O
protein -X- _ O
pairs -X- _ O
database -X- _ O
for -X- _ O
the -X- _ O
PPI -X- _ O
task -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
DrugBank -X- _ O
( -X- _ O
Wishart -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
and -X- _ O
BioGRID -X- _ O
( -X- _ O
Stark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
are -X- _ O
utilized -X- _ O
for -X- _ O
DDI -X- _ B-TaskName
and -X- _ O
ChemProt -X- _ B-TaskName
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
column -X- _ O
" -X- _ O
EK -X- _ O
" -X- _ O
of -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
the -X- _ O
statistics -X- _ O
of -X- _ O
datasets -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
generated -X- _ O
by -X- _ O
external -X- _ O
knowledge -X- _ O
bases -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
datasets -X- _ O
from -X- _ O
the -X- _ O
external -X- _ O
database -X- _ O
are -X- _ O
much -X- _ O
larger -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
human -X- _ O
- -X- _ O
labeled -X- _ O
datasets -X- _ O
. -X- _ O
As -X- _ O
discussed -X- _ O
before -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
utilize -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
as -X- _ O
the -X- _ O
encoder -X- _ O
for -X- _ O
the -X- _ O
inputs -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
employ -X- _ O
two -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
for -X- _ O
the -X- _ O
biomedical -X- _ O
domain -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
: -X- _ O
BioBERT -X- _ B-MethodName
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
PubMedBERT -X- _ B-MethodName
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
evaluate -X- _ O
our -X- _ O
method -X- _ O
on -X- _ O
three -X- _ O
benchmark -X- _ O
datasets -X- _ O
. -X- _ O
The -X- _ O
statistics -X- _ O
of -X- _ O
these -X- _ O
datasets -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
For -X- _ O
ChemProt -X- _ B-TaskName
and -X- _ O
DDI -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
the -X- _ O
corpora -X- _ O
in -X- _ O
( -X- _ O
Krallinger -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
Herrero -X- _ O
- -X- _ O
Zazo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
PubMedBERT -X- _ B-MethodName
model -X- _ O
( -X- _ O
Gu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
during -X- _ O
the -X- _ O
model -X- _ O
evaluation -X- _ O
. -X- _ O
We -X- _ O
utilize -X- _ O
the -X- _ O
AIMed -X- _ B-DatasetName
corpus -X- _ O
for -X- _ O
the -X- _ O
PPI -X- _ B-TaskName
task -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
will -X- _ O
employ -X- _ O
10 -X- _ B-HyperparameterValue
- -X- _ O
fold -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
on -X- _ O
it -X- _ O
since -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
standard -X- _ O
split -X- _ O
of -X- _ O
training -X- _ O
and -X- _ O
test -X- _ O
. -X- _ O
PPI -X- _ B-TaskName
is -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
problem -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
will -X- _ O
use -X- _ O
the -X- _ O
standard -X- _ O
precision -X- _ B-MetricName
( -X- _ O
P -X- _ B-MetricName
) -X- _ O
, -X- _ O
recall -X- _ B-MetricName
( -X- _ O
R -X- _ B-MetricName
) -X- _ O
and -X- _ O
F1 -X- _ B-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
( -X- _ O
F -X- _ B-MetricName
) -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
ChemProt -X- _ B-TaskName
and -X- _ O
DDI -X- _ B-TaskName
tasks -X- _ O
are -X- _ O
multiclass -X- _ O
classification -X- _ O
problems -X- _ O
. -X- _ O
The -X- _ O
ChemProt -X- _ B-DatasetName
corpus -X- _ O
is -X- _ O
labeled -X- _ O
with -X- _ O
five -X- _ O
positive -X- _ O
classes -X- _ O
and -X- _ O
the -X- _ O
negative -X- _ O
class -X- _ O
: -X- _ O
CPR:3 -X- _ O
, -X- _ O
CPR:4 -X- _ O
, -X- _ O
CPR:5 -X- _ O
, -X- _ O
CPR:6 -X- _ O
, -X- _ O
CPR:9 -X- _ O
and -X- _ O
negative -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
DDI -X- _ B-DatasetName
corpus -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
four -X- _ O
positive -X- _ O
labels -X- _ O
and -X- _ O
one -X- _ O
negative -X- _ O
label -X- _ O
: -X- _ O
AD -X- _ O
- -X- _ O
VICE -X- _ O
, -X- _ O
EFFECT -X- _ O
, -X- _ O
INT -X- _ O
, -X- _ O
MECHANISM -X- _ O
and -X- _ O
negative -X- _ O
. -X- _ O
The -X- _ O
models -X- _ O
for -X- _ O
ChemProt -X- _ B-TaskName
and -X- _ O
DDI -X- _ B-TaskName
will -X- _ O
be -X- _ O
evaluated -X- _ O
utilizing -X- _ O
micro -X- _ B-MetricName
precision -X- _ I-MetricName
, -X- _ O
recall -X- _ B-MetricName
and -X- _ O
F1 -X- _ B-MetricName
score -X- _ I-MetricName
on -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
negative -X- _ O
classes -X- _ O
. -X- _ O
One -X- _ O
instance -X- _ O
of -X- _ O
relation -X- _ B-TaskName
extraction -X- _ I-TaskName
task -X- _ O
contains -X- _ O
two -X- _ O
parts -X- _ O
: -X- _ O
the -X- _ O
text -X- _ O
and -X- _ O
the -X- _ O
entity -X- _ O
mentions -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
identify -X- _ O
the -X- _ O
positions -X- _ O
of -X- _ O
the -X- _ O
entities -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
relevant -X- _ O
entity -X- _ O
names -X- _ O
with -X- _ O
predefined -X- _ O
tags -X- _ O
by -X- _ O
following -X- _ O
the -X- _ O
standard -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
step -X- _ O
for -X- _ O
relation -X- _ O
extraction -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
protein -X- _ O
names -X- _ O
are -X- _ O
replaced -X- _ O
with -X- _ O
@PROTEIN$ -X- _ O
, -X- _ O
drug -X- _ O
names -X- _ O
with -X- _ O
@DRUG$ -X- _ O
, -X- _ O
and -X- _ O
chemical -X- _ O
names -X- _ O
with -X- _ O
@CHEMI -X- _ O
- -X- _ O
CAL$. -X- _ O
In -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
processed -X- _ O
example -X- _ O
of -X- _ O
the -X- _ O
PPI -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
of -X- _ O
the -X- _ O
BioBERT -X- _ B-MethodName
models -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
16 -X- _ B-HyperparameterValue
, -X- _ O
training -X- _ B-HyperparameterName
epoch -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
max -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
128.During -X- _ B-HyperparameterValue
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
of -X- _ O
PubMedBERT -X- _ B-MethodName
models -X- _ O
, -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8 -X- _ B-HyperparameterValue
, -X- _ O
training -X- _ B-HyperparameterName
epoch -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
and -X- _ O
max -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
are -X- _ O
utilized -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
step -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
with -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
training -X- _ B-HyperparameterName
epoch -X- _ I-HyperparameterName
is -X- _ O
selected -X- _ O
from -X- _ O
[ -X- _ O
2,4,6,8,10 -X- _ B-HyperparameterValue
] -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O
If -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
development -X- _ O
set -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
PPI -X- _ B-TaskName
task -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
use -X- _ O
6 -X- _ B-HyperparameterValue
as -X- _ O
the -X- _ O
default -X- _ O
training -X- _ O
epoch -X- _ B-HyperparameterName
. -X- _ O
Since -X- _ O
contrastive -X- _ O
learning -X- _ O
benefits -X- _ O
more -X- _ O
from -X- _ O
larger -X- _ O
batch -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
and -X- _ O
128 -X- _ B-HyperparameterValue
for -X- _ O
BioBERT -X- _ B-MethodName
and -X- _ O
Pub -X- _ B-MethodName
- -X- _ I-MethodName
MedBERT -X- _ I-MethodName
respectively -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
temperature -X- _ B-HyperparameterName
parameter -X- _ I-HyperparameterName
τ -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.1 -X- _ B-HyperparameterValue
during -X- _ O
the -X- _ O
training -X- _ O
. -X- _ O
5.1 -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
performance -X- _ O
with -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
ever -X- _ O
, -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
on -X- _ O
human -X- _ O
- -X- _ O
labeled -X- _ O
dataset -X- _ O
only -X- _ O
improves -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
margin -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
the -X- _ O
limited -X- _ O
improvement -X- _ O
might -X- _ O
be -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
poor -X- _ O
generalization -X- _ O
on -X- _ O
small -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
more -X- _ O
data -X- _ O
( -X- _ O
EK -X- _ O
data -X- _ O
) -X- _ O
in -X- _ O
contrastive -X- _ O
learning -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
model -X- _ O
generalizability -X- _ O
. -X- _ O
The -X- _ O
data -X- _ O
generated -X- _ O
from -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
base -X- _ O
are -X- _ O
much -X- _ O
more -X- _ O
than -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
human -X- _ O
- -X- _ O
labeled -X- _ O
dataset -X- _ O
( -X- _ O
column -X- _ O
" -X- _ O
EK -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
train -X- _ O
" -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
third -X- _ O
and -X- _ O
sixth -X- _ O
row -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
contrastive -X- _ O
learning -X- _ O
with -X- _ O
more -X- _ O
external -X- _ O
data -X- _ O
can -X- _ O
further -X- _ O
boost -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
Compared -X- _ O
with -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
without -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
an -X- _ O
averaged -X- _ O
F1 -X- _ B-MetricName
score -X- _ I-MetricName
improvement -X- _ O
( -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
) -X- _ O
of -X- _ O
1.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
1.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
and -X- _ O
0.85 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
ChemProt -X- _ B-DatasetName
, -X- _ O
DDI -X- _ B-DatasetName
, -X- _ O
and -X- _ O
PPI -X- _ B-DatasetName
datasets -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Since -X- _ O
PubMedBERT -X- _ B-MethodName
is -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
( -X- _ O
SOTA -X- _ O
) -X- _ O
model -X- _ O
on -X- _ O
these -X- _ O
three -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
improve -X- _ O
its -X- _ O
performance -X- _ O
by -X- _ O
adding -X- _ O
contrastive -X- _ O
pretraining -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
datasets -X- _ O
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
performance -X- _ O
after -X- _ O
including -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
augmented -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
synonym -X- _ B-MethodName
replacement -X- _ I-MethodName
( -X- _ O
SR -X- _ B-MethodName
) -X- _ O
operation -X- _ O
yields -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
tasks -X- _ O
. -X- _ O
Therefore -X- _ O
we -X- _ O
use -X- _ O
it -X- _ O
as -X- _ O
our -X- _ O
default -X- _ O
operation -X- _ O
to -X- _ O
generate -X- _ O
augmented -X- _ O
data -X- _ O
in -X- _ O
all -X- _ O
our -X- _ O
contrastive -X- _ O
learning -X- _ O
experiments -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
notice -X- _ O
that -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
random -X- _ B-MethodName
swap -X- _ I-MethodName
( -X- _ O
RS -X- _ B-MethodName
) -X- _ O
operation -X- _ O
hurt -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
DDI -X- _ B-TaskName
and -X- _ O
PPI -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
this -X- _ O
operation -X- _ O
might -X- _ O
change -X- _ O
the -X- _ O
relation -X- _ O
expression -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
Thus -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
operations -X- _ O
before -X- _ O
applying -X- _ O
them -X- _ O
on -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Instead -X- _ O
, -X- _ O
radiolabeled -X- _ O
@CHEMICAL$ -X- _ O
resulting -X- _ O
from -X- _ O
@PROTEIN$ -X- _ O
hydrolysis -X- _ O
were -X- _ O
observed -X- _ O
. -X- _ O
CPR:9(2 -X- _ O
) -X- _ O
Or -X- _ O
else -X- _ O
, -X- _ O
radiolabeled -X- _ O
@CHEMICAL$ -X- _ O
resulting -X- _ O
from -X- _ O
@PROTEIN$ -X- _ O
hydrolysis -X- _ O
were -X- _ O
observed -X- _ O
. -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
These -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
membrane -X- _ O
@PRO -X- _ O
- -X- _ O
TEIN$ -X- _ O
levels -X- _ O
in -X- _ O
N-38 -X- _ O
neurons -X- _ O
are -X- _ O
dynamically -X- _ O
autoregulated -X- _ O
by -X- _ O
@CHEMICAL$.CPR:3(2 -X- _ O
) -X- _ O
These -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
membrane -X- _ O
@PRO -X- _ O
- -X- _ O
TEIN$ -X- _ O
levels -X- _ O
in -X- _ O
N-38 -X- _ O
nerve -X- _ O
cell -X- _ O
are -X- _ O
dynamically -X- _ O
autoregulated -X- _ O
by -X- _ O
@CHEMICAL$. -X- _ O
As -X- _ O
discussed -X- _ O
previously -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
the -X- _ O
words -X- _ O
on -X- _ O
the -X- _ O
shortest -X- _ O
dependency -X- _ O
path -X- _ O
( -X- _ O
SDP -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
rationales -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
should -X- _ O
make -X- _ O
its -X- _ O
predictions -X- _ O
based -X- _ O
on -X- _ O
them -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
model -X- _ O
predictions -X- _ O
are -X- _ O
all -X- _ O
made -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
define -X- _ O
this -X- _ O
specific -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
completely -X- _ O
faithful -X- _ O
rationales -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
the -X- _ O
rationales -X- _ O
are -X- _ O
more -X- _ O
faithful -X- _ O
means -X- _ O
they -X- _ O
are -X- _ O
more -X- _ O
influential -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
predictions -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
new -X- _ O
metric -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
faithfulness -X- _ O
of -X- _ O
the -X- _ O
rationales -X- _ O
: -X- _ O
" -X- _ O
prediction -X- _ B-MetricName
shift -X- _ I-MetricName
" -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
one -X- _ O
test -X- _ O
example -X- _ O
( -X- _ O
nonnegative -X- _ O
) -X- _ O
with -X- _ O
label -X- _ O
L -X- _ O
t -X- _ O
, -X- _ O
but -X- _ O
changes -X- _ O
its -X- _ O
prediction -X- _ O
on -X- _ O
its -X- _ O
neighbor -X- _ O
( -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
point -X- _ O
) -X- _ O
with -X- _ O
another -X- _ O
label -X- _ O
L -X- _ O
t -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
say -X- _ O
a -X- _ O
" -X- _ O
prediction -X- _ O
shift -X- _ O
" -X- _ O
happens -X- _ O
( -X- _ O
In -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
give -X- _ O
two -X- _ O
examples -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
diction -X- _ O
shift -X- _ O
on -X- _ O
PubMedBERT -X- _ B-MethodName
model -X- _ O
) -X- _ O
. -X- _ O
Fewer -X- _ O
" -X- _ O
prediction -X- _ O
shift -X- _ O
" -X- _ O
indicates -X- _ O
the -X- _ O
information -X- _ O
outside -X- _ O
of -X- _ O
SDP -X- _ O
influences -X- _ O
the -X- _ O
prediction -X- _ O
less -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
the -X- _ O
rationales -X- _ O
are -X- _ O
more -X- _ O
faithful -X- _ O
. -X- _ O
To -X- _ O
generate -X- _ O
a -X- _ O
similar -X- _ O
set -X- _ O
( -X- _ O
with -X- _ O
test -X- _ O
set -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
measurement -X- _ O
of -X- _ O
" -X- _ O
prediction -X- _ O
shift -X- _ O
" -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
same -X- _ O
synonym -X- _ B-MethodName
replacement -X- _ I-MethodName
( -X- _ O
SR -X- _ B-MethodName
) -X- _ O
technique -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
retain -X- _ O
the -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
on -X- _ O
the -X- _ O
shortest -X- _ O
dependency -X- _ O
path -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
entities -X- _ O
, -X- _ O
the -X- _ O
generated -X- _ O
data -X- _ O
should -X- _ O
express -X- _ O
the -X- _ O
same -X- _ O
relation -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
ones -X- _ O
. -X- _ O
The -X- _ O
trained -X- _ O
model -X- _ O
should -X- _ O
predict -X- _ O
them -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
labels -X- _ O
if -X- _ O
the -X- _ O
rationales -X- _ O
of -X- _ O
input -X- _ O
are -X- _ O
utilized -X- _ O
during -X- _ O
inference -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
that -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
say -X- _ O
the -X- _ O
rationales -X- _ O
are -X- _ O
faithful -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
" -X- _ O
prediction -X- _ O
shift -X- _ O
" -X- _ O
on -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
: -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
with -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
illustrates -X- _ O
that -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
with -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
dramatically -X- _ O
reduce -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
" -X- _ O
prediction -X- _ O
shift -X- _ O
" -X- _ O
. -X- _ O
Those -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
with -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
rely -X- _ O
more -X- _ O
on -X- _ O
the -X- _ O
information -X- _ O
of -X- _ O
shortest -X- _ O
dependency -X- _ O
path -X- _ O
for -X- _ O
prediction -X- _ O
, -X- _ O
a.k.a -X- _ O
. -X- _ O
, -X- _ O
the -X- _ O
rationales -X- _ O
are -X- _ O
more -X- _ O
faithful -X- _ O
. -X- _ O
From -X- _ O
another -X- _ O
perspective -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
also -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
with -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
are -X- _ O
resilient -X- _ O
to -X- _ O
small -X- _ O
changes -X- _ O
of -X- _ O
the -X- _ O
inputs -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
the -X- _ O
models -X- _ O
are -X- _ O
more -X- _ O
robust -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
method -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
text -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
differs -X- _ O
from -X- _ O
previous -X- _ O
studies -X- _ O
in -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
text -X- _ O
data -X- _ O
augmentation -X- _ O
with -X- _ O
linguistic -X- _ O
knowledge -X- _ O
and -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
bases -X- _ O
to -X- _ O
construct -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
data -X- _ O
to -X- _ O
facilitate -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
method -X- _ O
outperforms -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
on -X- _ O
three -X- _ O
relation -X- _ O
extraction -X- _ O
benchmarks -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
shows -X- _ O
robustness -X- _ O
to -X- _ O
slightly -X- _ O
changed -X- _ O
inputs -X- _ O
over -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
investigate -X- _ O
different -X- _ O
settings -X- _ O
of -X- _ O
data -X- _ O
augmentation -X- _ O
and -X- _ O
contrastive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
to -X- _ O
exploit -X- _ O
their -X- _ O
capability -X- _ O
on -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
hope -X- _ O
that -X- _ O
our -X- _ O
work -X- _ O
can -X- _ O
inspire -X- _ O
researchers -X- _ O
to -X- _ O
design -X- _ O
better -X- _ O
metrics -X- _ O
and -X- _ O
create -X- _ O
highquality -X- _ O
datasets -X- _ O
for -X- _ O
the -X- _ O
exploration -X- _ O
of -X- _ O
model -X- _ O
interpretability -X- _ O
. -X- _ O

Existing -X- _ O
goal -X- _ O
- -X- _ O
oriented -X- _ O
dialogue -X- _ O
datasets -X- _ O
focus -X- _ O
mainly -X- _ O
on -X- _ O
identifying -X- _ O
slots -X- _ O
and -X- _ O
values -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
customer -X- _ O
support -X- _ O
interactions -X- _ O
in -X- _ O
reality -X- _ O
often -X- _ O
involve -X- _ O
agents -X- _ O
following -X- _ O
multi -X- _ O
- -X- _ O
step -X- _ O
procedures -X- _ O
derived -X- _ O
from -X- _ O
explicitly -X- _ O
- -X- _ O
defined -X- _ O
company -X- _ O
policies -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
To -X- _ O
study -X- _ B-DatasetName
customer -X- _ I-DatasetName
service -X- _ I-DatasetName
dialogue -X- _ I-DatasetName
systems -X- _ I-DatasetName
in -X- _ I-DatasetName
more -X- _ I-DatasetName
realistic -X- _ I-DatasetName
settings -X- _ I-DatasetName
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ B-DatasetName
Action -X- _ I-DatasetName
- -X- _ I-DatasetName
Based -X- _ I-DatasetName
Conversations -X- _ I-DatasetName
Dataset -X- _ O
( -X- _ O
ABCD -X- _ B-DatasetName
) -X- _ O
, -X- _ O
a -X- _ O
fully -X- _ O
- -X- _ O
labeled -X- _ O
dataset -X- _ O
with -X- _ O
over -X- _ O
10 -X- _ O
K -X- _ O
human -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
human -X- _ O
dialogues -X- _ O
containing -X- _ O
55 -X- _ O
distinct -X- _ O
user -X- _ O
intents -X- _ O
requiring -X- _ O
unique -X- _ O
sequences -X- _ O
of -X- _ O
actions -X- _ O
constrained -X- _ O
by -X- _ O
policies -X- _ O
to -X- _ O
achieve -X- _ O
task -X- _ O
success -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
two -X- _ O
additional -X- _ O
dialog -X- _ O
tasks -X- _ O
, -X- _ O
Action -X- _ B-MetricName
State -X- _ I-MetricName
Tracking -X- _ I-MetricName
and -X- _ O
Cascading -X- _ B-MetricName
Dialogue -X- _ I-MetricName
Success -X- _ I-MetricName
, -X- _ O
and -X- _ O
establish -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
baselines -X- _ O
involving -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O
Empirical -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
while -X- _ O
more -X- _ O
sophisticated -X- _ O
networks -X- _ O
outperform -X- _ O
simpler -X- _ O
models -X- _ O
, -X- _ O
a -X- _ O
considerable -X- _ O
gap -X- _ O
( -X- _ O
50.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ B-MetricName
accuracy -X- _ I-MetricName
) -X- _ O
still -X- _ O
exists -X- _ O
to -X- _ O
reach -X- _ O
human -X- _ O
- -X- _ O
level -X- _ O
performance -X- _ O
on -X- _ O
ABCD -X- _ O
. -X- _ O
1 -X- _ O
The -X- _ O
broad -X- _ O
adoption -X- _ O
of -X- _ O
virtual -X- _ O
assistants -X- _ O
and -X- _ O
customer -X- _ O
service -X- _ O
chatbots -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
has -X- _ O
been -X- _ O
driven -X- _ O
in -X- _ O
no -X- _ O
small -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
usefulness -X- _ O
of -X- _ O
these -X- _ O
tools -X- _ O
, -X- _ O
whereby -X- _ O
actions -X- _ O
are -X- _ O
taken -X- _ O
on -X- _ O
behalf -X- _ O
of -X- _ O
the -X- _ O
user -X- _ O
to -X- _ O
accomplish -X- _ O
their -X- _ O
desired -X- _ O
targets -X- _ O
( -X- _ O
Amazon -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Google -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Research -X- _ O
into -X- _ O
taskoriented -X- _ O
dialogue -X- _ O
has -X- _ O
concurrently -X- _ O
made -X- _ O
tremendous -X- _ O
progress -X- _ O
on -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
of -X- _ O
user -X- _ O
needs -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Rastogi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b;Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
selecting -X- _ O
actions -X- _ O
in -X- _ O
real -X- _ O
life -X- _ O
requires -X- _ O
not -X- _ O
only -X- _ O
obeying -X- _ O
user -X- _ O
requests -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
following -X- _ O
practical -X- _ O
policy -X- _ O
limitations -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
at -X- _ O
odds -X- _ O
with -X- _ O
those -X- _ O
requests -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
while -X- _ O
a -X- _ O
user -X- _ O
may -X- _ O
ask -X- _ O
for -X- _ O
a -X- _ O
refund -X- _ O
on -X- _ O
their -X- _ O
purchase -X- _ O
, -X- _ O
an -X- _ O
agent -X- _ O
should -X- _ O
only -X- _ O
honor -X- _ O
such -X- _ O
a -X- _ O
request -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
valid -X- _ O
with -X- _ O
regards -X- _ O
to -X- _ O
the -X- _ O
store -X- _ O
's -X- _ O
return -X- _ O
policy -X- _ O
. -X- _ O
Described -X- _ O
in -X- _ O
actions -X- _ O
, -X- _ O
before -X- _ O
an -X- _ O
agent -X- _ O
1 -X- _ O
All -X- _ O
code -X- _ O
and -X- _ O
data -X- _ O
will -X- _ O
be -X- _ O
available -X- _ O
at -X- _ O
this -X- _ O
location -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
An -X- _ O
interaction -X- _ O
from -X- _ O
ABCD -X- _ B-DatasetName
( -X- _ O
left -X- _ O
) -X- _ O
starts -X- _ O
with -X- _ O
the -X- _ O
customer -X- _ O
receiving -X- _ O
a -X- _ O
prompt -X- _ O
( -X- _ O
top -X- _ O
right -X- _ O
) -X- _ O
to -X- _ O
ground -X- _ O
the -X- _ O
dialogue -X- _ O
. -X- _ O
The -X- _ O
agent -X- _ O
follows -X- _ O
the -X- _ O
guidelines -X- _ O
( -X- _ O
bottom -X- _ O
right -X- _ O
) -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
customer -X- _ O
intent -X- _ O
and -X- _ O
to -X- _ O
assist -X- _ O
them -X- _ O
in -X- _ O
resolving -X- _ O
the -X- _ O
issue -X- _ O
through -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
actions -X- _ O
. -X- _ O
can -X- _ O
[ -X- _ O
Offer -X- _ O
Refund -X- _ O
] -X- _ O
, -X- _ O
they -X- _ O
must -X- _ O
first -X- _ O
[ -X- _ O
Validate -X- _ O
Purchase -X- _ O
] -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
resolving -X- _ O
customer -X- _ O
issues -X- _ O
often -X- _ O
concerns -X- _ O
multiple -X- _ O
actions -X- _ O
completed -X- _ O
in -X- _ O
succession -X- _ O
with -X- _ O
a -X- _ O
specific -X- _ O
order -X- _ O
since -X- _ O
prior -X- _ O
steps -X- _ O
may -X- _ O
influence -X- _ O
future -X- _ O
decision -X- _ O
states -X- _ O
. -X- _ O
( -X- _ O
See -X- _ O
Figure -X- _ O
1)To -X- _ O
more -X- _ O
closely -X- _ O
model -X- _ O
real -X- _ O
customer -X- _ O
service -X- _ O
agents -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
Action -X- _ B-DatasetName
- -X- _ I-DatasetName
Based -X- _ I-DatasetName
Conversations -X- _ I-DatasetName
Dataset -X- _ O
( -X- _ O
ABCD -X- _ B-DatasetName
) -X- _ O
consisting -X- _ O
of -X- _ O
10,042 -X- _ O
conversations -X- _ O
containing -X- _ O
numerous -X- _ O
actions -X- _ O
with -X- _ O
precise -X- _ O
procedural -X- _ O
requirements -X- _ O
. -X- _ O
These -X- _ O
actions -X- _ O
differ -X- _ O
from -X- _ O
typical -X- _ O
dialogue -X- _ O
acts -X- _ O
because -X- _ O
tracking -X- _ O
them -X- _ O
necessitates -X- _ O
striking -X- _ O
a -X- _ O
balance -X- _ O
between -X- _ O
external -X- _ O
user -X- _ O
requests -X- _ O
and -X- _ O
internally -X- _ O
- -X- _ O
imposed -X- _ O
guidelines -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
major -X- _ O
difference -X- _ O
between -X- _ O
ABCD -X- _ O
and -X- _ O
other -X- _ O
dialogue -X- _ O
datasets -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Mul -X- _ B-DatasetName
- -X- _ I-DatasetName
tiWOZ -X- _ I-DatasetName
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
asks -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
adhere -X- _ O
to -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
policies -X- _ O
while -X- _ O
simultaneously -X- _ O
dealing -X- _ O
with -X- _ O
customer -X- _ O
requests -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
prevalent -X- _ O
data -X- _ O
collection -X- _ O
paradigm -X- _ O
involves -X- _ O
Wizard -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Oz -X- _ O
techniques -X- _ O
, -X- _ O
our -X- _ O
situation -X- _ O
containing -X- _ O
asymmetric -X- _ O
speakers -X- _ O
compelled -X- _ O
the -X- _ O
design -X- _ B-TaskName
of -X- _ I-TaskName
a -X- _ I-TaskName
novel -X- _ I-TaskName
Expert -X- _ I-TaskName
Live -X- _ I-TaskName
Chat -X- _ I-TaskName
system -X- _ I-TaskName
. -X- _ O
Our -X- _ O
dataset -X- _ O
includes -X- _ O
asymmetric -X- _ O
speakers -X- _ O
because -X- _ O
, -X- _ O
unlike -X- _ O
customers -X- _ O
, -X- _ O
agents -X- _ O
must -X- _ O
undergo -X- _ O
extensive -X- _ O
training -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
navigate -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
during -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
conversations -X- _ O
. -X- _ O
This -X- _ O
makes -X- _ O
a -X- _ O
naive -X- _ O
pairing -X- _ O
process -X- _ O
untenable -X- _ O
since -X- _ O
arbitrary -X- _ O
matching -X- _ O
might -X- _ O
lead -X- _ O
to -X- _ O
chats -X- _ O
containing -X- _ O
two -X- _ O
users -X- _ O
who -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
role -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
unique -X- _ O
aspects -X- _ O
of -X- _ O
ABCD -X- _ B-DatasetName
, -X- _ O
we -X- _ O
propose -X- _ O
two -X- _ O
new -X- _ O
tasks -X- _ O
. -X- _ O
To -X- _ O
start -X- _ O
, -X- _ O
Action -X- _ B-MetricName
State -X- _ I-MetricName
Tracking -X- _ I-MetricName
( -X- _ O
AST -X- _ B-MetricName
) -X- _ O
closely -X- _ O
mirrors -X- _ O
the -X- _ O
format -X- _ O
of -X- _ O
Dialogue -X- _ O
State -X- _ O
Tracking -X- _ O
where -X- _ O
the -X- _ O
user -X- _ O
intent -X- _ O
is -X- _ O
inferred -X- _ O
from -X- _ O
the -X- _ O
dialogue -X- _ O
history -X- _ O
. -X- _ O
AST -X- _ B-MetricName
then -X- _ O
differs -X- _ O
since -X- _ O
the -X- _ O
correct -X- _ O
state -X- _ O
must -X- _ O
also -X- _ O
be -X- _ O
reconciled -X- _ O
with -X- _ O
the -X- _ O
requirements -X- _ O
outlined -X- _ O
in -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
second -X- _ O
task -X- _ O
, -X- _ O
Cascading -X- _ B-MetricName
Dialogue -X- _ I-MetricName
Success -X- _ I-MetricName
( -X- _ O
CDS -X- _ B-MetricName
) -X- _ O
extends -X- _ O
this -X- _ O
notion -X- _ O
across -X- _ O
the -X- _ O
entire -X- _ O
conversation -X- _ O
. -X- _ O
At -X- _ O
each -X- _ O
turn -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
decides -X- _ O
to -X- _ O
take -X- _ O
an -X- _ O
action -X- _ O
, -X- _ O
respond -X- _ O
with -X- _ O
an -X- _ O
utterance -X- _ O
or -X- _ O
end -X- _ O
the -X- _ O
chat -X- _ O
. -X- _ O
As -X- _ O
needed -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
should -X- _ O
also -X- _ O
predict -X- _ O
the -X- _ O
right -X- _ O
action -X- _ O
or -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
utterance -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
various -X- _ O
models -X- _ O
to -X- _ O
establish -X- _ O
baseline -X- _ O
performance -X- _ O
and -X- _ O
to -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
constraint -X- _ O
. -X- _ O
Experiments -X- _ O
show -X- _ O
that -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
conversation -X- _ O
history -X- _ O
, -X- _ O
conditioning -X- _ O
on -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
further -X- _ O
boosts -X- _ O
performance -X- _ O
, -X- _ O
with -X- _ O
top -X- _ O
models -X- _ O
relying -X- _ O
on -X- _ O
both -X- _ O
aspects -X- _ O
to -X- _ O
reach -X- _ O
31.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
. -X- _ O
Additional -X- _ O
results -X- _ O
show -X- _ O
removing -X- _ O
action -X- _ O
context -X- _ O
hurts -X- _ O
performance -X- _ O
, -X- _ O
implying -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
the -X- _ O
sequential -X- _ O
nature -X- _ O
of -X- _ O
actions -X- _ O
. -X- _ O
Lastly -X- _ O
, -X- _ O
human -X- _ O
evaluation -X- _ O
reaches -X- _ O
82.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
demonstrating -X- _ O
ample -X- _ O
room -X- _ O
for -X- _ O
future -X- _ O
improvement -X- _ O
. -X- _ O
The -X- _ O
contribution -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
three -X- _ O
- -X- _ O
fold -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
provide -X- _ O
a -X- _ O
novel -X- _ O
, -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
dataset -X- _ O
containing -X- _ O
context -X- _ O
- -X- _ O
dependent -X- _ O
, -X- _ O
procedural -X- _ O
actions -X- _ O
along -X- _ O
with -X- _ O
corresponding -X- _ O
Agent -X- _ O
Guidelines -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
establish -X- _ O
a -X- _ O
new -X- _ O
technique -X- _ O
called -X- _ O
Expert -X- _ B-MethodName
Live -X- _ I-MethodName
Chat -X- _ I-MethodName
for -X- _ O
capturing -X- _ O
natural -X- _ O
dialogue -X- _ O
between -X- _ O
two -X- _ O
unequal -X- _ O
interlocutors -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
two -X- _ O
metrics -X- _ O
, -X- _ O
Action -X- _ B-MetricName
State -X- _ I-MetricName
Tracking -X- _ I-MetricName
and -X- _ O
Cascading -X- _ B-MetricName
Dialogue -X- _ I-MetricName
Success -X- _ I-MetricName
, -X- _ O
for -X- _ O
measuring -X- _ O
dialogue -X- _ O
comprehension -X- _ O
with -X- _ O
policy -X- _ O
constraints -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
on -X- _ O
pretrained -X- _ O
neural -X- _ O
models -X- _ O
to -X- _ O
serve -X- _ O
as -X- _ O
baselines -X- _ O
for -X- _ O
these -X- _ O
tasks -X- _ O
. -X- _ O
Traditional -X- _ O
Dialogue -X- _ O
Datasets -X- _ O
In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
dialogue -X- _ O
datasets -X- _ O
have -X- _ O
grown -X- _ O
in -X- _ O
size -X- _ O
from -X- _ O
hundreds -X- _ O
of -X- _ O
conversations -X- _ O
to -X- _ O
the -X- _ O
tens -X- _ O
of -X- _ O
thousands -X- _ O
( -X- _ O
Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Peskov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Unlike -X- _ O
opendomain -X- _ O
chatbots -X- _ O
often -X- _ O
built -X- _ O
for -X- _ O
entertainment -X- _ O
, -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
dialogue -X- _ O
systems -X- _ O
trained -X- _ O
on -X- _ O
such -X- _ O
datasets -X- _ O
are -X- _ O
intended -X- _ O
for -X- _ O
solving -X- _ O
user -X- _ O
issues -X- _ O
. -X- _ O
The -X- _ O
resolution -X- _ O
of -X- _ O
these -X- _ O
issues -X- _ O
implicitly -X- _ O
requires -X- _ O
taking -X- _ O
actions -X- _ O
, -X- _ O
where -X- _ O
an -X- _ O
action -X- _ O
is -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
utterance -X- _ O
decision -X- _ O
that -X- _ O
depends -X- _ O
on -X- _ O
both -X- _ O
user -X- _ O
and -X- _ O
system -X- _ O
inputs -X- _ O
. -X- _ O
Despite -X- _ O
the -X- _ O
tremendous -X- _ O
number -X- _ O
of -X- _ O
dialogues -X- _ O
, -X- _ O
examples -X- _ O
in -X- _ O
previous -X- _ O
benchmarks -X- _ O
fixate -X- _ O
on -X- _ O
the -X- _ O
single -X- _ O
knowledge -X- _ O
base -X- _ O
( -X- _ O
KB -X- _ O
) -X- _ O
lookup -X- _ O
action -X- _ O
where -X- _ O
the -X- _ O
agent -X- _ O
searches -X- _ O
for -X- _ O
an -X- _ O
item -X- _ O
that -X- _ O
matches -X- _ O
the -X- _ O
user -X- _ O
's -X- _ O
desires -X- _ O
and -X- _ O
is -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
KB -X- _ O
. -X- _ O
By -X- _ O
sticking -X- _ O
to -X- _ O
this -X- _ O
sole -X- _ O
interaction -X- _ O
, -X- _ O
conversations -X- _ O
can -X- _ O
be -X- _ O
generated -X- _ O
through -X- _ O
rules -X- _ O
( -X- _ O
Weston -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
paraphrased -X- _ O
from -X- _ O
templates -X- _ O
( -X- _ O
Byrne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
taken -X- _ O
from -X- _ O
static -X- _ O
text -X- _ O
scenarios -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
dialogues -X- _ O
that -X- _ O
are -X- _ O
predominantly -X- _ O
homogeneous -X- _ O
in -X- _ O
nature -X- _ O
. -X- _ O
Many -X- _ O
datasets -X- _ O
have -X- _ O
scaled -X- _ O
to -X- _ O
more -X- _ O
domains -X- _ O
as -X- _ O
well -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Peskov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
Since -X- _ O
each -X- _ O
new -X- _ O
domain -X- _ O
introduces -X- _ O
a -X- _ O
KB -X- _ O
lookup -X- _ O
requiring -X- _ O
different -X- _ O
slotvalues -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
unique -X- _ O
actions -X- _ O
grows -X- _ O
as -X- _ O
a -X- _ O
linear -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
domains -X- _ O
covered -X- _ O
. -X- _ O
Rather -X- _ O
than -X- _ O
expanding -X- _ O
wider -X- _ O
, -X- _ O
ABCD -X- _ B-DatasetName
instead -X- _ O
focuses -X- _ O
deeper -X- _ O
by -X- _ O
increasing -X- _ O
the -X- _ O
count -X- _ O
and -X- _ O
diversity -X- _ O
of -X- _ O
actions -X- _ O
within -X- _ O
a -X- _ O
single -X- _ O
domain -X- _ O
. -X- _ O
Exploring -X- _ O
Other -X- _ O
Avenues -X- _ O
Multiple -X- _ O
aspects -X- _ O
are -X- _ O
explored -X- _ O
by -X- _ O
conversational -X- _ O
datasets -X- _ O
attempting -X- _ O
to -X- _ O
mimic -X- _ O
reality -X- _ O
. -X- _ O
Rashkin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
studies -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
a -X- _ O
dialogue -X- _ O
model -X- _ O
to -X- _ O
handle -X- _ O
empathy -X- _ O
, -X- _ O
while -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
focuses -X- _ O
on -X- _ O
commonsense -X- _ O
reasoning -X- _ O
. -X- _ O
Another -X- _ O
approach -X- _ O
is -X- _ O
to -X- _ O
augment -X- _ O
dialogues -X- _ O
with -X- _ O
multi -X- _ O
- -X- _ O
modality -X- _ O
including -X- _ O
audio -X- _ O
( -X- _ O
Castro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
visual -X- _ O
( -X- _ O
Das -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017a -X- _ O
) -X- _ O
components -X- _ O
. -X- _ O
Other -X- _ O
researchers -X- _ O
have -X- _ O
explored -X- _ O
grounding -X- _ O
conversations -X- _ O
with -X- _ O
external -X- _ O
data -X- _ O
sources -X- _ O
such -X- _ O
as -X- _ O
personas -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
online -X- _ O
reviews -X- _ O
( -X- _ O
Ghazvininejad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
large -X- _ O
knowledge -X- _ O
bases -X- _ O
( -X- _ O
Dinan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Intricate -X- _ O
dialogues -X- _ O
can -X- _ O
also -X- _ O
appear -X- _ O
when -X- _ O
studying -X- _ O
collaboration -X- _ O
( -X- _ O
He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
or -X- _ O
negotiation -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
which -X- _ O
strongly -X- _ O
encourage -X- _ O
interaction -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
participant -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
, -X- _ O
ABCD -X- _ O
aims -X- _ O
to -X- _ O
make -X- _ O
dialogue -X- _ O
more -X- _ O
realistic -X- _ O
by -X- _ O
considering -X- _ O
distinct -X- _ O
constraints -X- _ O
from -X- _ O
policies -X- _ O
. -X- _ O
Dialogues -X- _ O
with -X- _ O
Policies -X- _ O
Procedural -X- _ O
actions -X- _ O
following -X- _ O
strict -X- _ O
guidelines -X- _ O
naturally -X- _ O
emerge -X- _ O
in -X- _ O
dialogue -X- _ O
research -X- _ O
geared -X- _ O
towards -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
appli -X- _ O
- -X- _ O
Subflows -X- _ O
recover -X- _ O
- -X- _ O
username -X- _ O
, -X- _ O
1 -X- _ O
recover -X- _ O
- -X- _ O
password -X- _ O
, -X- _ O
1 -X- _ O
reset-2fa -X- _ O
, -X- _ O
1 -X- _ O
status -X- _ O
- -X- _ O
service -X- _ O
- -X- _ O
added -X- _ O
, -X- _ O
2 -X- _ O
status -X- _ O
- -X- _ O
service -X- _ O
- -X- _ O
removed -X- _ O
, -X- _ O
2 -X- _ O
statusshipping -X- _ O
- -X- _ O
question -X- _ O
, -X- _ O
2 -X- _ O
status -X- _ O
- -X- _ O
credit -X- _ O
- -X- _ O
missing -X- _ O
, -X- _ O
2 -X- _ O
manage -X- _ O
- -X- _ O
change -X- _ O
- -X- _ O
address -X- _ O
, -X- _ O
2 -X- _ O
manage -X- _ O
- -X- _ O
change -X- _ O
- -X- _ O
name -X- _ O
, -X- _ O
2 -X- _ O
manage -X- _ O
- -X- _ O
changephone -X- _ O
, -X- _ O
2 -X- _ O
manage -X- _ O
- -X- _ O
payment -X- _ O
- -X- _ O
method -X- _ O
, -X- _ O
2 -X- _ O
status -X- _ O
- -X- _ O
mystery -X- _ O
- -X- _ O
fee -X- _ O
, -X- _ O
3 -X- _ O
status -X- _ O
- -X- _ O
delivery -X- _ O
- -X- _ O
time -X- _ O
, -X- _ O
3 -X- _ O
status -X- _ O
- -X- _ O
payment -X- _ O
- -X- _ O
method -X- _ O
, -X- _ O
3 -X- _ O
statusquantity -X- _ O
, -X- _ O
3 -X- _ O
manage -X- _ O
- -X- _ O
upgrade -X- _ O
, -X- _ O
3 -X- _ O
manage -X- _ O
- -X- _ O
downgrade -X- _ O
, -X- _ O
3 -X- _ O
manage -X- _ O
- -X- _ O
create -X- _ O
, -X- _ O
3 -X- _ O
manage -X- _ O
- -X- _ O
cancel -X- _ O
, -X- _ O
3 -X- _ O
refund -X- _ O
- -X- _ O
initiate -X- _ O
, -X- _ O
4 -X- _ O
refundupdate -X- _ O
, -X- _ O
4 -X- _ O
refund -X- _ O
- -X- _ O
status -X- _ O
, -X- _ O
4 -X- _ O
return -X- _ O
- -X- _ O
stain -X- _ O
, -X- _ O
4 -X- _ O
return -X- _ O
- -X- _ O
color -X- _ O
, -X- _ O
4 -X- _ O
return -X- _ O
- -X- _ O
size -X- _ O
, -X- _ O
4 -X- _ O
bad -X- _ O
- -X- _ O
price -X- _ O
- -X- _ O
competitor -X- _ O
, -X- _ O
5 -X- _ O
bad -X- _ O
- -X- _ O
price -X- _ O
- -X- _ O
yesterday -X- _ O
, -X- _ O
5 -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
stock -X- _ O
- -X- _ O
general -X- _ O
, -X- _ O
5 -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
stock -X- _ O
- -X- _ O
one -X- _ O
- -X- _ O
item -X- _ O
, -X- _ O
5 -X- _ O
promo -X- _ O
- -X- _ O
code -X- _ O
- -X- _ O
invalid -X- _ O
, -X- _ O
5 -X- _ O
promo -X- _ O
- -X- _ O
code -X- _ O
- -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
date -X- _ O
, -X- _ O
5 -X- _ O
mistimed -X- _ O
- -X- _ O
billingalready -X- _ O
- -X- _ O
returned -X- _ O
, -X- _ O
5 -X- _ O
mistimed -X- _ O
- -X- _ O
billing -X- _ O
- -X- _ O
never -X- _ O
- -X- _ O
bought -X- _ O
, -X- _ O
5 -X- _ O
status -X- _ O
, -X- _ O
6 -X- _ O
manage -X- _ O
, -X- _ O
6 -X- _ O
missing -X- _ O
, -X- _ O
6 -X- _ O
cost -X- _ O
, -X- _ O
6 -X- _ O
boots -X- _ O
, -X- _ O
7 -X- _ O
shirt -X- _ O
, -X- _ O
7 -X- _ O
jeans -X- _ O
, -X- _ O
7 -X- _ O
jacket -X- _ O
, -X- _ O
7 -X- _ O
pricing -X- _ O
, -X- _ O
8 -X- _ O
membership -X- _ O
, -X- _ O
8 -X- _ O
timing -X- _ O
, -X- _ O
8 -X- _ O
policy -X- _ O
, -X- _ O
8 -X- _ O
status -X- _ O
- -X- _ O
active -X- _ O
, -X- _ O
9 -X- _ O
status -X- _ O
- -X- _ O
due -X- _ O
- -X- _ O
amount -X- _ O
, -X- _ O
9 -X- _ O
status -X- _ O
- -X- _ O
due -X- _ O
- -X- _ O
date -X- _ O
, -X- _ O
9 -X- _ O
manage -X- _ O
- -X- _ O
pay -X- _ O
- -X- _ O
bill -X- _ O
, -X- _ O
9 -X- _ O
manage -X- _ O
- -X- _ O
extension -X- _ O
, -X- _ O
9 -X- _ O
manage -X- _ O
- -X- _ O
dispute -X- _ O
- -X- _ O
bill -X- _ O
, -X- _ O
9 -X- _ O
credit -X- _ O
- -X- _ O
card -X- _ O
, -X- _ O
10 -X- _ O
shopping -X- _ O
- -X- _ O
cart -X- _ O
, -X- _ O
10 -X- _ O
search -X- _ O
- -X- _ O
results -X- _ O
, -X- _ O
10 -X- _ O
slow -X- _ O
- -X- _ O
speed -X- _ O
10 -X- _ O
Actions -X- _ O
verify -X- _ O
- -X- _ O
identity -X- _ O
, -X- _ O
ask -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
oracle -X- _ O
, -X- _ O
validate -X- _ O
- -X- _ O
purchase -X- _ O
, -X- _ O
make -X- _ O
- -X- _ O
password -X- _ O
, -X- _ O
promo -X- _ O
- -X- _ O
code -X- _ O
, -X- _ O
subscription -X- _ O
- -X- _ O
status -X- _ O
, -X- _ O
offer -X- _ O
- -X- _ O
refund -X- _ O
, -X- _ O
make -X- _ O
- -X- _ O
purchase -X- _ O
, -X- _ O
record -X- _ O
- -X- _ O
reason -X- _ O
, -X- _ O
enter -X- _ O
- -X- _ O
details -X- _ O
, -X- _ O
shipping -X- _ O
- -X- _ O
status -X- _ O
, -X- _ O
update -X- _ O
- -X- _ O
order -X- _ O
, -X- _ O
pull -X- _ O
- -X- _ O
up -X- _ O
- -X- _ O
account -X- _ O
, -X- _ O
update -X- _ O
- -X- _ O
account -X- _ O
, -X- _ O
sendlink -X- _ O
, -X- _ O
notify -X- _ O
- -X- _ O
team -X- _ O
, -X- _ O
membership -X- _ O
, -X- _ O
search -X- _ O
- -X- _ O
faq -X- _ O
, -X- _ O
try -X- _ O
- -X- _ O
again -X- _ O
, -X- _ O
log -X- _ O
- -X- _ O
out -X- _ O
- -X- _ O
in -X- _ O
, -X- _ O
instructions -X- _ O
, -X- _ O
search -X- _ O
- -X- _ O
jeans -X- _ O
, -X- _ O
search -X- _ O
- -X- _ O
shirt -X- _ O
, -X- _ O
searchboots -X- _ O
, -X- _ O
search -X- _ O
- -X- _ O
jacket -X- _ O
, -X- _ O
search -X- _ O
- -X- _ O
pricing -X- _ O
, -X- _ O
search -X- _ O
- -X- _ O
membership -X- _ O
, -X- _ O
search -X- _ O
- -X- _ O
timing -X- _ O
, -X- _ O
search -X- _ O
- -X- _ O
policy -X- _ O
, -X- _ O
select -X- _ O
- -X- _ O
faq -X- _ O
Table -X- _ O
1 -X- _ O
: -X- _ O
Full -X- _ O
ontology -X- _ O
of -X- _ O
Agent -X- _ O
Guidelines -X- _ O
decomposable -X- _ O
into -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
flows -X- _ O
describing -X- _ O
the -X- _ O
overall -X- _ O
category -X- _ O
and -X- _ O
subflows -X- _ O
defining -X- _ O
a -X- _ O
unique -X- _ O
set -X- _ O
of -X- _ O
intents -X- _ O
. -X- _ O
All -X- _ O
actions -X- _ O
are -X- _ O
also -X- _ O
shown -X- _ O
. -X- _ O
Upper -X- _ O
script -X- _ O
numeral -X- _ O
indicates -X- _ O
the -X- _ O
flow -X- _ O
that -X- _ O
the -X- _ O
subflow -X- _ O
belongs -X- _ O
to -X- _ O
. -X- _ O
1 -X- _ O
: -X- _ O
account -X- _ O
access -X- _ O
, -X- _ O
2 -X- _ O
: -X- _ O
manage -X- _ O
account -X- _ O
, -X- _ O
3 -X- _ O
: -X- _ O
order -X- _ O
issue -X- _ O
, -X- _ O
4 -X- _ O
: -X- _ O
product -X- _ O
defect -X- _ O
, -X- _ O
5 -X- _ O
: -X- _ O
purchase -X- _ O
dispute -X- _ O
, -X- _ O
6 -X- _ O
: -X- _ O
shipping -X- _ O
issue -X- _ O
, -X- _ O
7 -X- _ O
: -X- _ O
single -X- _ O
item -X- _ O
query -X- _ O
, -X- _ O
8 -X- _ O
: -X- _ O
storewide -X- _ O
query -X- _ O
, -X- _ O
9 -X- _ O
: -X- _ O
subscription -X- _ O
inquiry -X- _ O
, -X- _ O
10 -X- _ O
: -X- _ O
troubleshoot -X- _ O
site -X- _ O
cations -X- _ O
. -X- _ O
Hybrid -X- _ O
Code -X- _ O
Networks -X- _ O
encode -X- _ O
business -X- _ O
logic -X- _ O
through -X- _ O
masking -X- _ O
templates -X- _ O
since -X- _ O
various -X- _ O
behaviors -X- _ O
become -X- _ O
nonsensical -X- _ O
in -X- _ O
certain -X- _ O
situations -X- _ O
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Research -X- _ O
from -X- _ O
Moiseeva -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
studies -X- _ O
multi -X- _ O
- -X- _ O
purpose -X- _ O
virtual -X- _ O
assistants -X- _ O
that -X- _ O
attempt -X- _ O
to -X- _ O
distinguish -X- _ O
among -X- _ O
thirteen -X- _ O
explicit -X- _ O
actions -X- _ O
. -X- _ O
The -X- _ O
closest -X- _ O
prior -X- _ O
work -X- _ O
to -X- _ O
ABCD -X- _ B-DatasetName
is -X- _ O
the -X- _ O
Schema -X- _ B-DatasetName
Guided -X- _ I-DatasetName
Dialogue -X- _ I-DatasetName
( -X- _ O
SGD -X- _ B-DatasetName
) -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
contains -X- _ O
dozens -X- _ O
of -X- _ O
API -X- _ O
calls -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
individual -X- _ O
actions -X- _ O
sending -X- _ O
commands -X- _ O
to -X- _ O
a -X- _ O
SQL -X- _ O
engine -X- _ O
( -X- _ O
Rastogi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
functionality -X- _ O
of -X- _ O
these -X- _ O
actions -X- _ O
is -X- _ O
occasionally -X- _ O
restricted -X- _ O
to -X- _ O
reflect -X- _ O
constraints -X- _ O
of -X- _ O
real -X- _ O
- -X- _ O
life -X- _ O
services -X- _ O
. -X- _ O
The -X- _ O
action -X- _ O
restrictions -X- _ O
within -X- _ O
ABCD -X- _ B-DatasetName
are -X- _ O
made -X- _ O
explicit -X- _ O
by -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
manual -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
task -X- _ O
setting -X- _ O
of -X- _ O
ABCD -X- _ B-DatasetName
by -X- _ O
following -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
example -X- _ O
dialog -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
During -X- _ O
data -X- _ O
collection -X- _ O
, -X- _ O
customers -X- _ O
are -X- _ O
given -X- _ O
a -X- _ O
simple -X- _ O
prompt -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
You -X- _ O
want -X- _ O
to -X- _ O
keep -X- _ O
your -X- _ O
subscription -X- _ O
another -X- _ O
year -X- _ O
. -X- _ O
" -X- _ O
) -X- _ O
instead -X- _ O
of -X- _ O
step -X- _ O
- -X- _ O
by -X- _ O
- -X- _ O
step -X- _ O
instructions -X- _ O
, -X- _ O
which -X- _ O
reflects -X- _ O
how -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
customers -X- _ O
innately -X- _ O
understand -X- _ O
their -X- _ O
own -X- _ O
issue -X- _ O
, -X- _ O
but -X- _ O
only -X- _ O
have -X- _ O
a -X- _ O
rough -X- _ O
idea -X- _ O
of -X- _ O
how -X- _ O
to -X- _ O
resolve -X- _ O
said -X- _ O
issue -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
customers -X- _ O
within -X- _ O
ABCD -X- _ B-DatasetName
remain -X- _ O
oblivious -X- _ O
towards -X- _ O
what -X- _ O
values -X- _ O
apply -X- _ O
to -X- _ O
which -X- _ O
actions -X- _ O
, -X- _ O
nor -X- _ O
are -X- _ O
they -X- _ O
aware -X- _ O
that -X- _ O
actions -X- _ O
exist -X- _ O
in -X- _ O
first -X- _ O
place -X- _ O
. -X- _ O
This -X- _ O
ambiguity -X- _ O
forces -X- _ O
the -X- _ O
agent -X- _ O
and -X- _ O
customer -X- _ O
to -X- _ O
collaboratively -X- _ O
uncover -X- _ O
the -X- _ O
correct -X- _ O
latent -X- _ O
intent -X- _ O
through -X- _ O
back -X- _ O
and -X- _ O
forth -X- _ O
communication -X- _ O
, -X- _ O
naturally -X- _ O
leading -X- _ O
to -X- _ O
longer -X- _ O
dialogues -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
standard -X- _ O
dialog -X- _ O
setup -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
starts -X- _ O
by -X- _ O
parsing -X- _ O
the -X- _ O
dialogue -X- _ O
history -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
customer -X- _ O
intent -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
is -X- _ O
a -X- _ O
subscription -X- _ O
extension -X- _ O
. -X- _ O
ABCD -X- _ B-DatasetName
then -X- _ O
diverges -X- _ O
as -X- _ O
the -X- _ O
next -X- _ O
step -X- _ O
involves -X- _ O
interpreting -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
, -X- _ O
a -X- _ O
document -X- _ O
representing -X- _ O
the -X- _ O
internal -X- _ O
policies -X- _ O
of -X- _ O
a -X- _ O
company -X- _ O
in -X- _ O
the -X- _ O
online -X- _ O
retail -X- _ O
domain -X- _ O
( -X- _ O
See -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
Using -X- _ O
the -X- _ O
guidelines -X- _ O
, -X- _ O
the -X- _ O
trained -X- _ O
agent -X- _ O
should -X- _ O
find -X- _ O
the -X- _ O
one -X- _ O
unique -X- _ O
subflow -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
customer -X- _ O
intent -X- _ O
. -X- _ O
Each -X- _ O
subflow -X- _ O
in -X- _ O
turn -X- _ O
is -X- _ O
defined -X- _ O
by -X- _ O
exactly -X- _ O
one -X- _ O
unique -X- _ O
sequence -X- _ O
of -X- _ O
actions -X- _ O
. -X- _ O
While -X- _ O
identifying -X- _ O
a -X- _ O
subflow -X- _ O
may -X- _ O
seem -X- _ O
straightforward -X- _ O
, -X- _ O
information -X- _ O
asymmetry -X- _ O
prevents -X- _ O
the -X- _ O
customers -X- _ O
from -X- _ O
directly -X- _ O
revealing -X- _ O
the -X- _ O
name -X- _ O
of -X- _ O
their -X- _ O
intent -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
customer -X- _ O
might -X- _ O
inquire -X- _ O
about -X- _ O
the -X- _ O
status -X- _ O
of -X- _ O
their -X- _ O
recent -X- _ O
purchase -X- _ O
, -X- _ O
but -X- _ O
an -X- _ O
agent -X- _ O
has -X- _ O
over -X- _ O
a -X- _ O
dozen -X- _ O
different -X- _ O
subflows -X- _ O
related -X- _ O
to -X- _ O
order -X- _ O
statuses -X- _ O
, -X- _ O
so -X- _ O
selecting -X- _ O
the -X- _ O
right -X- _ O
one -X- _ O
suddenly -X- _ O
becomes -X- _ O
highly -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
eventually -X- _ O
figures -X- _ O
out -X- _ O
the -X- _ O
correct -X- _ O
subflow -X- _ O
and -X- _ O
begins -X- _ O
to -X- _ O
execute -X- _ O
actions -X- _ O
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
recording -X- _ O
values -X- _ O
given -X- _ O
by -X- _ O
the -X- _ O
customer -X- _ O
, -X- _ O
namely -X- _ O
the -X- _ O
customer -X- _ O
's -X- _ O
full -X- _ O
name -X- _ O
or -X- _ O
account -X- _ O
ID -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
[ -X- _ O
Pull -X- _ O
up -X- _ O
Account -X- _ O
] -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
third -X- _ O
action -X- _ O
, -X- _ O
the -X- _ O
guidelines -X- _ O
instruct -X- _ O
the -X- _ O
agent -X- _ O
to -X- _ O
ask -X- _ O
for -X- _ O
the -X- _ O
customer -X- _ O
's -X- _ O
membership -X- _ O
level -X- _ O
. -X- _ O
After -X- _ O
the -X- _ O
customer -X- _ O
supplies -X- _ O
this -X- _ O
information -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
enters -X- _ O
the -X- _ O
" -X- _ O
guest -X- _ O
" -X- _ O
value -X- _ O
into -X- _ O
the -X- _ O
agent -X- _ O
dashboard -X- _ O
by -X- _ O
clicking -X- _ O
the -X- _ O
[ -X- _ O
Membership -X- _ O
] -X- _ O
button -X- _ O
. -X- _ O
Buttons -X- _ O
have -X- _ O
variable -X- _ O
slots -X- _ O
that -X- _ O
may -X- _ O
or -X- _ O
may -X- _ O
not -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
filled -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
context -X- _ O
( -X- _ O
See -X- _ O
Table -X- _ O
1 -X- _ O
for -X- _ O
a -X- _ O
full -X- _ O
list -X- _ O
) -X- _ O
. -X- _ O
Dialogue -X- _ O
success -X- _ O
demands -X- _ O
that -X- _ O
agents -X- _ O
execute -X- _ O
a -X- _ O
chain -X- _ O
of -X- _ O
such -X- _ O
actions -X- _ O
in -X- _ O
the -X- _ O
right -X- _ O
order -X- _ O
with -X- _ O
the -X- _ O
right -X- _ O
values -X- _ O
, -X- _ O
while -X- _ O
simultaneously -X- _ O
engaging -X- _ O
the -X- _ O
customer -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
conversation -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
three -X- _ O
reasons -X- _ O
that -X- _ O
make -X- _ O
carrying -X- _ O
out -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
actions -X- _ O
more -X- _ O
difficult -X- _ O
than -X- _ O
the -X- _ O
task -X- _ O
lets -X- _ O
on -X- _ O
. -X- _ O
To -X- _ O
start -X- _ O
, -X- _ O
the -X- _ O
permitted -X- _ O
actions -X- _ O
in -X- _ O
a -X- _ O
given -X- _ O
state -X- _ O
are -X- _ O
determined -X- _ O
not -X- _ O
only -X- _ O
by -X- _ O
Agent -X- _ O
Guidelines -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
by -X- _ O
the -X- _ O
user -X- _ O
's -X- _ O
desire -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
in -X- _ O
conflict -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
customer -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
wanted -X- _ O
to -X- _ O
extend -X- _ O
their -X- _ O
subscription -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
guidelines -X- _ O
prevented -X- _ O
the -X- _ O
agent -X- _ O
from -X- _ O
doing -X- _ O
so -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
actions -X- _ O
must -X- _ O
be -X- _ O
completed -X- _ O
in -X- _ O
order -X- _ O
. -X- _ O
This -X- _ O
procedural -X- _ O
requirement -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
realization -X- _ O
that -X- _ O
completing -X- _ O
actions -X- _ O
out -X- _ O
of -X- _ O
order -X- _ O
( -X- _ O
or -X- _ O
with -X- _ O
missing -X- _ O
steps -X- _ O
) -X- _ O
do -X- _ O
not -X- _ O
make -X- _ O
sense -X- _ O
in -X- _ O
many -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
scenarios -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
critical -X- _ O
to -X- _ O
[ -X- _ O
Verify -X- _ O
Identity -X- _ O
] -X- _ O
before -X- _ O
resetting -X- _ O
someone -X- _ O
's -X- _ O
password -X- _ O
, -X- _ O
not -X- _ O
after -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
actions -X- _ O
themselves -X- _ O
induce -X- _ O
stochastic -X- _ O
outcomes -X- _ O
, -X- _ O
preventing -X- _ O
agents -X- _ O
from -X- _ O
memorizing -X- _ O
patterns -X- _ O
of -X- _ O
subflow -X- _ O
resolution -X- _ O
. -X- _ O
As -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
[ -X- _ O
Ask -X- _ O
the -X- _ O
Oracle -X- _ O
] -X- _ O
often -X- _ O
determines -X- _ O
if -X- _ O
a -X- _ O
customer -X- _ O
complaint -X- _ O
was -X- _ O
valid -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
a -X- _ O
company -X- _ O
error -X- _ O
, -X- _ O
the -X- _ O
agent -X- _ O
is -X- _ O
compelled -X- _ O
to -X- _ O
immediately -X- _ O
resolve -X- _ O
the -X- _ O
issue -X- _ O
, -X- _ O
whereas -X- _ O
a -X- _ O
misunderstanding -X- _ O
made -X- _ O
by -X- _ O
the -X- _ O
customer -X- _ O
warrants -X- _ O
a -X- _ O
different -X- _ O
set -X- _ O
of -X- _ O
responses -X- _ O
. -X- _ O
This -X- _ O
section -X- _ O
outlines -X- _ O
how -X- _ O
we -X- _ O
collect -X- _ O
and -X- _ O
annotate -X- _ O
our -X- _ O
dataset -X- _ O
with -X- _ O
context -X- _ O
- -X- _ O
dependent -X- _ O
actions -X- _ O
. -X- _ O
Managing -X- _ O
complex -X- _ O
guidelines -X- _ O
requires -X- _ O
filtering -X- _ O
for -X- _ O
top -X- _ O
agents -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
do -X- _ O
by -X- _ O
certifying -X- _ O
Mechanical -X- _ O
Turk -X- _ O
( -X- _ O
MTurk -X- _ O
) -X- _ O
workers -X- _ O
through -X- _ O
an -X- _ O
extensive -X- _ O
20 -X- _ O
- -X- _ O
question -X- _ O
quiz -X- _ O
touching -X- _ O
on -X- _ O
all -X- _ O
aspects -X- _ O
of -X- _ O
task -X- _ O
completion -X- _ O
. -X- _ O
Keeping -X- _ O
the -X- _ O
bar -X- _ O
high -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
a -X- _ O
minimum -X- _ O
threshold -X- _ O
of -X- _ O
80 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
of -X- _ O
the -X- _ O
quiz -X- _ O
which -X- _ O
resulted -X- _ O
in -X- _ O
a -X- _ O
low -X- _ O
20 -X- _ O
% -X- _ O
pass -X- _ O
rate -X- _ O
. -X- _ O
After -X- _ O
passing -X- _ O
the -X- _ O
exam -X- _ O
, -X- _ O
we -X- _ O
offered -X- _ O
the -X- _ O
answer -X- _ O
key -X- _ O
to -X- _ O
agents -X- _ O
which -X- _ O
further -X- _ O
improved -X- _ O
understanding -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
created -X- _ O
short -X- _ O
, -X- _ O
10 -X- _ O
- -X- _ O
minute -X- _ O
tutorial -X- _ O
videos -X- _ O
to -X- _ O
showcase -X- _ O
how -X- _ O
to -X- _ O
handle -X- _ O
the -X- _ O
most -X- _ O
difficult -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
A -X- _ O
group -X- _ O
chat -X- _ O
app -X- _ O
was -X- _ O
also -X- _ O
deployed -X- _ O
to -X- _ O
offer -X- _ O
live -X- _ O
feedback -X- _ O
for -X- _ O
agents -X- _ O
, -X- _ O
simulating -X- _ O
how -X- _ O
supervisors -X- _ O
coach -X- _ O
customer -X- _ O
service -X- _ O
representatives -X- _ O
in -X- _ O
real -X- _ O
life -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
carefully -X- _ O
designed -X- _ O
an -X- _ O
incentive -X- _ O
structure -X- _ O
that -X- _ O
rewards -X- _ O
agents -X- _ O
for -X- _ O
correctly -X- _ O
identifying -X- _ O
the -X- _ O
user -X- _ O
intent -X- _ O
to -X- _ O
encourage -X- _ O
clarification -X- _ O
behavior -X- _ O
. -X- _ O
( -X- _ O
Appendix -X- _ O
A -X- _ O
covers -X- _ O
more -X- _ O
details -X- _ O
. -X- _ O
) -X- _ O
Rather -X- _ O
than -X- _ O
utilizing -X- _ O
Wizard -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Oz -X- _ O
techniques -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
in -X- _ O
MultiWOZ -X- _ B-DatasetName
) -X- _ O
, -X- _ O
we -X- _ O
developed -X- _ O
Expert -X- _ O
Live -X- _ O
Chat -X- _ O
which -X- _ O
contains -X- _ O
three -X- _ O
unique -X- _ O
aspects:(1 -X- _ O
) -X- _ O
Conversations -X- _ O
are -X- _ O
conducted -X- _ O
continuously -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
. -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
Users -X- _ O
involved -X- _ O
are -X- _ O
not -X- _ O
interchangeable -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Players -X- _ O
are -X- _ O
informed -X- _ O
that -X- _ O
all -X- _ O
participants -X- _ O
are -X- _ O
human -X- _ O
-no -X- _ O
wizard -X- _ O
behind -X- _ O
the -X- _ O
scenes -X- _ O
. -X- _ O
Normal -X- _ O
human -X- _ O
conversations -X- _ O
occur -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
, -X- _ O
but -X- _ O
coordinating -X- _ O
multiple -X- _ O
users -X- _ O
in -X- _ O
this -X- _ O
manner -X- _ O
is -X- _ O
resource -X- _ O
- -X- _ O
intensive -X- _ O
, -X- _ O
so -X- _ O
other -X- _ O
datasets -X- _ O
often -X- _ O
employed -X- _ O
workarounds -X- _ O
to -X- _ O
avoid -X- _ O
this -X- _ O
difficulty -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
other -X- _ O
works -X- _ O
have -X- _ O
applied -X- _ O
rules -X- _ O
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
templates -X- _ O
( -X- _ O
Byrne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
paraphrasing -X- _ O
( -X- _ O
Shah -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
produce -X- _ O
conversations -X- _ O
. -X- _ O
Wizard -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
Oz -X- _ O
( -X- _ O
WoZ -X- _ O
) -X- _ O
techniques -X- _ O
incorporate -X- _ O
humans -X- _ O
into -X- _ O
the -X- _ O
mix -X- _ O
by -X- _ O
allowing -X- _ O
one -X- _ O
of -X- _ O
them -X- _ O
to -X- _ O
play -X- _ O
the -X- _ O
system -X- _ O
role -X- _ O
as -X- _ O
a -X- _ O
wizard -X- _ O
behind -X- _ O
the -X- _ O
scenes -X- _ O
( -X- _ O
Kelley -X- _ O
, -X- _ O
1984 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
decomposed -X- _ O
dialogues -X- _ O
into -X- _ O
individual -X- _ O
turns -X- _ O
, -X- _ O
where -X- _ O
for -X- _ O
each -X- _ O
turn -X- _ O
a -X- _ O
new -X- _ O
author -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
reading -X- _ O
the -X- _ O
context -X- _ O
and -X- _ O
generating -X- _ O
the -X- _ O
next -X- _ O
plausible -X- _ O
response -X- _ O
. -X- _ O
Despite -X- _ O
the -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
nature -X- _ O
, -X- _ O
some -X- _ O
datasets -X- _ O
have -X- _ O
produced -X- _ O
synchronous -X- _ O
dialogues -X- _ O
between -X- _ O
two -X- _ O
humans -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
skill -X- _ O
sets -X- _ O
of -X- _ O
ABCD -X- _ B-DatasetName
workers -X- _ O
are -X- _ O
notably -X- _ O
unequal -X- _ O
, -X- _ O
exacerbating -X- _ O
the -X- _ O
matching -X- _ O
problem -X- _ O
. -X- _ O
Expert -X- _ O
Live -X- _ O
Chat -X- _ O
matches -X- _ O
a -X- _ O
highly -X- _ O
trained -X- _ O
agent -X- _ O
with -X- _ O
a -X- _ O
knowledgeable -X- _ O
, -X- _ O
yet -X- _ O
otherwise -X- _ O
average -X- _ O
customer -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
time -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
backgrounds -X- _ O
are -X- _ O
uneven -X- _ O
, -X- _ O
unlike -X- _ O
other -X- _ O
datasets -X- _ O
with -X- _ O
concurrent -X- _ O
users -X- _ O
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Das -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017b -X- _ O
) -X- _ O
, -X- _ O
incoming -X- _ O
Turkers -X- _ O
can -X- _ O
not -X- _ O
simply -X- _ O
be -X- _ O
randomly -X- _ O
assigned -X- _ O
a -X- _ O
role -X- _ O
. -X- _ O
In -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
having -X- _ O
twenty -X- _ O
participants -X- _ O
does -X- _ O
not -X- _ O
necessarily -X- _ O
equate -X- _ O
to -X- _ O
ten -X- _ O
conversations -X- _ O
since -X- _ O
it -X- _ O
's -X- _ O
possible -X- _ O
that -X- _ O
only -X- _ O
a -X- _ O
quarter -X- _ O
of -X- _ O
them -X- _ O
are -X- _ O
qualified -X- _ O
as -X- _ O
agents -X- _ O
. -X- _ O
When -X- _ O
such -X- _ O
an -X- _ O
imbalance -X- _ O
inevitably -X- _ O
arises -X- _ O
, -X- _ O
one -X- _ O
group -X- _ O
must -X- _ O
wait -X- _ O
until -X- _ O
someone -X- _ O
from -X- _ O
the -X- _ O
other -X- _ O
side -X- _ O
becomes -X- _ O
available -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
leaving -X- _ O
either -X- _ O
side -X- _ O
waiting -X- _ O
for -X- _ O
too -X- _ O
long -X- _ O
leads -X- _ O
to -X- _ O
serious -X- _ O
consequences -X- _ O
since -X- _ O
idle -X- _ O
time -X- _ O
directly -X- _ O
affects -X- _ O
their -X- _ O
pay -X- _ O
rate -X- _ O
. -X- _ O
To -X- _ O
minimize -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
such -X- _ O
an -X- _ O
outcome -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
ensure -X- _ O
that -X- _ O
a -X- _ O
reasonable -X- _ O
pool -X- _ O
of -X- _ O
agents -X- _ O
are -X- _ O
always -X- _ O
available -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
active -X- _ O
customers -X- _ O
by -X- _ O
methodically -X- _ O
inviting -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
customers -X- _ O
one -X- _ O
batch -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
. -X- _ O
To -X- _ O
do -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
established -X- _ O
a -X- _ O
qualification -X- _ O
exam -X- _ O
for -X- _ O
customers -X- _ O
to -X- _ O
ensure -X- _ O
their -X- _ O
availability -X- _ O
during -X- _ O
a -X- _ O
specified -X- _ O
time -X- _ O
period -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
redesigned -X- _ O
the -X- _ O
chat -X- _ O
application -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
waiting -X- _ O
room -X- _ O
experience -X- _ O
more -X- _ O
palatable -X- _ O
. -X- _ O
( -X- _ O
See -X- _ O
Appendix -X- _ O
B -X- _ O
for -X- _ O
full -X- _ O
breakdown -X- _ O
. -X- _ O
) -X- _ O
With -X- _ O
these -X- _ O
changes -X- _ O
, -X- _ O
we -X- _ O
successfully -X- _ O
increased -X- _ O
the -X- _ O
pairing -X- _ O
rate -X- _ O
from -X- _ O
18 -X- _ O
out -X- _ O
of -X- _ O
80 -X- _ O
active -X- _ O
users -X- _ O
up -X- _ O
to -X- _ O
72 -X- _ O
out -X- _ O
of -X- _ O
83 -X- _ O
, -X- _ O
an -X- _ O
increase -X- _ O
of -X- _ O
nearly -X- _ O
400 -X- _ O
% -X- _ O
, -X- _ O
while -X- _ O
maintaining -X- _ O
wait -X- _ B-HyperparameterName
times -X- _ I-HyperparameterName
under -X- _ O
10 -X- _ B-HyperparameterValue
minutes -X- _ I-HyperparameterValue
. -X- _ O
Besides -X- _ O
pairing -X- _ O
, -X- _ O
we -X- _ O
increased -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
collecting -X- _ O
rich -X- _ O
dialogues -X- _ O
without -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
extensive -X- _ O
instructions -X- _ O
by -X- _ O
optimizing -X- _ O
the -X- _ O
chat -X- _ O
experience -X- _ O
itself -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
observed -X- _ O
the -X- _ O
greatest -X- _ O
gains -X- _ O
by -X- _ O
grounding -X- _ O
the -X- _ O
conversation -X- _ O
to -X- _ O
the -X- _ O
relatable -X- _ O
scenario -X- _ O
of -X- _ O
online -X- _ O
shopping -X- _ O
, -X- _ O
which -X- _ O
provided -X- _ O
immediate -X- _ O
context -X- _ O
to -X- _ O
participants -X- _ O
without -X- _ O
requiring -X- _ O
any -X- _ O
extra -X- _ O
training -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
Agent -X- _ O
Dashboard -X- _ O
was -X- _ O
arranged -X- _ O
to -X- _ O
closely -X- _ O
reflect -X- _ O
actual -X- _ O
agent -X- _ O
workspaces -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
customer -X- _ O
side -X- _ O
, -X- _ O
scenarios -X- _ O
in -X- _ O
the -X- _ O
Customer -X- _ O
Panel -X- _ O
included -X- _ O
an -X- _ O
image -X- _ O
of -X- _ O
the -X- _ O
product -X- _ O
being -X- _ O
discussed -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
other -X- _ O
meta -X- _ O
- -X- _ O
data -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
brand -X- _ O
or -X- _ O
price -X- _ O
to -X- _ O
match -X- _ O
a -X- _ O
true -X- _ O
shopping -X- _ O
experience -X- _ O
as -X- _ O
much -X- _ O
as -X- _ O
possible -X- _ O
( -X- _ O
Appendix -X- _ O
H -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
explicitly -X- _ O
told -X- _ O
customers -X- _ O
the -X- _ O
other -X- _ O
speaker -X- _ O
was -X- _ O
human -X- _ O
to -X- _ O
encourage -X- _ O
natural -X- _ O
responses -X- _ O
over -X- _ O
confined -X- _ O
commands -X- _ O
meant -X- _ O
for -X- _ O
machines -X- _ O
. -X- _ O
Most -X- _ O
importantly -X- _ O
, -X- _ O
customers -X- _ O
were -X- _ O
given -X- _ O
dynamically -X- _ O
generated -X- _ O
, -X- _ O
natural -X- _ O
- -X- _ O
language -X- _ O
prompts -X- _ O
that -X- _ O
did -X- _ O
not -X- _ O
include -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
values -X- _ O
needed -X- _ O
to -X- _ O
resolve -X- _ O
their -X- _ O
issue -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
general -X- _ O
framework -X- _ O
, -X- _ O
Ex -X- _ O
- -X- _ O
pert -X- _ O
Live -X- _ O
Chat -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
in -X- _ O
any -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
scenario -X- _ O
involving -X- _ O
an -X- _ O
expert -X- _ O
and -X- _ O
novice -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
verisimilitude -X- _ O
of -X- _ O
the -X- _ O
experience -X- _ O
is -X- _ O
precisely -X- _ O
what -X- _ O
allowed -X- _ O
higher -X- _ O
quality -X- _ O
dialogues -X- _ O
to -X- _ O
be -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
workers -X- _ O
. -X- _ O
The -X- _ O
flows -X- _ O
and -X- _ O
subflows -X- _ O
are -X- _ O
automatically -X- _ O
annotated -X- _ O
since -X- _ O
we -X- _ O
have -X- _ O
the -X- _ O
provenance -X- _ O
of -X- _ O
each -X- _ O
intent -X- _ O
when -X- _ O
generating -X- _ O
the -X- _ O
customer -X- _ O
prompt -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
subflow -X- _ O
of -X- _ O
each -X- _ O
conversation -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
deterministically -X- _ O
map -X- _ O
them -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
section -X- _ O
within -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
outlining -X- _ O
the -X- _ O
correct -X- _ O
actions -X- _ O
. -X- _ O
Calculating -X- _ O
accuracy -X- _ O
then -X- _ O
becomes -X- _ O
a -X- _ O
simple -X- _ O
exercise -X- _ O
to -X- _ O
align -X- _ O
the -X- _ O
predicted -X- _ O
actions -X- _ O
with -X- _ O
the -X- _ O
ones -X- _ O
required -X- _ O
by -X- _ O
the -X- _ O
manual -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
capture -X- _ O
a -X- _ O
key -X- _ O
benefit -X- _ O
of -X- _ O
machine -X- _ O
- -X- _ O
generated -X- _ O
text -X- _ O
( -X- _ O
Shah -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
without -X- _ O
sacrificing -X- _ O
the -X- _ O
benefit -X- _ O
of -X- _ O
engaging -X- _ O
real -X- _ O
users -X- _ O
. -X- _ O
We -X- _ O
validate -X- _ O
all -X- _ O
dialogues -X- _ O
to -X- _ O
pass -X- _ O
quality -X- _ O
thresholds -X- _ O
such -X- _ O
as -X- _ O
including -X- _ O
a -X- _ O
minimum -X- _ O
number -X- _ O
of -X- _ O
actions -X- _ O
and -X- _ O
avoiding -X- _ O
copy -X- _ O
/ -X- _ O
paste -X- _ O
behavior -X- _ O
. -X- _ O
After -X- _ O
filtering -X- _ O
, -X- _ O
we -X- _ O
end -X- _ O
up -X- _ O
with -X- _ O
10,042 -X- _ O
total -X- _ O
conversations -X- _ O
with -X- _ O
an -X- _ O
average -X- _ O
of -X- _ O
22.1 -X- _ O
turns -X- _ O
-the -X- _ O
highest -X- _ O
turn -X- _ O
count -X- _ O
among -X- _ O
all -X- _ O
compared -X- _ O
datasets -X- _ O
. -X- _ O
Unsurprisingly -X- _ O
, -X- _ O
ABCD -X- _ B-DatasetName
includes -X- _ O
more -X- _ O
actions -X- _ O
per -X- _ O
dialogue -X- _ O
than -X- _ O
other -X- _ O
datasets -X- _ O
, -X- _ O
by -X- _ O
at -X- _ O
least -X- _ O
a -X- _ O
factor -X- _ O
of -X- _ O
two -X- _ O
. -X- _ O
ABCD -X- _ B-DatasetName
also -X- _ O
contains -X- _ O
a -X- _ O
lower -X- _ O
absolute -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
variance -X- _ O
in -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
per -X- _ O
turn -X- _ O
. -X- _ O
( -X- _ O
See -X- _ O
Table -X- _ O
2.)Since -X- _ O
each -X- _ O
subflow -X- _ O
represents -X- _ O
a -X- _ O
unique -X- _ O
customer -X- _ O
intent -X- _ O
, -X- _ O
ABCD -X- _ B-DatasetName
contains -X- _ O
55 -X- _ O
user -X- _ O
intents -X- _ O
evenly -X- _ O
distributed -X- _ O
through -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
By -X- _ O
interpreting -X- _ O
buttons -X- _ O
as -X- _ O
domains -X- _ O
, -X- _ O
the -X- _ O
dataset -X- _ O
contains -X- _ O
30 -X- _ O
domains -X- _ O
and -X- _ O
231 -X- _ O
associated -X- _ O
slots -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
7 -X- _ O
domains -X- _ O
and -X- _ O
24 -X- _ O
slots -X- _ O
within -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
WOZ -X- _ I-DatasetName
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).By -X- _ O
grounding -X- _ O
to -X- _ O
the -X- _ O
relatable -X- _ O
scenario -X- _ O
of -X- _ O
chatting -X- _ O
with -X- _ O
customer -X- _ O
support -X- _ O
of -X- _ O
an -X- _ O
online -X- _ O
retail -X- _ O
company -X- _ O
, -X- _ O
speakers -X- _ O
often -X- _ O
showcase -X- _ O
various -X- _ O
forms -X- _ O
of -X- _ O
natural -X- _ O
dialogue -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
offering -X- _ O
diverse -X- _ O
reasons -X- _ O
for -X- _ O
shopping -X- _ O
or -X- _ O
asking -X- _ O
detailed -X- _ O
follow -X- _ O
- -X- _ O
up -X- _ O
questions -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
unconstrained -X- _ O
nature -X- _ O
of -X- _ O
Expert -X- _ O
Live -X- _ O
Chat -X- _ O
allows -X- _ O
users -X- _ O
to -X- _ O
chat -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
in -X- _ O
a -X- _ O
free -X- _ O
- -X- _ O
form -X- _ O
style -X- _ O
. -X- _ O
Dialogues -X- _ O
exhibited -X- _ O
normal -X- _ O
texting -X- _ O
behavior -X- _ O
such -X- _ O
as -X- _ O
users -X- _ O
speaking -X- _ O
for -X- _ O
many -X- _ O
turns -X- _ O
in -X- _ O
a -X- _ O
row -X- _ O
or -X- _ O
fixing -X- _ O
typos -X- _ O
with -X- _ O
a -X- _ O
star -X- _ O
in -X- _ O
the -X- _ O
subsequent -X- _ O
line -X- _ O
. -X- _ O
Other -X- _ O
examples -X- _ O
of -X- _ O
linguistic -X- _ O
phenomenon -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
The -X- _ O
novel -X- _ O
features -X- _ O
in -X- _ O
ABCD -X- _ B-DatasetName
brings -X- _ O
two -X- _ O
new -X- _ O
dialog -X- _ O
tasks -X- _ O
, -X- _ O
Action -X- _ B-TaskName
State -X- _ I-TaskName
Tracking -X- _ I-TaskName
and -X- _ O
Cascading -X- _ B-TaskName
Dialogue -X- _ I-TaskName
Success -X- _ I-TaskName
. -X- _ O
We -X- _ O
also -X- _ O
build -X- _ O
baseline -X- _ O
systems -X- _ O
that -X- _ O
are -X- _ O
variants -X- _ O
of -X- _ O
standard -X- _ O
dialogue -X- _ O
models -X- _ O
and -X- _ O
report -X- _ O
their -X- _ O
results -X- _ O
on -X- _ O
ABCD -X- _ B-DatasetName
. -X- _ O
Action -X- _ B-TaskName
State -X- _ I-TaskName
Tracking -X- _ I-TaskName
( -X- _ O
AST -X- _ B-TaskName
) -X- _ O
aims -X- _ O
at -X- _ O
detecting -X- _ O
the -X- _ O
pertinent -X- _ O
intent -X- _ O
by -X- _ O
interpreting -X- _ O
customer -X- _ O
utterances -X- _ O
while -X- _ O
taking -X- _ O
into -X- _ O
account -X- _ O
constraints -X- _ O
from -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
, -X- _ O
an -X- _ O
aspect -X- _ O
not -X- _ O
considered -X- _ O
in -X- _ O
traditional -X- _ O
dialog -X- _ B-TaskName
state -X- _ I-TaskName
tracking -X- _ I-TaskName
( -X- _ O
DST -X- _ B-TaskName
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
conceivable -X- _ O
dialogue -X- _ O
task -X- _ O
might -X- _ O
entail -X- _ O
helping -X- _ O
a -X- _ O
customer -X- _ O
[ -X- _ O
Reset -X- _ O
Password -X- _ O
] -X- _ O
once -X- _ O
this -X- _ O
intent -X- _ O
has -X- _ O
been -X- _ O
identified -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
appropriate -X- _ O
next -X- _ O
step -X- _ O
within -X- _ O
AST -X- _ B-TaskName
is -X- _ O
governed -X- _ O
by -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
, -X- _ O
which -X- _ O
might -X- _ O
require -X- _ O
[ -X- _ O
Verify -X- _ O
Identity -X- _ O
] -X- _ O
of -X- _ O
the -X- _ O
customer -X- _ O
first -X- _ O
, -X- _ O
or -X- _ O
any -X- _ O
number -X- _ O
of -X- _ O
other -X- _ O
actions -X- _ O
, -X- _ O
before -X- _ O
executing -X- _ O
the -X- _ O
password -X- _ O
reset -X- _ O
. -X- _ O
Each -X- _ O
series -X- _ O
of -X- _ O
actions -X- _ O
is -X- _ O
considered -X- _ O
a -X- _ O
unique -X- _ O
subflow -X- _ O
that -X- _ O
belongs -X- _ O
to -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
high -X- _ O
- -X- _ O
level -X- _ O
conversational -X- _ O
flows -X- _ O
. -X- _ O
Each -X- _ O
individual -X- _ O
action -X- _ O
includes -X- _ O
the -X- _ O
active -X- _ O
button -X- _ O
b -X- _ O
to -X- _ O
click -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
slots -X- _ O
s -X- _ O
and -X- _ O
values -X- _ O
v. -X- _ O
The -X- _ O
task -X- _ O
consists -X- _ O
of -X- _ O
executing -X- _ O
an -X- _ O
action -X- _ O
, -X- _ O
which -X- _ O
constitutes -X- _ O
a -X- _ O
single -X- _ O
agent -X- _ O
turn -X- _ O
. -X- _ O
More -X- _ O
specifically -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
context -X- _ O
C -X- _ O
t -X- _ O
= -X- _ O
[ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
t -X- _ O
] -X- _ O
where -X- _ O
x -X- _ O
t -X- _ O
can -X- _ O
be -X- _ O
a -X- _ O
customer -X- _ O
utterance -X- _ O
x -X- _ O
c -X- _ O
t -X- _ O
, -X- _ O
an -X- _ O
agent -X- _ O
utterance -X- _ O
x -X- _ O
a -X- _ O
t -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
prior -X- _ O
action -X- _ O
x -X- _ O
b -X- _ O
t -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
should -X- _ O
predict -X- _ O
the -X- _ O
button -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
action -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
relevant -X- _ O
slots -X- _ O
and -X- _ O
values -X- _ O
, -X- _ O
if -X- _ O
any -X- _ O
exist -X- _ O
{ -X- _ O
x -X- _ O
b -X- _ O
t+1 -X- _ O
= -X- _ O
( -X- _ O
b -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
v -X- _ O
) -X- _ O
∈ -X- _ O
B -X- _ O
× -X- _ O
S -X- _ O
× -X- _ O
V -X- _ O
} -X- _ O
. -X- _ O
This -X- _ O
structure -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
mimic -X- _ O
DST -X- _ O
where -X- _ O
each -X- _ O
user -X- _ O
intent -X- _ O
is -X- _ O
broken -X- _ O
down -X- _ O
into -X- _ O
domains -X- _ O
, -X- _ O
slots -X- _ O
and -X- _ O
values -X- _ O
( -X- _ O
d -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
v -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
AST -X- _ O
and -X- _ O
DST -X- _ O
, -X- _ O
the -X- _ O
higher -X- _ O
level -X- _ O
domain -X- _ O
or -X- _ O
button -X- _ O
can -X- _ O
have -X- _ O
vary -X- _ O
- -X- _ O
ing -X- _ O
slots -X- _ O
. -X- _ O
The -X- _ O
reverse -X- _ O
is -X- _ O
also -X- _ O
true -X- _ O
-a -X- _ O
given -X- _ O
slot -X- _ O
can -X- _ O
be -X- _ O
associated -X- _ O
with -X- _ O
multiple -X- _ O
domains -X- _ O
or -X- _ O
buttons -X- _ O
. -X- _ O
Lastly -X- _ O
, -X- _ O
both -X- _ O
contain -X- _ O
values -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
enumerable -X- _ O
( -X- _ O
i.e. -X- _ O
payment -X- _ O
types -X- _ O
or -X- _ O
shipping -X- _ O
statuses -X- _ O
) -X- _ O
or -X- _ O
non -X- _ O
- -X- _ O
enumerable -X- _ O
( -X- _ O
phone -X- _ O
numbers -X- _ O
or -X- _ O
email -X- _ O
addresses -X- _ O
) -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
pattern -X- _ O
set -X- _ O
by -X- _ O
Rastogi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
enumerable -X- _ O
values -X- _ O
are -X- _ O
given -X- _ O
in -X- _ O
the -X- _ O
ontology -X- _ O
to -X- _ O
be -X- _ O
accessible -X- _ O
by -X- _ O
a -X- _ O
model -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
enumerable -X- _ O
items -X- _ O
are -X- _ O
not -X- _ O
. -X- _ O
Despite -X- _ O
the -X- _ O
similar -X- _ O
structure -X- _ O
, -X- _ O
AST -X- _ B-TaskName
deviates -X- _ O
from -X- _ O
DST -X- _ B-TaskName
since -X- _ O
predicting -X- _ O
the -X- _ O
right -X- _ O
action -X- _ O
requires -X- _ O
not -X- _ O
only -X- _ O
parsing -X- _ O
the -X- _ O
customer -X- _ O
utterance -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
adhering -X- _ O
to -X- _ O
Agent -X- _ O
Guidelines -X- _ O
. -X- _ O
Suppose -X- _ O
a -X- _ O
customer -X- _ O
is -X- _ O
entitled -X- _ O
to -X- _ O
a -X- _ O
discount -X- _ O
which -X- _ O
will -X- _ O
be -X- _ O
offered -X- _ O
by -X- _ O
issuing -X- _ O
a -X- _ O
[ -X- _ O
Promo -X- _ O
Code -X- _ O
] -X- _ O
. -X- _ O
The -X- _ O
customer -X- _ O
might -X- _ O
request -X- _ O
30 -X- _ O
% -X- _ O
off -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
guidelines -X- _ O
stipulate -X- _ O
only -X- _ O
15 -X- _ O
% -X- _ O
is -X- _ O
permitted -X- _ O
, -X- _ O
which -X- _ O
would -X- _ O
make -X- _ O
" -X- _ O
30 -X- _ O
" -X- _ O
a -X- _ O
reasonable -X- _ O
, -X- _ O
but -X- _ O
ultimately -X- _ O
flawed -X- _ O
slot -X- _ O
- -X- _ O
value -X- _ O
. -X- _ O
To -X- _ O
measure -X- _ O
a -X- _ O
model -X- _ O
's -X- _ O
ability -X- _ O
to -X- _ O
comprehend -X- _ O
such -X- _ O
nuanced -X- _ O
situations -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
overall -X- _ O
accuracy -X- _ O
as -X- _ O
the -X- _ O
evaluation -X- _ O
metric -X- _ O
for -X- _ O
AST -X- _ B-TaskName
. -X- _ O
Since -X- _ O
the -X- _ O
appropriate -X- _ O
action -X- _ O
often -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
situation -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
the -X- _ O
Cascading -X- _ B-TaskName
Dialogue -X- _ I-TaskName
Success -X- _ I-TaskName
( -X- _ O
CDS -X- _ B-TaskName
) -X- _ O
task -X- _ O
to -X- _ O
measure -X- _ O
a -X- _ O
model -X- _ O
's -X- _ O
ability -X- _ O
to -X- _ O
understand -X- _ O
actions -X- _ O
in -X- _ O
context -X- _ O
. -X- _ O
Whereas -X- _ O
AST -X- _ O
assumes -X- _ O
an -X- _ O
action -X- _ O
occurs -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
turn -X- _ O
, -X- _ O
CDS -X- _ B-TaskName
gives -X- _ O
an -X- _ O
agent -X- _ O
the -X- _ O
additional -X- _ O
options -X- _ O
of -X- _ O
responding -X- _ O
with -X- _ O
an -X- _ O
utterance -X- _ O
or -X- _ O
ending -X- _ O
the -X- _ O
conversation -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
proficiency -X- _ O
is -X- _ O
no -X- _ O
longer -X- _ O
measured -X- _ O
as -X- _ O
success -X- _ O
over -X- _ O
isolated -X- _ O
turns -X- _ O
but -X- _ O
rather -X- _ O
as -X- _ O
success -X- _ O
over -X- _ O
sequences -X- _ O
of -X- _ O
consecutive -X- _ O
turns -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
given -X- _ O
C -X- _ O
t -X- _ O
= -X- _ O
[ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
t -X- _ O
] -X- _ O
as -X- _ O
a -X- _ O
context -X- _ O
composed -X- _ O
of -X- _ O
utterances -X- _ O
x -X- _ O
c -X- _ O
, -X- _ O
x -X- _ O
a -X- _ O
∈ -X- _ O
U -X- _ O
and -X- _ O
actions -X- _ O
x -X- _ O
b -X- _ O
∈ -X- _ O
A -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
should -X- _ O
predict -X- _ O
all -X- _ O
remaining -X- _ O
steps -X- _ O
x -X- _ O
> -X- _ O
t -X- _ O
along -X- _ O
with -X- _ O
their -X- _ O
realized -X- _ O
forms -X- _ O
. -X- _ O
Pos -X- _ O
- -X- _ O
sible -X- _ O
next -X- _ O
steps -X- _ O
are -X- _ O
to -X- _ O
take -X- _ O
an -X- _ O
action -X- _ O
, -X- _ O
respond -X- _ O
with -X- _ O
text -X- _ O
or -X- _ O
end -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
next -X- _ O
step -X- _ O
is -X- _ O
an -X- _ O
action -X- _ O
x -X- _ O
b -X- _ O
t+1 -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
should -X- _ O
predict -X- _ O
the -X- _ O
button -X- _ O
with -X- _ O
its -X- _ O
slots -X- _ O
and -X- _ O
values -X- _ O
as -X- _ O
in -X- _ O
AST -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
agent -X- _ O
speaks -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
step -X- _ O
x -X- _ O
a -X- _ O
t+1 -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
should -X- _ O
rank -X- _ O
the -X- _ O
true -X- _ O
utterance -X- _ O
highest -X- _ O
, -X- _ O
as -X- _ O
measured -X- _ O
by -X- _ O
recall -X- _ O
metrics -X- _ O
. -X- _ O
1 -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
should -X- _ O
recognize -X- _ O
when -X- _ O
to -X- _ O
end -X- _ O
the -X- _ O
conversation -X- _ O
. -X- _ O
Rewarding -X- _ O
the -X- _ O
model -X- _ O
only -X- _ O
when -X- _ O
it -X- _ O
predicts -X- _ O
every -X- _ O
step -X- _ O
correctly -X- _ O
is -X- _ O
counter -X- _ O
- -X- _ O
productive -X- _ O
because -X- _ O
minor -X- _ O
variations -X- _ O
in -X- _ O
sentence -X- _ O
order -X- _ O
do -X- _ O
not -X- _ O
alter -X- _ O
overall -X- _ O
customer -X- _ O
satisfaction -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
CDS -X- _ B-TaskName
is -X- _ O
scored -X- _ O
using -X- _ O
a -X- _ O
variation -X- _ O
on -X- _ O
Cascading -X- _ O
Evaluation -X- _ O
( -X- _ O
Suhr -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Rather -X- _ O
than -X- _ O
receiving -X- _ O
a -X- _ O
single -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
conversation -X- _ O
, -X- _ O
cascaded -X- _ O
evaluation -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
receive -X- _ O
" -X- _ O
partial -X- _ O
credit -X- _ O
" -X- _ O
whenever -X- _ O
it -X- _ O
successfully -X- _ O
predicts -X- _ O
each -X- _ O
successive -X- _ O
step -X- _ O
in -X- _ O
the -X- _ O
chat -X- _ O
. -X- _ O
This -X- _ O
score -X- _ O
is -X- _ O
calculated -X- _ O
on -X- _ O
every -X- _ O
turn -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
evaluated -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
percent -X- _ O
of -X- _ O
remaining -X- _ O
steps -X- _ O
correctly -X- _ O
predicted -X- _ O
, -X- _ O
averaged -X- _ O
across -X- _ O
all -X- _ O
available -X- _ O
turns -X- _ O
. -X- _ O
( -X- _ O
See -X- _ O
Appendix -X- _ O
C -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
. -X- _ O
) -X- _ O
We -X- _ O
also -X- _ O
run -X- _ O
several -X- _ O
baselines -X- _ O
on -X- _ O
these -X- _ O
new -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
backbone -X- _ O
of -X- _ O
all -X- _ O
our -X- _ O
baseline -X- _ O
systems -X- _ O
is -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
acting -X- _ O
as -X- _ O
a -X- _ O
context -X- _ O
encoder -X- _ O
. -X- _ O
More -X- _ O
specifically -X- _ O
, -X- _ O
given -X- _ O
the -X- _ O
dialogue -X- _ O
history -X- _ O
as -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
utterances -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
join -X- _ O
the -X- _ O
utterances -X- _ O
together -X- _ O
with -X- _ O
a -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
token -X- _ O
and -X- _ O
then -X- _ O
tokenize -X- _ O
the -X- _ O
entire -X- _ O
input -X- _ O
using -X- _ O
Word -X- _ O
- -X- _ O
Piece -X- _ O
( -X- _ O
Schuster -X- _ O
and -X- _ O
Nakajima -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
feed -X- _ O
the -X- _ O
entire -X- _ O
input -X- _ O
into -X- _ O
a -X- _ O
BERT -X- _ O
model -X- _ O
and -X- _ O
perform -X- _ O
a -X- _ O
learned -X- _ O
pooling -X- _ O
on -X- _ O
the -X- _ O
hidden -X- _ O
states -X- _ O
in -X- _ O
the -X- _ O
final -X- _ O
layer -X- _ O
, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
fixed -X- _ O
- -X- _ O
length -X- _ O
latent -X- _ O
vector -X- _ O
h -X- _ O
enc -X- _ O
∈ -X- _ O
R -X- _ O
128 -X- _ O
( -X- _ O
Wolf -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Afterwards -X- _ O
, -X- _ O
we -X- _ O
attach -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
prediction -X- _ O
heads -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
h -X- _ O
enc -X- _ O
vector -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
final -X- _ O
output -X- _ O
. -X- _ O
Details -X- _ O
of -X- _ O
the -X- _ O
prediction -X- _ O
heads -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
proposed -X- _ O
tasks -X- _ O
are -X- _ O
described -X- _ O
next -X- _ O
. -X- _ O
We -X- _ O
break -X- _ O
down -X- _ O
Action -X- _ B-TaskName
State -X- _ I-TaskName
Tracking -X- _ I-TaskName
( -X- _ O
AST -X- _ B-TaskName
) -X- _ O
into -X- _ O
two -X- _ O
sub -X- _ O
- -X- _ O
problems -X- _ O
, -X- _ O
button -X- _ O
- -X- _ O
slot -X- _ O
prediction -X- _ O
and -X- _ O
value -X- _ O
- -X- _ O
filling -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
ontology -X- _ O
, -X- _ O
button -X- _ O
prediction -X- _ O
is -X- _ O
a -X- _ O
straightforward -X- _ O
classification -X- _ O
task -X- _ O
over -X- _ O
231 -X- _ O
known -X- _ O
options -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
prediction -X- _ O
head -X- _ O
is -X- _ O
just -X- _ O
a -X- _ O
linear -X- _ O
classifier -X- _ O
with -X- _ O
a -X- _ O
softmax -X- _ O
activation -X- _ O
for -X- _ O
normalization -X- _ O
:P -X- _ O
b•slot -X- _ O
= -X- _ O
Softmax(W -X- _ O
a -X- _ O
h -X- _ O
enc -X- _ O
+ -X- _ O
b -X- _ O
a -X- _ O
) -X- _ O
.To -X- _ O
handle -X- _ O
value -X- _ O
- -X- _ O
filling -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
decompose -X- _ O
1 -X- _ O
Sentences -X- _ O
with -X- _ O
similar -X- _ O
semantics -X- _ O
may -X- _ O
be -X- _ O
formulated -X- _ O
in -X- _ O
several -X- _ O
ways -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
opt -X- _ O
for -X- _ O
response -X- _ O
retrieval -X- _ O
over -X- _ O
text -X- _ O
generation -X- _ O
since -X- _ O
common -X- _ O
metrics -X- _ O
( -X- _ O
i.e. -X- _ O
BLEU -X- _ O
score -X- _ O
) -X- _ O
tend -X- _ O
to -X- _ O
become -X- _ O
unreliable -X- _ O
in -X- _ O
these -X- _ O
situations -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
the -X- _ O
task -X- _ O
into -X- _ O
predicting -X- _ O
enumerable -X- _ O
and -X- _ O
nonenumerable -X- _ O
values -X- _ O
. -X- _ O
The -X- _ O
ontology -X- _ O
lists -X- _ O
out -X- _ O
all -X- _ O
|E| -X- _ O
enumerable -X- _ O
values -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
prediction -X- _ O
head -X- _ O
p -X- _ O
enum -X- _ O
simply -X- _ O
maps -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
h -X- _ O
enc -X- _ O
into -X- _ O
the -X- _ O
appropriate -X- _ O
dimensions -X- _ O
. -X- _ O
To -X- _ O
handle -X- _ O
non -X- _ O
- -X- _ O
enumerable -X- _ O
values -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
insight -X- _ O
from -X- _ O
( -X- _ O
Ma -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
which -X- _ O
notes -X- _ O
that -X- _ O
practically -X- _ O
all -X- _ O
such -X- _ O
values -X- _ O
are -X- _ O
stated -X- _ O
by -X- _ O
the -X- _ O
customer -X- _ O
in -X- _ O
conversation -X- _ O
, -X- _ O
so -X- _ O
a -X- _ O
model -X- _ O
can -X- _ O
copy -X- _ O
these -X- _ O
values -X- _ O
from -X- _ O
the -X- _ O
tokenized -X- _ O
context -X- _ O
. -X- _ O
During -X- _ O
pre -X- _ O
- -X- _ O
processing -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
up -X- _ O
to -X- _ O
|N -X- _ O
| -X- _ O
unique -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
natural -X- _ O
language -X- _ O
customer -X- _ O
utterances -X- _ O
, -X- _ O
where -X- _ O
p -X- _ O
copy -X- _ O
then -X- _ O
represents -X- _ O
the -X- _ O
distribution -X- _ O
over -X- _ O
these -X- _ O
possible -X- _ O
options -X- _ O
. -X- _ O
2 -X- _ O
We -X- _ O
imitate -X- _ O
the -X- _ O
TRADE -X- _ O
architecture -X- _ O
from -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
action -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
chooses -X- _ O
to -X- _ O
either -X- _ O
copy -X- _ O
from -X- _ O
the -X- _ O
context -X- _ O
p -X- _ O
copy -X- _ O
or -X- _ O
select -X- _ O
from -X- _ O
the -X- _ O
enumerable -X- _ O
entities -X- _ O
p -X- _ O
enum -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
gating -X- _ O
mechanism -X- _ O
. -X- _ O
The -X- _ O
gate -X- _ O
is -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
h -X- _ O
enc -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
learned -X- _ O
context -X- _ O
vector -X- _ O
c -X- _ O
i -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
p -X- _ O
enum -X- _ O
= -X- _ O
Softmax(W -X- _ O
e -X- _ O
h -X- _ O
enc -X- _ O
+ -X- _ O
b -X- _ O
e -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
|E| -X- _ O
p -X- _ O
copy -X- _ O
= -X- _ O
Softmax(W -X- _ O
c -X- _ O
h -X- _ O
enc -X- _ O
+ -X- _ O
b -X- _ O
c -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
|N -X- _ O
| -X- _ O
c -X- _ O
i -X- _ O
= -X- _ O
W -X- _ O
c -X- _ O
• -X- _ O
p -X- _ O
copy -X- _ O
∈ -X- _ O
R -X- _ O
hid -X- _ O
p -X- _ O
gate -X- _ O
= -X- _ O
σ(W -X- _ O
g -X- _ O
• -X- _ O
[ -X- _ O
h -X- _ O
enc -X- _ O
; -X- _ O
c -X- _ O
i -X- _ O
] -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
1 -X- _ O
P -X- _ O
val -X- _ O
= -X- _ O
[ -X- _ O
p -X- _ O
gate -X- _ O
× -X- _ O
p -X- _ O
copy -X- _ O
; -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
p -X- _ O
gate -X- _ O
) -X- _ O
× -X- _ O
p -X- _ O
enum -X- _ O
] -X- _ O
∈ -X- _ O
R -X- _ O
|E+N -X- _ O
|where -X- _ O
σ -X- _ O
represents -X- _ O
the -X- _ O
Sigmoid -X- _ O
function -X- _ O
and -X- _ O
[ -X- _ O
• -X- _ O
; -X- _ O
• -X- _ O
] -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
operation -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
value -X- _ O
predictions -X- _ O
are -X- _ O
the -X- _ O
argmax -X- _ O
of -X- _ O
P -X- _ O
val -X- _ O
which -X- _ O
merge -X- _ O
the -X- _ O
probabilities -X- _ O
of -X- _ O
p -X- _ O
enum -X- _ O
and -X- _ O
p -X- _ O
copy -X- _ O
together -X- _ O
. -X- _ O
For -X- _ O
Cascading -X- _ O
Dialogue -X- _ O
Success -X- _ O
( -X- _ O
CDS -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
tackle -X- _ O
next -X- _ O
step -X- _ O
selection -X- _ O
, -X- _ O
utterance -X- _ O
ranking -X- _ O
, -X- _ O
and -X- _ O
intent -X- _ O
classification -X- _ O
. -X- _ O
Next -X- _ O
step -X- _ O
selection -X- _ O
is -X- _ O
a -X- _ O
choice -X- _ O
between -X- _ O
retrieve -X- _ O
utterance -X- _ O
, -X- _ O
take -X- _ O
action -X- _ O
and -X- _ O
end -X- _ O
conversation -X- _ O
. -X- _ O
Intent -X- _ O
classification -X- _ O
consists -X- _ O
of -X- _ O
choosing -X- _ O
from -X- _ O
the -X- _ O
55 -X- _ O
available -X- _ O
subflows -X- _ O
. -X- _ O
Given -X- _ O
this -X- _ O
basic -X- _ O
setting -X- _ O
, -X- _ O
both -X- _ O
tasks -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
setup -X- _ O
of -X- _ O
a -X- _ O
linear -X- _ O
layer -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
softmax -X- _ O
, -X- _ O
albeit -X- _ O
with -X- _ O
their -X- _ O
own -X- _ O
respective -X- _ O
weights -X- _ O
W -X- _ O
N -X- _ O
S -X- _ O
∈ -X- _ O
R -X- _ O
3×hid -X- _ O
and -X- _ O
W -X- _ O
IC -X- _ O
∈ -X- _ O
R -X- _ O
55×hid -X- _ O
. -X- _ O
When -X- _ O
the -X- _ O
next -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
take -X- _ O
action -X- _ O
, -X- _ O
the -X- _ O
AST -X- _ B-TaskName
model -X- _ O
is -X- _ O
reused -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
button -X- _ O
- -X- _ O
slot -X- _ O
and -X- _ O
value -X- _ O
. -X- _ O
When -X- _ O
end -X- _ O
conversation -X- _ O
is -X- _ O
selected -X- _ O
, -X- _ O
all -X- _ O
future -X- _ O
predictions -X- _ O
are -X- _ O
ignored -X- _ O
, -X- _ O
much -X- _ O
like -X- _ O
an -X- _ O
< -X- _ O
EOS -X- _ O
> -X- _ O
symbol -X- _ O
signifies -X- _ O
stopping -X- _ O
. -X- _ O
This -X- _ O
leaves -X- _ O
us -X- _ O
with -X- _ O
utterance -X- _ O
ranking -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
only -X- _ O
evaluated -X- _ O
when -X- _ O
retrieve -X- _ O
utterance -X- _ O
is -X- _ O
chosen -X- _ O
as -X- _ O
the -X- _ O
next -X- _ O
step -X- _ O
. -X- _ O
Our -X- _ O
ranker -X- _ O
reproduces -X- _ O
the -X- _ O
design -X- _ O
from -X- _ O
( -X- _ O
Guu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
encoded -X- _ O
context -X- _ O
h -X- _ O
ctx -X- _ O
is -X- _ O
compared -X- _ O
against -X- _ O
each -X- _ O
encoded -X- _ O
candidate -X- _ O
response -X- _ O
h -X- _ O
cand -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
ranking -X- _ O
score -X- _ O
. -X- _ O
To -X- _ O
embed -X- _ O
each -X- _ O
j -X- _ O
th -X- _ O
candidate -X- _ O
d -X- _ O
j -X- _ O
we -X- _ O
first -X- _ O
create -X- _ O
its -X- _ O
input -X- _ O
d -X- _ O
input -X- _ O
j -X- _ O
. -X- _ O
Following -X- _ O
standard -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
prepend -X- _ O
the -X- _ O
candidate -X- _ O
text -X- _ O
d -X- _ O
j -X- _ O
with -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
, -X- _ O
separate -X- _ O
the -X- _ O
individual -X- _ O
utterances -X- _ O
u -X- _ O
i -X- _ O
within -X- _ O
the -X- _ O
candidate -X- _ O
response -X- _ O
using -X- _ O
a -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
token -X- _ O
, -X- _ O
and -X- _ O
append -X- _ O
a -X- _ O
final -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
token -X- _ O
afterwards -X- _ O
. -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
input -X- _ O
d -X- _ O
input -X- _ O
j -X- _ O
is -X- _ O
then -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
static -X- _ O
pretrained -X- _ O
BERT -X- _ O
model -X- _ O
to -X- _ O
get -X- _ O
an -X- _ O
initial -X- _ O
hidden -X- _ O
state -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
finally -X- _ O
projected -X- _ O
using -X- _ O
a -X- _ O
learned -X- _ O
weight -X- _ O
W -X- _ O
d -X- _ O
j -X- _ O
∈ -X- _ O
R -X- _ O
128×hid -X- _ O
to -X- _ O
produce -X- _ O
h -X- _ O
cand -X- _ O
. -X- _ O
To -X- _ O
obtain -X- _ O
h -X- _ O
ctx -X- _ O
we -X- _ O
start -X- _ O
with -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
h -X- _ O
enc -X- _ O
from -X- _ O
before -X- _ O
and -X- _ O
apply -X- _ O
a -X- _ O
projection -X- _ O
matrix -X- _ O
W -X- _ O
U -X- _ O
R -X- _ O
∈ -X- _ O
R -X- _ O
128×hid -X- _ O
to -X- _ O
reach -X- _ O
the -X- _ O
desired -X- _ O
dimensionality.d -X- _ O
input -X- _ O
j -X- _ O
= -X- _ O
[ -X- _ O
CLS]u -X- _ O
1 -X- _ O
[ -X- _ O
SEP]u -X- _ O
2 -X- _ O
[ -X- _ O
SEP] -X- _ O
... -X- _ O
[SEP]u -X- _ O
n -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
h -X- _ O
cand -X- _ O
= -X- _ O
W -X- _ O
d -X- _ O
j -X- _ O
BERT -X- _ O
base -X- _ O
( -X- _ O
d -X- _ O
input -X- _ O
j -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
128 -X- _ O
h -X- _ O
ctx -X- _ O
= -X- _ O
W -X- _ O
U -X- _ O
R -X- _ O
h -X- _ O
enc -X- _ O
∈ -X- _ O
R -X- _ O
128 -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
d -X- _ O
j -X- _ O
) -X- _ O
= -X- _ O
h -X- _ O
ctx -X- _ O
h -X- _ O
cand -X- _ O
P -X- _ O
rank -X- _ O
j -X- _ O
= -X- _ O
exp(f -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
d -X- _ O
j -X- _ O
) -X- _ O
) -X- _ O
Σ -X- _ O
d -X- _ O
j -X- _ O
exp -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
d -X- _ O
j -X- _ O
) -X- _ O
The -X- _ O
final -X- _ O
rank -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
normalizing -X- _ O
each -X- _ O
j -X- _ O
th -X- _ O
score -X- _ O
against -X- _ O
all -X- _ O
other -X- _ O
candidate -X- _ O
scores -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
training -X- _ O
objective -X- _ O
from -X- _ O
( -X- _ O
Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
calculate -X- _ O
the -X- _ O
loss -X- _ O
: -X- _ O
J -X- _ O
= -X- _ O
M -X- _ O
= -X- _ O
100 -X- _ O
j=1 -X- _ O
P -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
d -X- _ O
j -X- _ O
) -X- _ O
− -X- _ O
M -X- _ O
i=1 -X- _ O
log -X- _ O
M -X- _ O
j=1 -X- _ O
exp -X- _ O
f -X- _ O
( -X- _ O
x -X- _ O
i -X- _ O
, -X- _ O
d -X- _ O
j -X- _ O
) -X- _ O
where -X- _ O
M -X- _ O
is -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
candidate -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
performed -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
two -X- _ O
newly -X- _ O
proposed -X- _ O
tasks -X- _ O
, -X- _ O
AST -X- _ B-TaskName
and -X- _ O
CDS -X- _ B-TaskName
. -X- _ O
AST -X- _ B-TaskName
consists -X- _ O
of -X- _ O
two -X- _ O
subtasks -X- _ O
, -X- _ O
button -X- _ O
- -X- _ O
slot -X- _ O
prediction -X- _ O
and -X- _ O
value -X- _ O
- -X- _ O
filling -X- _ O
, -X- _ O
while -X- _ O
CDS -X- _ O
builds -X- _ O
on -X- _ O
this -X- _ O
with -X- _ O
three -X- _ O
additional -X- _ O
subtasks -X- _ O
of -X- _ O
next -X- _ O
step -X- _ O
selection -X- _ O
, -X- _ O
utterance -X- _ O
ranking -X- _ O
, -X- _ O
and -X- _ O
intent -X- _ O
classification -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
experimented -X- _ O
with -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
frameworks -X- _ O
, -X- _ O
a -X- _ O
pipeline -X- _ O
version -X- _ O
and -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
version -X- _ O
. -X- _ O
The -X- _ O
pipeline -X- _ O
version -X- _ O
trains -X- _ O
each -X- _ O
subtask -X- _ O
separately -X- _ O
while -X- _ O
the -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
optimizes -X- _ O
all -X- _ O
tasks -X- _ O
jointly -X- _ O
( -X- _ O
Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Rastogi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a;Ham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).The -X- _ O
pipeline -X- _ O
model -X- _ O
uses -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
RAdam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
. -X- _ O
To -X- _ O
test -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
different -X- _ O
pretrained -X- _ O
models -X- _ O
under -X- _ O
the -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
three -X- _ O
additional -X- _ O
encoders -X- _ O
, -X- _ O
Al -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
Large -X- _ I-MethodName
. -X- _ O
AlBERT -X- _ B-MethodName
model -X- _ O
has -X- _ O
an -X- _ O
inter -X- _ O
- -X- _ O
sentence -X- _ O
coherence -X- _ O
task -X- _ O
and -X- _ O
a -X- _ O
lighter -X- _ O
memory -X- _ O
footprint -X- _ O
compared -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
while -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
has -X- _ O
substantially -X- _ O
more -X- _ O
data -X- _ O
and -X- _ O
hyper -X- _ O
- -X- _ O
parameter -X- _ O
tuning -X- _ O
in -X- _ O
pretraining -X- _ O
than -X- _ O
BERT.In -X- _ B-MethodName
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
plan -X- _ O
to -X- _ O
include -X- _ O
GPT -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
DialoGPT -X- _ B-MethodName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
in -X- _ O
our -X- _ O
comparison -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
tasks -X- _ O
, -X- _ O
moving -X- _ O
from -X- _ O
the -X- _ O
pipeline -X- _ O
architecture -X- _ O
to -X- _ O
a -X- _ O
jointly -X- _ O
trained -X- _ O
method -X- _ O
displayed -X- _ O
noticeable -X- _ O
improvement -X- _ O
in -X- _ O
accuracy -X- _ O
. -X- _ O
As -X- _ O
hinted -X- _ O
at -X- _ O
in -X- _ O
prior -X- _ O
works -X- _ O
( -X- _ O
Liang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
suspect -X- _ O
the -X- _ O
group -X- _ O
effort -X- _ O
gives -X- _ O
each -X- _ O
subtask -X- _ O
extra -X- _ O
supervision -X- _ O
from -X- _ O
other -X- _ O
subtasks -X- _ O
for -X- _ O
more -X- _ O
data -X- _ O
efficient -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
AST -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
steady -X- _ O
improvements -X- _ O
as -X- _ O
we -X- _ O
move -X- _ O
from -X- _ O
the -X- _ O
older -X- _ O
to -X- _ O
the -X- _ O
newer -X- _ O
models -X- _ O
with -X- _ O
vanilla -X- _ O
BERT -X- _ B-MethodName
at -X- _ O
59.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
and -X- _ O
RoBERTa -X- _ B-MethodName
doing -X- _ O
the -X- _ O
best -X- _ O
at -X- _ O
65.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
For -X- _ O
the -X- _ O
CDS -X- _ B-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
a -X- _ O
similar -X- _ O
trend -X- _ O
where -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ I-MethodName
Large -X- _ I-MethodName
outperforms -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
but -X- _ O
only -X- _ O
by -X- _ O
a -X- _ O
mere -X- _ O
0.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
We -X- _ O
hypothesize -X- _ O
this -X- _ O
small -X- _ O
gap -X- _ O
between -X- _ O
models -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
none -X- _ O
were -X- _ O
particularly -X- _ O
trained -X- _ O
on -X- _ O
dialogue -X- _ O
data -X- _ O
which -X- _ O
impacts -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
useful -X- _ O
encoding -X- _ O
( -X- _ O
Wu -X- _ O
and -X- _ O
Xiong -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Separately -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
CDS -X- _ B-TaskName
subtask -X- _ O
difficulty -X- _ O
by -X- _ O
asking -X- _ O
human -X- _ O
volunteers -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
correct -X- _ O
label -X- _ O
from -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
possible -X- _ O
options -X- _ O
. -X- _ O
As -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
workers -X- _ O
would -X- _ O
be -X- _ O
presented -X- _ O
with -X- _ O
55 -X- _ O
different -X- _ O
classes -X- _ O
for -X- _ O
Intent -X- _ B-TaskName
Classification -X- _ I-TaskName
and -X- _ O
asked -X- _ O
to -X- _ O
choose -X- _ O
the -X- _ O
right -X- _ O
one -X- _ O
. -X- _ O
Since -X- _ O
humans -X- _ O
typically -X- _ O
struggle -X- _ O
when -X- _ O
choosing -X- _ O
from -X- _ O
large -X- _ O
collections -X- _ O
of -X- _ O
items -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
performed -X- _ O
roughly -X- _ O
on -X- _ O
par -X- _ O
or -X- _ O
better -X- _ O
compared -X- _ O
to -X- _ O
humans -X- _ O
in -X- _ O
this -X- _ O
unnatural -X- _ O
setting -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
human -X- _ O
evaluation -X- _ O
for -X- _ O
the -X- _ O
overall -X- _ O
CDS -X- _ B-TaskName
task -X- _ O
was -X- _ O
judged -X- _ O
by -X- _ O
measuring -X- _ O
the -X- _ O
success -X- _ O
rate -X- _ O
in -X- _ O
a -X- _ O
standard -X- _ O
conversational -X- _ O
scenarios -X- _ O
where -X- _ O
behavioral -X- _ O
instincts -X- _ O
are -X- _ O
activated -X- _ O
, -X- _ O
so -X- _ O
humans -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
excel -X- _ O
on -X- _ O
this -X- _ O
environment -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
significance -X- _ O
of -X- _ O
the -X- _ O
key -X- _ O
features -X- _ O
in -X- _ O
ABCD -X- _ B-DatasetName
. -X- _ O
Recall -X- _ O
, -X- _ O
actions -X- _ O
are -X- _ O
characterized -X- _ O
by -X- _ O
their -X- _ O
dual -X- _ O
nature -X- _ O
of -X- _ O
requiring -X- _ O
signals -X- _ O
from -X- _ O
both -X- _ O
the -X- _ O
customer -X- _ O
and -X- _ O
the -X- _ O
company -X- _ O
guidelines -X- _ O
. -X- _ O
To -X- _ O
that -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
provided -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
intent -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
customer -X- _ O
side -X- _ O
. -X- _ O
Conversely -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
test -X- _ O
the -X- _ O
company -X- _ O
side -X- _ O
by -X- _ O
masking -X- _ O
out -X- _ O
invalid -X- _ O
buttons -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
insight -X- _ O
that -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
are -X- _ O
useful -X- _ O
for -X- _ O
narrowing -X- _ O
down -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
possible -X- _ O
actions -X- _ O
. -X- _ O
In -X- _ O
both -X- _ O
situations -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
expect -X- _ O
that -X- _ O
providing -X- _ O
such -X- _ O
oracle -X- _ O
guidance -X- _ O
would -X- _ O
boost -X- _ O
performance -X- _ O
. -X- _ O
Lastly -X- _ O
, -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
appropriate -X- _ O
action -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
outcomes -X- _ O
of -X- _ O
prior -X- _ O
actions -X- _ O
, -X- _ O
so -X- _ O
for -X- _ O
a -X- _ O
final -X- _ O
experiment -X- _ O
we -X- _ O
removed -X- _ O
prior -X- _ O
actions -X- _ O
and -X- _ O
their -X- _ O
explanations -X- _ O
from -X- _ O
the -X- _ O
context -X- _ O
to -X- _ O
test -X- _ O
their -X- _ O
impact -X- _ O
on -X- _ O
task -X- _ O
success -X- _ O
. -X- _ O
( -X- _ O
See -X- _ O
Appendix -X- _ O
E -X- _ O
for -X- _ O
details.)We -X- _ O
observe -X- _ O
that -X- _ O
supplying -X- _ O
the -X- _ O
intent -X- _ O
information -X- _ O
to -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
causes -X- _ O
a -X- _ O
noticeable -X- _ O
boost -X- _ O
in -X- _ O
dialog -X- _ O
success -X- _ O
, -X- _ O
bringing -X- _ O
the -X- _ O
score -X- _ O
to -X- _ O
32.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
However -X- _ O
, -X- _ O
augmenting -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
knowledge -X- _ O
of -X- _ O
the -X- _ O
guidelines -X- _ O
unexpectedly -X- _ O
dropped -X- _ O
performance -X- _ O
down -X- _ O
to -X- _ O
30.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Further -X- _ O
analysis -X- _ O
revealed -X- _ O
the -X- _ O
imperfect -X- _ O
intent -X- _ O
classifier -X- _ O
would -X- _ O
occasionally -X- _ O
mask -X- _ O
out -X- _ O
valid -X- _ O
buttons -X- _ O
, -X- _ O
leaving -X- _ O
only -X- _ O
incorrect -X- _ O
ones -X- _ O
to -X- _ O
choose -X- _ O
from -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
downstream -X- _ O
action -X- _ O
predictor -X- _ O
would -X- _ O
be -X- _ O
prevented -X- _ O
from -X- _ O
doing -X- _ O
its -X- _ O
job -X- _ O
, -X- _ O
causing -X- _ O
errors -X- _ O
to -X- _ O
accumulate -X- _ O
. -X- _ O
To -X- _ O
test -X- _ O
this -X- _ O
hypothesis -X- _ O
, -X- _ O
we -X- _ O
ran -X- _ O
another -X- _ O
model -X- _ O
( -X- _ O
Intent+Guide -X- _ O
) -X- _ O
which -X- _ O
had -X- _ O
access -X- _ O
to -X- _ O
guidelines -X- _ O
along -X- _ O
with -X- _ O
an -X- _ O
oracle -X- _ O
intent -X- _ O
classifier -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
reached -X- _ O
the -X- _ O
peak -X- _ O
observed -X- _ O
performance -X- _ O
of -X- _ O
32.7 -X- _ B-TaskName
% -X- _ I-TaskName
, -X- _ O
highlighting -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
both -X- _ O
components -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
final -X- _ O
result -X- _ O
, -X- _ O
removing -X- _ O
action -X- _ O
information -X- _ O
away -X- _ O
from -X- _ O
actionbased -X- _ O
conversations -X- _ O
unsurprisingly -X- _ O
causes -X- _ O
a -X- _ O
major -X- _ O
performance -X- _ O
drop -X- _ O
( -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
conclusion -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
presented -X- _ O
ABCD -X- _ B-DatasetName
which -X- _ O
includes -X- _ O
over -X- _ O
10 -X- _ O
K -X- _ O
dialogues -X- _ O
that -X- _ O
incorporate -X- _ O
procedural -X- _ O
, -X- _ O
dual -X- _ O
- -X- _ O
constrained -X- _ O
actions -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
established -X- _ O
a -X- _ O
scalable -X- _ O
method -X- _ O
for -X- _ O
collecting -X- _ O
live -X- _ O
human -X- _ O
conversations -X- _ O
with -X- _ O
unequal -X- _ O
partners -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
perform -X- _ O
decent -X- _ O
on -X- _ O
Action -X- _ B-TaskName
State -X- _ I-TaskName
Tracking -X- _ I-TaskName
, -X- _ O
but -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
large -X- _ O
gap -X- _ O
between -X- _ O
humans -X- _ O
agents -X- _ O
and -X- _ O
the -X- _ O
top -X- _ O
systems -X- _ O
for -X- _ B-TaskName
Cascading -X- _ I-TaskName
Dialogue -X- _ I-TaskName
Success -X- _ I-TaskName
. -X- _ O
We -X- _ O
plan -X- _ O
to -X- _ O
incorporate -X- _ O
GPT -X- _ O
- -X- _ O
related -X- _ O
models -X- _ O
( -X- _ O
Hosseini -X- _ O
- -X- _ O
Asl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
alternate -X- _ O
forms -X- _ O
of -X- _ O
preprocessing -X- _ O
have -X- _ O
shown -X- _ O
promise -X- _ O
in -X- _ O
other -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
Other -X- _ O
techniques -X- _ O
could -X- _ O
also -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
incorporate -X- _ O
speaker -X- _ O
info -X- _ O
, -X- _ O
action -X- _ O
semantics -X- _ O
and -X- _ O
other -X- _ O
meta -X- _ O
- -X- _ O
data -X- _ O
. -X- _ O
Wholly -X- _ O
new -X- _ O
systems -X- _ O
that -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
in -X- _ O
a -X- _ O
fully -X- _ O
differentiable -X- _ O
manner -X- _ O
are -X- _ O
also -X- _ O
worth -X- _ O
exploring -X- _ O
. -X- _ O
By -X- _ O
grounding -X- _ O
dialogues -X- _ O
to -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
scenarios -X- _ O
with -X- _ O
explicit -X- _ O
policies -X- _ O
, -X- _ O
we -X- _ O
hope -X- _ O
to -X- _ O
have -X- _ O
pushed -X- _ O
towards -X- _ O
a -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
dialogue -X- _ O
success -X- _ O
. -X- _ O
Optimizing -X- _ O
agents -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
split -X- _ O
into -X- _ O
preparation -X- _ O
before -X- _ O
the -X- _ O
HIT -X- _ B-TaskName
( -X- _ O
Human -X- _ B-TaskName
Intelligence -X- _ I-TaskName
Task -X- _ I-TaskName
) -X- _ O
, -X- _ O
improving -X- _ O
HIT -X- _ B-TaskName
itself -X- _ O
, -X- _ O
and -X- _ O
ongoing -X- _ O
training -X- _ O
afterwards -X- _ O
. -X- _ O
Starting -X- _ O
with -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
HIT -X- _ B-TaskName
phase -X- _ O
, -X- _ O
the -X- _ O
major -X- _ O
steps -X- _ O
largely -X- _ O
center -X- _ O
around -X- _ O
multiple -X- _ O
rounds -X- _ O
of -X- _ O
qualifications -X- _ O
to -X- _ O
filter -X- _ O
for -X- _ O
the -X- _ O
highest -X- _ O
quality -X- _ O
workers -X- _ O
available -X- _ O
. -X- _ O
During -X- _ O
the -X- _ O
post -X- _ O
- -X- _ O
HIT -X- _ B-TaskName
phase -X- _ O
, -X- _ O
effort -X- _ O
shifts -X- _ O
to -X- _ O
ensuring -X- _ O
that -X- _ O
each -X- _ O
worker -X- _ O
becomes -X- _ O
increasingly -X- _ O
comfortable -X- _ O
with -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
HIT -X- _ O
Phase -X- _ O
Qualifications -X- _ O
take -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
online -X- _ O
quizzes -X- _ O
which -X- _ O
serve -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
training -X- _ O
motivated -X- _ O
workers -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
simply -X- _ O
removing -X- _ O
unqualified -X- _ O
ones -X- _ O
. -X- _ O
When -X- _ O
designing -X- _ O
the -X- _ O
qualification -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
and -X- _ O
style -X- _ O
of -X- _ O
questions -X- _ O
were -X- _ O
iterated -X- _ O
on -X- _ O
to -X- _ O
limit -X- _ O
the -X- _ O
feeling -X- _ O
of -X- _ O
a -X- _ O
tight -X- _ O
time -X- _ O
constraint -X- _ O
, -X- _ O
while -X- _ O
still -X- _ O
remaining -X- _ O
quite -X- _ O
difficult -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
some -X- _ O
agents -X- _ O
who -X- _ O
had -X- _ O
previously -X- _ O
had -X- _ O
actual -X- _ O
customer -X- _ O
service -X- _ O
jobs -X- _ O
mentioned -X- _ O
they -X- _ O
felt -X- _ O
like -X- _ O
they -X- _ O
were -X- _ O
right -X- _ O
back -X- _ O
at -X- _ O
the -X- _ O
office -X- _ O
. -X- _ O
This -X- _ O
difficulty -X- _ O
resulted -X- _ O
in -X- _ O
a -X- _ O
high -X- _ O
rejection -X- _ O
rate -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
costly -X- _ O
because -X- _ O
we -X- _ O
paid -X- _ O
Turkers -X- _ O
$ -X- _ O
2 -X- _ O
regardless -X- _ O
of -X- _ O
passing -X- _ O
the -X- _ O
exam -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
larger -X- _ O
$ -X- _ O
8 -X- _ O
bonus -X- _ O
for -X- _ O
passing -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
, -X- _ O
the -X- _ O
cost -X- _ O
was -X- _ O
well -X- _ O
worth -X- _ O
the -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
since -X- _ O
having -X- _ O
high -X- _ O
quality -X- _ O
agents -X- _ O
would -X- _ O
pay -X- _ O
dividends -X- _ O
down -X- _ O
the -X- _ O
road -X- _ O
. -X- _ O
To -X- _ O
move -X- _ O
efficiently -X- _ O
, -X- _ O
we -X- _ O
leaned -X- _ O
heavily -X- _ O
on -X- _ O
multiple -X- _ O
choice -X- _ O
questions -X- _ O
and -X- _ O
MTurk -X- _ O
APIs -X- _ O
to -X- _ O
help -X- _ O
automate -X- _ O
grading -X- _ O
and -X- _ O
assignment -X- _ O
of -X- _ O
qualifications -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
learned -X- _ O
that -X- _ O
including -X- _ O
screenshots -X- _ O
of -X- _ O
the -X- _ O
Agent -X- _ O
Dashboard -X- _ O
in -X- _ O
the -X- _ O
quizzes -X- _ O
was -X- _ O
a -X- _ O
great -X- _ O
way -X- _ O
to -X- _ O
familiarize -X- _ O
the -X- _ O
agents -X- _ O
with -X- _ O
the -X- _ O
platform -X- _ O
before -X- _ O
performing -X- _ O
the -X- _ O
actual -X- _ O
task -X- _ O
. -X- _ O
During -X- _ O
- -X- _ O
HIT -X- _ B-TaskName
Phase -X- _ O
The -X- _ O
HIT -X- _ B-TaskName
itself -X- _ O
was -X- _ O
priced -X- _ O
at -X- _ O
$ -X- _ O
1.50 -X- _ O
for -X- _ O
completing -X- _ O
the -X- _ O
conversation -X- _ O
with -X- _ O
an -X- _ O
extra -X- _ O
$ -X- _ O
1.00 -X- _ O
bonus -X- _ O
for -X- _ O
identifying -X- _ O
the -X- _ O
correct -X- _ O
customer -X- _ O
intent -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
chat -X- _ O
survey -X- _ O
. -X- _ O
Since -X- _ O
agents -X- _ O
are -X- _ O
naturally -X- _ O
focused -X- _ O
on -X- _ O
getting -X- _ O
done -X- _ O
as -X- _ O
quickly -X- _ O
as -X- _ O
possible -X- _ O
, -X- _ O
they -X- _ O
would -X- _ O
often -X- _ O
only -X- _ O
take -X- _ O
the -X- _ O
customer -X- _ O
's -X- _ O
requests -X- _ O
into -X- _ O
account -X- _ O
, -X- _ O
bypassing -X- _ O
a -X- _ O
key -X- _ O
characteristic -X- _ O
of -X- _ O
what -X- _ O
makes -X- _ O
ABCD -X- _ O
unique -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
by -X- _ O
encouraging -X- _ O
agents -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
customer -X- _ O
intent -X- _ O
, -X- _ O
they -X- _ O
were -X- _ O
forced -X- _ O
to -X- _ O
peruse -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
for -X- _ O
the -X- _ O
associated -X- _ O
subflow -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
this -X- _ O
incentive -X- _ O
critical -X- _ O
for -X- _ O
aligning -X- _ O
agent -X- _ O
behaviors -X- _ O
with -X- _ O
optimal -X- _ O
outcomes -X- _ O
. -X- _ O
Post -X- _ O
- -X- _ O
HIT -X- _ B-TaskName
Phase -X- _ O
For -X- _ O
ongoing -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
began -X- _ O
producing -X- _ O
small -X- _ O
lists -X- _ O
of -X- _ O
bulletpoints -X- _ O
to -X- _ O
the -X- _ O
agents -X- _ O
on -X- _ O
areas -X- _ O
they -X- _ O
could -X- _ O
improve -X- _ O
on -X- _ O
. -X- _ O
Fur- -X- _ O
thermore -X- _ O
, -X- _ O
we -X- _ O
would -X- _ O
highlight -X- _ O
examples -X- _ O
of -X- _ O
good -X- _ O
and -X- _ O
bad -X- _ O
decision -X- _ O
- -X- _ O
making -X- _ O
and -X- _ O
appropriate -X- _ O
behavior -X- _ O
when -X- _ O
representing -X- _ O
the -X- _ O
fictitious -X- _ O
" -X- _ O
AcmeBrands -X- _ O
" -X- _ O
retail -X- _ O
company -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
recorded -X- _ O
videos -X- _ O
which -X- _ O
gave -X- _ O
agents -X- _ O
a -X- _ O
view -X- _ O
of -X- _ O
how -X- _ O
an -X- _ O
" -X- _ O
ideal -X- _ O
" -X- _ O
agent -X- _ O
would -X- _ O
behave -X- _ O
at -X- _ O
every -X- _ O
step -X- _ O
of -X- _ O
the -X- _ O
chat -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
that -X- _ O
by -X- _ O
engaging -X- _ O
with -X- _ O
the -X- _ O
Turkers -X- _ O
through -X- _ O
the -X- _ O
group -X- _ O
chat -X- _ O
and -X- _ O
respecting -X- _ O
their -X- _ O
feedback -X- _ O
, -X- _ O
they -X- _ O
were -X- _ O
very -X- _ O
willing -X- _ O
to -X- _ O
work -X- _ O
on -X- _ O
improving -X- _ O
despite -X- _ O
not -X- _ O
having -X- _ O
extra -X- _ O
monetary -X- _ O
incentive -X- _ O
to -X- _ O
do -X- _ O
so -X- _ O
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
the -X- _ O
agents -X- _ O
were -X- _ O
quite -X- _ O
wonderful -X- _ O
to -X- _ O
work -X- _ O
with -X- _ O
and -X- _ O
their -X- _ O
end -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
task -X- _ O
feedback -X- _ O
strongly -X- _ O
suggests -X- _ O
they -X- _ O
enjoyed -X- _ O
the -X- _ O
process -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
( -X- _ O
See -X- _ O
Figure -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
credit -X- _ O
this -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
details -X- _ O
mentioned -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
and -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
the -X- _ O
Expert -X- _ O
Live -X- _ O
Chat -X- _ O
procedure -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
regular -X- _ O
Mechanical -X- _ O
Turk -X- _ O
( -X- _ O
MTurk -X- _ O
) -X- _ O
setup -X- _ O
, -X- _ O
HITs -X- _ O
are -X- _ O
made -X- _ O
available -X- _ O
to -X- _ O
a -X- _ O
large -X- _ O
audience -X- _ O
who -X- _ O
can -X- _ O
pick -X- _ O
up -X- _ O
as -X- _ O
many -X- _ O
or -X- _ O
as -X- _ O
few -X- _ O
as -X- _ O
they -X- _ O
want -X- _ O
. -X- _ O
Expert -X- _ O
Live -X- _ O
Chat -X- _ O
dictates -X- _ O
a -X- _ O
dialogue -X- _ O
between -X- _ O
two -X- _ O
speakers -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
need -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
workers -X- _ O
: -X- _ O
agents -X- _ O
and -X- _ O
customers -X- _ O
. -X- _ O
Let -X- _ O
us -X- _ O
consider -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
agents -X- _ O
available -X- _ O
as -X- _ O
A -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
customers -X- _ O
available -X- _ O
as -X- _ O
C. -X- _ O
Given -X- _ O
budget -X- _ O
constraints -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
only -X- _ O
pay -X- _ O
some -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
workers -X- _ O
M -X- _ O
. -X- _ O
Simultaneously -X- _ O
, -X- _ O
given -X- _ O
time -X- _ O
constraints -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
a -X- _ O
minimum -X- _ O
number -X- _ O
of -X- _ O
conversations -X- _ O
collected -X- _ O
per -X- _ O
week -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
available -X- _ O
workers -X- _ O
N -X- _ O
= -X- _ O
f -X- _ O
( -X- _ O
A -X- _ O
, -X- _ O
C -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
leads -X- _ O
to -X- _ O
three -X- _ O
issues -X- _ O
that -X- _ O
must -X- _ O
be -X- _ O
considered -X- _ O
in -X- _ O
conjunction -X- _ O
: -X- _ O
N -X- _ O
< -X- _ O
A+C -X- _ O
< -X- _ O
M -X- _ O
Operating -X- _ O
the -X- _ O
Agent -X- _ O
Dashboard -X- _ O
requires -X- _ O
a -X- _ O
highly -X- _ O
skilled -X- _ O
worker -X- _ O
, -X- _ O
so -X- _ O
efficient -X- _ O
data -X- _ O
collection -X- _ O
is -X- _ O
limited -X- _ O
by -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
available -X- _ O
agents -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
customer -X- _ O
side -X- _ O
of -X- _ O
ABCD -X- _ B-DatasetName
is -X- _ O
a -X- _ O
simpler -X- _ O
task -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
minimum -X- _ O
bar -X- _ O
to -X- _ O
be -X- _ O
met -X- _ O
to -X- _ O
prevent -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
customers -X- _ O
who -X- _ O
spam -X- _ O
with -X- _ O
random -X- _ O
text -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
customers -X- _ O
who -X- _ O
fake -X- _ O
scenarios -X- _ O
or -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
customers -X- _ O
who -X- _ O
hoard -X- _ O
HITs -X- _ O
and -X- _ O
never -X- _ O
show -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
chat -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
there -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
sufficient -X- _ O
amount -X- _ O
of -X- _ O
both -X- _ O
agent -X- _ O
A -X- _ O
and -X- _ O
customers -X- _ O
C -X- _ O
qualified -X- _ O
and -X- _ O
available -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
surpass -X- _ O
the -X- _ O
minimum -X- _ O
threshold -X- _ O
set -X- _ O
by -X- _ O
N -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
simply -X- _ O
paying -X- _ O
more -X- _ O
per -X- _ O
HIT -X- _ O
bumps -X- _ O
up -X- _ O
against -X- _ O
the -X- _ O
limits -X- _ O
set -X- _ O
by -X- _ O
M -X- _ O
.C -X- _ O
> -X- _ O
> -X- _ O
A -X- _ O
Since -X- _ O
training -X- _ O
agents -X- _ O
is -X- _ O
more -X- _ O
resource -X- _ O
intensive -X- _ O
than -X- _ O
training -X- _ O
customers -X- _ O
, -X- _ O
it -X- _ O
makes -X- _ O
sense -X- _ O
to -X- _ O
simply -X- _ O
have -X- _ O
more -X- _ O
of -X- _ O
the -X- _ O
latter -X- _ O
. -X- _ O
Yet -X- _ O
by -X- _ O
doing -X- _ O
so -X- _ O
leads -X- _ O
to -X- _ O
an -X- _ O
issue -X- _ O
where -X- _ O
customers -X- _ O
wait -X- _ O
around -X- _ O
for -X- _ O
agents -X- _ O
when -X- _ O
they -X- _ O
arrive -X- _ O
in -X- _ O
the -X- _ O
waitroom -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
typical -X- _ O
scenario -X- _ O
, -X- _ O
a -X- _ O
customer -X- _ O
might -X- _ O
leave -X- _ O
the -X- _ O
tab -X- _ O
open -X- _ O
to -X- _ O
work -X- _ O
on -X- _ O
other -X- _ O
tasks -X- _ O
, -X- _ O
but -X- _ O
when -X- _ O
they -X- _ O
are -X- _ O
eventually -X- _ O
paired -X- _ O
, -X- _ O
the -X- _ O
customer -X- _ O
is -X- _ O
often -X- _ O
busy -X- _ O
doing -X- _ O
something -X- _ O
else -X- _ O
, -X- _ O
leaving -X- _ O
the -X- _ O
chat -X- _ O
to -X- _ O
flounder -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
worst -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
customer -X- _ O
starts -X- _ O
to -X- _ O
verbally -X- _ O
abuse -X- _ O
the -X- _ O
agent -X- _ O
about -X- _ O
the -X- _ O
long -X- _ O
wait -X- _ O
time -X- _ O
when -X- _ O
they -X- _ O
are -X- _ O
finally -X- _ O
paired -X- _ O
. -X- _ O
A -X- _ O
> -X- _ O
> -X- _ O
C -X- _ O
Finding -X- _ O
as -X- _ O
many -X- _ O
agents -X- _ O
as -X- _ O
possible -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
solution -X- _ O
either -X- _ O
because -X- _ O
now -X- _ O
the -X- _ O
agents -X- _ O
will -X- _ O
end -X- _ O
up -X- _ O
waiting -X- _ O
around -X- _ O
for -X- _ O
customers -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
waiting -X- _ O
periods -X- _ O
are -X- _ O
too -X- _ O
long -X- _ O
, -X- _ O
agents -X- _ O
will -X- _ O
abandon -X- _ O
the -X- _ O
task -X- _ O
and -X- _ O
disparage -X- _ O
your -X- _ O
reputation -X- _ O
on -X- _ O
various -X- _ O
forms -X- _ O
of -X- _ O
social -X- _ O
media -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
difficult -X- _ O
, -X- _ O
the -X- _ O
pool -X- _ O
of -X- _ O
workers -X- _ O
who -X- _ O
may -X- _ O
eventually -X- _ O
qualify -X- _ O
as -X- _ O
agents -X- _ O
is -X- _ O
finite -X- _ O
, -X- _ O
so -X- _ O
too -X- _ O
many -X- _ O
poor -X- _ O
interactions -X- _ O
can -X- _ O
halt -X- _ O
the -X- _ O
data -X- _ O
collection -X- _ O
process -X- _ O
completely -X- _ O
. -X- _ O
To -X- _ O
resolve -X- _ O
this -X- _ O
situation -X- _ O
, -X- _ O
we -X- _ O
begin -X- _ O
with -X- _ O
the -X- _ O
maximum -X- _ O
number -X- _ O
of -X- _ O
workers -X- _ O
M -X- _ O
as -X- _ O
the -X- _ O
starting -X- _ O
constraint -X- _ O
given -X- _ O
a -X- _ O
fixed -X- _ O
budget -X- _ O
. -X- _ O
If -X- _ O
we -X- _ O
qualify -X- _ O
too -X- _ O
many -X- _ O
workers -X- _ O
, -X- _ O
then -X- _ O
we -X- _ O
will -X- _ O
not -X- _ O
have -X- _ O
enough -X- _ O
budget -X- _ O
left -X- _ O
for -X- _ O
the -X- _ O
actual -X- _ O
conversations -X- _ O
, -X- _ O
so -X- _ O
instead -X- _ O
we -X- _ O
qualify -X- _ O
workers -X- _ O
in -X- _ O
mini -X- _ O
- -X- _ O
batches -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
pool -X- _ O
of -X- _ O
potential -X- _ O
workers -X- _ O
who -X- _ O
may -X- _ O
meet -X- _ O
the -X- _ O
strict -X- _ O
requirements -X- _ O
for -X- _ O
agents -X- _ O
A -X- _ O
is -X- _ O
more -X- _ O
limited -X- _ O
than -X- _ O
customer -X- _ O
candidates -X- _ O
C -X- _ O
, -X- _ O
we -X- _ O
start -X- _ O
on -X- _ O
the -X- _ O
agent -X- _ O
side -X- _ O
. -X- _ O
Given -X- _ O
some -X- _ O
amount -X- _ O
of -X- _ O
qualified -X- _ O
agents -X- _ O
, -X- _ O
only -X- _ O
a -X- _ O
percentage -X- _ O
of -X- _ O
them -X- _ O
will -X- _ O
show -X- _ O
up -X- _ O
at -X- _ O
the -X- _ O
desired -X- _ O
time -X- _ O
slot -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
increment -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
until -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
available -X- _ O
workers -X- _ O
passes -X- _ O
the -X- _ O
minimum -X- _ O
A -X- _ O
> -X- _ O
N/2.To -X- _ O
limit -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
customers -X- _ O
who -X- _ O
show -X- _ O
up -X- _ O
, -X- _ O
we -X- _ O
filter -X- _ O
for -X- _ O
users -X- _ O
by -X- _ O
location -X- _ O
, -X- _ O
number -X- _ O
of -X- _ O
completed -X- _ O
HITS -X- _ O
, -X- _ O
and -X- _ O
sufficient -X- _ O
rating -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
establish -X- _ O
an -X- _ O
exam -X- _ O
that -X- _ O
is -X- _ O
purposely -X- _ O
very -X- _ O
easy -X- _ O
( -X- _ O
to -X- _ O
minimize -X- _ O
costs -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
just -X- _ O
hard -X- _ O
enough -X- _ O
to -X- _ O
deter -X- _ O
bots -X- _ O
and -X- _ O
spammers -X- _ O
. -X- _ O
To -X- _ O
raise -X- _ O
the -X- _ O
likelihood -X- _ O
that -X- _ O
the -X- _ O
customer -X- _ O
will -X- _ O
show -X- _ O
up -X- _ O
, -X- _ O
we -X- _ O
include -X- _ O
a -X- _ O
question -X- _ O
in -X- _ O
the -X- _ O
quiz -X- _ O
which -X- _ O
simply -X- _ O
asks -X- _ O
when -X- _ O
the -X- _ O
customer -X- _ O
is -X- _ O
available -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
HIT -X- _ O
. -X- _ O
We -X- _ O
really -X- _ O
emphasize -X- _ O
this -X- _ O
question -X- _ O
and -X- _ O
make -X- _ O
it -X- _ O
required -X- _ O
, -X- _ O
so -X- _ O
workers -X- _ O
are -X- _ O
aware -X- _ O
of -X- _ O
its -X- _ O
significance -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
tune -X- _ O
the -X- _ O
customer -X- _ O
count -X- _ O
such -X- _ O
that -X- _ O
C -X- _ O
≈ -X- _ O
A.Note -X- _ O
that -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
higher -X- _ O
pay -X- _ O
rate -X- _ O
, -X- _ O
agents -X- _ O
are -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
show -X- _ O
up -X- _ O
than -X- _ O
customers -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
there -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
higher -X- _ O
ratio -X- _ O
of -X- _ O
customers -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
this -X- _ O
imbalance -X- _ O
. -X- _ O
For -X- _ O
some -X- _ O
intuition -X- _ O
on -X- _ O
where -X- _ O
to -X- _ O
start -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
that -X- _ O
a -X- _ O
good -X- _ O
rule -X- _ O
of -X- _ O
thumb -X- _ O
was -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
appearance -X- _ O
ratio -X- _ O
as -X- _ O
inversely -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
pay -X- _ O
. -X- _ O
One -X- _ O
final -X- _ O
insight -X- _ O
is -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
HITs -X- _ O
heavily -X- _ O
dependent -X- _ O
on -X- _ O
bonus -X- _ O
pay -X- _ O
, -X- _ O
with -X- _ O
base -X- _ O
pay -X- _ O
very -X- _ O
low -X- _ O
. -X- _ O
This -X- _ O
will -X- _ O
keep -X- _ O
spammers -X- _ O
away -X- _ O
since -X- _ O
they -X- _ O
will -X- _ O
end -X- _ O
up -X- _ O
with -X- _ O
a -X- _ O
pittance -X- _ O
when -X- _ O
attempting -X- _ O
to -X- _ O
game -X- _ O
the -X- _ O
system -X- _ O
. -X- _ O
To -X- _ O
improve -X- _ O
the -X- _ O
waitroom -X- _ O
experience -X- _ O
, -X- _ O
we -X- _ O
added -X- _ O
a -X- _ O
feature -X- _ O
where -X- _ O
a -X- _ O
user -X- _ O
's -X- _ O
place -X- _ O
in -X- _ O
the -X- _ O
queue -X- _ O
would -X- _ O
be -X- _ O
updated -X- _ O
live -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
a -X- _ O
timer -X- _ O
indicating -X- _ O
the -X- _ O
expected -X- _ O
wait -X- _ O
. -X- _ O
For -X- _ O
Turkers -X- _ O
willing -X- _ O
to -X- _ O
wait -X- _ O
around -X- _ O
, -X- _ O
helpful -X- _ O
and -X- _ O
encouraging -X- _ O
messages -X- _ O
would -X- _ O
also -X- _ O
be -X- _ O
displayed -X- _ O
to -X- _ O
keep -X- _ O
them -X- _ O
occupied -X- _ O
. -X- _ O
Alternatively -X- _ O
, -X- _ O
for -X- _ O
Turkers -X- _ O
who -X- _ O
were -X- _ O
multi -X- _ O
- -X- _ O
tasking -X- _ O
, -X- _ O
visual -X- _ O
and -X- _ O
audio -X- _ O
notifications -X- _ O
were -X- _ O
added -X- _ O
to -X- _ O
signify -X- _ O
the -X- _ O
start -X- _ O
of -X- _ O
a -X- _ O
chat -X- _ O
, -X- _ O
allowing -X- _ O
them -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
other -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
meantime -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
our -X- _ O
modifications -X- _ O
have -X- _ O
only -X- _ O
scratched -X- _ O
the -X- _ O
surface -X- _ O
and -X- _ O
that -X- _ O
improving -X- _ O
the -X- _ O
user -X- _ O
experience -X- _ O
for -X- _ O
data -X- _ O
collection -X- _ O
offers -X- _ O
an -X- _ O
interesting -X- _ O
line -X- _ O
of -X- _ O
HCI -X- _ B-TaskName
research -X- _ O
to -X- _ O
explore -X- _ O
. -X- _ O
To -X- _ O
motivate -X- _ O
cascading -X- _ B-TaskName
dialogue -X- _ I-TaskName
success -X- _ I-TaskName
( -X- _ O
CDS -X- _ B-TaskName
) -X- _ O
over -X- _ O
typical -X- _ O
other -X- _ O
accuracy -X- _ O
metrics -X- _ O
, -X- _ O
consider -X- _ O
the -X- _ O
scenario -X- _ O
where -X- _ O
a -X- _ O
model -X- _ O
gets -X- _ O
80 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
turns -X- _ O
correct -X- _ O
, -X- _ O
while -X- _ O
still -X- _ O
achieving -X- _ O
0 -X- _ O
% -X- _ O
accuracy -X- _ O
on -X- _ O
the -X- _ O
conversation -X- _ O
level -X- _ O
because -X- _ O
it -X- _ O
always -X- _ O
messes -X- _ O
up -X- _ O
somewhere -X- _ O
right -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
dialogue -X- _ O
. -X- _ O
A -X- _ O
turnbased -X- _ O
metric -X- _ O
would -X- _ O
over -X- _ O
- -X- _ O
estimate -X- _ O
performance -X- _ O
since -X- _ O
such -X- _ O
a -X- _ O
metric -X- _ O
fails -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
consistent -X- _ O
shortcomings -X- _ O
in -X- _ O
closing -X- _ O
conversations -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
conversation -X- _ O
- -X- _ O
based -X- _ O
metrics -X- _ O
under -X- _ O
- -X- _ O
estimate -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
performance -X- _ O
because -X- _ O
such -X- _ O
measures -X- _ O
fail -X- _ O
to -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
system -X- _ O
is -X- _ O
mostly -X- _ O
successful -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
each -X- _ O
evaluation -X- _ O
would -X- _ O
be -X- _ O
limited -X- _ O
to -X- _ O
occurring -X- _ O
only -X- _ O
once -X- _ O
per -X- _ O
conversation -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
inefficient -X- _ O
use -X- _ O
of -X- _ O
scarce -X- _ O
data -X- _ O
as -X- _ O
a -X- _ O
resource -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
cascading -X- _ B-TaskName
dialogue -X- _ I-TaskName
success -X- _ I-TaskName
creates -X- _ O
an -X- _ O
evaluation -X- _ O
example -X- _ O
for -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
each -X- _ O
conversation -X- _ O
starting -X- _ O
from -X- _ O
each -X- _ O
turn -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
suppose -X- _ O
a -X- _ O
chat -X- _ O
contained -X- _ O
4 -X- _ O
turns -X- _ O
: -X- _ O
[ -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
and -X- _ O
D -X- _ O
] -X- _ O
, -X- _ O
training -X- _ O
instances -X- _ O
can -X- _ O
be -X- _ O
created -X- _ O
with -X- _ O
this -X- _ O
data -X- _ O
that -X- _ O
include -X- _ O
: -X- _ O
[ -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
D -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
D -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
C -X- _ O
, -X- _ O
D -X- _ O
] -X- _ O
and -X- _ O
[ -X- _ O
D -X- _ O
] -X- _ O
by -X- _ O
itself -X- _ O
. -X- _ O
Now -X- _ O
imagine -X- _ O
the -X- _ O
model -X- _ O
consistently -X- _ O
predicted -X- _ O
turn -X- _ O
C -X- _ O
incorrectly -X- _ O
, -X- _ O
and -X- _ O
everything -X- _ O
else -X- _ O
correct -X- _ O
. -X- _ O
Then -X- _ O
its -X- _ O
scores -X- _ O
would -X- _ O
be -X- _ O
2/4 -X- _ O
, -X- _ O
1/3 -X- _ O
, -X- _ O
0 -X- _ O
and -X- _ O
1 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Averaging -X- _ O
across -X- _ O
all -X- _ O
turns -X- _ O
would -X- _ O
yield -X- _ O
a -X- _ O
final -X- _ O
cascading -X- _ B-MetricName
success -X- _ I-MetricName
rate -X- _ I-MetricName
of -X- _ O
45.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
A -X- _ O
turn -X- _ O
- -X- _ O
based -X- _ O
metric -X- _ O
would -X- _ O
yield -X- _ O
75 -X- _ B-MetricValue
% -X- _ I-MetricValue
while -X- _ O
a -X- _ O
conversation -X- _ O
- -X- _ O
based -X- _ O
metric -X- _ O
would -X- _ O
yield -X- _ O
0 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Thus -X- _ O
, -X- _ O
CDS -X- _ B-TaskName
allows -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
earn -X- _ O
partial -X- _ O
credit -X- _ O
on -X- _ O
what -X- _ O
it -X- _ O
has -X- _ O
learned -X- _ O
without -X- _ O
severe -X- _ O
penalties -X- _ O
in -X- _ O
either -X- _ O
direction -X- _ O
. -X- _ O
When -X- _ O
training -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
for -X- _ B-TaskName
Action -X- _ I-TaskName
State -X- _ I-TaskName
Tracking -X- _ I-TaskName
, -X- _ O
we -X- _ O
ended -X- _ O
up -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ B-HyperparameterName
hidden -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
of -X- _ O
1024 -X- _ B-HyperparameterValue
, -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.05 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
10 -X- _ B-HyperparameterValue
examples -X- _ O
. -X- _ O
Training -X- _ O
lasted -X- _ O
for -X- _ O
14 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
where -X- _ O
we -X- _ O
early -X- _ O
stopped -X- _ O
if -X- _ O
overall -X- _ O
accuracy -X- _ B-MetricName
failed -X- _ O
to -X- _ O
improve -X- _ O
for -X- _ O
three -X- _ O
epochs -X- _ O
in -X- _ O
a -X- _ O
row -X- _ O
. -X- _ O
The -X- _ O
RAdam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
had -X- _ O
a -X- _ O
linear -X- _ O
warm -X- _ O
- -X- _ O
up -X- _ O
for -X- _ O
three -X- _ O
epochs -X- _ O
, -X- _ O
with -X- _ O
hyperparameters -X- _ O
kept -X- _ O
at -X- _ O
their -X- _ O
defaults -X- _ O
of -X- _ O
0.9 -X- _ B-HyperparameterValue
and -X- _ O
0.999 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
also -X- _ O
add -X- _ O
the -X- _ O
delexicalized -X- _ O
slots -X- _ O
into -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
the -X- _ O
tokenizer -X- _ O
. -X- _ O
For -X- _ O
Cascading -X- _ B-TaskName
Dialogue -X- _ I-TaskName
Success -X- _ I-TaskName
, -X- _ O
our -X- _ O
best -X- _ O
model -X- _ O
had -X- _ O
a -X- _ O
1e-5 -X- _ B-HyperparameterValue
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
, -X- _ O
1024 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
and -X- _ O
no -X- _ O
weight -X- _ O
decay -X- _ O
. -X- _ O
The -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
was -X- _ O
shrunk -X- _ O
to -X- _ O
3 -X- _ B-HyperparameterValue
examples -X- _ O
, -X- _ O
but -X- _ O
this -X- _ O
was -X- _ O
due -X- _ O
purely -X- _ O
to -X- _ O
memory -X- _ O
rather -X- _ O
than -X- _ O
performance -X- _ O
reasons -X- _ O
. -X- _ O
Train -X- _ O
- -X- _ O
ing -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
21 -X- _ O
epochs -X- _ O
, -X- _ O
and -X- _ O
again -X- _ O
we -X- _ O
early -X- _ O
stopped -X- _ O
if -X- _ O
overall -X- _ O
accuracy -X- _ O
failed -X- _ O
to -X- _ O
improve -X- _ O
for -X- _ O
three -X- _ O
epochs -X- _ O
in -X- _ O
a -X- _ O
row -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
optimizer -X- _ O
again -X- _ O
had -X- _ O
a -X- _ O
linear -X- _ O
warm -X- _ O
- -X- _ O
up -X- _ O
for -X- _ O
three -X- _ O
epochs -X- _ O
with -X- _ O
hyperparameters -X- _ O
kept -X- _ O
at -X- _ O
their -X- _ O
defaults -X- _ O
. -X- _ O
We -X- _ O
augment -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
access -X- _ O
to -X- _ O
intent -X- _ O
information -X- _ O
in -X- _ O
two -X- _ O
ways -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
subflow -X- _ O
is -X- _ O
translated -X- _ O
into -X- _ O
an -X- _ O
index -X- _ O
which -X- _ O
is -X- _ O
concatenated -X- _ O
to -X- _ O
all -X- _ O
input -X- _ O
contexts -X- _ O
so -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
leverage -X- _ O
this -X- _ O
information -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
the -X- _ O
intent -X- _ O
classifier -X- _ O
is -X- _ O
directly -X- _ O
fed -X- _ O
the -X- _ O
solution -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
what -X- _ O
allows -X- _ O
it -X- _ O
to -X- _ O
trivially -X- _ O
reach -X- _ O
perfect -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
We -X- _ O
leverage -X- _ O
the -X- _ O
Agent -X- _ O
Guidelines -X- _ O
by -X- _ O
using -X- _ O
it -X- _ O
to -X- _ O
mask -X- _ O
invalid -X- _ O
action -X- _ O
predictions -X- _ O
. -X- _ O
More -X- _ O
specifically -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
predicted -X- _ O
subflow -X- _ O
, -X- _ O
the -X- _ O
guidelines -X- _ O
outline -X- _ O
all -X- _ O
possible -X- _ O
actions -X- _ O
and -X- _ O
values -X- _ O
within -X- _ O
that -X- _ O
subflow -X- _ O
. -X- _ O
With -X- _ O
this -X- _ O
information -X- _ O
, -X- _ O
a -X- _ O
mask -X- _ O
is -X- _ O
created -X- _ O
before -X- _ O
training -X- _ O
and -X- _ O
applied -X- _ O
during -X- _ O
evaluation -X- _ O
to -X- _ O
only -X- _ O
allow -X- _ O
valid -X- _ O
actions -X- _ O
. -X- _ O
Since -X- _ O
ABCD -X- _ B-DatasetName
was -X- _ O
collected -X- _ O
using -X- _ O
Expert -X- _ O
Live -X- _ O
Chat -X- _ O
rather -X- _ O
than -X- _ O
templates -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
various -X- _ O
linguistic -X- _ O
diversity -X- _ O
in -X- _ O
the -X- _ O
chats -X- _ O
. -X- _ O
These -X- _ O
phenomena -X- _ O
limit -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
models -X- _ O
to -X- _ O
memorize -X- _ O
artificial -X- _ O
patterns -X- _ O
when -X- _ O
making -X- _ O
predictions -X- _ O
. -X- _ O
Co -X- _ O
- -X- _ O
reference -X- _ O
CUS -X- _ O
: -X- _ O
I -X- _ O
'd -X- _ O
like -X- _ O
to -X- _ O
return -X- _ O
something -X- _ O
AGT -X- _ O
: -X- _ O
OK -X- _ O
AGT -X- _ O
: -X- _ O
Can -X- _ O
I -X- _ O
get -X- _ O
your -X- _ O
full -X- _ O
name -X- _ O
AGT -X- _ O
: -X- _ O
Also -X- _ O
user -X- _ O
name -X- _ O
, -X- _ O
email -X- _ O
address -X- _ O
, -X- _ O
order -X- _ O
i -X- _ O
d -X- _ O
AGT -X- _ O
: -X- _ O
Membershp -X- _ O
level -X- _ O
and -X- _ O
reason -X- _ O
for -X- _ O
return -X- _ O
CUS -X- _ O
: -X- _ O
Alessandro -X- _ O
Phoenix -X- _ O
, -X- _ O
aphoenix872@email.com -X- _ O
, -X- _ O
order -X- _ O
ID -X- _ O
is -X- _ O
4024067912 -X- _ O
CUS -X- _ O
: -X- _ O
I -X- _ O
'm -X- _ O
at -X- _ O
the -X- _ O
Gold -X- _ O
level -X- _ O
. -X- _ O
I -X- _ O
'm -X- _ O
returning -X- _ O
it -X- _ O
because -X- _ O
it -X- _ O
's -X- _ O
the -X- _ O
wrong -X- _ O
size -X- _ O
Chit -X- _ O
- -X- _ O
Chat -X- _ O
AGT -X- _ O
: -X- _ O
Do -X- _ O
you -X- _ O
need -X- _ O
any -X- _ O
more -X- _ O
help -X- _ O
? -X- _ O
CUS -X- _ O
: -X- _ O
a -X- _ O
break -X- _ O
, -X- _ O
I -X- _ O
need -X- _ O
a -X- _ O
coffee -X- _ O
break -X- _ O
CUS -X- _ O
: -X- _ O
but -X- _ O
no -X- _ O
, -X- _ O
nothing -X- _ O
from -X- _ O
you -X- _ O
CUS -X- _ O
: -X- _ O
thanks -X- _ O
for -X- _ O
the -X- _ O
save -X- _ O
AGT -X- _ O
: -X- _ O
Haha -X- _ O
have -X- _ O
a -X- _ O
good -X- _ O
break -X- _ O
! -X- _ O
And -X- _ O
have -X- _ O
an -X- _ O
even -X- _ O
better -X- _ O
day -X- _ O
. -X- _ O
Emotion -X- _ O
AGT -X- _ O
: -X- _ O
Ok -X- _ O
, -X- _ O
there -X- _ O
was -X- _ O
a -X- _ O
mistake -X- _ O
made -X- _ O
. -X- _ O
Do -X- _ O
you -X- _ O
have -X- _ O
the -X- _ O
Shipping -X- _ O
Status -X- _ O
? -X- _ O
CUS -X- _ O
: -X- _ O
It -X- _ O
's -X- _ O
in -X- _ O
transit -X- _ O
AGT -X- _ O
: -X- _ O
Ok -X- _ O
, -X- _ O
that -X- _ O
means -X- _ O
it -X- _ O
's -X- _ O
already -X- _ O
out -X- _ O
for -X- _ O
shipment -X- _ O
CUS -X- _ O
: -X- _ O
so -X- _ O
two -X- _ O
are -X- _ O
being -X- _ O
sent -X- _ O
? -X- _ O
AGT -X- _ O
: -X- _ O
Yes -X- _ O
. -X- _ O
Unfortunately -X- _ O
that -X- _ O
means -X- _ O
when -X- _ O
you -X- _ O
get -X- _ O
the -X- _ O
item -X- _ O
you -X- _ O
will -X- _ O
need -X- _ O
to -X- _ O
call -X- _ O
back -X- _ O
and -X- _ O
make -X- _ O
a -X- _ O
return -X- _ O
CUS -X- _ O
: -X- _ O
oh -X- _ O
you -X- _ O
got -X- _ O
ta -X- _ O
be -X- _ O
kidding -X- _ O
me -X- _ O
! -X- _ O
shows -X- _ O
an -X- _ O
on -X- _ O
- -X- _ O
going -X- _ O
conversation -X- _ O
with -X- _ O
customer -X- _ O
messages -X- _ O
in -X- _ O
grey -X- _ O
, -X- _ O
agent -X- _ O
messages -X- _ O
in -X- _ O
blue -X- _ O
, -X- _ O
and -X- _ O
actions -X- _ O
in -X- _ O
green -X- _ O
. -X- _ O
The -X- _ O
customer -X- _ O
prompt -X- _ O
( -X- _ O
right -X- _ O
top -X- _ O
) -X- _ O
grounds -X- _ O
the -X- _ O
customer -X- _ O
to -X- _ O
a -X- _ O
specific -X- _ O
issue -X- _ O
and -X- _ O
backstory -X- _ O
. -X- _ O
The -X- _ O
info -X- _ O
sections -X- _ O
( -X- _ O
right -X- _ O
middle -X- _ O
and -X- _ O
bottom -X- _ O
) -X- _ O
contains -X- _ O
values -X- _ O
that -X- _ O
the -X- _ O
customer -X- _ O
has -X- _ O
to -X- _ O
provide -X- _ O
in -X- _ O
the -X- _ O
conversation -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
other -X- _ O
meta -X- _ O
- -X- _ O
data -X- _ O
such -X- _ O
as -X- _ O
product -X- _ O
information -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Tao -X- _ O
Lei -X- _ O
, -X- _ O
Felix -X- _ O
Wu -X- _ O
and -X- _ O
Anmol -X- _ O
Kabra -X- _ O
for -X- _ O
their -X- _ O
feedback -X- _ O
and -X- _ O
support -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
also -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
NAACL -X- _ O
2021 -X- _ O
reviewers -X- _ O
for -X- _ O
pointing -X- _ O
out -X- _ O
specific -X- _ O
areas -X- _ O
of -X- _ O
confusion -X- _ O
in -X- _ O
our -X- _ O
submission -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
have -X- _ O
tried -X- _ O
our -X- _ O
best -X- _ O
to -X- _ O
clarify -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
presents -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
which -X- _ O
was -X- _ O
collected -X- _ O
through -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
crowdworkers -X- _ O
. -X- _ O
All -X- _ O
agent -X- _ O
workers -X- _ O
were -X- _ O
compensated -X- _ O
a -X- _ O
fair -X- _ O
wage -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
local -X- _ O
standard -X- _ O
of -X- _ O
living -X- _ O
, -X- _ O
where -X- _ O
their -X- _ O
location -X- _ O
was -X- _ O
determined -X- _ O
during -X- _ O
the -X- _ O
vetting -X- _ O
process -X- _ O
. -X- _ O
( -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
. -X- _ O
) -X- _ O

Nowadays -X- _ O
, -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
verify -X- _ O
whether -X- _ O
a -X- _ O
news -X- _ O
document -X- _ O
is -X- _ O
trusted -X- _ O
or -X- _ O
fake -X- _ O
, -X- _ O
has -X- _ O
become -X- _ O
urgent -X- _ O
and -X- _ O
important -X- _ O
. -X- _ O
Most -X- _ O
existing -X- _ O
methods -X- _ O
rely -X- _ O
heavily -X- _ O
on -X- _ O
linguistic -X- _ O
and -X- _ O
semantic -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
news -X- _ O
content -X- _ O
, -X- _ O
and -X- _ O
fail -X- _ O
to -X- _ O
effectively -X- _ O
exploit -X- _ O
external -X- _ O
knowledge -X- _ O
which -X- _ O
could -X- _ O
help -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
is -X- _ O
trusted -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
end -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
end -X- _ I-MethodName
graph -X- _ I-MethodName
neural -X- _ I-MethodName
model -X- _ I-MethodName
called -X- _ O
CompareNet -X- _ B-MethodName
, -X- _ O
which -X- _ O
compares -X- _ O
the -X- _ O
news -X- _ O
to -X- _ O
the -X- _ O
knowledge -X- _ O
base -X- _ O
( -X- _ O
KB -X- _ O
) -X- _ O
through -X- _ O
entities -X- _ O
for -X- _ B-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
Considering -X- _ O
that -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
is -X- _ O
correlated -X- _ O
with -X- _ O
topics -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
incorporate -X- _ O
topics -X- _ O
to -X- _ O
enrich -X- _ O
the -X- _ O
news -X- _ O
representation -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
construct -X- _ O
a -X- _ O
directed -X- _ B-MethodName
heterogeneous -X- _ I-MethodName
document -X- _ I-MethodName
graph -X- _ I-MethodName
for -X- _ O
each -X- _ O
news -X- _ O
incorporating -X- _ O
topics -X- _ O
and -X- _ O
entities -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
heterogeneous -X- _ B-MethodName
graph -X- _ I-MethodName
attention -X- _ I-MethodName
network -X- _ I-MethodName
for -X- _ O
learning -X- _ O
the -X- _ O
topic -X- _ O
- -X- _ O
enriched -X- _ O
news -X- _ O
representation -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
that -X- _ O
encode -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
news -X- _ O
content -X- _ O
. -X- _ O
The -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
are -X- _ O
then -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
KB -X- _ O
- -X- _ O
based -X- _ O
entity -X- _ O
representations -X- _ O
through -X- _ O
a -X- _ O
carefully -X- _ O
designed -X- _ O
entity -X- _ O
comparison -X- _ O
network -X- _ O
, -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
consistency -X- _ O
between -X- _ O
the -X- _ O
news -X- _ O
content -X- _ O
and -X- _ O
KB -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
topic -X- _ O
- -X- _ O
enriched -X- _ O
news -X- _ O
representation -X- _ O
combining -X- _ O
the -X- _ O
entity -X- _ O
comparison -X- _ O
features -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
a -X- _ O
fake -X- _ O
news -X- _ O
classifier -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
demonstrate -X- _ O
that -X- _ O
CompareNet -X- _ B-MethodName
significantly -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
rapid -X- _ O
development -X- _ O
of -X- _ O
the -X- _ O
Internet -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
increasingly -X- _ O
huge -X- _ O
opportunities -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
* -X- _ O
The -X- _ O
work -X- _ O
was -X- _ O
done -X- _ O
while -X- _ O
visiting -X- _ O
Micorosft -X- _ O
Research -X- _ O
Asia.production -X- _ O
, -X- _ O
dissemination -X- _ O
and -X- _ O
consumption -X- _ O
. -X- _ O
Fake -X- _ O
news -X- _ O
are -X- _ O
news -X- _ O
documents -X- _ O
that -X- _ O
are -X- _ O
intentionally -X- _ O
and -X- _ O
verifiably -X- _ O
false -X- _ O
, -X- _ O
and -X- _ O
could -X- _ O
mislead -X- _ O
readers -X- _ O
( -X- _ O
Allcott -X- _ O
and -X- _ O
Gentzkow -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Fake -X- _ O
news -X- _ O
can -X- _ O
easily -X- _ O
misguide -X- _ O
public -X- _ O
opinion -X- _ O
, -X- _ O
cause -X- _ O
the -X- _ O
crisis -X- _ O
of -X- _ O
confidence -X- _ O
, -X- _ O
and -X- _ O
disturb -X- _ O
the -X- _ O
social -X- _ O
order -X- _ O
( -X- _ O
Vosoughi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
well -X- _ O
known -X- _ O
that -X- _ O
fake -X- _ O
news -X- _ O
exerted -X- _ O
an -X- _ O
influence -X- _ O
in -X- _ O
the -X- _ O
past -X- _ O
2016 -X- _ O
US -X- _ O
presidential -X- _ O
elections -X- _ O
( -X- _ O
Allcott -X- _ O
and -X- _ O
Gentzkow -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
very -X- _ O
important -X- _ O
to -X- _ O
develop -X- _ O
effective -X- _ O
methods -X- _ O
for -X- _ O
early -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
textual -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
. -X- _ O
Some -X- _ O
existing -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
methods -X- _ O
rely -X- _ O
heavily -X- _ O
on -X- _ O
various -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
linguistic -X- _ O
and -X- _ O
semantic -X- _ O
features -X- _ O
for -X- _ O
differentiating -X- _ O
between -X- _ O
news -X- _ O
documents -X- _ O
( -X- _ O
Conroy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Rubin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Rashkin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Khurana -X- _ O
and -X- _ O
Intelligentie -X- _ O
, -X- _ O
2017;Shu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
feature -X- _ O
engineering -X- _ O
, -X- _ O
deep -X- _ O
neural -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
Bi -X- _ B-MethodName
- -X- _ I-MethodName
LSTM -X- _ I-MethodName
and -X- _ I-MethodName
convolutional -X- _ I-MethodName
neural -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
CNN -X- _ B-MethodName
) -X- _ O
have -X- _ O
been -X- _ O
employed -X- _ O
( -X- _ O
Oshikawa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Wang -X- _ O
, -X- _ O
2017;Rodríguez -X- _ O
and -X- _ O
Iglesias -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
they -X- _ O
fail -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
sentence -X- _ O
interactions -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
. -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
showed -X- _ O
that -X- _ O
trusted -X- _ O
news -X- _ O
and -X- _ O
fake -X- _ O
news -X- _ O
have -X- _ O
different -X- _ O
patterns -X- _ O
of -X- _ O
sentence -X- _ O
interactions -X- _ O
( -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
modeled -X- _ O
a -X- _ O
news -X- _ O
document -X- _ O
as -X- _ O
a -X- _ O
fully -X- _ O
connected -X- _ O
sentence -X- _ O
graph -X- _ O
and -X- _ O
proposed -X- _ O
a -X- _ O
graph -X- _ B-MethodName
attention -X- _ I-MethodName
model -X- _ I-MethodName
for -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
Although -X- _ O
these -X- _ O
existing -X- _ O
approaches -X- _ O
can -X- _ O
be -X- _ O
effective -X- _ O
, -X- _ O
they -X- _ O
fail -X- _ O
to -X- _ O
fully -X- _ O
exploit -X- _ O
external -X- _ O
KB -X- _ O
which -X- _ O
could -X- _ O
help -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
news -X- _ O
is -X- _ O
fake -X- _ O
or -X- _ O
trusted -X- _ O
. -X- _ O
External -X- _ O
KB -X- _ O
such -X- _ O
as -X- _ O
Wikipedia -X- _ B-DatasetName
contains -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
structured -X- _ O
subjectpredicate -X- _ O
- -X- _ O
object -X- _ O
triplets -X- _ O
and -X- _ O
unstructured -X- _ O
entity -X- _ O
descriptions -X- _ O
, -X- _ O
which -X- _ O
could -X- _ O
serve -X- _ O
as -X- _ O
evidence -X- _ O
for -X- _ O
detecting -X- _ O
fake -X- _ O
news -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
about -X- _ O
" -X- _ O
mammograms -X- _ O
are -X- _ O
not -X- _ O
effective -X- _ O
at -X- _ O
detecting -X- _ O
breast -X- _ O
tumors -X- _ O
" -X- _ O
is -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
detected -X- _ O
as -X- _ O
fake -X- _ O
news -X- _ O
with -X- _ O
the -X- _ O
knowledge -X- _ O
that -X- _ O
" -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
mammography -X- _ O
is -X- _ O
the -X- _ O
early -X- _ O
detection -X- _ O
of -X- _ O
breast -X- _ O
cancer -X- _ O
" -X- _ O
in -X- _ O
the -X- _ O
Wikipedia -X- _ O
entity -X- _ O
description -X- _ O
page -X- _ O
1 -X- _ O
. -X- _ O
Pan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
proposed -X- _ O
to -X- _ O
construct -X- _ O
knowledge -X- _ O
graphs -X- _ O
from -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
news -X- _ O
, -X- _ O
and -X- _ O
apply -X- _ O
TransE -X- _ B-MethodName
to -X- _ O
learn -X- _ O
triplet -X- _ O
scores -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
( -X- _ O
Pan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
is -X- _ O
largely -X- _ O
influenced -X- _ O
by -X- _ O
construction -X- _ O
of -X- _ O
the -X- _ O
knowledge -X- _ O
graph -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
to -X- _ O
take -X- _ O
full -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
endto -X- _ B-MethodName
- -X- _ I-MethodName
end -X- _ I-MethodName
graph -X- _ I-MethodName
neural -X- _ I-MethodName
model -X- _ I-MethodName
CompareNet -X- _ I-MethodName
which -X- _ O
directly -X- _ O
compares -X- _ O
the -X- _ O
news -X- _ O
to -X- _ O
the -X- _ O
KB -X- _ O
through -X- _ O
entities -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
. -X- _ O
In -X- _ O
CompareNet -X- _ B-MethodName
, -X- _ O
we -X- _ O
also -X- _ O
consider -X- _ O
using -X- _ O
topics -X- _ O
to -X- _ O
enrich -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
representation -X- _ O
for -X- _ O
improving -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
, -X- _ O
since -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
and -X- _ O
topics -X- _ O
are -X- _ O
highly -X- _ O
correlated -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
news -X- _ O
documents -X- _ O
in -X- _ O
the -X- _ O
" -X- _ O
health -X- _ O
" -X- _ O
topic -X- _ O
are -X- _ O
inclined -X- _ O
towards -X- _ O
false -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
documents -X- _ O
belonging -X- _ O
to -X- _ O
the -X- _ O
" -X- _ O
economy -X- _ O
" -X- _ O
topic -X- _ O
are -X- _ O
biased -X- _ O
to -X- _ O
be -X- _ O
trusted -X- _ O
instead -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
construct -X- _ O
a -X- _ O
directed -X- _ O
heterogeneous -X- _ O
document -X- _ O
graph -X- _ O
for -X- _ O
each -X- _ O
news -X- _ O
document -X- _ O
, -X- _ O
containing -X- _ O
sentences -X- _ O
, -X- _ O
topics -X- _ O
and -X- _ O
entities -X- _ O
as -X- _ O
nodes -X- _ O
. -X- _ O
The -X- _ O
sentences -X- _ O
are -X- _ O
fully -X- _ O
connected -X- _ O
in -X- _ O
bidirection -X- _ O
. -X- _ O
Each -X- _ O
sentence -X- _ O
is -X- _ O
also -X- _ O
connected -X- _ O
with -X- _ O
its -X- _ O
top -X- _ O
relevant -X- _ O
topics -X- _ O
in -X- _ O
bi -X- _ O
- -X- _ O
direction -X- _ O
. -X- _ O
If -X- _ O
a -X- _ O
sentence -X- _ O
contains -X- _ O
an -X- _ O
entity -X- _ O
, -X- _ O
one -X- _ O
directed -X- _ O
link -X- _ O
is -X- _ O
built -X- _ O
from -X- _ O
the -X- _ O
sentence -X- _ O
to -X- _ O
the -X- _ O
entity -X- _ O
. -X- _ O
The -X- _ O
reason -X- _ O
for -X- _ O
building -X- _ O
one -X- _ O
- -X- _ O
way -X- _ O
links -X- _ O
from -X- _ O
sentences -X- _ O
to -X- _ O
entities -X- _ O
is -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
learn -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
that -X- _ O
encode -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
news -X- _ O
, -X- _ O
while -X- _ O
avoiding -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
the -X- _ O
true -X- _ O
entity -X- _ O
knowledge -X- _ O
to -X- _ O
the -X- _ O
news -X- _ O
representation -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
directed -X- _ O
heterogeneous -X- _ O
document -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
heterogeneous -X- _ B-MethodName
graph -X- _ I-MethodName
attention -X- _ I-MethodName
network -X- _ I-MethodName
to -X- _ O
learn -X- _ O
topic -X- _ O
- -X- _ O
enriched -X- _ O
news -X- _ O
representations -X- _ O
and -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
. -X- _ O
The -X- _ O
learned -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
are -X- _ O
then -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
KB -X- _ O
- -X- _ O
based -X- _ O
entity -X- _ O
representations -X- _ O
with -X- _ O
a -X- _ O
carefully -X- _ O
designed -X- _ O
entity -X- _ O
comparison -X- _ O
network -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
semantic -X- _ O
consistency -X- _ O
between -X- _ O
the -X- _ O
news -X- _ O
content -X- _ O
and -X- _ O
external -X- _ O
KB -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
topic -X- _ O
- -X- _ O
enriched -X- _ O
news -X- _ O
representations -X- _ O
and -X- _ O
the -X- _ O
entity -X- _ O
comparison -X- _ O
features -X- _ O
are -X- _ O
combined -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
classification -X- _ O
. -X- _ O
To -X- _ O
facilitate -X- _ O
related -X- _ O
researches -X- _ O
, -X- _ O
we -X- _ O
release -X- _ O
both -X- _ O
our -X- _ O
code -X- _ O
and -X- _ O
dataset -X- _ O
to -X- _ O
the -X- _ O
public -X- _ O
2 -X- _ O
.1 -X- _ O
https://en.wikipedia.org/wiki/Mammography -X- _ O
2 -X- _ O
https://github.com/ytc272098215/FakeNewsDetection -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
our -X- _ O
main -X- _ O
contributions -X- _ O
include -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
end -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
end -X- _ I-MethodName
graph -X- _ I-MethodName
neural -X- _ I-MethodName
model -X- _ I-MethodName
CompareNet -X- _ I-MethodName
which -X- _ O
compares -X- _ O
the -X- _ O
news -X- _ O
to -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
through -X- _ O
entities -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
detection.2 -X- _ O
) -X- _ O
In -X- _ O
CompareNet -X- _ B-MethodName
, -X- _ O
we -X- _ O
also -X- _ O
consider -X- _ O
the -X- _ O
useful -X- _ O
topic -X- _ O
information -X- _ O
. -X- _ O
We -X- _ O
construct -X- _ O
a -X- _ O
directed -X- _ O
heterogeneous -X- _ O
document -X- _ O
graph -X- _ O
incorporating -X- _ O
topics -X- _ O
and -X- _ O
entities -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
develop -X- _ O
heterogeneous -X- _ O
graph -X- _ O
attention -X- _ O
networks -X- _ O
to -X- _ O
learn -X- _ O
topicenriched -X- _ O
news -X- _ O
representations -X- _ O
. -X- _ O
A -X- _ O
novel -X- _ O
entity -X- _ O
comparison -X- _ O
network -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
compare -X- _ O
the -X- _ O
news -X- _ O
to -X- _ O
the -X- _ O
KB.3 -X- _ O
) -X- _ O
Extensive -X- _ O
experiments -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
demonstrate -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
significantly -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
on -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
by -X- _ O
effectively -X- _ O
incorporating -X- _ O
external -X- _ O
knowledge -X- _ O
and -X- _ O
topic -X- _ O
information -X- _ O
. -X- _ O
Fake -X- _ O
news -X- _ O
detection -X- _ O
has -X- _ O
attracted -X- _ O
much -X- _ O
attention -X- _ O
in -X- _ O
recent -X- _ O
years -X- _ O
( -X- _ O
Zhou -X- _ O
and -X- _ O
Zafarani -X- _ O
, -X- _ O
2020;Oshikawa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
lot -X- _ O
of -X- _ O
works -X- _ O
also -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
related -X- _ O
problem -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
fact -X- _ O
checking -X- _ O
, -X- _ O
which -X- _ O
aims -X- _ O
to -X- _ O
search -X- _ O
evidence -X- _ O
from -X- _ O
external -X- _ O
knowledge -X- _ O
to -X- _ O
verify -X- _ O
the -X- _ O
veracity -X- _ O
of -X- _ O
a -X- _ O
claim -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
subject -X- _ O
- -X- _ O
predicateobject -X- _ O
triple -X- _ O
) -X- _ O
( -X- _ O
Thorne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Zhong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
usually -X- _ O
focuses -X- _ O
on -X- _ O
news -X- _ O
events -X- _ O
while -X- _ O
fact -X- _ O
- -X- _ O
checking -X- _ O
is -X- _ O
broader -X- _ O
( -X- _ O
Oshikawa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
approaches -X- _ O
for -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
can -X- _ O
be -X- _ O
divided -X- _ O
into -X- _ O
two -X- _ O
categories -X- _ O
: -X- _ O
social -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
content -X- _ O
- -X- _ O
based -X- _ O
. -X- _ O
Social -X- _ O
context -X- _ O
related -X- _ O
to -X- _ O
news -X- _ O
documents -X- _ O
contains -X- _ O
rich -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
user -X- _ O
profiles -X- _ O
and -X- _ O
social -X- _ O
relationships -X- _ O
to -X- _ O
help -X- _ O
detect -X- _ O
fake -X- _ O
news -X- _ O
. -X- _ O
Social -X- _ B-MethodName
based -X- _ I-MethodName
models -X- _ O
basically -X- _ O
include -X- _ O
stance -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
and -X- _ O
propagation -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
. -X- _ O
Stance -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
models -X- _ O
utilize -X- _ O
users -X- _ O
' -X- _ O
opinions -X- _ O
to -X- _ O
infer -X- _ O
news -X- _ O
veracity -X- _ O
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Tacchini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
constructed -X- _ O
a -X- _ O
bipartite -X- _ O
network -X- _ O
of -X- _ O
user -X- _ O
and -X- _ O
posts -X- _ O
with -X- _ O
' -X- _ O
like -X- _ O
' -X- _ O
stance -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
proposed -X- _ O
a -X- _ O
semisupervised -X- _ O
probabilistic -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
likelihood -X- _ O
of -X- _ O
posts -X- _ O
being -X- _ O
hoaxes -X- _ O
( -X- _ O
Tacchini -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Propagation -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
approaches -X- _ O
for -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
are -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
basic -X- _ O
assumption -X- _ O
that -X- _ O
the -X- _ O
credibility -X- _ O
of -X- _ O
a -X- _ O
news -X- _ O
event -X- _ O
is -X- _ O
highly -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
credibilities -X- _ O
of -X- _ O
relevant -X- _ O
social -X- _ O
media -X- _ O
posts -X- _ O
. -X- _ O
Both -X- _ O
homogeneous -X- _ B-MethodName
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
heterogeneous -X- _ B-MethodName
credibility -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
Gupta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012;Shu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
built -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
propagation -X- _ O
process -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
constructed -X- _ O
a -X- _ O
heterogeneous -X- _ O
network -X- _ O
of -X- _ O
news -X- _ O
articles -X- _ O
, -X- _ O
creators -X- _ O
and -X- _ O
news -X- _ O
subjects -X- _ O
, -X- _ O
and -X- _ O
proposed -X- _ O
a -X- _ O
deep -X- _ B-MethodName
diffusive -X- _ I-MethodName
network -X- _ I-MethodName
model -X- _ O
for -X- _ O
incorporating -X- _ O
the -X- _ O
network -X- _ O
structure -X- _ O
information -X- _ O
to -X- _ O
simultaneously -X- _ O
detect -X- _ B-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
articles -X- _ I-TaskName
, -X- _ O
creators -X- _ O
and -X- _ O
subjects -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
news -X- _ O
contents -X- _ O
contain -X- _ O
the -X- _ O
clues -X- _ O
to -X- _ O
differentiate -X- _ O
fake -X- _ O
and -X- _ O
trusted -X- _ O
news -X- _ O
. -X- _ O
A -X- _ O
lot -X- _ O
of -X- _ O
existing -X- _ O
works -X- _ O
extract -X- _ O
specific -X- _ O
writing -X- _ O
styles -X- _ O
such -X- _ O
as -X- _ O
lexical -X- _ O
and -X- _ O
syntactic -X- _ O
features -X- _ O
( -X- _ O
Conroy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Rubin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Khurana -X- _ O
and -X- _ O
Intelligentie -X- _ O
, -X- _ O
2017;Rashkin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Shu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Oshikawa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
sensational -X- _ O
headlines -X- _ O
( -X- _ O
Potthast -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Sitaula -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
classifier -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
hand -X- _ O
- -X- _ O
crafted -X- _ O
feature -X- _ O
engineering -X- _ O
, -X- _ O
neural -X- _ O
models -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
( -X- _ O
Wang -X- _ O
, -X- _ O
2017;Rodríguez -X- _ O
and -X- _ O
Iglesias -X- _ O
, -X- _ O
2019 -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
works -X- _ O
fail -X- _ O
to -X- _ O
consider -X- _ O
different -X- _ O
sentence -X- _ O
interaction -X- _ O
patterns -X- _ O
between -X- _ O
trusted -X- _ O
and -X- _ O
fake -X- _ O
news -X- _ O
documents -X- _ O
. -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
proposed -X- _ O
to -X- _ O
model -X- _ O
a -X- _ O
document -X- _ O
as -X- _ O
a -X- _ O
sentence -X- _ O
graph -X- _ O
capturing -X- _ O
the -X- _ O
sentence -X- _ O
interactions -X- _ O
and -X- _ O
applied -X- _ O
graph -X- _ O
attention -X- _ O
networks -X- _ O
for -X- _ O
learning -X- _ O
document -X- _ O
representation -X- _ O
( -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Pan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
proposed -X- _ O
to -X- _ O
construct -X- _ O
knowledge -X- _ O
graphs -X- _ O
from -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
news -X- _ O
, -X- _ O
and -X- _ O
apply -X- _ O
TransE -X- _ B-MethodName
to -X- _ O
learn -X- _ O
triplet -X- _ O
scores -X- _ O
for -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
( -X- _ O
Pan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
they -X- _ O
relied -X- _ O
heavily -X- _ O
on -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
construction -X- _ O
of -X- _ O
knowledge -X- _ O
graphs -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
graph -X- _ O
neural -X- _ O
model -X- _ O
Com -X- _ B-MethodName
- -X- _ I-MethodName
pareNet -X- _ I-MethodName
which -X- _ O
directly -X- _ O
compares -X- _ O
the -X- _ O
news -X- _ O
to -X- _ O
external -X- _ O
knowledge -X- _ O
for -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
Considering -X- _ O
that -X- _ O
the -X- _ O
detection -X- _ B-TaskName
of -X- _ I-TaskName
fake -X- _ I-TaskName
news -X- _ I-TaskName
is -X- _ O
correlated -X- _ O
with -X- _ O
topics -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
topics -X- _ O
to -X- _ O
enrich -X- _ O
the -X- _ O
news -X- _ O
representation -X- _ O
for -X- _ O
improving -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
Some -X- _ O
works -X- _ O
( -X- _ O
Wang -X- _ O
, -X- _ O
2017;Khattar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
;) -X- _ O
also -X- _ O
consider -X- _ O
incorporating -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
features -X- _ O
such -X- _ O
as -X- _ O
images -X- _ O
for -X- _ O
improving -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
detail -X- _ O
our -X- _ O
proposed -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
model -X- _ O
CompareNet -X- _ B-MethodName
, -X- _ O
which -X- _ O
directly -X- _ O
compares -X- _ O
the -X- _ O
news -X- _ O
to -X- _ O
external -X- _ O
knowledge -X- _ O
for -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
consider -X- _ O
topics -X- _ O
for -X- _ O
enriching -X- _ O
news -X- _ O
representation -X- _ O
since -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
is -X- _ O
highly -X- _ O
correlated -X- _ O
with -X- _ O
topics -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
construct -X- _ O
a -X- _ O
directed -X- _ O
heterogeneous -X- _ O
document -X- _ O
graph -X- _ O
for -X- _ O
each -X- _ O
news -X- _ O
document -X- _ O
incorporating -X- _ O
topics -X- _ O
and -X- _ O
entities -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
graph -X- _ O
well -X- _ O
captures -X- _ O
the -X- _ O
interactions -X- _ O
among -X- _ O
sentences -X- _ O
, -X- _ O
topics -X- _ O
and -X- _ O
entities -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
heterogeneous -X- _ B-MethodName
graph -X- _ I-MethodName
attention -X- _ I-MethodName
network -X- _ I-MethodName
to -X- _ O
learn -X- _ O
the -X- _ O
topic -X- _ O
- -X- _ O
enriched -X- _ O
news -X- _ O
representation -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
that -X- _ O
encode -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
. -X- _ O
To -X- _ O
fully -X- _ O
leverage -X- _ O
external -X- _ O
KB -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
entities -X- _ O
as -X- _ O
the -X- _ O
bridge -X- _ O
between -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
and -X- _ O
the -X- _ O
KB -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
KB -X- _ O
- -X- _ O
based -X- _ O
entity -X- _ O
representations -X- _ O
using -X- _ O
a -X- _ O
carefully -X- _ O
designed -X- _ O
entity -X- _ O
comparison -X- _ O
network -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
obtained -X- _ O
entity -X- _ O
comparison -X- _ O
features -X- _ O
are -X- _ O
combined -X- _ O
with -X- _ O
the -X- _ O
topic -X- _ O
- -X- _ O
enriched -X- _ O
news -X- _ O
document -X- _ O
representation -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
news -X- _ O
document -X- _ O
d -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
directed -X- _ O
heterogeneous -X- _ O
document -X- _ O
graph -X- _ O
G -X- _ O
= -X- _ O
( -X- _ O
V -X- _ O
, -X- _ O
E -X- _ O
) -X- _ O
incorporating -X- _ O
topics -X- _ O
and -X- _ O
entities -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
three -X- _ O
kinds -X- _ O
of -X- _ O
nodes -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
: -X- _ O
sentences -X- _ O
S -X- _ O
= -X- _ O
{ -X- _ O
s -X- _ O
1 -X- _ O
, -X- _ O
s -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
s -X- _ O
m -X- _ O
} -X- _ O
, -X- _ O
topics -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
t -X- _ O
1 -X- _ O
, -X- _ O
t -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
t -X- _ O
K -X- _ O
} -X- _ O
and -X- _ O
entities -X- _ O
E -X- _ O
= -X- _ O
{ -X- _ O
e -X- _ O
1 -X- _ O
, -X- _ O
e -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
e -X- _ O
n -X- _ O
} -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
V -X- _ O
= -X- _ O
S -X- _ O
∪ -X- _ O
T -X- _ O
∪ -X- _ O
E.The -X- _ O
set -X- _ O
of -X- _ O
edges -X- _ O
E -X- _ O
represent -X- _ O
the -X- _ O
relations -X- _ O
among -X- _ O
sentences -X- _ O
, -X- _ O
topics -X- _ O
and -X- _ O
entities -X- _ O
. -X- _ O
The -X- _ O
details -X- _ O
of -X- _ O
constructing -X- _ O
the -X- _ O
graph -X- _ O
are -X- _ O
described -X- _ O
as -X- _ O
follows -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
split -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
as -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
sentences -X- _ O
. -X- _ O
Sentences -X- _ O
are -X- _ O
bidirectionally -X- _ O
connected -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
in -X- _ O
the -X- _ O
graph -X- _ O
, -X- _ O
capturing -X- _ O
the -X- _ O
interaction -X- _ O
of -X- _ O
each -X- _ O
sentence -X- _ O
with -X- _ O
every -X- _ O
other -X- _ O
sentence -X- _ O
. -X- _ O
Since -X- _ O
topic -X- _ O
information -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
unsupervised -X- _ B-MethodName
LDA -X- _ I-MethodName
( -X- _ O
Blei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
( -X- _ O
the -X- _ O
total -X- _ B-HyperparameterName
topic -X- _ I-HyperparameterName
number -X- _ I-HyperparameterName
K -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
as -X- _ O
100 -X- _ B-HyperparameterValue
) -X- _ O
to -X- _ O
mine -X- _ O
the -X- _ O
latent -X- _ O
topics -X- _ O
T -X- _ O
from -X- _ O
all -X- _ O
the -X- _ O
sentences -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
documents -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
each -X- _ O
sentence -X- _ O
is -X- _ O
taken -X- _ O
as -X- _ O
a -X- _ O
pseudo -X- _ O
- -X- _ O
document -X- _ O
and -X- _ O
is -X- _ O
assigned -X- _ O
to -X- _ O
the -X- _ O
top -X- _ B-HyperparameterName
P -X- _ I-HyperparameterName
relevant -X- _ I-HyperparameterName
topics -X- _ I-HyperparameterName
with -X- _ O
the -X- _ O
largest -X- _ O
probabilities -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
each -X- _ O
sentence -X- _ O
is -X- _ O
also -X- _ O
connected -X- _ O
with -X- _ O
its -X- _ O
top -X- _ B-HyperparameterName
P -X- _ I-HyperparameterName
assigned -X- _ I-HyperparameterName
topics -X- _ I-HyperparameterName
in -X- _ O
bi -X- _ O
- -X- _ O
direction -X- _ O
, -X- _ O
allowing -X- _ O
the -X- _ O
useful -X- _ O
topic -X- _ O
information -X- _ O
to -X- _ O
propagate -X- _ O
among -X- _ O
the -X- _ O
sentences -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
also -X- _ O
deal -X- _ O
with -X- _ O
new -X- _ O
coming -X- _ O
news -X- _ O
documents -X- _ O
by -X- _ O
inferring -X- _ O
the -X- _ O
topics -X- _ O
with -X- _ O
trained -X- _ O
LDA -X- _ B-MethodName
. -X- _ O
We -X- _ O
identify -X- _ O
the -X- _ O
entities -X- _ O
E -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
d -X- _ O
and -X- _ O
map -X- _ O
them -X- _ O
to -X- _ O
Wikipedia -X- _ B-DatasetName
using -X- _ O
the -X- _ O
entity -X- _ O
linking -X- _ O
tool -X- _ O
TAGME -X- _ O
3 -X- _ O
. -X- _ O
If -X- _ O
a -X- _ O
sentence -X- _ O
s -X- _ O
contains -X- _ O
an -X- _ O
entity -X- _ O
e -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
way -X- _ O
directed -X- _ O
edge -X- _ O
from -X- _ O
a -X- _ O
sentence -X- _ O
to -X- _ O
the -X- _ O
entity -X- _ O
e -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
allow -X- _ O
only -X- _ O
information -X- _ O
propagation -X- _ O
from -X- _ O
sentences -X- _ O
to -X- _ O
entities -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
avoid -X- _ O
integrating -X- _ O
true -X- _ O
entity -X- _ O
knowledge -X- _ O
directly -X- _ O
into -X- _ O
news -X- _ O
representation -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
mislead -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
fake -X- _ O
news -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
above -X- _ O
directed -X- _ O
heterogeneous -X- _ O
document -X- _ O
graph -X- _ O
G -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
heterogeneous -X- _ B-MethodName
graph -X- _ I-MethodName
attention -X- _ I-MethodName
network -X- _ I-MethodName
for -X- _ O
learning -X- _ O
the -X- _ O
news -X- _ O
representation -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
. -X- _ O
It -X- _ O
considers -X- _ O
not -X- _ O
only -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
different -X- _ O
nodes -X- _ O
with -X- _ O
different -X- _ O
types -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
but -X- _ O
also -X- _ O
the -X- _ O
edge -X- _ O
directions -X- _ O
in -X- _ O
the -X- _ O
heterogeneous -X- _ O
graph -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
three -X- _ O
types -X- _ O
T -X- _ O
= -X- _ O
{ -X- _ O
τ -X- _ O
1 -X- _ O
, -X- _ O
τ -X- _ O
2 -X- _ O
, -X- _ O
τ -X- _ O
3 -X- _ O
} -X- _ O
of -X- _ O
nodes -X- _ O
: -X- _ O
sentences -X- _ O
S -X- _ O
, -X- _ O
topics -X- _ O
T -X- _ O
and -X- _ O
entities -X- _ O
E -X- _ O
with -X- _ O
different -X- _ O
feature -X- _ O
spaces -X- _ O
. -X- _ O
We -X- _ O
apply -X- _ O
LSTM -X- _ O
to -X- _ O
encode -X- _ O
a -X- _ O
sentence -X- _ O
s -X- _ O
= -X- _ O
{ -X- _ O
w -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
w -X- _ O
m -X- _ O
} -X- _ O
and -X- _ O
get -X- _ O
its -X- _ O
feature -X- _ O
vector -X- _ O
x -X- _ O
s -X- _ O
∈ -X- _ O
R -X- _ O
M -X- _ O
. -X- _ O
The -X- _ O
entity -X- _ O
e -X- _ O
∈ -X- _ O
E -X- _ O
is -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
entity -X- _ O
representations -X- _ O
e -X- _ O
KB -X- _ O
∈ -X- _ O
R -X- _ O
M -X- _ O
learned -X- _ O
from -X- _ O
the -X- _ O
external -X- _ O
KB -X- _ O
( -X- _ O
see -X- _ O
Subsection -X- _ O
3.3.1 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
topic -X- _ O
t -X- _ O
∈ -X- _ O
T -X- _ O
is -X- _ O
initialized -X- _ O
with -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
vector -X- _ O
x -X- _ O
t -X- _ O
∈ -X- _ O
R -X- _ O
K -X- _ O
.Next -X- _ O
, -X- _ O
consider -X- _ O
the -X- _ O
graph -X- _ O
G -X- _ O
= -X- _ O
( -X- _ O
V -X- _ O
, -X- _ O
E -X- _ O
) -X- _ O
where -X- _ O
V -X- _ O
and -X- _ O
E -X- _ O
represent -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
nodes -X- _ O
and -X- _ O
edges -X- _ O
respectively -X- _ O
. -X- _ O
Let -X- _ O
X -X- _ O
∈ -X- _ O
R -X- _ O
|V|×M -X- _ O
be -X- _ O
a -X- _ O
matrix -X- _ O
containing -X- _ O
the -X- _ O
nodes -X- _ O
with -X- _ O
their -X- _ O
features -X- _ O
x -X- _ O
v -X- _ O
∈ -X- _ O
R -X- _ O
M -X- _ O
( -X- _ O
each -X- _ O
row -X- _ O
x -X- _ O
v -X- _ O
is -X- _ O
a -X- _ O
feature -X- _ O
vector -X- _ O
for -X- _ O
a -X- _ O
node -X- _ O
v -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
and -X- _ O
D -X- _ O
are -X- _ O
the -X- _ O
adjacency -X- _ O
matrix -X- _ O
and -X- _ O
the -X- _ O
degree -X- _ O
matrix -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
heterogeneous -X- _ O
convolution -X- _ O
layer -X- _ O
updates -X- _ O
the -X- _ O
( -X- _ O
l -X- _ O
+ -X- _ O
1)-th -X- _ O
layer -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
nodes -X- _ O
H -X- _ O
( -X- _ O
l+1 -X- _ O
) -X- _ O
by -X- _ O
aggregating -X- _ O
the -X- _ O
features -X- _ O
of -X- _ O
their -X- _ O
neighboring -X- _ O
nodes -X- _ O
H -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
τ -X- _ O
with -X- _ O
different -X- _ O
types -X- _ O
τ -X- _ O
. -X- _ O
( -X- _ O
Initially -X- _ O
, -X- _ O
H -X- _ O
( -X- _ O
0 -X- _ O
) -X- _ O
= -X- _ O
X):H -X- _ O
( -X- _ O
l+1 -X- _ O
) -X- _ O
= -X- _ O
σ -X- _ O
( -X- _ O
τ -X- _ O
∈T -X- _ O
B -X- _ O
τ -X- _ O
• -X- _ O
H -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
τ -X- _ O
• -X- _ O
W -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
τ -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
1)where -X- _ O
σ(• -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
activation -X- _ O
function -X- _ O
. -X- _ O
Nodes -X- _ O
with -X- _ O
different -X- _ O
types -X- _ O
τ -X- _ O
have -X- _ O
different -X- _ O
transformation -X- _ O
matrix -X- _ O
W(l)τ -X- _ O
. -X- _ O
The -X- _ O
transformation -X- _ O
matrix -X- _ O
W -X- _ O
( -X- _ O
l)τ -X- _ O
considers -X- _ O
the -X- _ O
different -X- _ O
feature -X- _ O
spaces -X- _ O
and -X- _ O
projects -X- _ O
them -X- _ O
into -X- _ O
an -X- _ O
implicit -X- _ O
common -X- _ O
space -X- _ O
. -X- _ O
B -X- _ O
τ -X- _ O
∈ -X- _ O
R -X- _ O
|V|×|Vτ -X- _ O
| -X- _ O
is -X- _ O
the -X- _ O
attention -X- _ O
matrix -X- _ O
, -X- _ O
whose -X- _ O
rows -X- _ O
represent -X- _ O
all -X- _ O
the -X- _ O
nodes -X- _ O
and -X- _ O
columns -X- _ O
represent -X- _ O
their -X- _ O
neighboring -X- _ O
nodes -X- _ O
with -X- _ O
the -X- _ O
type -X- _ O
τ -X- _ O
. -X- _ O
Its -X- _ O
element -X- _ O
β -X- _ O
vv -X- _ O
in -X- _ O
the -X- _ O
v -X- _ O
- -X- _ O
th -X- _ O
row -X- _ O
and -X- _ O
the -X- _ O
v -X- _ O
-th -X- _ O
column -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
β -X- _ O
vv -X- _ O
= -X- _ O
Softmax -X- _ O
v -X- _ O
( -X- _ O
σ(ν -X- _ O
T -X- _ O
• -X- _ O
α -X- _ O
τ -X- _ O
[ -X- _ O
h -X- _ O
v -X- _ O
, -X- _ O
h -X- _ O
v -X- _ O
] -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
2)where -X- _ O
ν -X- _ O
is -X- _ O
the -X- _ O
attention -X- _ O
vector -X- _ O
and -X- _ O
α -X- _ O
τ -X- _ O
is -X- _ O
the -X- _ O
typelevel -X- _ O
attention -X- _ O
weight -X- _ O
. -X- _ O
h -X- _ O
v -X- _ O
and -X- _ O
h -X- _ O
v -X- _ O
are -X- _ O
respectively -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
current -X- _ O
node -X- _ O
v -X- _ O
and -X- _ O
its -X- _ O
neighboring -X- _ O
node -X- _ O
v -X- _ O
. -X- _ O
Softmax -X- _ O
function -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
normalize -X- _ O
across -X- _ O
the -X- _ O
neighboring -X- _ O
nodes -X- _ O
of -X- _ O
node -X- _ O
v. -X- _ O
We -X- _ O
calculate -X- _ O
the -X- _ O
type -X- _ O
- -X- _ O
level -X- _ O
attention -X- _ O
weights -X- _ O
α -X- _ O
τ -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
current -X- _ O
node -X- _ O
embedding -X- _ O
h -X- _ O
v -X- _ O
and -X- _ O
the -X- _ O
type -X- _ O
embedding -X- _ O
h -X- _ O
τ -X- _ O
= -X- _ O
v -X- _ O
Ã -X- _ O
vv -X- _ O
h -X- _ O
v -X- _ O
( -X- _ O
the -X- _ O
weighted -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
neighboring -X- _ O
node -X- _ O
embeddings -X- _ O
h -X- _ O
v -X- _ O
with -X- _ O
the -X- _ O
type -X- _ O
τ -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
weight -X- _ O
matrixÃ -X- _ O
= -X- _ O
D -X- _ O
− -X- _ O
1 -X- _ O
2 -X- _ O
( -X- _ O
A+ -X- _ O
I)D -X- _ O
− -X- _ O
1 -X- _ O
2 -X- _ O
is -X- _ O
the -X- _ O
normalized -X- _ O
adjacency -X- _ O
matrix -X- _ O
with -X- _ O
added -X- _ O
self -X- _ O
- -X- _ O
connections -X- _ O
) -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
α -X- _ O
τ -X- _ O
= -X- _ O
Softmax -X- _ O
τ -X- _ O
( -X- _ O
σ(µ -X- _ O
T -X- _ O
τ -X- _ O
• -X- _ O
[ -X- _ O
h -X- _ O
v -X- _ O
, -X- _ O
h -X- _ O
τ -X- _ O
] -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
3)where -X- _ O
µ -X- _ O
τ -X- _ O
is -X- _ O
the -X- _ O
attention -X- _ O
vector -X- _ O
for -X- _ O
the -X- _ O
type -X- _ O
τ -X- _ O
. -X- _ O
Softmax -X- _ O
function -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
normalize -X- _ O
across -X- _ O
all -X- _ O
the -X- _ O
types -X- _ O
. -X- _ O
After -X- _ O
L -X- _ O
- -X- _ O
layer -X- _ O
heterogeneous -X- _ O
graph -X- _ O
convolution -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
finally -X- _ O
get -X- _ O
all -X- _ O
the -X- _ O
node -X- _ O
( -X- _ O
including -X- _ O
sentences -X- _ O
and -X- _ O
entities -X- _ O
) -X- _ O
representations -X- _ O
aggregating -X- _ O
neighborhood -X- _ O
semantics -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
max -X- _ O
pooling -X- _ O
over -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
nodes -X- _ O
H -X- _ O
s -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
topic -X- _ O
- -X- _ O
enriched -X- _ O
news -X- _ O
document -X- _ O
embedding -X- _ O
H -X- _ O
d -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
. -X- _ O
The -X- _ O
learned -X- _ O
entity -X- _ O
representations -X- _ O
that -X- _ O
encode -X- _ O
the -X- _ O
contextual -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
document -X- _ O
are -X- _ O
taken -X- _ O
as -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
e -X- _ O
c -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
subsection -X- _ O
, -X- _ O
we -X- _ O
detail -X- _ O
our -X- _ O
entity -X- _ O
comparison -X- _ O
network -X- _ O
which -X- _ O
compares -X- _ O
the -X- _ O
learned -X- _ O
contextual -X- _ O
entity -X- _ O
embeddings -X- _ O
e -X- _ O
c -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
KBbased -X- _ O
entity -X- _ O
embeddings -X- _ O
e -X- _ O
KB -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
entity -X- _ O
comparison -X- _ O
features -X- _ O
could -X- _ O
improve -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
based -X- _ O
on -X- _ O
the -X- _ O
assumption -X- _ O
that -X- _ O
e -X- _ O
c -X- _ O
learned -X- _ O
from -X- _ O
trusted -X- _ O
news -X- _ O
document -X- _ O
can -X- _ O
be -X- _ O
better -X- _ O
aligned -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
e -X- _ O
KB -X- _ O
; -X- _ O
while -X- _ O
inverse -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
illustrate -X- _ O
how -X- _ O
to -X- _ O
take -X- _ O
full -X- _ O
advantage -X- _ O
of -X- _ O
both -X- _ O
structured -X- _ O
subject -X- _ O
- -X- _ O
predicate -X- _ O
- -X- _ O
object -X- _ O
triplets -X- _ O
and -X- _ O
unstructured -X- _ O
textual -X- _ O
entity -X- _ O
descriptions -X- _ O
in -X- _ O
the -X- _ O
KB -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
Wikipedia -X- _ O
) -X- _ O
to -X- _ O
learn -X- _ O
KB -X- _ O
- -X- _ O
based -X- _ O
entity -X- _ O
representations -X- _ O
e -X- _ O
KB -X- _ O
.Structural -X- _ O
Embedding -X- _ O
. -X- _ O
A -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
knowledge -X- _ O
graph -X- _ O
embedding -X- _ O
methods -X- _ O
can -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
obtain -X- _ O
structured -X- _ O
entity -X- _ O
embeddings -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
simplicity -X- _ O
of -X- _ O
TransE -X- _ B-MethodName
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
adopted -X- _ O
TransE -X- _ B-MethodName
to -X- _ O
learn -X- _ O
entity -X- _ O
representations -X- _ O
e -X- _ O
s -X- _ O
∈ -X- _ O
R -X- _ O
M -X- _ O
from -X- _ O
the -X- _ O
triplets -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
triplet -X- _ O
( -X- _ O
h -X- _ O
, -X- _ O
r -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
, -X- _ O
TransE -X- _ B-MethodName
regards -X- _ O
a -X- _ O
relationship -X- _ O
r -X- _ O
as -X- _ O
a -X- _ O
translation -X- _ O
vector -X- _ O
r -X- _ O
from -X- _ O
the -X- _ O
head -X- _ O
entity -X- _ O
h -X- _ O
to -X- _ O
the -X- _ O
tail -X- _ O
entity -X- _ O
t -X- _ O
, -X- _ O
namely -X- _ O
h -X- _ O
+ -X- _ O
r -X- _ O
= -X- _ O
t. -X- _ O
Textual -X- _ O
Embedding -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
entity -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
first -X- _ O
paragraph -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
Wikipedia -X- _ O
page -X- _ O
as -X- _ O
its -X- _ O
text -X- _ O
description -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
apply -X- _ O
LSTM -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
to -X- _ O
learn -X- _ O
entity -X- _ O
representations -X- _ O
e -X- _ O
d -X- _ O
∈ -X- _ O
R -X- _ O
M -X- _ O
that -X- _ O
encode -X- _ O
the -X- _ O
entity -X- _ O
descriptions -X- _ O
. -X- _ O
Gating -X- _ O
Integration -X- _ O
. -X- _ O
Since -X- _ O
both -X- _ O
the -X- _ O
structural -X- _ O
triplets -X- _ O
and -X- _ O
textual -X- _ O
description -X- _ O
provide -X- _ O
valuable -X- _ O
information -X- _ O
for -X- _ O
an -X- _ O
entity -X- _ O
, -X- _ O
we -X- _ O
integrate -X- _ O
these -X- _ O
information -X- _ O
into -X- _ O
a -X- _ O
joint -X- _ O
representation -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
have -X- _ O
the -X- _ O
structural -X- _ O
embedding -X- _ O
e -X- _ O
s -X- _ O
and -X- _ O
textual -X- _ O
embedding -X- _ O
e -X- _ O
d -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
learnable -X- _ O
gating -X- _ O
function -X- _ O
to -X- _ O
integrate -X- _ O
entity -X- _ O
embeddings -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
sources -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
e -X- _ O
KB -X- _ O
= -X- _ O
g -X- _ O
e -X- _ O
e -X- _ O
s -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
g -X- _ O
e -X- _ O
) -X- _ O
e -X- _ O
d -X- _ O
, -X- _ O
( -X- _ O
4)where -X- _ O
g -X- _ O
e -X- _ O
∈ -X- _ O
R -X- _ O
M -X- _ O
is -X- _ O
a -X- _ O
gating -X- _ O
vector -X- _ O
( -X- _ O
w.r.t -X- _ O
. -X- _ O
the -X- _ O
entity -X- _ O
e -X- _ O
) -X- _ O
to -X- _ O
trade -X- _ O
- -X- _ O
off -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
sources -X- _ O
and -X- _ O
its -X- _ O
elements -X- _ O
are -X- _ O
in -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
. -X- _ O
denotes -X- _ O
elementwise -X- _ O
multiplication -X- _ O
. -X- _ O
The -X- _ O
gating -X- _ O
vector -X- _ O
g -X- _ O
e -X- _ O
means -X- _ O
that -X- _ O
each -X- _ O
dimension -X- _ O
of -X- _ O
e -X- _ O
s -X- _ O
and -X- _ O
e -X- _ O
d -X- _ O
are -X- _ O
summed -X- _ O
by -X- _ O
different -X- _ O
weights -X- _ O
. -X- _ O
To -X- _ O
constrain -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
each -X- _ O
element -X- _ O
in -X- _ O
[ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
] -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
gate -X- _ O
g -X- _ O
e -X- _ O
with -X- _ O
the -X- _ O
Sigmoid -X- _ O
function -X- _ O
: -X- _ O
g -X- _ O
e -X- _ O
= -X- _ O
σ(g -X- _ O
e -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
5)whereg -X- _ O
e -X- _ O
∈ -X- _ O
R -X- _ O
M -X- _ O
is -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
value -X- _ O
vector -X- _ O
and -X- _ O
is -X- _ O
learned -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
After -X- _ O
fusing -X- _ O
the -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
embeddings -X- _ O
with -X- _ O
the -X- _ O
gating -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
final -X- _ O
KB -X- _ O
- -X- _ O
based -X- _ O
entity -X- _ O
embeddings -X- _ O
e -X- _ O
KB -X- _ O
∈ -X- _ O
R -X- _ O
M -X- _ O
which -X- _ O
encode -X- _ O
both -X- _ O
structural -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
triplets -X- _ O
and -X- _ O
textual -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
entity -X- _ O
descriptions -X- _ O
in -X- _ O
the -X- _ O
KB -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
perform -X- _ O
entity -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
entity -X- _ O
comparison -X- _ O
between -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
and -X- _ O
the -X- _ O
KB -X- _ O
, -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
semantic -X- _ O
consistency -X- _ O
between -X- _ O
the -X- _ O
news -X- _ O
content -X- _ O
and -X- _ O
the -X- _ O
KB -X- _ O
. -X- _ O
We -X- _ O
calculate -X- _ O
a -X- _ O
comparison -X- _ O
vector -X- _ O
a -X- _ O
i -X- _ O
between -X- _ O
each -X- _ O
contextual -X- _ O
entity -X- _ O
representation -X- _ O
e -X- _ O
c -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
KB -X- _ O
- -X- _ O
based -X- _ O
entity -X- _ O
embedding -X- _ O
e -X- _ O
KB -X- _ O
∈ -X- _ O
R -X- _ O
M -X- _ O
.a -X- _ O
i -X- _ O
= -X- _ O
f -X- _ O
cmp -X- _ O
( -X- _ O
e -X- _ O
c -X- _ O
, -X- _ O
W -X- _ O
e -X- _ O
• -X- _ O
e -X- _ O
KB -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
6)where -X- _ O
f -X- _ O
cmp -X- _ O
( -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
comparison -X- _ O
function -X- _ O
, -X- _ O
and -X- _ O
W -X- _ O
e -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
×M -X- _ O
is -X- _ O
a -X- _ O
transformation -X- _ O
matrix -X- _ O
. -X- _ O
To -X- _ O
measure -X- _ O
the -X- _ O
embedding -X- _ O
closeness -X- _ O
and -X- _ O
relevance -X- _ O
( -X- _ O
Shen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
our -X- _ O
comparison -X- _ O
function -X- _ O
as -X- _ O
: -X- _ O
f -X- _ O
cmp -X- _ O
( -X- _ O
x -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
= -X- _ O
W -X- _ O
a -X- _ O
[ -X- _ O
x -X- _ O
− -X- _ O
y -X- _ O
, -X- _ O
x -X- _ O
y],(7)where -X- _ O
W -X- _ O
a -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
×2N -X- _ O
is -X- _ O
a -X- _ O
transformation -X- _ O
matrix -X- _ O
and -X- _ O
is -X- _ O
hadamard -X- _ O
product -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
product -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
output -X- _ O
comparison -X- _ O
feature -X- _ O
vector -X- _ O
C -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
is -X- _ O
obtained -X- _ O
by -X- _ O
the -X- _ O
max -X- _ O
pooling -X- _ O
over -X- _ O
the -X- _ O
alignment -X- _ O
vectors -X- _ O
A -X- _ O
= -X- _ O
[ -X- _ O
a -X- _ O
1 -X- _ O
, -X- _ O
a -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
a -X- _ O
n -X- _ O
] -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
entities -X- _ O
E -X- _ O
= -X- _ O
{ -X- _ O
e -X- _ O
1 -X- _ O
, -X- _ O
e -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
e -X- _ O
n -X- _ O
} -X- _ O
in -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
. -X- _ O
After -X- _ O
obtaining -X- _ O
the -X- _ O
comparison -X- _ O
vector -X- _ O
C -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
news -X- _ O
document -X- _ O
representation -X- _ O
vector -X- _ O
H -X- _ O
d -X- _ O
∈ -X- _ O
R -X- _ O
N -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
and -X- _ O
feed -X- _ O
them -X- _ O
into -X- _ O
a -X- _ O
Softmax -X- _ O
layer -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
classification -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
Z -X- _ O
= -X- _ O
Softmax(W -X- _ O
o -X- _ O
[ -X- _ O
H -X- _ O
d -X- _ O
, -X- _ O
C -X- _ O
] -X- _ O
+ -X- _ O
b -X- _ O
o -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
8)where -X- _ O
L -X- _ O
= -X- _ O
− -X- _ O
i∈D -X- _ O
train -X- _ O
j=1 -X- _ O
Y -X- _ O
ij -X- _ O
• -X- _ O
log -X- _ O
Z -X- _ O
ij -X- _ O
+ -X- _ O
η -X- _ O
Θ -X- _ O
2 -X- _ O
, -X- _ O
( -X- _ O
9)where -X- _ O
D -X- _ O
train -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
news -X- _ O
documents -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
Y -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
label -X- _ O
indicator -X- _ O
matrix -X- _ O
, -X- _ O
Θ -X- _ O
is -X- _ O
the -X- _ O
model -X- _ O
parameters -X- _ O
, -X- _ O
and -X- _ O
η -X- _ O
is -X- _ O
regularization -X- _ O
factor -X- _ O
. -X- _ O
For -X- _ O
model -X- _ O
optimization -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
gradient -X- _ O
descent -X- _ O
algorithm -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
extensive -X- _ O
experiments -X- _ O
across -X- _ O
various -X- _ O
settings -X- _ O
and -X- _ O
datasets -X- _ O
. -X- _ O
Following -X- _ O
the -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
SLN -X- _ B-DatasetName
: -X- _ O
Satirical -X- _ B-DatasetName
and -X- _ I-DatasetName
Legitimate -X- _ I-DatasetName
News -X- _ I-DatasetName
Database -X- _ I-DatasetName
( -X- _ O
Rubin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
LUN -X- _ B-DatasetName
: -X- _ O
Labeled -X- _ B-DatasetName
Unreliable -X- _ I-DatasetName
News -X- _ I-DatasetName
Dataset -X- _ O
( -X- _ O
Rashkin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
statistics -X- _ O
. -X- _ O
Our -X- _ O
baseline -X- _ O
models -X- _ O
include -X- _ O
deep -X- _ O
neural -X- _ O
models -X- _ O
: -X- _ O
LSTM -X- _ B-MethodName
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
, -X- _ O
CNN -X- _ B-MethodName
( -X- _ O
Kim -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
BERT+LSTM -X- _ B-MethodName
( -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
for -X- _ O
sentence -X- _ O
encoder -X- _ O
and -X- _ O
then -X- _ O
LSTM -X- _ B-MethodName
for -X- _ O
document -X- _ O
encoder -X- _ O
) -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
( -X- _ O
directly -X- _ O
for -X- _ O
document -X- _ O
encoder -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
graph -X- _ O
neural -X- _ O
models -X- _ O
: -X- _ O
GCN -X- _ B-MethodName
and -X- _ O
GAT -X- _ B-MethodName
based -X- _ O
on -X- _ O
an -X- _ O
undirected -X- _ O
fully -X- _ O
- -X- _ O
connected -X- _ O
sentence -X- _ O
graph -X- _ O
, -X- _ O
which -X- _ O
use -X- _ O
attention -X- _ O
pooling -X- _ O
or -X- _ O
max -X- _ O
pooling -X- _ O
for -X- _ O
learning -X- _ O
news -X- _ O
document -X- _ O
representation -X- _ O
. -X- _ O
For -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
the -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
LSTM -X- _ B-MethodName
to -X- _ O
encode -X- _ O
sentences -X- _ O
with -X- _ O
randomly -X- _ O
initialized -X- _ O
word -X- _ O
embeddings -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
all -X- _ O
the -X- _ O
graph -X- _ O
neural -X- _ O
baselines -X- _ O
. -X- _ O
We -X- _ O
run -X- _ O
our -X- _ O
model -X- _ O
5 -X- _ O
times -X- _ O
and -X- _ O
report -X- _ O
the -X- _ O
micro -X- _ O
- -X- _ O
averaged -X- _ O
( -X- _ O
Precision -X- _ O
= -X- _ O
Recall -X- _ O
= -X- _ O
F1 -X- _ O
) -X- _ O
and -X- _ O
macro -X- _ O
- -X- _ O
averaged -X- _ O
scores -X- _ O
( -X- _ O
Precision -X- _ O
, -X- _ O
Recall -X- _ O
, -X- _ O
F1 -X- _ O
) -X- _ O
in -X- _ O
all -X- _ O
the -X- _ O
settings -X- _ O
including -X- _ O
2 -X- _ O
- -X- _ O
way -X- _ O
and -X- _ O
4 -X- _ O
- -X- _ O
way -X- _ O
classification.2 -X- _ O
- -X- _ O
way -X- _ O
classification -X- _ O
: -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
satirical -X- _ O
and -X- _ O
trusted -X- _ O
news -X- _ O
articles -X- _ O
from -X- _ O
LUN -X- _ B-DatasetName
- -X- _ I-DatasetName
train -X- _ I-DatasetName
for -X- _ O
training -X- _ O
, -X- _ O
LUN -X- _ B-DatasetName
- -X- _ I-DatasetName
test -X- _ I-DatasetName
for -X- _ O
validation -X- _ O
and -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
entire -X- _ O
SLN -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
done -X- _ O
to -X- _ O
emulate -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
scenario -X- _ O
where -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
see -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
an -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
dataset.4 -X- _ O
- -X- _ O
way -X- _ O
classification -X- _ O
: -X- _ O
We -X- _ O
split -X- _ O
the -X- _ O
LUN -X- _ B-DatasetName
- -X- _ I-DatasetName
train -X- _ I-DatasetName
into -X- _ O
a -X- _ O
80:20 -X- _ O
split -X- _ O
to -X- _ O
create -X- _ O
our -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
LUN -X- _ B-DatasetName
- -X- _ I-DatasetName
test -X- _ I-DatasetName
as -X- _ O
our -X- _ O
in -X- _ O
- -X- _ O
domain -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
Experimental -X- _ O
Setting -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
topics -X- _ I-HyperparameterName
K -X- _ I-HyperparameterName
= -X- _ O
100 -X- _ B-HyperparameterValue
in -X- _ O
LDA -X- _ B-MethodName
. -X- _ O
Each -X- _ O
sentence -X- _ O
is -X- _ O
assigned -X- _ O
to -X- _ O
top -X- _ B-HyperparameterName
P -X- _ I-HyperparameterName
= -X- _ O
2 -X- _ B-HyperparameterValue
topics -X- _ O
with -X- _ O
the -X- _ O
largest -X- _ O
probabilities -X- _ O
. -X- _ O
The -X- _ O
layer -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
our -X- _ I-HyperparameterName
heterogeneous -X- _ I-HyperparameterName
graph -X- _ I-HyperparameterName
convolution -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
as -X- _ B-HyperparameterName
L -X- _ I-HyperparameterName
= -X- _ O
1 -X- _ B-HyperparameterValue
. -X- _ O
These -X- _ O
parameters -X- _ O
are -X- _ O
chosen -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
experimental -X- _ O
results -X- _ O
on -X- _ O
validation -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
other -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
are -X- _ O
set -X- _ O
as -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
the -X- _ O
baseline -X- _ O
( -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
fair -X- _ O
comparison -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
dimensions -X- _ I-HyperparameterName
used -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
are -X- _ O
set -X- _ O
as -X- _ O
M -X- _ B-HyperparameterName
= -X- _ O
100 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
node -X- _ B-HyperparameterName
embedding -X- _ I-HyperparameterName
dimension -X- _ I-HyperparameterName
N -X- _ B-HyperparameterName
= -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
GCN -X- _ B-HyperparameterName
, -X- _ O
GAT -X- _ B-HyperparameterName
and -X- _ O
CompareNet -X- _ B-HyperparameterName
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
activation -X- _ B-HyperparameterValue
function -X- _ I-HyperparameterValue
as -X- _ O
LeakyRelU -X- _ B-HyperparameterValue
with -X- _ O
slope -X- _ B-HyperparameterName
0.2 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
model -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
models -X- _ O
for -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
15 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
0.001 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
set -X- _ O
L2 -X- _ B-HyperparameterName
normalization -X- _ I-HyperparameterName
factor -X- _ I-HyperparameterName
η -X- _ B-HyperparameterName
as -X- _ O
1e-6 -X- _ B-HyperparameterValue
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
- -X- _ O
way -X- _ O
classification -X- _ O
between -X- _ O
satirical -X- _ O
and -X- _ O
trusted -X- _ O
news -X- _ O
articles -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
only -X- _ O
micro -X- _ B-MetricName
F1 -X- _ I-MetricName
since -X- _ O
micro -X- _ B-MetricName
Precision -X- _ I-MetricName
= -X- _ O
Recall -X- _ B-MetricName
= -X- _ O
F1 -X- _ B-MetricName
. -X- _ O
As -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
model -X- _ O
CompareNet -X- _ B-HyperparameterName
significantly -X- _ O
outperforms -X- _ O
all -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
baselines -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
metrics -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
baseline -X- _ O
model -X- _ O
, -X- _ O
CompareNet -X- _ B-HyperparameterName
improves -X- _ O
both -X- _ O
micro -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
by -X- _ O
nearly -X- _ O
3 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
We -X- _ O
can -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
graph -X- _ O
neural -X- _ O
network -X- _ O
based -X- _ O
models -X- _ O
GCN -X- _ B-MethodName
and -X- _ O
GAT -X- _ B-MethodName
all -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
deep -X- _ O
neural -X- _ O
models -X- _ O
including -X- _ O
CNN -X- _ B-MethodName
, -X- _ O
LSTM -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
The -X- _ O
reason -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
deep -X- _ O
neural -X- _ O
models -X- _ O
fail -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
interactions -X- _ O
between -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
since -X- _ O
different -X- _ O
interaction -X- _ O
patterns -X- _ O
are -X- _ O
observed -X- _ O
in -X- _ O
trusted -X- _ O
and -X- _ O
fake -X- _ O
news -X- _ O
documents -X- _ O
( -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
Com -X- _ B-MethodName
- -X- _ I-MethodName
pareNet -X- _ I-MethodName
further -X- _ O
improves -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
by -X- _ O
effectively -X- _ O
exploiting -X- _ O
the -X- _ O
topics -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
external -X- _ O
KB -X- _ O
. -X- _ O
The -X- _ O
topics -X- _ O
enrich -X- _ O
the -X- _ O
news -X- _ O
representation -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
external -X- _ O
KB -X- _ O
offers -X- _ O
evidences -X- _ O
for -X- _ O
fake -X- _ B-TaskName
news -X- _ I-TaskName
detection -X- _ I-TaskName
. -X- _ O
We -X- _ O
also -X- _ O
present -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
four -X- _ O
- -X- _ O
way -X- _ O
classification -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Consistently -X- _ O
, -X- _ O
all -X- _ O
graph -X- _ O
neural -X- _ O
models -X- _ O
capturing -X- _ O
sentence -X- _ O
interactions -X- _ O
outperform -X- _ O
the -X- _ O
deep -X- _ O
neural -X- _ O
models -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
CompareNet -X- _ B-MethodName
achieves -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
all -X- _ O
metrics -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
CompareNet -X- _ B-MethodName
benefits -X- _ O
from -X- _ O
the -X- _ O
topics -X- _ O
and -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
subsection -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
experiments -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
each -X- _ O
module -X- _ O
in -X- _ O
CompareNet -X- _ B-MethodName
and -X- _ O
the -X- _ O
way -X- _ O
we -X- _ O
incorporate -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O
We -X- _ O
study -X- _ O
the -X- _ O
average -X- _ O
performance -X- _ O
of -X- _ O
5 -X- _ O
runs -X- _ O
on -X- _ O
the -X- _ O
LUN -X- _ B-DatasetName
- -X- _ I-DatasetName
test -X- _ I-DatasetName
set -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
test -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
CompareNet -X- _ B-MethodName
removing -X- _ O
structured -X- _ O
triplets -X- _ O
, -X- _ O
removing -X- _ O
the -X- _ O
entire -X- _ O
external -X- _ O
knowledge -X- _ O
, -X- _ O
removing -X- _ O
topics -X- _ O
, -X- _ O
and -X- _ O
removing -X- _ O
both -X- _ O
topics -X- _ O
and -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
last -X- _ O
two -X- _ O
rows -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
information -X- _ O
is -X- _ O
as -X- _ O
important -X- _ O
as -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O
Removing -X- _ O
both -X- _ O
topics -X- _ O
and -X- _ O
external -X- _ O
knowledge -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
w/o -X- _ O
Both -X- _ O
) -X- _ O
will -X- _ O
lead -X- _ O
to -X- _ O
substantial -X- _ O
performance -X- _ O
drop -X- _ O
( -X- _ O
4.0 -X- _ B-MetricValue
- -X- _ I-MetricValue
5.0 -X- _ I-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
It -X- _ O
demonstrates -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
both -X- _ O
topics -X- _ O
and -X- _ O
external -X- _ O
knowledge -X- _ O
. -X- _ O
The -X- _ O
variant -X- _ O
model -X- _ O
CompareNet -X- _ B-MethodName
( -X- _ I-MethodName
undirected -X- _ I-MethodName
) -X- _ I-MethodName
although -X- _ O
incorporating -X- _ O
both -X- _ O
topics -X- _ O
and -X- _ O
external -X- _ O
knowledge -X- _ O
achieves -X- _ O
lower -X- _ O
performance -X- _ O
than -X- _ O
CompareNet -X- _ B-MethodName
w/o -X- _ I-MethodName
Entity -X- _ I-MethodName
Cmp -X- _ I-MethodName
and -X- _ O
CompareNet -X- _ B-MethodName
w/o -X- _ I-MethodName
Topics -X- _ I-MethodName
. -X- _ O
The -X- _ O
reason -X- _ O
could -X- _ O
be -X- _ O
that -X- _ O
CompareNet -X- _ B-MethodName
( -X- _ I-MethodName
undirected -X- _ I-MethodName
) -X- _ I-MethodName
directly -X- _ O
aggregates -X- _ O
the -X- _ O
true -X- _ O
entity -X- _ O
knowledge -X- _ O
into -X- _ O
the -X- _ O
news -X- _ O
representation -X- _ O
in -X- _ O
graph -X- _ O
convolution -X- _ O
without -X- _ O
considering -X- _ O
the -X- _ O
directed -X- _ O
edges -X- _ O
, -X- _ O
which -X- _ O
misleads -X- _ O
the -X- _ O
classifier -X- _ O
for -X- _ O
differentiating -X- _ O
fake -X- _ O
news -X- _ O
. -X- _ O
This -X- _ O
verifies -X- _ O
the -X- _ O
appropriateness -X- _ O
of -X- _ O
our -X- _ O
constructed -X- _ O
directed -X- _ O
heterogeneous -X- _ O
document -X- _ O
graph -X- _ O
. -X- _ O
The -X- _ O
last -X- _ O
variant -X- _ O
Com -X- _ B-MethodName
- -X- _ I-MethodName
pareNet -X- _ I-MethodName
( -X- _ I-MethodName
concatenation -X- _ I-MethodName
) -X- _ I-MethodName
also -X- _ O
performs -X- _ O
lower -X- _ O
than -X- _ O
CompareNet -X- _ B-MethodName
w/o -X- _ I-MethodName
Entity -X- _ I-MethodName
Cmp -X- _ I-MethodName
, -X- _ O
further -X- _ O
indicating -X- _ O
that -X- _ O
directly -X- _ O
concatenating -X- _ O
true -X- _ O
entity -X- _ O
knowledge -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
good -X- _ O
way -X- _ O
for -X- _ O
incorporating -X- _ O
entity -X- _ O
knowledge -X- _ O
. -X- _ O
Its -X- _ O
performance -X- _ O
drops -X- _ O
by -X- _ O
around -X- _ O
2.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
compared -X- _ O
to -X- _ O
CompareNet -X- _ B-MethodName
. -X- _ O
These -X- _ O
demonstrate -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
carefully -X- _ O
designed -X- _ O
entity -X- _ O
comparison -X- _ O
network -X- _ O
in -X- _ O
CompareNet -X- _ B-MethodName
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
performance -X- _ O
( -X- _ O
micro -X- _ B-MetricName
and -X- _ I-MetricName
macro -X- _ I-MetricName
F1 -X- _ I-MetricName
) -X- _ O
of -X- _ O
our -X- _ O
model -X- _ O
CompareNet -X- _ B-MethodName
on -X- _ O
LUN -X- _ B-DatasetName
validation -X- _ I-DatasetName
set -X- _ O
with -X- _ O
different -X- _ O
number -X- _ O
of -X- _ O
top -X- _ B-HyperparameterName
assigned -X- _ I-HyperparameterName
topics -X- _ I-HyperparameterName
P -X- _ I-HyperparameterName
to -X- _ O
each -X- _ O
sentence -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
clearly -X- _ O
, -X- _ O
micro -X- _ B-MetricName
F1 -X- _ I-MetricName
and -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
first -X- _ O
consistently -X- _ O
rises -X- _ O
with -X- _ O
the -X- _ O
increase -X- _ O
of -X- _ O
P -X- _ B-HyperparameterName
and -X- _ O
then -X- _ O
drops -X- _ O
when -X- _ O
P -X- _ B-HyperparameterName
is -X- _ O
larger -X- _ O
than -X- _ O
2 -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
because -X- _ O
that -X- _ O
connecting -X- _ O
too -X- _ O
many -X- _ O
lowprobability -X- _ O
topics -X- _ O
will -X- _ O
introduce -X- _ O
some -X- _ O
noise -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
P -X- _ B-HyperparameterName
= -X- _ O
2 -X- _ B-HyperparameterValue
. -X- _ O
To -X- _ O
further -X- _ O
illustrate -X- _ O
why -X- _ O
our -X- _ O
model -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
baseline -X- _ O
GAT+Attn -X- _ B-MethodName
( -X- _ O
Vaibhav -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
4 -X- _ O
, -X- _ O
the -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
is -X- _ O
in -X- _ O
conflict -X- _ O
with -X- _ O
the -X- _ O
entity -X- _ O
description -X- _ O
from -X- _ O
Wikipedia -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
the -X- _ O
news -X- _ O
about -X- _ O
" -X- _ O
FDA -X- _ O
target -X- _ O
and -X- _ O
threaten -X- _ O
the -X- _ O
natural -X- _ O
health -X- _ O
community -X- _ O
" -X- _ O
delivers -X- _ O
contrary -X- _ O
meaning -X- _ O
from -X- _ O
the -X- _ O
entity -X- _ O
description -X- _ O
that -X- _ O
" -X- _ O
FDA -X- _ O
is -X- _ O
responsible -X- _ O
for -X- _ O
protecting -X- _ O
and -X- _ O
promoting -X- _ O
public -X- _ O
health -X- _ O
" -X- _ O
4 -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
about -X- _ O
" -X- _ O
mammograms -X- _ O
are -X- _ O
not -X- _ O
effective -X- _ O
at -X- _ O
detecting -X- _ O
breast -X- _ O
tumors -X- _ O
" -X- _ O
conveys -X- _ O
different -X- _ O
meaning -X- _ O
from -X- _ O
the -X- _ O
entity -X- _ O
description -X- _ O
of -X- _ O
" -X- _ O
mammograms -X- _ O
" -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
CompareNet -X- _ B-MethodName
benefits -X- _ O
from -X- _ O
the -X- _ O
comparison -X- _ O
to -X- _ O
Wikipedia -X- _ B-DatasetName
knowledge -X- _ I-DatasetName
by -X- _ O
the -X- _ O
entity -X- _ O
comparison -X- _ O
network -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
there -X- _ O
are -X- _ O
also -X- _ O
unsuccessful -X- _ O
cases -X- _ O
since -X- _ O
an -X- _ O
entity -X- _ O
could -X- _ O
be -X- _ O
mistakenly -X- _ O
linked -X- _ O
to -X- _ O
a -X- _ O
wrong -X- _ O
entity -X- _ O
in -X- _ O
the -X- _ O
Wikipedia -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
graph -X- _ O
neural -X- _ O
model -X- _ O
CompareNet -X- _ B-MethodName
which -X- _ O
compares -X- _ O
the -X- _ O
news -X- _ O
to -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
. -X- _ O
Considering -X- _ O
that -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
fake -X- _ O
news -X- _ O
is -X- _ O
correlated -X- _ O
with -X- _ O
topics -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
topics -X- _ O
to -X- _ O
enrich -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
representation -X- _ O
for -X- _ O
improving -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
. -X- _ O
Particularly -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
construct -X- _ O
a -X- _ O
directed -X- _ O
heterogeneous -X- _ O
document -X- _ O
graph -X- _ O
for -X- _ O
each -X- _ O
news -X- _ O
document -X- _ O
capturing -X- _ O
the -X- _ O
interactions -X- _ O
among -X- _ O
sentences -X- _ O
, -X- _ O
topics -X- _ O
and -X- _ O
entities -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
heterogeneous -X- _ O
graph -X- _ O
attention -X- _ O
network -X- _ O
for -X- _ O
learning -X- _ O
topic -X- _ O
- -X- _ O
enriched -X- _ O
news -X- _ O
representation -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
that -X- _ O
encode -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
news -X- _ O
document -X- _ O
. -X- _ O
To -X- _ O
capture -X- _ O
the -X- _ O
semantic -X- _ O
consistency -X- _ O
of -X- _ O
the -X- _ O
news -X- _ O
content -X- _ O
and -X- _ O
the -X- _ O
KB -X- _ O
, -X- _ O
the -X- _ O
learned -X- _ O
contextual -X- _ O
entity -X- _ O
representations -X- _ O
are -X- _ O
then -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
KB -X- _ O
- -X- _ O
based -X- _ O
entity -X- _ O
representations -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
carefully -X- _ O
designed -X- _ O
entity -X- _ O
comparison -X- _ O
network -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
obtained -X- _ O
entity -X- _ O
comparison -X- _ O
features -X- _ O
are -X- _ O
combined -X- _ O
with -X- _ O
the -X- _ O
news -X- _ O
representation -X- _ O
for -X- _ O
an -X- _ O
improved -X- _ O
fake -X- _ O
news -X- _ O
classifier -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
two -X- _ O
benchmark -X- _ O
datasets -X- _ O
have -X- _ O
demonstrated -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
way -X- _ O
we -X- _ O
incorporate -X- _ O
the -X- _ O
external -X- _ O
knowledge -X- _ O
and -X- _ O
topics -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
explore -X- _ O
a -X- _ O
better -X- _ O
way -X- _ O
to -X- _ O
combine -X- _ O
multi -X- _ O
- -X- _ O
modal -X- _ O
data -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
images -X- _ O
) -X- _ O
and -X- _ O
external -X- _ O
knowledge -X- _ O
for -X- _ O
fake -X- _ O
news -X- _ O
detection -X- _ O
. -X- _ O
The -X- _ O
work -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Natural -X- _ O
Science -X- _ O
Fundation -X- _ O
of -X- _ O
China -X- _ O
( -X- _ O
No -X- _ O
. -X- _ O
61806020 -X- _ O
, -X- _ O
U1936220 -X- _ O
, -X- _ O
61972047 -X- _ O
, -X- _ O
62076245 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Microsoft -X- _ O
Research -X- _ O
Asia -X- _ O
's -X- _ O
Star -X- _ O
Track -X- _ O
project -X- _ O
. -X- _ O

This -X- _ O
paper -X- _ O
describes -X- _ O
three -X- _ O
open -X- _ O
access -X- _ O
Yoloxóchitl -X- _ B-DatasetName
Mixtec -X- _ I-DatasetName
corpora -X- _ O
and -X- _ O
presents -X- _ O
the -X- _ O
results -X- _ O
and -X- _ O
implications -X- _ O
of -X- _ O
end -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
end -X- _ I-TaskName
automatic -X- _ I-TaskName
speech -X- _ I-TaskName
recognition -X- _ I-TaskName
for -X- _ I-TaskName
endangered -X- _ I-TaskName
language -X- _ I-TaskName
documentation -X- _ I-TaskName
. -X- _ O
Two -X- _ O
issues -X- _ O
are -X- _ O
addressed -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
advantage -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
accuracy -X- _ O
of -X- _ O
targeting -X- _ O
informational -X- _ O
( -X- _ O
BPE -X- _ B-MethodName
) -X- _ O
units -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
, -X- _ O
or -X- _ O
in -X- _ O
substitution -X- _ O
of -X- _ O
, -X- _ O
linguistic -X- _ O
units -X- _ O
( -X- _ O
word -X- _ B-MethodName
, -X- _ O
morpheme -X- _ B-MethodName
, -X- _ O
morae -X- _ B-MethodName
) -X- _ O
and -X- _ O
then -X- _ O
using -X- _ O
ROVER -X- _ B-MethodName
for -X- _ O
system -X- _ O
combination -X- _ O
. -X- _ O
BPE -X- _ B-MethodName
units -X- _ O
consistently -X- _ O
outperform -X- _ O
linguistic -X- _ O
units -X- _ O
although -X- _ O
the -X- _ O
best -X- _ O
results -X- _ O
are -X- _ O
obtained -X- _ O
by -X- _ O
system -X- _ O
combination -X- _ O
of -X- _ O
different -X- _ O
BPE -X- _ B-MethodName
targets -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
a -X- _ O
case -X- _ O
is -X- _ O
made -X- _ O
that -X- _ O
for -X- _ O
endangered -X- _ O
language -X- _ O
documentation -X- _ O
, -X- _ O
ASR -X- _ B-TaskName
contributions -X- _ O
should -X- _ O
be -X- _ O
evaluated -X- _ O
according -X- _ O
to -X- _ O
extrinsic -X- _ O
criteria -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
positive -X- _ B-MetricName
impact -X- _ I-MetricName
on -X- _ I-MetricName
downstream -X- _ I-MetricName
tasks -X- _ I-MetricName
) -X- _ O
and -X- _ O
not -X- _ O
simply -X- _ O
intrinsic -X- _ O
metrics -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
CER -X- _ B-MetricName
and -X- _ O
WER -X- _ B-MetricName
) -X- _ O
. -X- _ O
The -X- _ O
extrinsic -X- _ O
metric -X- _ O
chosen -X- _ O
is -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
reduction -X- _ O
in -X- _ O
the -X- _ O
human -X- _ O
effort -X- _ O
needed -X- _ O
to -X- _ O
produce -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
transcriptions -X- _ O
for -X- _ O
permanent -X- _ O
archiving -X- _ O
. -X- _ O
1 -X- _ O
Introduction -X- _ O
: -X- _ O
Endangered -X- _ O
language -X- _ O
documentation -X- _ O
history -X- _ O
and -X- _ O
contextEndangered -X- _ O
language -X- _ O
( -X- _ O
EL -X- _ O
) -X- _ O
documentation -X- _ O
emerged -X- _ O
as -X- _ O
a -X- _ O
field -X- _ O
of -X- _ O
linguistic -X- _ O
activity -X- _ O
in -X- _ O
the -X- _ O
1990s -X- _ O
, -X- _ O
as -X- _ O
reflected -X- _ O
in -X- _ O
several -X- _ O
seminal -X- _ O
moments -X- _ O
. -X- _ O
In -X- _ O
1991 -X- _ O
the -X- _ O
Linguistic -X- _ O
Society -X- _ O
of -X- _ O
America -X- _ O
held -X- _ O
a -X- _ O
symposium -X- _ O
entitled -X- _ O
" -X- _ O
Endangered -X- _ O
Languages -X- _ O
and -X- _ O
their -X- _ O
Preservation -X- _ O
" -X- _ O
; -X- _ O
in -X- _ O
1992 -X- _ O
Hale -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
1992 -X- _ O
) -X- _ O
published -X- _ O
a -X- _ O
seminal -X- _ O
article -X- _ O
on -X- _ O
endangered -X- _ O
languages -X- _ O
in -X- _ O
Language -X- _ O
, -X- _ O
the -X- _ O
LSA -X- _ O
's -X- _ O
flagship -X- _ O
journal -X- _ O
. -X- _ O
, -X- _ O
Himmelmann -X- _ O
( -X- _ O
1998 -X- _ O
argued -X- _ O
for -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
documentary -X- _ O
linguistics -X- _ O
as -X- _ O
an -X- _ O
endeavor -X- _ O
separate -X- _ O
from -X- _ O
and -X- _ O
complementary -X- _ O
to -X- _ O
descriptive -X- _ O
linguistics -X- _ O
. -X- _ O
By -X- _ O
the -X- _ O
early -X- _ O
years -X- _ O
of -X- _ O
the -X- _ O
present -X- _ O
millennium -X- _ O
, -X- _ O
infrastructure -X- _ O
efforts -X- _ O
were -X- _ O
being -X- _ O
developed -X- _ O
: -X- _ O
metadata -X- _ O
standards -X- _ O
and -X- _ O
best -X- _ O
practices -X- _ O
for -X- _ O
archiving -X- _ O
( -X- _ O
Bird -X- _ O
and -X- _ O
Simons -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
; -X- _ O
tools -X- _ O
for -X- _ O
lexicography -X- _ O
and -X- _ O
corpus -X- _ O
developments -X- _ O
such -X- _ O
as -X- _ O
Shoebox -X- _ O
, -X- _ O
Transcriber -X- _ O
( -X- _ O
Barras -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ELAN -X- _ O
( -X- _ O
Wittenburg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
financial -X- _ O
support -X- _ O
for -X- _ O
endangered -X- _ O
language -X- _ O
documentation -X- _ O
( -X- _ O
the -X- _ O
Volkswagen -X- _ O
Foundation -X- _ O
, -X- _ O
the -X- _ O
NSF -X- _ O
Documenting -X- _ O
Endangered -X- _ O
Language -X- _ O
Program -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
SOAS -X- _ O
Endangered -X- _ O
Language -X- _ O
Documentation -X- _ O
Programme -X- _ O
) -X- _ O
. -X- _ O
Recent -X- _ O
retrospectives -X- _ O
on -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
Hale -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
1992 -X- _ O
) -X- _ O
and -X- _ O
Himmelmann -X- _ O
( -X- _ O
1998 -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
published -X- _ O
by -X- _ O
Seifart -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
McDonnell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Within -X- _ O
the -X- _ O
last -X- _ O
decade -X- _ O
, -X- _ O
the -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
supported -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
three -X- _ O
workshops -X- _ O
, -X- _ O
under -X- _ O
the -X- _ O
acronym -X- _ O
AARDVARC -X- _ O
( -X- _ O
Automatically -X- _ O
Annotated -X- _ O
Repository -X- _ O
of -X- _ O
Digital -X- _ O
Audio -X- _ O
and -X- _ O
Video -X- _ O
Resources -X- _ O
Community -X- _ O
) -X- _ O
to -X- _ O
bring -X- _ O
together -X- _ O
field -X- _ O
linguists -X- _ O
working -X- _ O
on -X- _ O
endangered -X- _ O
languages -X- _ O
and -X- _ O
computational -X- _ O
linguists -X- _ O
working -X- _ O
on -X- _ O
automatic -X- _ O
annotation -X- _ O
- -X- _ O
particularly -X- _ O
automatic -X- _ B-TaskName
speech -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
ASR)-to -X- _ B-TaskName
address -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
what -X- _ O
has -X- _ O
been -X- _ O
called -X- _ O
the -X- _ O
" -X- _ O
transcription -X- _ O
bottleneck -X- _ O
" -X- _ O
( -X- _ O
Whalen -X- _ O
and -X- _ O
Damir -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
Interest -X- _ O
in -X- _ O
applying -X- _ O
machine -X- _ O
learning -X- _ O
to -X- _ O
endangered -X- _ O
language -X- _ O
documentation -X- _ O
is -X- _ O
also -X- _ O
manifested -X- _ O
in -X- _ O
four -X- _ O
biennial -X- _ O
workshops -X- _ O
on -X- _ O
this -X- _ O
topic -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
in -X- _ O
2014 -X- _ O
( -X- _ O
Good -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
articles -X- _ O
directly -X- _ O
referencing -X- _ O
ASR -X- _ B-TaskName
of -X- _ O
endangered -X- _ O
languages -X- _ O
have -X- _ O
become -X- _ O
increasingly -X- _ O
common -X- _ O
over -X- _ O
the -X- _ O
last -X- _ O
five -X- _ O
years -X- _ O
( -X- _ O
Adams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2020Ćavar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Foley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018Foley -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2019Gupta -X- _ O
and -X- _ O
Boulianne -X- _ O
, -X- _ O
2020;Michaud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Mitra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021).This -X- _ O
article -X- _ O
continues -X- _ O
work -X- _ O
on -X- _ O
Yoloxóchitl -X- _ B-DatasetName
Mixtec -X- _ I-DatasetName
ASR -X- _ B-TaskName
( -X- _ O
Mitra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
recent -X- _ O
efforts -X- _ O
( -X- _ O
2020 -X- _ O
and -X- _ O
2021 -X- _ O
) -X- _ O
have -X- _ O
adopted -X- _ O
the -X- _ O
ESPNet -X- _ O
toolkit -X- _ O
for -X- _ O
end -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
end -X- _ I-TaskName
automatic -X- _ I-TaskName
speech -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
) -X- _ O
. -X- _ O
This -X- _ O
approach -X- _ O
has -X- _ O
proven -X- _ O
to -X- _ O
be -X- _ O
very -X- _ O
efficient -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
time -X- _ O
needed -X- _ O
to -X- _ O
develop -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
recipe -X- _ O
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
and -X- _ O
in -X- _ O
yielding -X- _ O
ASR -X- _ B-TaskName
hypotheses -X- _ O
of -X- _ O
an -X- _ O
accuracy -X- _ O
capable -X- _ O
of -X- _ O
significantly -X- _ O
reducing -X- _ O
the -X- _ O
extent -X- _ O
of -X- _ O
human -X- _ O
effort -X- _ O
needed -X- _ O
to -X- _ O
finalize -X- _ O
accurate -X- _ O
transcribed -X- _ O
audio -X- _ O
for -X- _ O
permanent -X- _ O
archiving -X- _ O
as -X- _ O
here -X- _ O
demonstrated -X- _ O
. -X- _ O
Section -X- _ O
2 -X- _ O
discusses -X- _ O
the -X- _ O
Yoloxóchitl -X- _ B-DatasetName
Mixtec -X- _ I-DatasetName
corpora -X- _ O
, -X- _ O
and -X- _ O
Section -X- _ O
3 -X- _ O
explores -X- _ O
the -X- _ O
general -X- _ O
goals -X- _ O
of -X- _ O
EL -X- _ O
documentation -X- _ O
. -X- _ O
Section -X- _ O
4 -X- _ O
reviews -X- _ O
the -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
and -X- _ O
corresponding -X- _ O
results -X- _ O
using -X- _ O
ESPNet -X- _ O
. -X- _ O
The -X- _ O
conclusion -X- _ O
is -X- _ O
offered -X- _ O
in -X- _ O
Section -X- _ O
5.2 -X- _ O
Yoloxóchitl -X- _ B-DatasetName
Mixtec -X- _ I-DatasetName
: -X- _ O
Corpus -X- _ O
characteristics -X- _ O
and -X- _ O
development -X- _ O
Much -X- _ O
work -X- _ O
on -X- _ O
computer -X- _ O
- -X- _ O
assisted -X- _ O
EL -X- _ O
documentation -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
work -X- _ O
on -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
, -X- _ O
for -X- _ O
the -X- _ O
obvious -X- _ O
reason -X- _ O
that -X- _ O
most -X- _ O
ELs -X- _ O
have -X- _ O
limited -X- _ O
resources -X- _ O
, -X- _ O
be -X- _ O
they -X- _ O
time -X- _ O
- -X- _ O
coded -X- _ O
transcriptions -X- _ O
, -X- _ O
interlinearized -X- _ O
texts -X- _ O
, -X- _ O
or -X- _ O
corpora -X- _ O
in -X- _ O
parallel -X- _ O
translation -X- _ O
. -X- _ O
The -X- _ O
resources -X- _ O
for -X- _ O
Yoloxóchitl -X- _ B-DatasetName
Mixtec -X- _ I-DatasetName
, -X- _ O
the -X- _ O
language -X- _ O
targeted -X- _ O
in -X- _ O
this -X- _ O
present -X- _ O
study -X- _ O
, -X- _ O
are -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
relatively -X- _ O
abundant -X- _ O
by -X- _ O
EL -X- _ O
standards -X- _ O
( -X- _ O
119.32 -X- _ O
hours -X- _ O
over -X- _ O
three -X- _ O
corpora -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
over -X- _ O
a -X- _ O
decade -X- _ O
of -X- _ O
linguistic -X- _ O
and -X- _ O
anthropological -X- _ O
research -X- _ O
by -X- _ O
Amith -X- _ O
and -X- _ O
Castillo -X- _ O
García -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Yoloxóchitl -X- _ B-DatasetName
Mixtec -X- _ I-DatasetName
( -X- _ O
henceforth -X- _ O
YM -X- _ B-DatasetName
) -X- _ O
, -X- _ O
an -X- _ O
endangered -X- _ O
Mixtecan -X- _ O
language -X- _ O
spoken -X- _ O
in -X- _ O
the -X- _ O
municipality -X- _ O
of -X- _ O
San -X- _ O
Luis -X- _ O
Acatlán -X- _ O
, -X- _ O
Guerrero -X- _ O
, -X- _ O
Mexico -X- _ O
, -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
some -X- _ O
50 -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
Mixtec -X- _ O
language -X- _ O
family -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
within -X- _ O
a -X- _ O
larger -X- _ O
unit -X- _ O
, -X- _ O
Otomanguean -X- _ O
, -X- _ O
that -X- _ O
Suárez -X- _ O
( -X- _ O
1983 -X- _ O
) -X- _ O
considers -X- _ O
a -X- _ O
hyper -X- _ O
- -X- _ O
family -X- _ O
or -X- _ O
stock -X- _ O
. -X- _ O
Mixtec -X- _ O
languages -X- _ O
( -X- _ O
spoken -X- _ O
in -X- _ O
Oaxaca -X- _ O
, -X- _ O
Guerrero -X- _ O
, -X- _ O
and -X- _ O
Puebla -X- _ O
) -X- _ O
are -X- _ O
highly -X- _ O
varied -X- _ O
, -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
approximately -X- _ O
2,000 -X- _ O
years -X- _ O
of -X- _ O
diversification -X- _ O
. -X- _ O
YM -X- _ B-DatasetName
is -X- _ O
spoken -X- _ O
in -X- _ O
four -X- _ O
communities -X- _ O
: -X- _ O
Yoloxóchitl -X- _ O
, -X- _ O
Cuanacaxtitlan -X- _ O
, -X- _ O
Arroyo -X- _ O
Cumiapa -X- _ O
, -X- _ O
and -X- _ O
Buena -X- _ O
Vista -X- _ O
. -X- _ O
Mutual -X- _ O
intelligibility -X- _ O
among -X- _ O
the -X- _ O
four -X- _ O
communities -X- _ O
is -X- _ O
high -X- _ O
despite -X- _ O
differences -X- _ O
in -X- _ O
phonology -X- _ O
, -X- _ O
morphology -X- _ O
, -X- _ O
and -X- _ O
syntax -X- _ O
. -X- _ O
All -X- _ O
villages -X- _ O
have -X- _ O
a -X- _ O
simple -X- _ O
common -X- _ O
segmental -X- _ O
inventory -X- _ O
but -X- _ O
apparently -X- _ O
significant -X- _ O
though -X- _ O
still -X- _ O
undocumented -X- _ O
variation -X- _ O
in -X- _ O
tonal -X- _ O
phonology -X- _ O
; -X- _ O
only -X- _ O
Cuanacaxtitlan -X- _ O
manifests -X- _ O
tone -X- _ O
sandhi -X- _ O
. -X- _ O
YMC -X- _ B-DatasetName
( -X- _ O
referring -X- _ O
only -X- _ O
to -X- _ O
the -X- _ O
Mixtec -X- _ O
of -X- _ O
the -X- _ O
community -X- _ O
of -X- _ O
Yoloxóchitl -X- _ O
[ -X- _ O
16.81602 -X- _ O
, -X- _ O
-98.68597 -X- _ O
] -X- _ O
) -X- _ O
manifests -X- _ O
28 -X- _ O
distinct -X- _ O
tonal -X- _ O
patterns -X- _ O
on -X- _ O
1,451 -X- _ O
to -X- _ O
- -X- _ O
date -X- _ O
identified -X- _ O
bimoraic -X- _ O
lexical -X- _ O
stems -X- _ O
. -X- _ O
The -X- _ O
tonal -X- _ O
patterns -X- _ O
carry -X- _ O
a -X- _ O
significant -X- _ O
functional -X- _ O
load -X- _ O
regarding -X- _ O
the -X- _ O
lexicon -X- _ O
and -X- _ O
inflection -X- _ O
( -X- _ O
Palancar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
24 -X- _ O
distinct -X- _ O
tonal -X- _ O
patterns -X- _ O
on -X- _ O
the -X- _ O
bimoraic -X- _ O
segmental -X- _ O
sequence -X- _ O
[ -X- _ O
nama -X- _ O
] -X- _ O
yield -X- _ O
30 -X- _ O
words -X- _ O
( -X- _ O
including -X- _ O
five -X- _ O
homophones -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
three -X- _ O
principal -X- _ O
aspectual -X- _ O
forms -X- _ O
( -X- _ O
irrealis -X- _ O
, -X- _ O
incompletive -X- _ O
, -X- _ O
and -X- _ O
completive -X- _ O
) -X- _ O
are -X- _ O
almost -X- _ O
invariably -X- _ O
marked -X- _ O
by -X- _ O
a -X- _ O
tonal -X- _ O
variation -X- _ O
on -X- _ O
the -X- _ O
first -X- _ O
mora -X- _ O
of -X- _ O
the -X- _ O
verbal -X- _ O
stem -X- _ O
( -X- _ O
1 -X- _ O
or -X- _ O
3 -X- _ O
for -X- _ O
the -X- _ O
irrealis -X- _ O
, -X- _ O
4 -X- _ O
for -X- _ O
the -X- _ O
incompletive -X- _ O
, -X- _ O
and -X- _ O
13 -X- _ O
for -X- _ O
the -X- _ O
completive -X- _ O
; -X- _ O
in -X- _ O
addition -X- _ O
14 -X- _ O
on -X- _ O
the -X- _ O
initial -X- _ O
mora -X- _ O
almost -X- _ O
always -X- _ O
indicates -X- _ O
negation -X- _ O
of -X- _ O
the -X- _ O
irrealis -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
not -X- _ O
- -X- _ O
insignificant -X- _ O
number -X- _ O
of -X- _ O
cases -X- _ O
, -X- _ O
suppletive -X- _ O
stems -X- _ O
exist -X- _ O
, -X- _ O
generally -X- _ O
manifesting -X- _ O
variation -X- _ O
in -X- _ O
a -X- _ O
stem -X- _ O
- -X- _ O
initial -X- _ O
consonant -X- _ O
and -X- _ O
often -X- _ O
the -X- _ O
stem -X- _ O
- -X- _ O
initial -X- _ O
vowel -X- _ O
. -X- _ O
The -X- _ O
ample -X- _ O
tonal -X- _ O
inventory -X- _ O
of -X- _ O
YMC -X- _ B-DatasetName
presents -X- _ O
obstacles -X- _ O
to -X- _ O
native -X- _ O
speaker -X- _ O
literacy -X- _ O
and -X- _ O
an -X- _ O
ASR -X- _ B-TaskName
system -X- _ O
learning -X- _ O
to -X- _ O
convert -X- _ O
an -X- _ O
acoustic -X- _ O
signal -X- _ O
to -X- _ O
text -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
complicates -X- _ O
the -X- _ O
construction -X- _ O
of -X- _ O
a -X- _ O
language -X- _ O
lexicon -X- _ O
for -X- _ O
HMM -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
systems -X- _ I-MethodName
, -X- _ O
a -X- _ O
lexicon -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
required -X- _ O
in -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
. -X- _ O
The -X- _ O
phonological -X- _ O
and -X- _ O
morphological -X- _ O
differences -X- _ O
between -X- _ O
YMC -X- _ B-DatasetName
and -X- _ O
the -X- _ O
Mixtec -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
other -X- _ O
YM -X- _ B-DatasetName
communities -X- _ O
create -X- _ O
challenges -X- _ O
for -X- _ O
transcription -X- _ O
and -X- _ O
, -X- _ O
by -X- _ O
extension -X- _ O
, -X- _ O
for -X- _ O
applying -X- _ O
YMC -X- _ B-DatasetName
ASR -X- _ B-TaskName
to -X- _ O
speech -X- _ O
recordings -X- _ O
from -X- _ O
these -X- _ O
other -X- _ O
villages -X- _ O
. -X- _ O
To -X- _ O
accomplish -X- _ O
this -X- _ O
, -X- _ O
it -X- _ O
will -X- _ O
be -X- _ O
necessary -X- _ O
first -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
phonology -X- _ O
and -X- _ O
morphology -X- _ O
of -X- _ O
these -X- _ O
variants -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
this -X- _ O
as -X- _ O
input -X- _ O
into -X- _ O
a -X- _ O
transfer -X- _ O
learning -X- _ O
scenario -X- _ O
. -X- _ O
Intralanguage -X- _ O
variation -X- _ O
among -X- _ O
distinct -X- _ O
communities -X- _ O
( -X- _ O
see -X- _ O
Hildebrandt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017b -X- _ O
andother -X- _ O
articles -X- _ O
in -X- _ O
Hildebrandt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017a -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
additional -X- _ O
factor -X- _ O
that -X- _ O
can -X- _ O
negatively -X- _ O
impact -X- _ O
computer -X- _ O
- -X- _ O
assisted -X- _ O
EL -X- _ O
documentation -X- _ O
efforts -X- _ O
in -X- _ O
both -X- _ O
intra -X- _ O
- -X- _ O
and -X- _ O
intercommunity -X- _ O
contexts -X- _ O
. -X- _ O
Ćavar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
; -X- _ O
. -X- _ O
This -X- _ O
ample -X- _ O
size -X- _ O
has -X- _ O
yielded -X- _ O
lower -X- _ O
character -X- _ B-MetricName
( -X- _ O
CER -X- _ B-MetricName
) -X- _ O
and -X- _ O
word -X- _ B-MetricName
( -X- _ O
WER -X- _ B-MetricName
) -X- _ O
error -X- _ O
rates -X- _ O
than -X- _ O
would -X- _ O
usually -X- _ O
occur -X- _ O
with -X- _ O
truly -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
EL -X- _ O
documentation -X- _ O
projects -X- _ O
. -X- _ O
Amith -X- _ O
and -X- _ O
Castillo -X- _ O
García -X- _ O
recorded -X- _ O
the -X- _ O
corpus -X- _ O
at -X- _ O
a -X- _ O
48KHz -X- _ O
sampling -X- _ O
rate -X- _ O
and -X- _ O
16 -X- _ O
- -X- _ O
bits -X- _ O
( -X- _ O
usually -X- _ O
with -X- _ O
a -X- _ O
Marantz -X- _ O
PMD -X- _ O
671 -X- _ O
recorder -X- _ O
, -X- _ O
Shure -X- _ O
SM-10a -X- _ O
dynamic -X- _ O
headset -X- _ O
mics -X- _ O
, -X- _ O
and -X- _ O
separate -X- _ O
channels -X- _ O
for -X- _ O
each -X- _ O
speaker -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
entire -X- _ O
corpus -X- _ O
was -X- _ O
transcribed -X- _ O
by -X- _ O
Castillo -X- _ O
, -X- _ O
a -X- _ O
native -X- _ O
speaker -X- _ O
linguist -X- _ O
( -X- _ O
García -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
second -X- _ O
YMC -X- _ B-DatasetName
corpus -X- _ O
( -X- _ B-DatasetName
YMC -X- _ I-DatasetName
- -X- _ I-DatasetName
FB -X- _ I-DatasetName
; -X- _ O
for -X- _ O
' -X- _ O
field -X- _ O
botany -X- _ O
' -X- _ O
) -X- _ O
was -X- _ O
developed -X- _ O
during -X- _ O
ethno -X- _ O
- -X- _ O
botanical -X- _ O
fieldwork -X- _ O
. -X- _ O
Kenia -X- _ O
Velasco -X- _ O
Gutiérrez -X- _ O
( -X- _ O
a -X- _ O
Spanish -X- _ O
- -X- _ O
speaking -X- _ O
botanist -X- _ O
) -X- _ O
and -X- _ O
Esteban -X- _ O
Guadalupe -X- _ O
Sierra -X- _ O
( -X- _ O
a -X- _ O
native -X- _ O
speaker -X- _ O
from -X- _ O
Yoloxóchitl -X- _ O
) -X- _ O
led -X- _ O
105 -X- _ O
days -X- _ O
of -X- _ O
fieldwork -X- _ O
that -X- _ O
yielded -X- _ O
888 -X- _ O
distinct -X- _ O
plant -X- _ O
collections -X- _ O
. -X- _ O
A -X- _ O
total -X- _ O
of -X- _ O
584 -X- _ O
recordings -X- _ O
were -X- _ O
made -X- _ O
in -X- _ O
all -X- _ O
four -X- _ O
YM -X- _ O
communities -X- _ O
; -X- _ O
only -X- _ O
452 -X- _ O
were -X- _ O
in -X- _ O
Yoloxóchitl -X- _ O
, -X- _ O
and -X- _ O
of -X- _ O
these -X- _ O
, -X- _ O
435 -X- _ O
, -X- _ O
totaling -X- _ O
15.17 -X- _ O
hours -X- _ O
with -X- _ O
only -X- _ O
three -X- _ O
speakers -X- _ O
, -X- _ O
were -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
second -X- _ O
test -X- _ O
case -X- _ O
for -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
. -X- _ O
Recordings -X- _ O
were -X- _ O
done -X- _ O
outdoors -X- _ O
at -X- _ O
the -X- _ O
plant -X- _ O
collection -X- _ O
site -X- _ O
with -X- _ O
a -X- _ O
Zoom -X- _ O
H4n -X- _ O
handheld -X- _ O
digital -X- _ O
recorder -X- _ O
. -X- _ O
The -X- _ O
Zoom -X- _ O
H4n -X- _ O
internal -X- _ O
mic -X- _ O
was -X- _ O
used -X- _ O
; -X- _ O
recordings -X- _ O
were -X- _ O
48KHz -X- _ O
, -X- _ O
16 -X- _ O
- -X- _ O
bit -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
channel -X- _ O
with -X- _ O
one -X- _ O
speaker -X- _ O
talking -X- _ O
after -X- _ O
another -X- _ O
( -X- _ O
no -X- _ O
overlap -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
recording -X- _ O
has -X- _ O
a -X- _ O
short -X- _ O
introduction -X- _ O
by -X- _ O
Velasco -X- _ O
describing -X- _ O
, -X- _ O
in -X- _ O
Spanish -X- _ O
, -X- _ O
the -X- _ O
plant -X- _ O
being -X- _ O
collected -X- _ O
. -X- _ O
This -X- _ O
Spanish -X- _ O
section -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
factored -X- _ O
into -X- _ O
the -X- _ O
duration -X- _ O
of -X- _ O
the -X- _ O
YMC -X- _ B-DatasetName
- -X- _ I-DatasetName
FB -X- _ I-DatasetName
corpus -X- _ O
, -X- _ O
nor -X- _ O
has -X- _ O
it -X- _ O
been -X- _ O
evaluated -X- _ O
for -X- _ O
character -X- _ O
and -X- _ O
word -X- _ O
error -X- _ O
rates -X- _ O
at -X- _ O
this -X- _ O
time -X- _ O
( -X- _ O
pending -X- _ O
future -X- _ O
implementation -X- _ O
of -X- _ O
a -X- _ O
multilingual -X- _ O
model -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
processing -X- _ O
of -X- _ O
the -X- _ O
435 -X- _ O
recordings -X- _ O
falls -X- _ O
into -X- _ O
two -X- _ O
groups -X- _ O
. -X- _ O
9 -X- _ O
of -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021).• -X- _ O
178 -X- _ O
recordings -X- _ O
( -X- _ O
6.81 -X- _ O
hours -X- _ O
) -X- _ O
were -X- _ O
processed -X- _ O
by -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
, -X- _ O
then -X- _ O
corrected -X- _ O
by -X- _ O
Castillo -X- _ O
. -X- _ O
This -X- _ O
set -X- _ O
was -X- _ O
not -X- _ O
used -X- _ O
to -X- _ O
teach -X- _ O
or -X- _ O
evaluate -X- _ O
novice -X- _ O
trainee -X- _ O
transcription -X- _ O
skills -X- _ O
but -X- _ O
only -X- _ O
to -X- _ O
determine -X- _ O
CER -X- _ B-MetricName
and -X- _ O
WER -X- _ B-MetricName
for -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
with -X- _ O
the -X- _ O
YMC -X- _ B-DatasetName
- -X- _ I-DatasetName
FB -X- _ I-DatasetName
corpus -X- _ O
. -X- _ O
No -X- _ O
training -X- _ O
or -X- _ O
validation -X- _ O
sets -X- _ O
were -X- _ O
created -X- _ O
from -X- _ O
this -X- _ O
YMC -X- _ B-DatasetName
- -X- _ I-DatasetName
FB -X- _ I-DatasetName
corpus -X- _ O
, -X- _ O
which -X- _ O
for -X- _ O
this -X- _ O
present -X- _ O
paper -X- _ O
was -X- _ O
used -X- _ O
solely -X- _ O
to -X- _ O
test -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
efficiency -X- _ O
using -X- _ O
the -X- _ O
recipe -X- _ O
developed -X- _ O
from -X- _ O
YMC -X- _ B-DatasetName
- -X- _ I-DatasetName
Exp -X- _ I-DatasetName
corpus -X- _ O
. -X- _ O
CER -X- _ B-MetricName
and -X- _ O
WER -X- _ B-MetricName
scores -X- _ O
for -X- _ O
YMC -X- _ B-DatasetName
- -X- _ I-DatasetName
FB -X- _ I-DatasetName
were -X- _ O
only -X- _ O
produced -X- _ O
after -X- _ O
Castillo -X- _ O
used -X- _ O
the -X- _ O
ELAN -X- _ O
interface -X- _ O
to -X- _ O
correct -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
hypotheses -X- _ O
for -X- _ O
this -X- _ O
corpus -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
A -X- _ O
for -X- _ O
an -X- _ O
example -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
corpus -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
24 -X- _ O
narratives -X- _ O
made -X- _ O
to -X- _ O
provide -X- _ O
background -X- _ O
information -X- _ O
and -X- _ O
off -X- _ O
- -X- _ O
camera -X- _ O
voice -X- _ O
for -X- _ O
a -X- _ O
documentary -X- _ O
video -X- _ O
. -X- _ O
The -X- _ O
recordings -X- _ O
involved -X- _ O
some -X- _ O
speakers -X- _ O
not -X- _ O
represented -X- _ O
in -X- _ O
the -X- _ O
YMC -X- _ B-DatasetName
- -X- _ I-DatasetName
Exp -X- _ I-DatasetName
corpus -X- _ O
. -X- _ O
All -X- _ O
recordings -X- _ O
( -X- _ O
5.16 -X- _ O
hours -X- _ O
) -X- _ O
were -X- _ O
made -X- _ O
at -X- _ O
44.1kHz -X- _ O
, -X- _ O
16 -X- _ O
- -X- _ O
bit -X- _ O
with -X- _ O
a -X- _ O
boom -X- _ O
- -X- _ O
held -X- _ O
microphone -X- _ O
and -X- _ O
a -X- _ O
Tascam -X- _ O
portable -X- _ O
digital -X- _ O
recorder -X- _ O
in -X- _ O
a -X- _ O
hotel -X- _ O
room -X- _ O
. -X- _ O
This -X- _ O
environment -X- _ O
may -X- _ O
have -X- _ O
introduced -X- _ O
reverb -X- _ O
or -X- _ O
other -X- _ O
effects -X- _ O
that -X- _ O
might -X- _ O
have -X- _ O
negatively -X- _ O
affected -X- _ O
ASR -X- _ B-TaskName
CER -X- _ B-MetricName
and -X- _ O
WER.Accessibility -X- _ B-MetricName
: -X- _ O
All -X- _ O
three -X- _ O
corpora -X- _ O
( -X- _ O
119.32 -X- _ O
hours -X- _ O
) -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
the -X- _ O
OpenSLR -X- _ O
data -X- _ O
portal -X- _ O
( -X- _ O
Amith -X- _ O
and -X- _ O
Castillo -X- _ O
García -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
3 -X- _ O
Goals -X- _ O
and -X- _ O
challenges -X- _ O
of -X- _ O
corpora -X- _ O
- -X- _ O
based -X- _ O
endangered -X- _ O
language -X- _ O
documentation -X- _ O
The -X- _ O
oft -X- _ O
- -X- _ O
cited -X- _ O
Boasian -X- _ O
trilogy -X- _ O
of -X- _ O
grammar -X- _ O
, -X- _ O
dictionaries -X- _ O
, -X- _ O
and -X- _ O
texts -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
foundation -X- _ O
for -X- _ O
EL -X- _ O
documentation -X- _ O
. -X- _ O
Good -X- _ O
( -X- _ O
2018 -X- _ O
, -X- _ O
p. -X- _ O
14 -X- _ O
) -X- _ O
parallels -X- _ O
this -X- _ O
classic -X- _ O
conception -X- _ O
with -X- _ O
a -X- _ O
" -X- _ O
Himmelmannian -X- _ O
" -X- _ O
trilogy -X- _ O
of -X- _ O
recordings -X- _ O
, -X- _ O
metadata -X- _ O
, -X- _ O
and -X- _ O
annotations -X- _ O
( -X- _ O
see -X- _ O
Himmelmann -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
the -X- _ O
definition -X- _ O
proposed -X- _ O
here -X- _ O
, -X- _ O
EL -X- _ O
documentation -X- _ O
is -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Boasian -X- _ O
trilogy -X- _ O
of -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
corpus -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
lexicon -X- _ O
( -X- _ O
in -X- _ O
the -X- _ O
sense -X- _ O
of -X- _ O
dictionary -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
grammar -X- _ O
. -X- _ O
In -X- _ O
turn -X- _ O
, -X- _ O
each -X- _ O
element -X- _ O
in -X- _ O
the -X- _ O
trilogy -X- _ O
is -X- _ O
molded -X- _ O
by -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
expectations -X- _ O
and -X- _ O
best -X- _ O
practices -X- _ O
. -X- _ O
An -X- _ O
audio -X- _ O
corpus -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
would -X- _ O
best -X- _ O
be -X- _ O
presented -X- _ O
interlinearized -X- _ O
with -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
lines -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
transcription -X- _ O
( -X- _ O
often -X- _ O
in -X- _ O
a -X- _ O
practical -X- _ O
orthography -X- _ O
or -X- _ O
IPA -X- _ O
transcription -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
morphological -X- _ O
segmentation -X- _ O
( -X- _ O
often -X- _ O
called -X- _ O
a -X- _ O
' -X- _ O
parse -X- _ O
' -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
parallel -X- _ O
glossing -X- _ O
of -X- _ O
each -X- _ O
morpheme -X- _ O
, -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
a -X- _ O
free -X- _ O
translation -X- _ O
into -X- _ O
a -X- _ O
target -X- _ O
, -X- _ O
often -X- _ O
colonial -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
e -X- _ O
) -X- _ O
metadata -X- _ O
about -X- _ O
recording -X- _ O
conditions -X- _ O
and -X- _ O
participants -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
effectively -X- _ O
the -X- _ O
Himmelmannian -X- _ O
trilogy -X- _ O
referenced -X- _ O
by -X- _ O
Good -X- _ O
. -X- _ O
A -X- _ O
dictionary -X- _ O
should -X- _ O
contain -X- _ O
certain -X- _ O
minimum -X- _ O
fields -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
part -X- _ O
of -X- _ O
speech -X- _ O
, -X- _ O
etymology -X- _ O
, -X- _ O
illustrative -X- _ O
sentences -X- _ O
) -X- _ O
. -X- _ O
Grammatical -X- _ O
descriptions -X- _ O
( -X- _ O
books -X- _ O
and -X- _ O
articles -X- _ O
) -X- _ O
are -X- _ O
more -X- _ O
openly -X- _ O
defined -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
reference -X- _ O
vs. -X- _ O
a -X- _ O
pedagogical -X- _ O
grammar -X- _ O
) -X- _ O
and -X- _ O
may -X- _ O
treat -X- _ O
only -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
verb -X- _ O
morphology).In -X- _ O
a -X- _ O
best -X- _ O
- -X- _ O
case -X- _ O
scenario -X- _ O
, -X- _ O
these -X- _ O
three -X- _ O
elements -X- _ O
of -X- _ O
the -X- _ O
Boasian -X- _ O
trilogy -X- _ O
are -X- _ O
interdependent -X- _ O
. -X- _ O
Corpusbased -X- _ O
lexicography -X- _ O
clearly -X- _ O
requires -X- _ O
ample -X- _ O
interlinearized -X- _ O
transcriptions -X- _ O
( -X- _ O
IGT -X- _ O
) -X- _ O
of -X- _ O
natural -X- _ O
speech -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
develop -X- _ O
concordances -X- _ O
mapped -X- _ O
to -X- _ O
lemmas -X- _ O
( -X- _ O
not -X- _ O
word -X- _ O
forms -X- _ O
) -X- _ O
; -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
enrich -X- _ O
a -X- _ O
dictionary -X- _ O
by -X- _ O
finding -X- _ O
lemmas -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
that -X- _ O
are -X- _ O
absent -X- _ O
from -X- _ O
an -X- _ O
extant -X- _ O
set -X- _ O
of -X- _ O
dictionary -X- _ O
headwords -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
discover -X- _ O
patterns -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
suggestive -X- _ O
of -X- _ O
multiword -X- _ O
lemmas -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
ku -X- _ O
3 -X- _ O
-na -X- _ O
3 -X- _ O
a -X- _ O
4 -X- _ O
followed -X- _ O
by -X- _ O
i -X- _ O
3 -X- _ O
ni -X- _ O
2 -X- _ O
( -X- _ O
lit -X- _ O
. -X- _ O
, -X- _ O
' -X- _ O
darken -X- _ O
heart -X- _ O
' -X- _ O
but -X- _ O
meaning -X- _ O
' -X- _ O
to -X- _ O
faint -X- _ O
' -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
grammar -X- _ O
will -X- _ O
inform -X- _ O
decisions -X- _ O
about -X- _ O
morphological -X- _ O
segmentation -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
IGT -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
part -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
tags -X- _ O
and -X- _ O
other -X- _ O
glosses -X- _ O
. -X- _ O
And -X- _ O
a -X- _ O
grammar -X- _ O
itself -X- _ O
would -X- _ O
benefit -X- _ O
greatly -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
set -X- _ O
of -X- _ O
annotated -X- _ O
natural -X- _ O
speech -X- _ O
recordings -X- _ O
not -X- _ O
simply -X- _ O
to -X- _ O
provide -X- _ O
examples -X- _ O
of -X- _ O
particular -X- _ O
structures -X- _ O
but -X- _ O
to -X- _ O
facilitate -X- _ O
a -X- _ O
statistical -X- _ O
analysis -X- _ O
of -X- _ O
speech -X- _ O
patterns -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
for -X- _ O
YMC -X- _ B-DatasetName
, -X- _ O
the -X- _ O
relative -X- _ O
frequency -X- _ O
of -X- _ O
completive -X- _ O
verbs -X- _ O
marked -X- _ O
solely -X- _ O
by -X- _ O
tone -X- _ O
vs. -X- _ O
those -X- _ O
marked -X- _ O
by -X- _ O
the -X- _ O
prefix -X- _ O
ni -X- _ O
1 -X- _ O
- -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
integration -X- _ O
of -X- _ O
elements -X- _ O
into -X- _ O
one -X- _ O
" -X- _ O
hypertextual -X- _ O
" -X- _ O
documentation -X- _ O
effort -X- _ O
is -X- _ O
proposed -X- _ O
by -X- _ O
Musgrave -X- _ O
and -X- _ O
Thieberger -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
note -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
spontaneous -X- _ O
text -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
corpora -X- _ O
, -X- _ O
which -X- _ O
they -X- _ O
separate -X- _ O
into -X- _ O
two -X- _ O
elements -X- _ O
, -X- _ O
media -X- _ O
, -X- _ O
and -X- _ O
text -X- _ O
) -X- _ O
and -X- _ O
comment -X- _ O
that -X- _ O
" -X- _ O
all -X- _ O
examples -X- _ O
[ -X- _ O
in -X- _ O
the -X- _ O
dictionary -X- _ O
and -X- _ O
grammar -X- _ O
] -X- _ O
should -X- _ O
come -X- _ O
from -X- _ O
the -X- _ O
spontaneous -X- _ O
text -X- _ O
and -X- _ O
should -X- _ O
be -X- _ O
viewed -X- _ O
in -X- _ O
context -X- _ O
" -X- _ O
( -X- _ O
p. -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O
Musgrave -X- _ O
and -X- _ O
Thieberger -X- _ O
is -X- _ O
central -X- _ O
to -X- _ O
effective -X- _ O
endangered -X- _ O
language -X- _ O
documentation -X- _ O
based -X- _ O
on -X- _ O
natural -X- _ O
speech -X- _ O
and -X- _ O
that -X- _ O
textual -X- _ O
transcription -X- _ O
of -X- _ O
multimedia -X- _ O
recordings -X- _ O
of -X- _ O
natural -X- _ O
speech -X- _ O
is -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
the -X- _ O
foundation -X- _ O
for -X- _ O
a -X- _ O
dictionary -X- _ O
and -X- _ O
grammar -X- _ O
based -X- _ O
on -X- _ O
actual -X- _ O
language -X- _ O
use -X- _ O
. -X- _ O
End -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
end -X- _ I-TaskName
ASR -X- _ I-TaskName
is -X- _ O
used -X- _ O
to -X- _ O
rapidly -X- _ O
increase -X- _ O
corpus -X- _ O
size -X- _ O
while -X- _ O
offering -X- _ O
the -X- _ O
opportunity -X- _ O
to -X- _ O
target -X- _ O
certain -X- _ O
genres -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
expert -X- _ O
conversations -X- _ O
on -X- _ O
the -X- _ O
nomenclature -X- _ O
, -X- _ O
classification -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
of -X- _ O
local -X- _ O
flora -X- _ O
and -X- _ O
fauna -X- _ O
; -X- _ O
ritual -X- _ O
discourse -X- _ O
; -X- _ O
material -X- _ O
cultural -X- _ O
production -X- _ O
; -X- _ O
techniques -X- _ O
for -X- _ O
fishing -X- _ O
and -X- _ O
hunting -X- _ O
) -X- _ O
that -X- _ O
are -X- _ O
of -X- _ O
ethnographic -X- _ O
interest -X- _ O
but -X- _ O
are -X- _ O
often -X- _ O
insufficiently -X- _ O
covered -X- _ O
in -X- _ O
EL -X- _ O
documentation -X- _ O
projects -X- _ O
that -X- _ O
struggle -X- _ O
to -X- _ O
produce -X- _ O
large -X- _ O
and -X- _ O
varied -X- _ O
corpora -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
human -X- _ O
effortreducing -X- _ O
advances -X- _ O
in -X- _ O
ASR -X- _ B-TaskName
for -X- _ O
YMC -X- _ B-DatasetName
presented -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
such -X- _ O
extensive -X- _ O
targeted -X- _ O
recording -X- _ O
of -X- _ O
endangered -X- _ O
cultural -X- _ O
knowledge -X- _ O
can -X- _ O
now -X- _ O
easily -X- _ O
be -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
documentation -X- _ O
effort -X- _ O
. -X- _ O
The -X- _ O
present -X- _ O
paper -X- _ O
focuses -X- _ O
on -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
automatic -X- _ O
speech -X- _ O
recognition -X- _ O
using -X- _ O
the -X- _ O
ESPNet -X- _ O
toolkit -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021;Watanabe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020Watanabe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2017Watanabe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018 -X- _ O
. -X- _ O
The -X- _ O
basic -X- _ O
goal -X- _ O
is -X- _ O
simple -X- _ O
: -X- _ O
To -X- _ O
develop -X- _ O
computational -X- _ O
tools -X- _ O
that -X- _ O
reduce -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
human -X- _ O
effort -X- _ O
required -X- _ O
to -X- _ O
produce -X- _ O
accurate -X- _ O
transcriptions -X- _ O
in -X- _ O
time -X- _ O
- -X- _ O
coded -X- _ O
interlinearized -X- _ O
format -X- _ O
that -X- _ O
will -X- _ O
serve -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
potential -X- _ O
stakeholders -X- _ O
, -X- _ O
from -X- _ O
native -X- _ O
and -X- _ O
heritage -X- _ O
speakers -X- _ O
to -X- _ O
specialized -X- _ O
academics -X- _ O
in -X- _ O
institutions -X- _ O
of -X- _ O
higher -X- _ O
learning -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
present -X- _ O
and -X- _ O
future -X- _ O
generations -X- _ O
. -X- _ O
The -X- _ O
evaluation -X- _ O
metric -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
is -X- _ O
not -X- _ O
intrinsic -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
reduced -X- _ B-MetricName
CER -X- _ I-MetricName
and -X- _ O
WER -X- _ B-MetricName
) -X- _ O
but -X- _ O
rather -X- _ O
extrinsic -X- _ O
: -X- _ O
the -X- _ O
impact -X- _ B-MetricName
of -X- _ I-MetricName
ASR -X- _ I-MetricName
on -X- _ I-MetricName
the -X- _ I-MetricName
downstream -X- _ I-MetricName
task -X- _ I-MetricName
of -X- _ I-MetricName
creating -X- _ I-MetricName
a -X- _ I-MetricName
large -X- _ I-MetricName
and -X- _ I-MetricName
varied -X- _ I-MetricName
corpus -X- _ I-MetricName
of -X- _ O
Yoloxóchitl -X- _ B-DatasetName
Mixtec -X- _ I-DatasetName
. -X- _ O
ASR -X- _ B-TaskName
for -X- _ I-TaskName
endangered -X- _ I-TaskName
languages -X- _ I-TaskName
is -X- _ O
made -X- _ O
difficult -X- _ O
not -X- _ O
simply -X- _ O
because -X- _ O
of -X- _ O
limited -X- _ O
resources -X- _ O
for -X- _ O
training -X- _ O
a -X- _ O
robust -X- _ O
system -X- _ O
but -X- _ O
by -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
factors -X- _ O
briefly -X- _ O
discussed -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O
Recording -X- _ O
conditions -X- _ O
: -X- _ O
Noisy -X- _ O
environments -X- _ O
, -X- _ O
including -X- _ O
overlapping -X- _ O
speech -X- _ O
, -X- _ O
reverberation -X- _ O
in -X- _ O
indoor -X- _ O
recordings -X- _ O
, -X- _ O
natural -X- _ O
sounds -X- _ O
in -X- _ O
outdoor -X- _ O
recordings -X- _ O
, -X- _ O
less -X- _ O
than -X- _ O
optimal -X- _ O
microphone -X- _ O
placement -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
boom -X- _ O
mic -X- _ O
in -X- _ O
video -X- _ O
recordings -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
failure -X- _ O
to -X- _ O
separately -X- _ O
mike -X- _ O
speakers -X- _ O
for -X- _ O
multichannel -X- _ O
recordings -X- _ O
all -X- _ O
negatively -X- _ O
impact -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
. -X- _ O
Also -X- _ O
to -X- _ O
the -X- _ O
point -X- _ O
, -X- _ O
field -X- _ O
recordings -X- _ O
are -X- _ O
seldom -X- _ O
made -X- _ O
with -X- _ O
an -X- _ O
eye -X- _ O
to -X- _ O
seeding -X- _ O
a -X- _ O
corpus -X- _ O
in -X- _ O
ways -X- _ O
that -X- _ O
would -X- _ O
specifically -X- _ O
benefit -X- _ O
ASR -X- _ B-TaskName
results -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
recording -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
speakers -X- _ O
for -X- _ O
shorter -X- _ O
durations -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
fewer -X- _ O
speakers -X- _ O
for -X- _ O
longer -X- _ O
times -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
date -X- _ O
, -X- _ O
then -X- _ O
, -X- _ O
processing -X- _ O
a -X- _ O
corpus -X- _ O
through -X- _ O
ASR -X- _ B-TaskName
techniques -X- _ O
of -X- _ O
any -X- _ O
nature -X- _ O
( -X- _ O
HMM -X- _ O
, -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
) -X- _ O
has -X- _ O
been -X- _ O
more -X- _ O
of -X- _ O
an -X- _ O
afterthought -X- _ O
than -X- _ O
planned -X- _ O
at -X- _ O
project -X- _ O
beginning -X- _ O
. -X- _ O
Development -X- _ O
of -X- _ O
a -X- _ O
corpus -X- _ O
from -X- _ O
the -X- _ O
beginning -X- _ O
with -X- _ O
an -X- _ O
eye -X- _ O
to -X- _ O
subsequent -X- _ O
ASR -X- _ B-TaskName
potential -X- _ O
would -X- _ O
be -X- _ O
immensely -X- _ O
helpful -X- _ O
to -X- _ O
these -X- _ O
computational -X- _ O
efforts -X- _ O
. -X- _ O
It -X- _ O
could -X- _ O
, -X- _ O
perhaps -X- _ O
should -X- _ O
, -X- _ O
be -X- _ O
increasingly -X- _ O
considered -X- _ O
in -X- _ O
the -X- _ O
initial -X- _ O
project -X- _ O
design -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
just -X- _ O
as -X- _ O
funding -X- _ O
agencies -X- _ O
such -X- _ O
as -X- _ O
NSF -X- _ O
require -X- _ O
that -X- _ O
projects -X- _ O
address -X- _ O
data -X- _ O
management -X- _ O
issues -X- _ O
, -X- _ O
it -X- _ O
might -X- _ O
be -X- _ O
worth -X- _ O
considering -X- _ O
the -X- _ O
suggested -X- _ O
inclusion -X- _ O
of -X- _ O
how -X- _ O
to -X- _ O
make -X- _ O
documentation -X- _ O
materials -X- _ O
more -X- _ O
amenable -X- _ O
to -X- _ O
ASR -X- _ B-TaskName
and -X- _ O
NLP -X- _ O
processing -X- _ O
as -X- _ O
machine -X- _ O
learning -X- _ O
technologies -X- _ O
are -X- _ O
getting -X- _ O
more -X- _ O
robust -X- _ O
. -X- _ O
Colonialization -X- _ O
of -X- _ O
language -X- _ O
: -X- _ O
Endangered -X- _ O
languages -X- _ O
do -X- _ O
not -X- _ O
die -X- _ O
, -X- _ O
to -X- _ O
paraphrase -X- _ O
Dorian -X- _ O
( -X- _ O
1978 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
their -X- _ O
" -X- _ O
boots -X- _ O
on -X- _ O
. -X- _ O
" -X- _ O
Rather -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
colonialized -X- _ O
situation -X- _ O
in -X- _ O
which -X- _ O
most -X- _ O
ELs -X- _ O
are -X- _ O
immersed -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
multiple -X- _ O
phonological -X- _ O
, -X- _ O
morphological -X- _ O
, -X- _ O
and -X- _ O
syntactic -X- _ O
influences -X- _ O
from -X- _ O
a -X- _ O
dominant -X- _ O
language -X- _ O
. -X- _ O
The -X- _ O
incidence -X- _ O
of -X- _ O
a -X- _ O
colonial -X- _ O
language -X- _ O
in -X- _ O
native -X- _ O
language -X- _ O
recordings -X- _ O
runs -X- _ O
a -X- _ O
gamut -X- _ O
from -X- _ O
multilanguage -X- _ O
situations -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
each -X- _ O
speaker -X- _ O
using -X- _ O
a -X- _ O
distinct -X- _ O
language -X- _ O
, -X- _ O
as -X- _ O
often -X- _ O
occurs -X- _ O
in -X- _ O
elicitation -X- _ O
sessions -X- _ O
: -X- _ O
' -X- _ O
How -X- _ O
would -X- _ O
you -X- _ O
translate -X- _ O
_ -X- _ O
_ -X- _ O
_ -X- _ O
into -X- _ O
Mixtec -X- _ O
? -X- _ O
' -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
code -X- _ O
- -X- _ O
switching -X- _ O
and -X- _ O
borrowing -X- _ O
or -X- _ O
relexification -X- _ O
in -X- _ O
the -X- _ O
speech -X- _ O
of -X- _ O
single -X- _ O
individuals -X- _ O
. -X- _ O
In -X- _ O
some -X- _ O
languages -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Nahuatl -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
may -X- _ O
easily -X- _ O
combine -X- _ O
stems -X- _ O
from -X- _ O
both -X- _ O
native -X- _ O
and -X- _ O
colonial -X- _ O
languages -X- _ O
. -X- _ O
Preliminary -X- _ O
, -X- _ O
though -X- _ O
not -X- _ O
quantified -X- _ O
, -X- _ O
CER -X- _ O
analysis -X- _ O
for -X- _ O
YMC -X- _ B-DatasetName
ASR -X- _ B-TaskName
suggests -X- _ O
that -X- _ O
" -X- _ O
Spanish -X- _ O
- -X- _ O
origin -X- _ O
" -X- _ O
words -X- _ O
provoke -X- _ O
a -X- _ O
significantly -X- _ O
higher -X- _ O
error -X- _ O
rate -X- _ O
than -X- _ O
the -X- _ O
YMC -X- _ B-DatasetName
lexicon -X- _ O
uninfluenced -X- _ O
by -X- _ O
Spanish -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
not -X- _ O
clear -X- _ O
that -X- _ O
a -X- _ O
multilingual -X- _ O
phone -X- _ O
recognition -X- _ O
system -X- _ O
is -X- _ O
the -X- _ O
solution -X- _ O
to -X- _ O
character -X- _ O
errors -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
ASR -X- _ O
hypothesis -X- _ O
' -X- _ O
cereso -X- _ O
' -X- _ O
for -X- _ O
Spanish -X- _ O
' -X- _ O
cerezo -X- _ O
' -X- _ O
) -X- _ O
that -X- _ O
may -X- _ O
derive -X- _ O
from -X- _ O
an -X- _ O
orthographic -X- _ O
system -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
that -X- _ O
for -X- _ O
Spanish -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
not -X- _ O
designed -X- _ O
, -X- _ O
as -X- _ O
many -X- _ O
EL -X- _ O
orthographies -X- _ O
are -X- _ O
, -X- _ O
for -X- _ O
consistency -X- _ O
. -X- _ O
Phonological -X- _ O
shifts -X- _ O
in -X- _ O
borrowed -X- _ O
terms -X- _ O
also -X- _ O
preclude -X- _ O
the -X- _ O
simple -X- _ O
application -X- _ O
of -X- _ O
lexical -X- _ O
tools -X- _ O
to -X- _ O
correct -X- _ O
misspellings -X- _ O
( -X- _ O
as -X- _ O
' -X- _ O
agustu -X- _ O
' -X- _ O
for -X- _ O
the -X- _ O
Spanish -X- _ O
month -X- _ O
' -X- _ O
agosto').Orthographic -X- _ O
conventions -X- _ O
: -X- _ O
The -X- _ O
practical -X- _ O
deep -X- _ O
orthography -X- _ O
developed -X- _ O
by -X- _ O
Amith -X- _ O
and -X- _ O
Castillo -X- _ O
marks -X- _ O
off -X- _ O
boundaries -X- _ O
of -X- _ O
affixes -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
hyphen -X- _ O
) -X- _ O
and -X- _ O
clitics -X- _ O
( -X- _ O
with -X- _ O
an -X- _ O
= -X- _ O
sign -X- _ O
) -X- _ O
. -X- _ O
Tones -X- _ O
are -X- _ O
indicated -X- _ O
by -X- _ O
superscript -X- _ O
numbers -X- _ O
, -X- _ O
from -X- _ O
1 -X- _ O
low -X- _ O
to -X- _ O
4 -X- _ O
high -X- _ O
, -X- _ O
with -X- _ O
five -X- _ O
common -X- _ O
rising -X- _ O
and -X- _ O
falling -X- _ O
tones -X- _ O
. -X- _ O
Stem -X- _ O
- -X- _ O
final -X- _ O
elided -X- _ O
tones -X- _ O
are -X- _ O
enclosed -X- _ O
in -X- _ O
parentheses -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
underlying -X- _ O
form -X- _ O
be -X- _ O
' -X- _ O
3 -X- _ O
e -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
2 -X- _ O
; -X- _ O
house=1sgPoss -X- _ O
, -X- _ O
' -X- _ O
my -X- _ O
house -X- _ O
' -X- _ O
; -X- _ O
surface -X- _ O
form -X- _ O
be -X- _ O
' -X- _ O
3 -X- _ O
e -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
Tone -X- _ O
- -X- _ O
based -X- _ O
inflectional -X- _ O
morphology -X- _ O
is -X- _ O
not -X- _ O
separated -X- _ O
in -X- _ O
any -X- _ O
YMC -X- _ B-DatasetName
transcriptions -X- _ O
. -X- _ O
2 -X- _ O
The -X- _ O
transcription -X- _ O
strategy -X- _ O
for -X- _ O
YMC -X- _ B-DatasetName
was -X- _ O
unusual -X- _ O
in -X- _ O
that -X- _ O
the -X- _ O
practical -X- _ O
orthography -X- _ O
was -X- _ O
a -X- _ O
deep -X- _ O
, -X- _ O
underlying -X- _ O
system -X- _ O
that -X- _ O
represented -X- _ O
segmental -X- _ O
morpheme -X- _ O
boundaries -X- _ O
and -X- _ O
showed -X- _ O
elided -X- _ O
tones -X- _ O
in -X- _ O
parentheses -X- _ O
. -X- _ O
The -X- _ O
original -X- _ O
plans -X- _ O
of -X- _ O
Amith -X- _ O
and -X- _ O
Castillo -X- _ O
were -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
transcribed -X- _ O
audio -X- _ O
as -X- _ O
primary -X- _ O
data -X- _ O
for -X- _ O
a -X- _ O
corpus -X- _ O
- -X- _ O
based -X- _ O
dictionary -X- _ O
. -X- _ O
A -X- _ O
deep -X- _ O
orthography -X- _ O
facilitates -X- _ O
discovery -X- _ O
( -X- _ O
without -X- _ O
recourse -X- _ O
to -X- _ O
a -X- _ O
morphological -X- _ O
analyzer -X- _ O
) -X- _ O
of -X- _ O
lemmas -X- _ O
that -X- _ O
may -X- _ O
be -X- _ O
altered -X- _ O
in -X- _ O
surface -X- _ O
pronunciations -X- _ O
by -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
personmarking -X- _ O
enclitics -X- _ O
and -X- _ O
certain -X- _ O
common -X- _ O
verbal -X- _ O
prefixes -X- _ O
( -X- _ O
see -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
, -X- _ O
§ -X- _ O
2.3).Only -X- _ O
after -X- _ O
documentation -X- _ O
( -X- _ O
recording -X- _ O
and -X- _ O
timecoded -X- _ O
transcriptions -X- _ O
) -X- _ O
was -X- _ O
well -X- _ O
advanced -X- _ O
did -X- _ O
work -X- _ O
begin -X- _ O
on -X- _ O
a -X- _ O
finite -X- _ O
state -X- _ O
transducer -X- _ O
for -X- _ O
the -X- _ O
YMC -X- _ B-DatasetName
corpus -X- _ O
. -X- _ O
this -X- _ O
was -X- _ O
made -X- _ O
possible -X- _ O
by -X- _ O
collaboration -X- _ O
with -X- _ O
another -X- _ O
NSF -X- _ O
- -X- _ O
DEL -X- _ O
sponsored -X- _ O
project -X- _ O
. -X- _ O
3 -X- _ O
The -X- _ O
code -X- _ O
was -X- _ O
written -X- _ O
by -X- _ O
Jason -X- _ O
Lilley -X- _ O
in -X- _ O
consultation -X- _ O
with -X- _ O
Amith -X- _ O
and -X- _ O
Castillo -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
FOMA -X- _ O
FST -X- _ O
was -X- _ O
being -X- _ O
built -X- _ O
, -X- _ O
FST -X- _ O
output -X- _ O
was -X- _ O
repeatedly -X- _ O
checked -X- _ O
against -X- _ O
expectations -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
morphological -X- _ O
grammar -X- _ O
until -X- _ O
no -X- _ O
discrepancies -X- _ O
were -X- _ O
noted -X- _ O
. -X- _ O
The -X- _ O
FST -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
only -X- _ O
generates -X- _ O
surface -X- _ O
forms -X- _ O
consistent -X- _ O
with -X- _ O
Castillo -X- _ O
's -X- _ O
grammar -X- _ O
. -X- _ O
If -X- _ O
speakers -X- _ O
varied -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
extent -X- _ O
of -X- _ O
vowel -X- _ O
harmonization -X- _ O
or -X- _ O
regressive -X- _ O
nasalization -X- _ O
, -X- _ O
the -X- _ O
FST -X- _ O
would -X- _ O
yield -X- _ O
only -X- _ O
one -X- _ O
surface -X- _ O
form -X- _ O
, -X- _ O
that -X- _ O
suggested -X- _ O
by -X- _ O
Castillo -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
most -X- _ O
common -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
underlying -X- _ O
be -X- _ O
3 -X- _ O
e -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
an -X- _ O
4 -X- _ O
( -X- _ O
house=3sgFem -X- _ O
; -X- _ O
' -X- _ O
her -X- _ O
house -X- _ O
' -X- _ O
) -X- _ O
surfaces -X- _ O
as -X- _ O
be -X- _ O
3ã4 -X- _ O
even -X- _ O
though -X- _ O
for -X- _ O
some -X- _ O
speakers -X- _ O
nasalization -X- _ O
spreads -X- _ O
to -X- _ O
the -X- _ O
stem -X- _ O
initial -X- _ O
vowel -X- _ O
. -X- _ O
Note -X- _ O
, -X- _ O
then -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
surface -X- _ O
forms -X- _ O
in -X- _ O
the -X- _ O
YMC -X- _ B-DatasetName
- -X- _ I-DatasetName
Exp -X- _ I-DatasetName
corpus -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
FST -X- _ O
generation -X- _ O
from -X- _ O
an -X- _ O
underlying -X- _ O
transcription -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
not -X- _ O
from -X- _ O
the -X- _ O
direct -X- _ O
transcription -X- _ O
of -X- _ O
the -X- _ O
acoustic -X- _ O
signal -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
occasionally -X- _ O
the -X- _ O
case -X- _ O
that -X- _ O
different -X- _ O
speakers -X- _ O
might -X- _ O
extend -X- _ O
vowel -X- _ O
harmonization -X- _ O
or -X- _ O
nasalization -X- _ O
leftward -X- _ O
to -X- _ O
different -X- _ O
degrees -X- _ O
. -X- _ O
This -X- _ O
could -X- _ O
increase -X- _ O
the -X- _ O
CER -X- _ B-MetricName
and -X- _ O
WER -X- _ B-MetricName
for -X- _ O
ASR -X- _ B-TaskName
of -X- _ O
surface -X- _ O
forms -X- _ O
, -X- _ O
given -X- _ O
that -X- _ O
the -X- _ O
reference -X- _ O
for -X- _ O
evaluation -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
acoustic -X- _ O
signal -X- _ O
while -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
hypothesis -X- _ O
is -X- _ O
so -X- _ O
derived -X- _ O
. -X- _ O
In -X- _ O
an -X- _ O
evaluation -X- _ O
across -X- _ O
the -X- _ O
YMC -X- _ B-DatasetName
- -X- _ I-DatasetName
Exp -X- _ I-DatasetName
development -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
( -X- _ O
total -X- _ O
6.53 -X- _ O
hours -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
relative -X- _ O
accuracy -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
when -X- _ O
using -X- _ O
underlying -X- _ O
versus -X- _ O
surface -X- _ O
orthography -X- _ O
, -X- _ O
it -X- _ O
was -X- _ O
found -X- _ O
that -X- _ O
training -X- _ O
on -X- _ O
underlying -X- _ O
orthography -X- _ O
produced -X- _ O
slightly -X- _ O
greater -X- _ O
accuracy -X- _ O
than -X- _ O
training -X- _ O
on -X- _ O
surface -X- _ O
forms -X- _ O
: -X- _ O
Underlying -X- _ O
= -X- _ O
7.7/16.0 -X- _ B-MetricValue
[ -X- _ O
CER -X- _ B-MetricName
/ -X- _ O
WER -X- _ B-MetricName
] -X- _ O
compared -X- _ O
to -X- _ O
Surface -X- _ O
= -X- _ O
7.8/16.5 -X- _ B-MetricValue
[ -X- _ O
CER -X- _ B-MetricName
/ -X- _ O
WER -X- _ B-MetricName
] -X- _ O
( -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
, -X- _ O
see -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
decision -X- _ O
to -X- _ O
use -X- _ O
underlying -X- _ O
representations -X- _ O
in -X- _ O
ASR -X- _ B-TaskName
training -X- _ O
has -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
several -X- _ O
more -X- _ O
important -X- _ O
advantages -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
for -X- _ O
native -X- _ O
speakers -X- _ O
, -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
learning -X- _ O
a -X- _ O
deep -X- _ O
practical -X- _ O
orthography -X- _ O
means -X- _ O
that -X- _ O
one -X- _ O
learns -X- _ O
segmental -X- _ O
morphology -X- _ O
as -X- _ O
one -X- _ O
learns -X- _ O
to -X- _ O
write -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
purposes -X- _ O
of -X- _ O
YMC -X- _ O
language -X- _ O
documentation -X- _ O
, -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
a -X- _ O
neural -X- _ O
network -X- _ O
to -X- _ O
directly -X- _ O
learn -X- _ O
segmental -X- _ O
morphology -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
ASR -X- _ O
training -X- _ O
has -X- _ O
resulted -X- _ O
in -X- _ O
a -X- _ O
YMC -X- _ O
ASR -X- _ O
output -X- _ O
across -X- _ O
all -X- _ O
three -X- _ O
corpora -X- _ O
with -X- _ O
affixes -X- _ O
and -X- _ O
clitics -X- _ O
separated -X- _ O
and -X- _ O
stem -X- _ O
- -X- _ O
final -X- _ O
elided -X- _ O
tones -X- _ O
marked -X- _ O
in -X- _ O
parentheses -X- _ O
. -X- _ O
Semi -X- _ O
- -X- _ O
or -X- _ O
un -X- _ O
- -X- _ O
supervised -X- _ O
morphological -X- _ O
learning -X- _ O
as -X- _ O
a -X- _ O
separate -X- _ O
NLP -X- _ O
task -X- _ O
is -X- _ O
unnecessary -X- _ O
when -X- _ O
ASR -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
was -X- _ O
successfully -X- _ O
carried -X- _ O
out -X- _ O
on -X- _ O
a -X- _ O
corpus -X- _ O
with -X- _ O
basic -X- _ O
morphological -X- _ O
segmentation -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
example -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
demonstrates -X- _ O
, -X- _ O
ASR -X- _ O
output -X- _ O
includes -X- _ O
basic -X- _ O
segmentation -X- _ O
at -X- _ O
the -X- _ O
morphological -X- _ O
level -X- _ O
. -X- _ O
3.3 -X- _ O
Intrinsic -X- _ O
metrics -X- _ O
: -X- _ O
CER -X- _ B-MetricName
, -X- _ O
WER -X- _ B-MetricName
, -X- _ O
and -X- _ O
consistency -X- _ B-MetricName
in -X- _ I-MetricName
transcriptions -X- _ I-MetricName
used -X- _ I-MetricName
as -X- _ I-MetricName
reference -X- _ I-MetricName
: -X- _ O
Although -X- _ O
both -X- _ O
CER -X- _ B-MetricName
and -X- _ O
WER -X- _ B-MetricName
reference -X- _ O
" -X- _ O
error -X- _ O
rate -X- _ O
" -X- _ O
in -X- _ O
regards -X- _ O
to -X- _ O
character -X- _ O
and -X- _ O
word -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
the -X- _ O
question -X- _ O
of -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
reference -X- _ O
itself -X- _ O
is -X- _ O
rarely -X- _ O
explored -X- _ O
( -X- _ O
but -X- _ O
cf -X- _ O
. -X- _ O
Saon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
YMC -X- _ B-DatasetName
, -X- _ O
only -X- _ O
one -X- _ O
speaker -X- _ O
, -X- _ O
Castillo -X- _ O
García -X- _ O
, -X- _ O
is -X- _ O
capable -X- _ O
of -X- _ O
accurate -X- _ O
transcription -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
YMC -X- _ B-DatasetName
is -X- _ O
the -X- _ O
sole -X- _ O
gold -X- _ O
standard -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
training -X- _ O
, -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
testing -X- _ O
. -X- _ O
Thus -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
consistency -X- _ O
to -X- _ O
the -X- _ O
transcription -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
reference -X- _ O
. -X- _ O
In -X- _ O
comparison -X- _ O
, -X- _ O
for -X- _ O
Highland -X- _ O
Puebla -X- _ O
Nahuat -X- _ O
( -X- _ O
another -X- _ O
language -X- _ O
that -X- _ O
the -X- _ O
present -X- _ O
team -X- _ O
is -X- _ O
exploring -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
situation -X- _ O
is -X- _ O
distinct -X- _ O
. -X- _ O
Three -X- _ O
native -X- _ O
speaker -X- _ O
experts -X- _ O
have -X- _ O
worked -X- _ O
with -X- _ O
Amith -X- _ O
on -X- _ O
transcription -X- _ O
for -X- _ O
over -X- _ O
six -X- _ O
years -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
reference -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
development -X- _ O
are -X- _ O
native -X- _ O
- -X- _ O
speaker -X- _ O
transcriptions -X- _ O
carefully -X- _ O
proofed -X- _ O
by -X- _ O
Amith -X- _ O
, -X- _ O
a -X- _ O
process -X- _ O
that -X- _ O
both -X- _ O
corrected -X- _ O
simple -X- _ O
errors -X- _ O
and -X- _ O
applied -X- _ O
a -X- _ O
single -X- _ O
standard -X- _ O
implemented -X- _ O
by -X- _ O
one -X- _ O
researcher -X- _ O
. -X- _ O
When -X- _ O
all -X- _ O
three -X- _ O
native -X- _ O
speaker -X- _ O
experts -X- _ O
were -X- _ O
asked -X- _ O
to -X- _ O
transcribe -X- _ O
the -X- _ O
same -X- _ O
90 -X- _ O
minutes -X- _ O
or -X- _ O
recordings -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
were -X- _ O
compared -X- _ O
, -X- _ O
there -X- _ O
was -X- _ O
not -X- _ O
an -X- _ O
insignificant -X- _ O
level -X- _ O
of -X- _ O
variation -X- _ O
( -X- _ O
9%).The -X- _ O
aforementioned -X- _ O
scenario -X- _ O
suggests -X- _ O
the -X- _ O
impact -X- _ O
on -X- _ O
ASR -X- _ O
intrinsic -X- _ O
metrics -X- _ O
of -X- _ O
variation -X- _ O
in -X- _ O
transcriptions -X- _ O
across -X- _ O
multiple -X- _ O
annotators -X- _ O
, -X- _ O
or -X- _ O
even -X- _ O
inconsistencies -X- _ O
of -X- _ O
one -X- _ O
skilled -X- _ O
annotator -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
incipient -X- _ O
writing -X- _ O
systems -X- _ O
. -X- _ O
This -X- _ O
affects -X- _ O
not -X- _ O
only -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
but -X- _ O
also -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
accuracy -X- _ O
via -X- _ O
character -X- _ B-MetricName
and -X- _ O
word -X- _ B-MetricName
error -X- _ I-MetricName
rates -X- _ I-MetricName
. -X- _ O
It -X- _ O
may -X- _ O
be -X- _ O
that -X- _ O
rather -X- _ O
than -X- _ O
character -X- _ B-MetricName
and -X- _ O
word -X- _ B-MetricName
error -X- _ I-MetricName
rate -X- _ I-MetricName
, -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
advisable -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
character -X- _ O
and -X- _ O
word -X- _ O
discrepancy -X- _ O
rate -X- _ O
a -X- _ O
change -X- _ O
in -X- _ O
terminology -X- _ O
that -X- _ O
perhaps -X- _ O
better -X- _ O
communicates -X- _ O
the -X- _ O
idea -X- _ O
that -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
REF -X- _ O
and -X- _ O
HYP -X- _ O
are -X- _ O
often -X- _ O
as -X- _ O
much -X- _ O
a -X- _ O
matter -X- _ O
of -X- _ O
opinion -X- _ O
as -X- _ O
fact -X- _ O
. -X- _ O
The -X- _ O
nature -X- _ O
and -X- _ O
value -X- _ O
of -X- _ O
utilizing -X- _ O
intrinsic -X- _ O
metrics -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
CER -X- _ B-MetricName
and -X- _ O
WER -X- _ B-MetricName
) -X- _ O
for -X- _ O
evaluating -X- _ O
ASR -X- _ B-TaskName
effectiveness -X- _ I-TaskName
for -X- _ I-TaskName
endangered -X- _ I-TaskName
language -X- _ I-TaskName
documentation -X- _ I-TaskName
merits -X- _ O
rethinking -X- _ O
. -X- _ O
An -X- _ O
additional -X- _ O
factor -X- _ O
that -X- _ O
has -X- _ O
emerged -X- _ O
in -X- _ O
the -X- _ O
YMC -X- _ B-DatasetName
corpora -X- _ I-DatasetName
, -X- _ O
which -X- _ O
contains -X- _ O
very -X- _ O
rapid -X- _ O
speech -X- _ O
, -X- _ O
is -X- _ O
what -X- _ O
may -X- _ O
be -X- _ O
called -X- _ O
" -X- _ O
hypercorrection -X- _ O
" -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
not -X- _ O
uncommon -X- _ O
and -X- _ O
may -X- _ O
occur -X- _ O
with -X- _ O
lenited -X- _ O
forms -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
writing -X- _ O
ndi -X- _ O
1 -X- _ O
ku -X- _ O
4 -X- _ O
chi -X- _ O
4 -X- _ O
when -X- _ O
close -X- _ O
examination -X- _ O
of -X- _ O
the -X- _ O
acoustic -X- _ O
signal -X- _ O
reveals -X- _ O
that -X- _ O
the -X- _ O
speaker -X- _ O
used -X- _ O
the -X- _ O
fully -X- _ O
acceptable -X- _ O
lenited -X- _ O
form -X- _ O
ndiu -X- _ O
14 -X- _ O
chi -X- _ O
4 -X- _ O
) -X- _ O
or -X- _ O
when -X- _ O
certain -X- _ O
function -X- _ O
words -X- _ O
are -X- _ O
reduced -X- _ O
, -X- _ O
at -X- _ O
times -X- _ O
effectively -X- _ O
disappearing -X- _ O
from -X- _ O
the -X- _ O
acoustic -X- _ O
signal -X- _ O
though -X- _ O
not -X- _ O
from -X- _ O
the -X- _ O
mind -X- _ O
of -X- _ O
a -X- _ O
fluent -X- _ O
speaker -X- _ O
transcriber -X- _ O
. -X- _ O
In -X- _ O
both -X- _ O
cases -X- _ O
, -X- _ O
ASR -X- _ B-TaskName
" -X- _ O
errors -X- _ O
" -X- _ O
might -X- _ O
represent -X- _ O
a -X- _ O
more -X- _ O
accurate -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
acoustic -X- _ O
signal -X- _ O
than -X- _ O
the -X- _ O
transcription -X- _ O
of -X- _ O
even -X- _ O
the -X- _ O
most -X- _ O
highly -X- _ O
capable -X- _ O
native -X- _ O
speakers -X- _ O
. -X- _ O
The -X- _ O
above -X- _ O
discussion -X- _ O
also -X- _ O
brings -X- _ O
into -X- _ O
question -X- _ O
what -X- _ O
it -X- _ O
means -X- _ O
to -X- _ O
achieve -X- _ O
human -X- _ O
parity -X- _ O
via -X- _ O
an -X- _ O
ASR -X- _ O
system -X- _ O
. -X- _ O
Parity -X- _ O
could -X- _ O
perhaps -X- _ O
best -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
not -X- _ O
based -X- _ O
on -X- _ O
CER -X- _ B-MetricName
and -X- _ O
WER -X- _ B-MetricName
alone -X- _ O
but -X- _ O
on -X- _ O
whether -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
achieves -X- _ O
a -X- _ O
lower -X- _ O
error -X- _ O
rate -X- _ O
in -X- _ O
these -X- _ O
two -X- _ O
measurements -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
what -X- _ O
another -X- _ O
skilled -X- _ O
human -X- _ O
transcriber -X- _ O
might -X- _ O
achieve -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
EL -X- _ O
documentation -X- _ O
, -X- _ O
which -X- _ O
requires -X- _ O
high -X- _ O
levels -X- _ O
of -X- _ O
accuracy -X- _ O
if -X- _ O
the -X- _ O
corpus -X- _ O
is -X- _ O
to -X- _ O
be -X- _ O
easily -X- _ O
used -X- _ O
for -X- _ O
future -X- _ O
linguistic -X- _ O
research -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
essential -X- _ O
that -X- _ O
ASR -X- _ B-TaskName
- -X- _ O
generated -X- _ O
hypotheses -X- _ O
be -X- _ O
reviewed -X- _ O
by -X- _ O
an -X- _ O
expert -X- _ O
human -X- _ O
annotator -X- _ O
before -X- _ O
permanent -X- _ O
archiving -X- _ O
. -X- _ O
Certainly -X- _ O
, -X- _ O
audio -X- _ O
can -X- _ O
be -X- _ O
archived -X- _ O
with -X- _ O
metadata -X- _ O
alone -X- _ O
or -X- _ O
with -X- _ O
unchecked -X- _ O
ASR -X- _ B-TaskName
transcriptions -X- _ O
( -X- _ O
see -X- _ O
Michaud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
§ -X- _ O
4.3 -X- _ O
and -X- _ O
4.4 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
workflow -X- _ O
envisioned -X- _ O
for -X- _ O
YMC -X- _ B-DatasetName
is -X- _ O
to -X- _ O
use -X- _ O
ASR -X- _ O
to -X- _ O
reduce -X- _ O
human -X- _ O
effort -X- _ O
while -X- _ O
the -X- _ O
archived -X- _ O
corpus -X- _ O
of -X- _ O
audio -X- _ O
and -X- _ O
text -X- _ O
maintains -X- _ O
results -X- _ O
equivalent -X- _ O
to -X- _ O
those -X- _ O
that -X- _ O
would -X- _ O
be -X- _ O
obtained -X- _ O
by -X- _ O
careful -X- _ O
, -X- _ O
and -X- _ O
laborintensive -X- _ O
, -X- _ O
expert -X- _ O
transcription -X- _ O
. -X- _ O
CER -X- _ B-MetricName
and -X- _ O
WER -X- _ B-MetricName
were -X- _ O
measured -X- _ O
for -X- _ O
YMC -X- _ B-DatasetName
corpora -X- _ O
with -X- _ O
training -X- _ O
sets -X- _ O
of -X- _ O
10 -X- _ O
, -X- _ O
20 -X- _ O
, -X- _ O
50 -X- _ O
, -X- _ O
and -X- _ O
92 -X- _ O
hours -X- _ O
. -X- _ O
The -X- _ O
CER -X- _ O
/ -X- _ O
WER -X- _ O
were -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
19.5/39.2 -X- _ O
( -X- _ O
10 -X- _ O
hrs -X- _ O
. -X- _ O
) -X- _ O
, -X- _ O
12.7/26.2 -X- _ O
( -X- _ O
20 -X- _ O
hrs -X- _ O
. -X- _ O
) -X- _ O
, -X- _ O
10.2/24.9 -X- _ O
( -X- _ O
50 -X- _ O
hrs -X- _ O
. -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
7.7/16.1 -X- _ O
( -X- _ O
92 -X- _ O
hrs -X- _ O
. -X- _ O
) -X- _ O
; -X- _ O
Table -X- _ O
5 -X- _ O
in -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Measurement -X- _ O
of -X- _ O
human -X- _ O
effort -X- _ O
reduction -X- _ O
suggests -X- _ O
that -X- _ O
with -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
30 -X- _ O
- -X- _ O
50 -X- _ O
hours -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
a -X- _ O
relatively -X- _ O
challenging -X- _ O
language -X- _ O
such -X- _ O
as -X- _ O
YMC -X- _ B-DatasetName
, -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
can -X- _ O
achieve -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
accuracy -X- _ O
that -X- _ O
allows -X- _ O
a -X- _ O
reduction -X- _ O
of -X- _ O
human -X- _ O
effort -X- _ O
by -X- _ O
> -X- _ O
75 -X- _ O
percent -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
from -X- _ O
40 -X- _ O
to -X- _ O
10 -X- _ O
hours -X- _ O
, -X- _ O
approximately -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
totals -X- _ O
are -X- _ O
derived -X- _ O
from -X- _ O
measurements -X- _ O
with -X- _ O
the -X- _ O
FB -X- _ O
and -X- _ O
VN -X- _ O
corpora -X- _ O
, -X- _ O
the -X- _ O
two -X- _ O
corpora -X- _ O
for -X- _ O
which -X- _ O
ASR -X- _ B-TaskName
provided -X- _ O
the -X- _ O
initial -X- _ O
transcription -X- _ O
, -X- _ O
and -X- _ O
Castillo -X- _ O
subsequently -X- _ O
corrected -X- _ O
the -X- _ O
output -X- _ O
, -X- _ O
keeping -X- _ O
track -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
he -X- _ O
spent -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
first -X- _ O
corpus -X- _ O
, -X- _ O
Castillo -X- _ O
required -X- _ O
58.20 -X- _ O
hours -X- _ O
to -X- _ O
correct -X- _ O
6.65 -X- _ O
hours -X- _ O
of -X- _ O
audio -X- _ O
( -X- _ O
from -X- _ O
173 -X- _ O
of -X- _ O
the -X- _ O
178 -X- _ O
files -X- _ O
that -X- _ O
had -X- _ O
not -X- _ O
been -X- _ O
first -X- _ O
transcribed -X- _ O
by -X- _ O
a -X- _ O
speaker -X- _ O
trainee -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
yields -X- _ O
8.76 -X- _ O
hours -X- _ O
of -X- _ O
effort -X- _ O
per -X- _ O
hour -X- _ O
of -X- _ O
recording -X- _ O
. -X- _ O
The -X- _ O
5.16 -X- _ O
hours -X- _ O
( -X- _ O
in -X- _ O
24 -X- _ O
files -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
VN -X- _ O
corpus -X- _ O
required -X- _ O
53.07 -X- _ O
hours -X- _ O
to -X- _ O
correct -X- _ O
, -X- _ O
a -X- _ O
ratio -X- _ O
of -X- _ O
10.28 -X- _ O
hours -X- _ O
of -X- _ O
effort -X- _ O
to -X- _ O
finalize -X- _ O
1 -X- _ O
hour -X- _ O
of -X- _ O
speech -X- _ O
. -X- _ O
Over -X- _ O
the -X- _ O
entire -X- _ O
set -X- _ O
of -X- _ O
197 -X- _ O
files -X- _ O
( -X- _ O
11.81 -X- _ O
hours -X- _ O
) -X- _ O
, -X- _ O
human -X- _ O
effort -X- _ O
was -X- _ O
111.27 -X- _ O
hours -X- _ O
, -X- _ O
or -X- _ O
9.42 -X- _ O
hours -X- _ O
to -X- _ O
correct -X- _ O
1 -X- _ O
hour -X- _ O
of -X- _ O
audio -X- _ O
. -X- _ O
Given -X- _ O
that -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
system -X- _ I-TaskName
was -X- _ O
trained -X- _ O
on -X- _ O
an -X- _ O
underlying -X- _ O
orthography -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
result -X- _ O
of -X- _ O
< -X- _ O
10 -X- _ O
hours -X- _ O
of -X- _ O
human -X- _ O
effort -X- _ O
per -X- _ O
hour -X- _ O
of -X- _ O
audio -X- _ O
is -X- _ O
a -X- _ O
transcribed -X- _ O
and -X- _ O
partially -X- _ O
parsed -X- _ O
corpus -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
presents -X- _ O
an -X- _ O
analysis -X- _ O
of -X- _ O
two -X- _ O
lines -X- _ O
of -X- _ O
a -X- _ O
recording -X- _ O
that -X- _ O
was -X- _ O
first -X- _ O
processed -X- _ O
by -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
and -X- _ O
corrected -X- _ O
by -X- _ O
Castillo -X- _ O
García -X- _ O
. -X- _ O
A -X- _ O
fuller -X- _ O
presentation -X- _ O
and -X- _ O
analysis -X- _ O
are -X- _ O
offered -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O
This -X- _ O
focus -X- _ O
on -X- _ O
extrinsic -X- _ O
metrics -X- _ O
reflects -X- _ O
the -X- _ O
realization -X- _ O
that -X- _ O
the -X- _ O
ultimate -X- _ O
goal -X- _ O
of -X- _ O
computational -X- _ O
systems -X- _ O
is -X- _ O
not -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
lowest -X- _ O
CER -X- _ B-MetricName
and -X- _ O
WER -X- _ B-MetricName
but -X- _ O
to -X- _ O
help -X- _ O
documentation -X- _ O
initiatives -X- _ O
more -X- _ O
efficiently -X- _ O
produce -X- _ O
results -X- _ O
that -X- _ O
will -X- _ O
benefit -X- _ O
future -X- _ O
stakeholders -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
has -X- _ O
reached -X- _ O
comparable -X- _ O
or -X- _ O
better -X- _ O
performances -X- _ O
than -X- _ O
conventional -X- _ O
Hidden -X- _ B-MethodName
- -X- _ I-MethodName
Markov -X- _ I-MethodName
- -X- _ I-MethodName
Model -X- _ I-MethodName
- -X- _ O
based -X- _ O
ASR -X- _ B-TaskName
( -X- _ O
Graves -X- _ O
and -X- _ O
Jaitly -X- _ O
, -X- _ O
2014;Chiu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Karita -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a;Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
practice -X- _ O
, -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
systems -X- _ I-TaskName
are -X- _ O
less -X- _ O
affected -X- _ O
by -X- _ O
linguistic -X- _ O
constraints -X- _ O
and -X- _ O
are -X- _ O
generally -X- _ O
easier -X- _ O
to -X- _ O
train -X- _ O
. -X- _ O
The -X- _ O
benefits -X- _ O
of -X- _ O
such -X- _ O
systems -X- _ O
are -X- _ O
reflected -X- _ O
in -X- _ O
the -X- _ O
recent -X- _ O
trends -X- _ O
of -X- _ O
using -X- _ O
end -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
end -X- _ I-TaskName
ASR -X- _ I-TaskName
for -X- _ O
EL -X- _ O
documentation -X- _ O
( -X- _ O
Adams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Thai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Matsuura -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Hjortnaes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021).In -X- _ O
developing -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
recipes -X- _ O
for -X- _ O
YMC -X- _ B-DatasetName
, -X- _ O
we -X- _ O
have -X- _ O
adopted -X- _ O
transformer -X- _ B-MethodName
and -X- _ I-MethodName
conformerbased -X- _ I-MethodName
encoder -X- _ I-MethodName
- -X- _ I-MethodName
decoder -X- _ I-MethodName
networks -X- _ I-MethodName
with -X- _ I-MethodName
hybrid -X- _ I-MethodName
CTC -X- _ I-MethodName
/ -X- _ I-MethodName
attention -X- _ I-MethodName
training -X- _ O
( -X- _ O
Karita -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b;Watanabe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
YMC -X- _ B-DatasetName
- -X- _ I-DatasetName
Exp -X- _ I-DatasetName
( -X- _ O
trainsplit -X- _ O
) -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
other -X- _ O
YMC -X- _ B-DatasetName
corpora -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O
The -X- _ O
hyper -X- _ O
- -X- _ O
parameters -X- _ O
for -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
decoding -X- _ O
follow -X- _ O
Shi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Seven -X- _ O
systems -X- _ O
with -X- _ O
different -X- _ O
modeling -X- _ O
units -X- _ O
are -X- _ O
examined -X- _ O
in -X- _ O
the -X- _ O
experiments -X- _ O
. -X- _ O
Four -X- _ O
systems -X- _ O
employ -X- _ O
the -X- _ O
byte -X- _ B-MethodName
- -X- _ I-MethodName
pair -X- _ I-MethodName
encoding -X- _ I-MethodName
( -X- _ O
BPE -X- _ B-MethodName
) -X- _ O
method -X- _ O
trained -X- _ O
from -X- _ O
unigram -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Kudo -X- _ O
and -X- _ O
Richardson -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
transcription -X- _ B-HyperparameterName
alphabets -X- _ I-HyperparameterName
limited -X- _ O
to -X- _ O
the -X- _ O
150 -X- _ B-HyperparameterName
, -X- _ O
500 -X- _ B-HyperparameterName
, -X- _ O
1000 -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
1500 -X- _ B-HyperparameterName
most -X- _ O
frequent -X- _ O
byte -X- _ O
- -X- _ O
pairs -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
other -X- _ O
three -X- _ O
ASR -X- _ O
systems -X- _ O
adopt -X- _ O
linguistic -X- _ O
units -X- _ O
, -X- _ O
including -X- _ O
word -X- _ B-MethodName
, -X- _ O
morpheme -X- _ B-MethodName
, -X- _ O
and -X- _ O
mora -X- _ B-MethodName
. -X- _ O
The -X- _ O
YM -X- _ B-DatasetName
word -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
a -X- _ O
stem -X- _ O
with -X- _ O
all -X- _ O
prefixes -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
completetive -X- _ O
ni -X- _ O
1 -X- _ O
- -X- _ O
, -X- _ O
causative -X- _ O
sa -X- _ O
4 -X- _ O
- -X- _ O
, -X- _ O
and -X- _ O
iterative -X- _ O
nda -X- _ O
3 -X- _ O
- -X- _ O
) -X- _ O
separated -X- _ O
from -X- _ O
the -X- _ O
stem -X- _ O
by -X- _ O
a -X- _ O
hyphen -X- _ O
; -X- _ O
and -X- _ O
all -X- _ O
enclitics -X- _ O
( -X- _ O
particularly -X- _ O
person -X- _ O
markers -X- _ O
for -X- _ O
subjects -X- _ O
, -X- _ O
objects -X- _ O
, -X- _ O
and -X- _ O
possessors -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
= -X- _ O
yu -X- _ O
3 -X- _ O
, -X- _ O
1sg -X- _ O
; -X- _ O
= -X- _ O
un -X- _ O
4 -X- _ O
, -X- _ O
2sg -X- _ O
; -X- _ O
= -X- _ O
an -X- _ O
4 -X- _ O
, -X- _ O
3sgFem -X- _ O
; -X- _ O
= -X- _ O
o -X- _ O
4 -X- _ O
, -X- _ O
1plIncl -X- _ O
; -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
= -X- _ O
lu -X- _ O
3 -X- _ O
, -X- _ O
augmentive -X- _ O
) -X- _ O
. -X- _ O
Many -X- _ O
vowel -X- _ O
- -X- _ O
initial -X- _ O
enclitics -X- _ O
have -X- _ O
alternative -X- _ O
vowels -X- _ O
, -X- _ O
and -X- _ O
many -X- _ O
encl -X- _ O
- -X- _ O
ASR -X- _ O
yo -X- _ O
' -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
xi -X- _ O
13 -X- _ O
i -X- _ O
2 -X- _ O
ba -X- _ O
42 -X- _ O
ndi -X- _ O
4 -X- _ O
ba -X- _ O
' -X- _ O
1 -X- _ O
a -X- _ O
3 -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ku -X- _ O
3 -X- _ O
-nu -X- _ O
' -X- _ O
3 -X- _ O
ni -X- _ O
2 -X- _ O
tu -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
kwi -X- _ O
3 -X- _ O
so -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ti -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
ko -X- _ O
14 -X- _ O
o -X- _ O
3 -X- _ O
yo -X- _ O
' -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
kwa -X- _ O
' -X- _ O
1 -X- _ O
an -X- _ O
1 -X- _ O
yo -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
xa -X- _ O
14 -X- _ O
ku -X- _ O
' -X- _ O
1 -X- _ O
u -X- _ O
1 -X- _ O
Exp -X- _ O
yo -X- _ O
' -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
xi -X- _ O
1 -X- _ O
i -X- _ O
32 -X- _ O
ba -X- _ O
42 -X- _ O
ndi -X- _ O
4 -X- _ O
ba -X- _ O
' -X- _ O
1 -X- _ O
a -X- _ O
3 -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ku -X- _ O
3 -X- _ O
-nu -X- _ O
' -X- _ O
3 -X- _ O
ni -X- _ O
2 -X- _ O
tu -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
kwi -X- _ O
3 -X- _ O
so -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ti -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
ko -X- _ O
14 -X- _ O
o -X- _ O
3 -X- _ O
yo -X- _ O
' -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
kwa -X- _ O
' -X- _ O
1 -X- _ O
an -X- _ O
1 -X- _ O
ji -X- _ O
' -X- _ O
4 -X- _ O
in -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
= -X- _ O
o -X- _ O
4 -X- _ O
xa -X- _ O
14 -X- _ O
ku -X- _ O
' -X- _ O
1 -X- _ O
u -X- _ O
1 -X- _ O
Note -X- _ O
ASR -X- _ O
missed -X- _ O
the -X- _ O
word -X- _ O
ji -X- _ O
' -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
( -X- _ O
' -X- _ O
with -X- _ O
' -X- _ O
, -X- _ O
comitative -X- _ O
) -X- _ O
and -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
wrote -X- _ O
the -X- _ O
1plInclusive -X- _ O
as -X- _ O
an -X- _ O
independent -X- _ O
pronoun -X- _ O
and -X- _ O
not -X- _ O
an -X- _ O
enclitic -X- _ O
. -X- _ O
ASR -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
tan -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
2 -X- _ O
tio -X- _ O
3 -X- _ O
o -X- _ O
2 -X- _ O
yu -X- _ O
3 -X- _ O
ku -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
ba -X- _ O
4 -X- _ O
li -X- _ O
4 -X- _ O
coco -X- _ O
nu -X- _ O
14 -X- _ O
u -X- _ O
3 -X- _ O
ñu -X- _ O
' -X- _ O
3 -X- _ O
u -X- _ O
4 -X- _ O
sa -X- _ O
3 -X- _ O
kan -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
Exp -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
tan -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
2 -X- _ O
tio -X- _ O
3 -X- _ O
o -X- _ O
2 -X- _ O
yu -X- _ O
3 -X- _ O
ku -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
ba -X- _ O
4 -X- _ O
li -X- _ O
4 -X- _ O
ko -X- _ O
4 -X- _ O
ko -X- _ O
13 -X- _ O
nu -X- _ O
14 -X- _ O
u -X- _ O
3 -X- _ O
ñu -X- _ O
' -X- _ O
3 -X- _ O
u -X- _ O
4 -X- _ O
sa -X- _ O
3 -X- _ O
kan -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
Note -X- _ O
ASR -X- _ B-TaskName
suggested -X- _ O
Spanish -X- _ O
' -X- _ O
coco -X- _ O
' -X- _ O
coconut -X- _ O
for -X- _ O
Mixtec -X- _ O
ko -X- _ O
4 -X- _ O
ko -X- _ O
13 -X- _ O
( -X- _ O
' -X- _ O
to -X- _ O
be -X- _ O
abundant[plants -X- _ O
] -X- _ O
' -X- _ O
) -X- _ O
itics -X- _ O
have -X- _ O
alternative -X- _ O
tones -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
stemfinal -X- _ O
vowel -X- _ O
and -X- _ O
tone -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Morphemes -X- _ O
are -X- _ O
stems -X- _ O
, -X- _ O
prefixes -X- _ O
, -X- _ O
and -X- _ O
enclitics -X- _ O
. -X- _ O
The -X- _ O
inflectional -X- _ O
tone -X- _ O
is -X- _ O
not -X- _ O
segmented -X- _ O
out -X- _ O
. -X- _ O
The -X- _ O
right -X- _ O
boundary -X- _ O
of -X- _ O
a -X- _ O
mora -X- _ O
is -X- _ O
a -X- _ O
vowel -X- _ O
or -X- _ O
dipthong -X- _ O
( -X- _ O
with -X- _ O
an -X- _ O
optional -X- _ O
< -X- _ O
n -X- _ O
> -X- _ O
to -X- _ O
indicate -X- _ O
a -X- _ O
nasalized -X- _ O
vowel -X- _ O
) -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
tone -X- _ O
. -X- _ O
The -X- _ O
left -X- _ O
boundary -X- _ O
is -X- _ O
a -X- _ O
preceding -X- _ O
mora -X- _ O
or -X- _ O
word -X- _ O
boundary -X- _ O
. -X- _ O
Thus -X- _ O
the -X- _ O
word -X- _ O
ni -X- _ O
1 -X- _ O
-xa -X- _ O
3 -X- _ O
nda -X- _ O
2 -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
( -X- _ O
completive -X- _ O
- -X- _ O
play(guitar)-1plIncl -X- _ O
) -X- _ O
would -X- _ O
be -X- _ O
divided -X- _ O
into -X- _ O
three -X- _ O
morphemes -X- _ O
ni -X- _ O
1 -X- _ O
- -X- _ O
, -X- _ O
xa -X- _ O
3 -X- _ O
nda -X- _ O
2 -X- _ O
, -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
and -X- _ O
into -X- _ O
four -X- _ O
morae -X- _ O
given -X- _ O
that -X- _ O
xa -X- _ O
3 -X- _ O
nda -X- _ O
2 -X- _ O
would -X- _ O
be -X- _ O
segmented -X- _ O
as -X- _ O
xa -X- _ O
3 -X- _ O
, -X- _ O
nda -X- _ O
2 -X- _ O
.We -X- _ O
adopt -X- _ O
recognizer -X- _ O
output -X- _ O
voting -X- _ O
error -X- _ O
reduction -X- _ O
( -X- _ O
ROVER -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
hypotheses -X- _ O
combination -X- _ O
( -X- _ O
Fiscus -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
. -X- _ O
Three -X- _ O
combinations -X- _ O
have -X- _ O
been -X- _ O
evaluated -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
ROVER -X- _ B-MethodName
among -X- _ O
only -X- _ O
linguistic -X- _ O
units -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
morae -X- _ B-MethodName
, -X- _ O
morpheme -X- _ B-MethodName
, -X- _ O
and -X- _ O
word -X- _ B-MethodName
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
ROVER -X- _ B-MethodName
among -X- _ O
only -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
units -X- _ O
( -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
BPE -X- _ B-MethodName
) -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
ROVER -X- _ B-MethodName
combination -X- _ O
utilizing -X- _ O
all -X- _ O
seven -X- _ O
systems -X- _ O
. -X- _ O
Experimental -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
two -X- _ O
subsections -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
addresses -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
end -X- _ B-TaskName
- -X- _ I-TaskName
to -X- _ I-TaskName
- -X- _ I-TaskName
end -X- _ I-TaskName
ASR -X- _ I-TaskName
across -X- _ O
three -X- _ O
corpora -X- _ O
, -X- _ O
each -X- _ O
with -X- _ O
slightly -X- _ O
different -X- _ O
recording -X- _ O
systems -X- _ O
and -X- _ O
content -X- _ O
. -X- _ O
As -X- _ O
clear -X- _ O
from -X- _ O
the -X- _ O
preceding -X- _ O
discussion -X- _ O
and -X- _ O
illustrated -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
word -X- _ O
unit -X- _ O
, -X- _ O
the -X- _ O
YMC -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
system -X- _ I-TaskName
was -X- _ O
trained -X- _ O
on -X- _ O
six -X- _ O
additional -X- _ O
linguistic -X- _ O
and -X- _ O
informational -X- _ O
sub -X- _ O
- -X- _ O
word -X- _ O
units -X- _ O
. -X- _ O
ROVER -X- _ B-MethodName
was -X- _ O
then -X- _ O
used -X- _ O
to -X- _ O
produce -X- _ O
composite -X- _ O
systems -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
all -X- _ O
seven -X- _ O
systems -X- _ O
were -X- _ O
combined -X- _ O
in -X- _ O
three -X- _ O
distinct -X- _ O
manners -X- _ O
. -X- _ O
In -X- _ O
all -X- _ O
cases -X- _ O
, -X- _ O
ROVER -X- _ B-MethodName
combinations -X- _ O
improved -X- _ O
the -X- _ O
result -X- _ O
of -X- _ O
any -X- _ O
individual -X- _ O
system -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
averages -X- _ O
for -X- _ O
either -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
units -X- _ O
: -X- _ O
linguistic -X- _ O
and -X- _ O
informational -X- _ O
. -X- _ O
4 -X- _ O
Those -X- _ O
interested -X- _ O
in -X- _ O
the -X- _ O
recordings -X- _ O
and -X- _ O
associated -X- _ O
ELAN -X- _ O
files -X- _ O
may -X- _ O
visit -X- _ O
Amith -X- _ O
and -X- _ O
Castillo -X- _ O
García -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
evident -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
across -X- _ O
all -X- _ O
corpora -X- _ O
, -X- _ O
informational -X- _ O
units -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
are -X- _ O
more -X- _ O
efficient -X- _ O
than -X- _ O
linguistic -X- _ O
units -X- _ O
( -X- _ O
word -X- _ O
, -X- _ O
morpheme -X- _ O
, -X- _ O
morae -X- _ O
) -X- _ O
in -X- _ O
regards -X- _ O
to -X- _ O
ASR -X- _ O
accuracy -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
CER -X- _ B-MetricName
/ -X- _ O
WER -X- _ B-MetricName
for -X- _ O
linguistic -X- _ O
units -X- _ O
( -X- _ O
rows -X- _ O
A -X- _ O
- -X- _ O
C -X- _ O
) -X- _ O
was -X- _ O
10.4/ -X- _ B-MetricValue
19.5 -X- _ B-MetricValue
( -X- _ O
Exp[test -X- _ B-DatasetName
] -X- _ I-DatasetName
) -X- _ O
, -X- _ O
13.6/23.3 -X- _ B-MetricValue
( -X- _ O
FB -X- _ B-DatasetName
) -X- _ O
, -X- _ O
and -X- _ O
10.7/21.7 -X- _ B-MetricValue
( -X- _ O
VN -X- _ B-DatasetName
) -X- _ O
. -X- _ O
The -X- _ O
corresponding -X- _ O
figures -X- _ O
for -X- _ O
the -X- _ O
BPE -X- _ O
units -X- _ O
( -X- _ O
rows -X- _ O
D -X- _ O
- -X- _ O
G -X- _ O
) -X- _ O
were -X- _ O
7.7/16.0 -X- _ B-MetricValue
( -X- _ O
Exp[test -X- _ B-DatasetName
] -X- _ I-DatasetName
) -X- _ O
, -X- _ O
9.7/19.5 -X- _ B-MetricValue
( -X- _ O
FB -X- _ B-DatasetName
) -X- _ O
, -X- _ O
and -X- _ O
6.8/16.8 -X- _ B-MetricValue
( -X- _ O
VN -X- _ B-DatasetName
) -X- _ O
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
percentage -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
units -X- _ O
, -X- _ O
the -X- _ O
numbers -X- _ O
are -X- _ O
not -X- _ O
insignificant -X- _ O
. -X- _ O
In -X- _ O
regards -X- _ O
to -X- _ O
CER -X- _ B-MetricName
, -X- _ O
performance -X- _ O
improved -X- _ O
from -X- _ O
linguistic -X- _ O
to -X- _ O
informational -X- _ O
units -X- _ O
by -X- _ O
26.0 -X- _ B-MetricValue
, -X- _ O
28.7 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
36.4 -X- _ B-MetricValue
percent -X- _ O
across -X- _ O
the -X- _ O
Exp(Test -X- _ B-DatasetName
) -X- _ I-DatasetName
, -X- _ O
FB -X- _ B-DatasetName
, -X- _ O
and -X- _ O
VN -X- _ B-DatasetName
corpora -X- _ O
. -X- _ O
In -X- _ O
regards -X- _ O
to -X- _ O
WER -X- _ B-MetricName
, -X- _ O
performance -X- _ O
improved -X- _ O
by -X- _ O
17.9 -X- _ B-MetricValue
, -X- _ O
16.3 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
22.6 -X- _ B-MetricValue
percent -X- _ O
across -X- _ O
the -X- _ O
same -X- _ O
three -X- _ O
corpora -X- _ O
. -X- _ O
The -X- _ O
experiments -X- _ O
also -X- _ O
addressed -X- _ O
two -X- _ O
remaining -X- _ O
questions -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
does -X- _ O
unweighted -X- _ O
ROVER -X- _ B-MethodName
combination -X- _ O
improve -X- _ O
the -X- _ O
accuracy -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
results -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
does -X- _ O
adding -X- _ O
linguistic -X- _ O
unit -X- _ O
performance -X- _ O
units -X- _ O
to -X- _ O
the -X- _ O
ROVER -X- _ B-MethodName
" -X- _ O
voting -X- _ O
pool -X- _ O
" -X- _ O
improve -X- _ O
results -X- _ O
over -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
only -X- _ O
BPE -X- _ B-MethodName
units -X- _ I-MethodName
. -X- _ O
In -X- _ O
regards -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
question -X- _ O
: -X- _ O
ROVER -X- _ B-MethodName
always -X- _ O
improves -X- _ O
results -X- _ O
over -X- _ O
any -X- _ O
individual -X- _ O
system -X- _ O
( -X- _ O
compare -X- _ O
row -X- _ O
H -X- _ O
to -X- _ O
rows -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
, -X- _ O
and -X- _ O
C -X- _ O
, -X- _ O
and -X- _ O
row -X- _ O
I -X- _ O
to -X- _ O
rows -X- _ O
D -X- _ O
, -X- _ O
E -X- _ O
, -X- _ O
F -X- _ O
, -X- _ O
and -X- _ O
G -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
question -X- _ O
is -X- _ O
addressed -X- _ O
by -X- _ O
comparing -X- _ O
rows -X- _ O
I -X- _ O
( -X- _ O
ROVER -X- _ B-MethodName
applied -X- _ O
only -X- _ O
to -X- _ O
the -X- _ O
four -X- _ O
BPE -X- _ B-MethodName
results -X- _ O
) -X- _ O
to -X- _ O
J -X- _ O
( -X- _ O
adding -X- _ O
the -X- _ O
ASR -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
three -X- _ O
linguistic -X- _ O
units -X- _ O
into -X- _ O
the -X- _ O
combination -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
only -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
six -X- _ O
cases -X- _ O
( -X- _ O
CER -X- _ B-MetricName
of -X- _ O
Exp[test -X- _ B-DatasetName
] -X- _ I-DatasetName
) -X- _ O
does -X- _ O
including -X- _ O
word -X- _ B-MethodName
, -X- _ O
morpheme -X- _ B-MethodName
, -X- _ O
and -X- _ O
morae -X- _ O
lower -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
from -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
a -X- _ O
simple -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
BPE -X- _ B-MethodName
results -X- _ O
( -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
from -X- _ O
7.6 -X- _ B-MetricValue
[ -X- _ O
row -X- _ O
I -X- _ O
] -X- _ O
to -X- _ O
7.4 -X- _ B-MetricValue
[ -X- _ O
row -X- _ O
J -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
one -X- _ O
case -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
change -X- _ O
( -X- _ O
CER -X- _ B-MetricName
for -X- _ O
the -X- _ O
VN -X- _ B-DatasetName
corpus -X- _ O
) -X- _ O
and -X- _ O
in -X- _ O
four -X- _ O
cases -X- _ O
, -X- _ O
including -X- _ O
linguistic -X- _ O
units -X- _ O
slightly -X- _ O
worsens -X- _ O
the -X- _ O
score -X- _ O
from -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
BPE -X- _ B-MethodName
units -X- _ I-MethodName
alone -X- _ O
( -X- _ O
row -X- _ O
I -X- _ O
with -X- _ O
bold -X- _ O
numbers -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
implication -X- _ O
of -X- _ O
the -X- _ O
preceding -X- _ O
is -X- _ O
that -X- _ O
ASR -X- _ O
using -X- _ O
linguistic -X- _ O
units -X- _ O
yields -X- _ O
significantly -X- _ O
lower -X- _ O
accuracy -X- _ O
than -X- _ O
ASR -X- _ B-TaskName
that -X- _ O
uses -X- _ O
informational -X- _ O
( -X- _ O
BPE -X- _ B-MethodName
) -X- _ O
units -X- _ O
. -X- _ O
Combining -X- _ O
the -X- _ O
former -X- _ O
with -X- _ O
the -X- _ O
latter -X- _ O
in -X- _ O
an -X- _ O
unweighted -X- _ O
ROVER -X- _ B-MethodName
system -X- _ O
in -X- _ O
most -X- _ O
cases -X- _ O
does -X- _ O
not -X- _ O
improve -X- _ O
results -X- _ O
. -X- _ O
Whether -X- _ O
a -X- _ O
weighted -X- _ O
combinatory -X- _ O
system -X- _ O
would -X- _ O
do -X- _ O
better -X- _ O
is -X- _ O
a -X- _ O
question -X- _ O
that -X- _ O
will -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
explored -X- _ O
. -X- _ O
A -X- _ O
fundamental -X- _ O
element -X- _ O
of -X- _ O
endangered -X- _ O
language -X- _ O
documentation -X- _ O
is -X- _ O
the -X- _ O
creation -X- _ O
of -X- _ O
an -X- _ O
extensive -X- _ O
corpus -X- _ O
of -X- _ O
audio -X- _ O
recordings -X- _ O
accompanied -X- _ O
by -X- _ O
timecoded -X- _ O
annotations -X- _ O
in -X- _ O
interlinear -X- _ O
format -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
cases -X- _ O
, -X- _ O
such -X- _ O
annotations -X- _ O
include -X- _ O
an -X- _ O
accurate -X- _ O
transcription -X- _ O
aligned -X- _ O
with -X- _ O
morphological -X- _ O
segmentation -X- _ O
, -X- _ O
glossing -X- _ O
, -X- _ O
and -X- _ O
free -X- _ O
translations -X- _ O
. -X- _ O
The -X- _ O
degree -X- _ O
to -X- _ O
which -X- _ O
such -X- _ O
corpus -X- _ O
creation -X- _ O
is -X- _ O
facilitated -X- _ O
is -X- _ O
the -X- _ O
extrinsic -X- _ O
metric -X- _ O
by -X- _ O
which -X- _ O
ASR -X- _ O
contributions -X- _ O
to -X- _ O
EL -X- _ O
documentation -X- _ O
should -X- _ O
be -X- _ O
considered -X- _ O
. -X- _ O
The -X- _ O
project -X- _ O
here -X- _ O
discussed -X- _ O
suggests -X- _ O
a -X- _ O
path -X- _ O
to -X- _ O
creating -X- _ O
such -X- _ O
corpora -X- _ O
using -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
ASR -X- _ O
technology -X- _ O
to -X- _ O
build -X- _ O
up -X- _ O
the -X- _ O
resources -X- _ O
( -X- _ O
30 -X- _ O
- -X- _ O
50 -X- _ O
hours -X- _ O
) -X- _ O
necessary -X- _ O
to -X- _ O
train -X- _ O
an -X- _ O
ASR -X- _ B-TaskName
system -X- _ O
with -X- _ O
perhaps -X- _ O
a -X- _ O
6 -X- _ B-MetricValue
- -X- _ I-MetricValue
10 -X- _ I-MetricValue
percent -X- _ I-MetricValue
CER -X- _ B-MetricName
. -X- _ O
Once -X- _ O
this -X- _ O
threshold -X- _ O
is -X- _ O
reached -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
unlikely -X- _ O
that -X- _ O
further -X- _ O
improvement -X- _ O
will -X- _ O
significantly -X- _ O
reduce -X- _ O
the -X- _ O
human -X- _ O
effort -X- _ O
needed -X- _ O
to -X- _ O
check -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
for -X- _ O
accuracy -X- _ O
. -X- _ O
Indeed -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
" -X- _ O
errors -X- _ O
" -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output -X- _ O
, -X- _ O
confirmation -X- _ O
of -X- _ O
this -X- _ O
through -X- _ O
careful -X- _ O
revision -X- _ O
of -X- _ O
the -X- _ O
recording -X- _ O
of -X- _ O
the -X- _ O
transcription -X- _ O
would -X- _ O
probably -X- _ O
still -X- _ O
take -X- _ O
3 -X- _ O
- -X- _ O
4 -X- _ O
hours -X- _ O
. -X- _ O
The -X- _ O
effort -X- _ O
reduction -X- _ O
of -X- _ O
75 -X- _ O
percent -X- _ O
documented -X- _ O
here -X- _ O
for -X- _ O
YMC -X- _ B-DatasetName
is -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
approaching -X- _ O
what -X- _ O
may -X- _ O
be -X- _ O
considered -X- _ O
the -X- _ O
minimum -X- _ O
amount -X- _ O
of -X- _ O
time -X- _ O
to -X- _ O
proofread -X- _ O
transcription -X- _ O
of -X- _ O
natural -X- _ O
speech -X- _ O
in -X- _ O
an -X- _ O
endangered -X- _ O
language -X- _ O
. -X- _ O
This -X- _ O
project -X- _ O
has -X- _ O
also -X- _ O
demonstrated -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
using -X- _ O
a -X- _ O
practical -X- _ O
orthography -X- _ O
that -X- _ O
separates -X- _ O
affixes -X- _ O
and -X- _ O
clitics -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
relatively -X- _ O
isolating -X- _ O
language -X- _ O
such -X- _ O
as -X- _ O
YM -X- _ O
, -X- _ O
such -X- _ O
a -X- _ O
system -X- _ O
is -X- _ O
not -X- _ O
difficult -X- _ O
for -X- _ O
native -X- _ O
speakers -X- _ O
to -X- _ O
write -X- _ O
nor -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
to -X- _ O
learn -X- _ O
. -X- _ O
It -X- _ O
has -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
creating -X- _ O
a -X- _ O
workflow -X- _ O
in -X- _ O
which -X- _ O
parsed -X- _ O
text -X- _ O
is -X- _ O
the -X- _ O
direct -X- _ O
output -X- _ O
of -X- _ O
E2E -X- _ B-TaskName
ASR -X- _ I-TaskName
. -X- _ O
The -X- _ O
error -X- _ O
rate -X- _ O
evaluations -X- _ O
across -X- _ O
the -X- _ O
spectrum -X- _ O
of -X- _ O
corpora -X- _ O
and -X- _ O
CER -X- _ B-MetricName
/ -X- _ O
WER -X- _ B-MetricName
also -X- _ O
demonstrate -X- _ O
the -X- _ O
advantage -X- _ O
of -X- _ O
using -X- _ O
subword -X- _ O
units -X- _ O
such -X- _ O
as -X- _ O
BPE -X- _ O
and -X- _ O
subsequent -X- _ O
processing -X- _ O
by -X- _ O
ROVER -X- _ B-MethodName
for -X- _ O
system -X- _ O
combination -X- _ O
( -X- _ O
see -X- _ O
above -X- _ O
and -X- _ O
Table -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
error -X- _ O
rates -X- _ O
could -X- _ O
perhaps -X- _ O
be -X- _ O
lowered -X- _ O
further -X- _ O
as -X- _ O
the -X- _ O
corpus -X- _ O
increases -X- _ O
in -X- _ O
size -X- _ O
, -X- _ O
as -X- _ O
more -X- _ O
care -X- _ O
is -X- _ O
placed -X- _ O
on -X- _ O
recording -X- _ O
environments -X- _ O
, -X- _ O
and -X- _ O
as -X- _ O
normalization -X- _ O
eliminates -X- _ O
reported -X- _ O
errors -X- _ O
for -X- _ O
minor -X- _ O
discrepancies -X- _ O
such -X- _ O
as -X- _ O
in -X- _ O
transcription -X- _ O
of -X- _ O
back -X- _ O
- -X- _ O
channel -X- _ O
cues -X- _ O
. -X- _ O
But -X- _ O
such -X- _ O
lower -X- _ O
error -X- _ O
rates -X- _ O
will -X- _ O
probably -X- _ O
not -X- _ O
significantly -X- _ O
reduce -X- _ O
the -X- _ O
time -X- _ O
for -X- _ O
final -X- _ O
revision -X- _ O
. -X- _ O
A -X- _ O
final -X- _ O
question -X- _ O
concerns -X- _ O
additional -X- _ O
steps -X- _ O
once -X- _ O
CER -X- _ B-MetricName
is -X- _ O
reduced -X- _ O
to -X- _ O
6 -X- _ B-MetricValue
- -X- _ I-MetricValue
8 -X- _ I-MetricValue
percent -X- _ I-MetricValue
, -X- _ O
and -X- _ O
additional -X- _ O
improvements -X- _ O
to -X- _ O
ASR -X- _ B-TaskName
would -X- _ O
not -X- _ O
significantly -X- _ O
affect -X- _ O
the -X- _ O
human -X- _ O
effort -X- _ O
needed -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
time -X- _ O
- -X- _ O
coded -X- _ O
transcription -X- _ O
and -X- _ O
segmentation -X- _ O
. -X- _ O
Four -X- _ O
topics -X- _ O
are -X- _ O
suggested -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
address -X- _ O
issues -X- _ O
of -X- _ O
noise -X- _ O
, -X- _ O
overlapping -X- _ O
speech -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
challenging -X- _ O
recording -X- _ O
situations -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
focus -X- _ O
on -X- _ O
transfer -X- _ O
learning -X- _ O
to -X- _ O
related -X- _ O
languages -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
explore -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
" -X- _ O
colonialization -X- _ O
" -X- _ O
by -X- _ O
a -X- _ O
dominant -X- _ O
language -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
focus -X- _ O
additional -X- _ O
ASR -X- _ B-TaskName
- -X- _ O
supported -X- _ O
corpus -X- _ O
development -X- _ O
on -X- _ O
producing -X- _ O
material -X- _ O
for -X- _ O
documentation -X- _ O
of -X- _ O
endangered -X- _ O
cultural -X- _ O
knowledge -X- _ O
, -X- _ O
a -X- _ O
facet -X- _ O
of -X- _ O
documentation -X- _ O
that -X- _ O
is -X- _ O
often -X- _ O
absent -X- _ O
from -X- _ O
endangered -X- _ O
language -X- _ O
documentation -X- _ O
projects -X- _ O
. -X- _ O
A -X- _ O
Analysis -X- _ O
of -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
in -X- _ O
one -X- _ O
recording -X- _ O
from -X- _ O
the -X- _ O
FB -X- _ O
corpus -X- _ O
Unique -X- _ O
identifier -X- _ O
: -X- _ O
2017 -X- _ O
- -X- _ O
12 -X- _ O
- -X- _ O
01 -X- _ O
- -X- _ O
b -X- _ O
Speakers -X- _ O
: -X- _ O
Constantino -X- _ O
Teodoro -X- _ O
Bautista -X- _ O
and -X- _ O
Esteban -X- _ O
Guadalupe -X- _ O
Sierra -X- _ O
Spanish -X- _ O
: -X- _ O
The -X- _ O
first -X- _ O
13 -X- _ O
seconds -X- _ O
( -X- _ O
3 -X- _ O
segments -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
recording -X- _ O
were -X- _ O
of -X- _ O
a -X- _ O
Spanish -X- _ O
speaker -X- _ O
describing -X- _ O
the -X- _ O
plant -X- _ O
being -X- _ O
collected -X- _ O
( -X- _ O
Passiflora -X- _ O
biflora -X- _ O
Lam -X- _ O
. -X- _ O
) -X- _ O
and -X- _ O
have -X- _ O
not -X- _ O
been -X- _ O
included -X- _ O
below -X- _ O
. -X- _ O
Note -X- _ O
: -X- _ O
A -X- _ O
total -X- _ O
16 -X- _ O
out -X- _ O
of -X- _ O
33 -X- _ O
segments -X- _ O
/ -X- _ O
utterances -X- _ O
are -X- _ O
without -X- _ O
ASR -X- _ B-TaskName
error -X- _ O
. -X- _ O
These -X- _ O
are -X- _ O
marked -X- _ O
with -X- _ O
an -X- _ O
asterisk -X- _ O
. -X- _ O
Original -X- _ O
recording -X- _ O
and -X- _ O
ELAN -X- _ O
file -X- _ O
: -X- _ O
Download -X- _ O
at -X- _ O
http://www.balsas-nahuatl.org/NLP -X- _ O
4 -X- _ O
* -X- _ O
. -X- _ O
00:00:13.442 -X- _ O
- -X- _ O
> -X- _ O
00:00:17.105 -X- _ O
ASR -X- _ O
constantino -X- _ O
teodoro -X- _ O
bautista -X- _ O
Exp -X- _ O
Constantino -X- _ O
Teodoro -X- _ O
Bautista -X- _ O
. -X- _ O
Notes -X- _ O
: -X- _ O
ASR -X- _ B-TaskName
does -X- _ O
not -X- _ O
output -X- _ O
caps -X- _ O
or -X- _ O
punctuation -X- _ O
. -X- _ O
5 -X- _ O
* -X- _ O
. -X- _ O
00:00:17.105 -X- _ O
- -X- _ O
> -X- _ O
00:00:19.477 -X- _ O
ASR -X- _ B-TaskName
ya -X- _ O
1 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
tu -X- _ O
1 -X- _ O
tu -X- _ O
' -X- _ O
4 -X- _ O
un -X- _ O
4 -X- _ O
ku -X- _ O
3 -X- _ O
rra -X- _ O
42 -X- _ O
Exp -X- _ O
Ya -X- _ O
1 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
tu -X- _ O
1 -X- _ O
tu -X- _ O
' -X- _ O
4 -X- _ O
un -X- _ O
4 -X- _ O
ku -X- _ O
3 -X- _ O
rra -X- _ O
42 -X- _ O
Notes -X- _ O
: -X- _ O
No -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
hypothesis.6 -X- _ O
. -X- _ O
00:00:19.477 -X- _ O
- -X- _ O
> -X- _ O
00:00:23.688 -X- _ O
ASR -X- _ O
ta -X- _ O
1 -X- _ O
mas -X- _ O
4 -X- _ O
tru -X- _ O
2 -X- _ O
tela -X- _ O
ya -X- _ O
1 -X- _ O
i -X- _ O
3 -X- _ O
chi -X- _ O
4 -X- _ O
ya -X- _ O
3 -X- _ O
tin -X- _ O
3 -X- _ O
ye -X- _ O
' -X- _ O
1 -X- _ O
4e -X- _ O
4 -X- _ O
ku -X- _ O
3 -X- _ O
rra -X- _ O
42 -X- _ O
ndi -X- _ O
4 -X- _ O
covalentín -X- _ O
yo -X- _ O
' -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
Exp -X- _ O
ta -X- _ O
1 -X- _ O
mas -X- _ O
4 -X- _ O
tru -X- _ O
2 -X- _ O
Tele -X- _ O
ya -X- _ O
1 -X- _ O
i -X- _ O
3 -X- _ O
chi -X- _ O
4 -X- _ O
ya -X- _ O
3 -X- _ O
tin -X- _ O
3 -X- _ O
ye -X- _ O
' -X- _ O
1 -X- _ O
4e -X- _ O
4 -X- _ O
ku -X- _ O
3 -X- _ O
rra -X- _ O
42 -X- _ O
Nicu -X- _ O
Valentín -X- _ O
yo -X- _ O
' -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
, -X- _ O
Notes -X- _ O
: -X- _ O
ASR -X- _ B-TaskName
missed -X- _ O
the -X- _ O
proper -X- _ O
name -X- _ O
, -X- _ O
Nicu -X- _ O
Valentín -X- _ O
( -X- _ O
short -X- _ O
for -X- _ O
Nicolás -X- _ O
Valentín -X- _ O
) -X- _ O
but -X- _ O
did -X- _ O
get -X- _ O
the -X- _ O
accent -X- _ O
on -X- _ O
Valentín -X- _ O
, -X- _ O
while -X- _ O
mistaking -X- _ O
the -X- _ O
first -X- _ O
name -X- _ O
Nicu -X- _ O
for -X- _ O
ndi -X- _ O
4 -X- _ O
co[valentín -X- _ O
] -X- _ O
7 -X- _ O
* -X- _ O
. -X- _ O
00:00:23.688 -X- _ O
- -X- _ O
> -X- _ O
00:00:31.086 -X- _ O
ASR -X- _ B-TaskName
ya -X- _ O
1 -X- _ O
i -X- _ O
3 -X- _ O
chi -X- _ O
4 -X- _ O
kwa -X- _ O
' -X- _ O
1 -X- _ O
an -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
tan -X- _ O
3 -X- _ O
xa -X- _ O
1 -X- _ O
a -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
ku -X- _ O
3 -X- _ O
rra -X- _ O
42 -X- _ O
chi -X- _ O
4 -X- _ O
ñu -X- _ O
3 -X- _ O
ka -X- _ O
4 -X- _ O
chi -X- _ O
2 -X- _ O
= -X- _ O
na -X- _ O
1 -X- _ O
ya -X- _ O
1 -X- _ O
kwa -X- _ O
' -X- _ O
1 -X- _ O
an -X- _ O
1 -X- _ O
ni -X- _ O
1 -X- _ O
nu -X- _ O
3 -X- _ O
yo -X- _ O
' -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
ju -X- _ O
13 -X- _ O
ta -X- _ O
' -X- _ O
3 -X- _ O
an -X- _ O
2 -X- _ O
= -X- _ O
ndu -X- _ O
1 -X- _ O
ya -X- _ O
1 -X- _ O
ko -X- _ O
4 -X- _ O
ndo -X- _ O
3 -X- _ O
kwi -X- _ O
1 -X- _ O
yo -X- _ O
' -X- _ O
1 -X- _ O
o -X- _ O
4 -X- _ O
ndi -X- _ O
3 -X- _ O
ku -X- _ O
' -X- _ O
3 -X- _ O
un -X- _ O
3 -X- _ O
Exp -X- _ O
ya -X- _ O
1 -X- _ O
i -X- _ O
3 -X- _ O
chi -X- _ O
4 -X- _ O
kwa -X- _ O
' -X- _ O
1 -X- _ O
an -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
tan -X- _ O
3 -X- _ O
xa -X- _ O
1 -X- _ O
a -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
ku -X- _ O
3 -X- _ O
rra -X- _ O
42 -X- _ O
chi -X- _ O
4 -X- _ O
ñu -X- _ O
3 -X- _ O
ka -X- _ O
4 -X- _ O
chi -X- _ O
2 -X- _ O
= -X- _ O
na -X- _ O
1 -X- _ O
ya -X- _ O
1 -X- _ O
kwa -X- _ O
' -X- _ O
1 -X- _ O
an -X- _ O
1 -X- _ O
ni -X- _ O
1 -X- _ O
nu -X- _ O
3 -X- _ O
yo -X- _ O
' -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
ju -X- _ O
13 -X- _ O
ta -X- _ O
' -X- _ O
3 -X- _ O
an -X- _ O
2 -X- _ O
= -X- _ O
ndu -X- _ O
1 -X- _ O
ya -X- _ O
1 -X- _ O
ko -X- _ O
4 -X- _ O
ndo -X- _ O
3 -X- _ O
kwi -X- _ O
1 -X- _ O
yo -X- _ O
' -X- _ O
1 -X- _ O
o -X- _ O
4 -X- _ O
ndi -X- _ O
3 -X- _ O
ku -X- _ O
' -X- _ O
3 -X- _ O
un -X- _ O
3 -X- _ O
Notes -X- _ O
: -X- _ O
No -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
hypothesis.8 -X- _ O
* -X- _ O
. -X- _ O
00:00:31.086 -X- _ O
- -X- _ O
> -X- _ O
00:00:37.318 -X- _ O
ASR -X- _ B-TaskName
kwi -X- _ O
1 -X- _ O
yo -X- _ O
' -X- _ O
1 -X- _ O
o -X- _ O
4 -X- _ O
ndi -X- _ O
3 -X- _ O
ku -X- _ O
' -X- _ O
3 -X- _ O
un -X- _ O
3 -X- _ O
kwi -X- _ O
4 -X- _ O
i -X- _ O
24 -X- _ O
ka -X- _ O
4 -X- _ O
chi -X- _ O
2 -X- _ O
= -X- _ O
na -X- _ O
1 -X- _ O
yo -X- _ O
' -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
ndi -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
yo -X- _ O
' -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
ndi -X- _ O
4 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nu -X- _ O
3 -X- _ O
su -X- _ O
4 -X- _ O
kun -X- _ O
1 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ti -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
yo -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
bi -X- _ O
1 -X- _ O
xin -X- _ O
3 -X- _ O
tan -X- _ O
3 -X- _ O
Exp -X- _ O
kwi -X- _ O
1 -X- _ O
yo -X- _ O
' -X- _ O
1 -X- _ O
o -X- _ O
4 -X- _ O
ndi -X- _ O
3 -X- _ O
ku -X- _ O
' -X- _ O
3 -X- _ O
un -X- _ O
3 -X- _ O
kwi -X- _ O
4 -X- _ O
i -X- _ O
24 -X- _ O
ka -X- _ O
4 -X- _ O
chi -X- _ O
2 -X- _ O
= -X- _ O
na -X- _ O
1 -X- _ O
yo -X- _ O
' -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
ndi -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
yo -X- _ O
' -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
ndi -X- _ O
4 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nu -X- _ O
3 -X- _ O
su -X- _ O
4 -X- _ O
kun -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
1 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ti -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
yo -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
bi -X- _ O
1 -X- _ O
xin -X- _ O
3 -X- _ O
tan -X- _ O
3 -X- _ O
Notes -X- _ O
: -X- _ O
The -X- _ O
ASR -X- _ B-TaskName
hypothesis -X- _ O
missed -X- _ O
the -X- _ O
inanimate -X- _ O
enclitic -X- _ O
after -X- _ O
the -X- _ O
verb -X- _ O
su -X- _ O
4 -X- _ O
kun -X- _ O
1 -X- _ O
and -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
failed -X- _ O
to -X- _ O
mark -X- _ O
the -X- _ O
elision -X- _ O
of -X- _ O
the -X- _ O
stem -X- _ O
- -X- _ O
final -X- _ O
low -X- _ O
tone -X- _ O
as -X- _ O
would -X- _ O
occur -X- _ O
before -X- _ O
a -X- _ O
following -X- _ O
low -X- _ O
- -X- _ O
tone -X- _ O
enclitic.9 -X- _ O
. -X- _ O
00:00:37.318 -X- _ O
- -X- _ O
> -X- _ O
00:00:42.959 -X- _ O
ASR -X- _ O
yo -X- _ O
' -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
xi -X- _ O
13 -X- _ O
i -X- _ O
2 -X- _ O
ba -X- _ O
42 -X- _ O
ndi -X- _ O
4 -X- _ O
ba -X- _ O
' -X- _ O
1 -X- _ O
a -X- _ O
3 -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ku -X- _ O
3 -X- _ O
-nu -X- _ O
' -X- _ O
3 -X- _ O
ni -X- _ O
2 -X- _ O
tu -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
kwi -X- _ O
3 -X- _ O
so -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ti -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
ko -X- _ O
14 -X- _ O
o -X- _ O
3 -X- _ O
yo -X- _ O
' -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
kwa -X- _ O
' -X- _ O
1 -X- _ O
an -X- _ O
1 -X- _ O
yo -X- _ O
4 -X- _ O
o -X- _ O
4 -X- _ O
xa -X- _ O
14 -X- _ O
ku -X- _ O
' -X- _ O
1 -X- _ O
u -X- _ O
1 -X- _ O
Exp -X- _ O
yo -X- _ O
' -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
xi -X- _ O
1 -X- _ O
i -X- _ O
32 -X- _ O
ba -X- _ O
42 -X- _ O
ndi -X- _ O
4 -X- _ O
ba -X- _ O
' -X- _ O
1 -X- _ O
a -X- _ O
3 -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ku -X- _ O
3 -X- _ O
-nu -X- _ O
' -X- _ O
3 -X- _ O
ni -X- _ O
2 -X- _ O
tu -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
kwi -X- _ O
3 -X- _ O
so -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ti -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
ko -X- _ O
14 -X- _ O
o -X- _ O
3 -X- _ O
yo -X- _ O
' -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
kwa -X- _ O
' -X- _ O
1 -X- _ O
an -X- _ O
1 -X- _ O
ji -X- _ O
' -X- _ O
4 -X- _ O
in -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
= -X- _ O
o -X- _ O
4 -X- _ O
xa -X- _ O
14 -X- _ O
ku -X- _ O
' -X- _ O
1 -X- _ O
u -X- _ O
1 -X- _ O
, -X- _ O
Notes -X- _ O
: -X- _ O
ASR -X- _ O
missed -X- _ O
the -X- _ O
word -X- _ O
ji -X- _ O
' -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
( -X- _ O
' -X- _ O
with -X- _ O
' -X- _ O
, -X- _ O
comitative -X- _ O
) -X- _ O
and -X- _ O
as -X- _ O
a -X- _ O
result -X- _ O
wrote -X- _ O
the -X- _ O
1plInclusive -X- _ O
as -X- _ O
an -X- _ O
independent -X- _ O
pronoun -X- _ O
and -X- _ O
not -X- _ O
an -X- _ O
enclitic.10 -X- _ O
. -X- _ O
00:00:42.959 -X- _ O
- -X- _ O
> -X- _ O
00:00:49.142 -X- _ O
ASR -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
tan -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
2 -X- _ O
tio -X- _ O
3 -X- _ O
o -X- _ O
2 -X- _ O
yu -X- _ O
3 -X- _ O
ku -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
ba -X- _ O
4 -X- _ O
li -X- _ O
4 -X- _ O
coco -X- _ O
nu -X- _ O
14 -X- _ O
u -X- _ O
3 -X- _ O
ñu -X- _ O
' -X- _ O
3 -X- _ O
u -X- _ O
4 -X- _ O
sa -X- _ O
3 -X- _ O
kan -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2Exp -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
tan -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
2 -X- _ O
tio -X- _ O
3 -X- _ O
o -X- _ O
2 -X- _ O
yu -X- _ O
3 -X- _ O
ku -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
ba -X- _ O
4 -X- _ O
li -X- _ O
4 -X- _ O
ko -X- _ O
4 -X- _ O
ko -X- _ O
13 -X- _ O
nu -X- _ O
14 -X- _ O
u -X- _ O
3 -X- _ O
ñu -X- _ O
' -X- _ O
3 -X- _ O
u -X- _ O
4 -X- _ O
sa -X- _ O
3 -X- _ O
kan -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
ta -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
, -X- _ O
Notes -X- _ O
: -X- _ O
ASR -X- _ B-TaskName
suggested -X- _ O
Spanish -X- _ O
' -X- _ O
coco -X- _ O
' -X- _ O
coconut -X- _ O
for -X- _ O
Mixtec -X- _ O
ko -X- _ O
4 -X- _ O
ko -X- _ O
13 -X- _ O
( -X- _ O
' -X- _ O
to -X- _ O
be -X- _ O
abundant[plants -X- _ O
] -X- _ O
' -X- _ O
) -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
' -X- _ O
coco -X- _ O
' -X- _ O
was -X- _ O
spelled -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
in -X- _ O
Spanish -X- _ O
and -X- _ O
no -X- _ O
tones -X- _ O
were -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
output.11 -X- _ O
. -X- _ O
00:00:49.142 -X- _ O
- -X- _ O
> -X- _ O
00:00:53.458 -X- _ O
ASR -X- _ O
la -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
= -X- _ O
ni -X- _ O
42 -X- _ O
ya -X- _ O
3 -X- _ O
a -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
tan -X- _ O
3 -X- _ O
ti -X- _ O
1 -X- _ O
xin -X- _ O
3 -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
nde -X- _ O
' -X- _ O
3 -X- _ O
e -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
tan -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
ra -X- _ O
2 -X- _ O
xi -X- _ O
4 -X- _ O
yo -X- _ O
13 -X- _ O
ndu -X- _ O
1 -X- _ O
u -X- _ O
4 -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
kwi -X- _ O
4 -X- _ O
i -X- _ O
24 -X- _ O
ba -X- _ O
43 -X- _ O
Exp -X- _ O
la -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
= -X- _ O
ni -X- _ O
42 -X- _ O
ya -X- _ O
3 -X- _ O
a -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
tan -X- _ O
3 -X- _ O
ti -X- _ O
1 -X- _ O
xin -X- _ O
3 -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
nde -X- _ O
' -X- _ O
3 -X- _ O
e -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
tan -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
ra -X- _ O
2 -X- _ O
xi -X- _ O
4 -X- _ O
yo -X- _ O
13 -X- _ O
ndu -X- _ O
1 -X- _ O
u -X- _ O
4 -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
ya -X- _ O
1 -X- _ O
kwi -X- _ O
4 -X- _ O
i -X- _ O
24 -X- _ O
ba -X- _ O
42 -X- _ O
, -X- _ O
Notes -X- _ O
: -X- _ O
ASR -X- _ B-TaskName
missed -X- _ O
tone -X- _ O
42 -X- _ O
, -X- _ O
writing -X- _ O
43 -X- _ O
instead -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
tone -X- _ O
patterns -X- _ O
are -X- _ O
alternate -X- _ O
forms -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
word -X- _ O
, -X- _ O
the -X- _ O
copula -X- _ O
used -X- _ O
in -X- _ O
regards -X- _ O
to -X- _ O
objects.12 -X- _ O
* -X- _ O
. -X- _ O
00:00:53.458 -X- _ O
- -X- _ O
> -X- _ O
00:00:57.279 -X- _ O
ASR -X- _ O
tan -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
ra -X- _ O
2 -X- _ O
chi -X- _ O
4 -X- _ O
chi -X- _ O
13 -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
ndu -X- _ O
1 -X- _ O
u -X- _ O
4 -X- _ O
nde -X- _ O
' -X- _ O
3 -X- _ O
e -X- _ O
4 -X- _ O
ku -X- _ O
4 -X- _ O
u -X- _ O
4 -X- _ O
ndu -X- _ O
1 -X- _ O
u -X- _ O
4 -X- _ O
= -X- _ O
a -X- _ O
3 -X- _ O
Exp -X- _ O
tan -X- _ O
3 -X- _ O
o -X- _ O
4 -X- _ O
ra -X- _ O
2 -X- _ O
chi -X- _ O
4 -X- _ O
chi -X- _ O
13 -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
ndu -X- _ O
1 -X- _ O
u -X- _ O
4 -X- _ O
nde -X- _ O
' -X- _ O
3 -X- _ O
e -X- _ O
4 -X- _ O
ku -X- _ O
4 -X- _ O
u -X- _ O
4 -X- _ O
ndu -X- _ O
1 -X- _ O
u -X- _ O
4 -X- _ O
= -X- _ O
a -X- _ O
3 -X- _ O
. -X- _ O
Notes -X- _ O
: -X- _ O
No -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ O
hypothesis.13 -X- _ O
* -X- _ O
. -X- _ O
00:00:57.279 -X- _ O
- -X- _ O
> -X- _ O
00:01:02.728 -X- _ O
ASR -X- _ O
yu -X- _ O
1 -X- _ O
ku -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
1 -X- _ O
ndi -X- _ O
4 -X- _ O
tan -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
ni -X- _ O
1 -X- _ O
-xa -X- _ O
' -X- _ O
3 -X- _ O
nda -X- _ O
2 -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
tan -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
yu -X- _ O
1 -X- _ O
ku -X- _ O
1 -X- _ O
tun -X- _ O
4 -X- _ O
si -X- _ O
13 -X- _ O
su -X- _ O
2 -X- _ O
kan -X- _ O
4 -X- _ O
sa -X- _ O
3 -X- _ O
kan -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
yu -X- _ O
1 -X- _ O
ku -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
1 -X- _ O
tan -X- _ O
3 -X- _ O
ndi -X- _ O
4 -X- _ O
Exp -X- _ O
Yu -X- _ O
1 -X- _ O
ku -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
1 -X- _ O
ndi -X- _ O
4 -X- _ O
tan -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
ni -X- _ O
1 -X- _ O
-xa -X- _ O
' -X- _ O
3 -X- _ O
nda -X- _ O
2 -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
tan -X- _ O
42 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
yu -X- _ O
1 -X- _ O
ku -X- _ O
1 -X- _ O
tun -X- _ O
4 -X- _ O
si -X- _ O
13 -X- _ O
su -X- _ O
2 -X- _ O
kan -X- _ O
4 -X- _ O
sa -X- _ O
3 -X- _ O
kan -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
yu -X- _ O
1 -X- _ O
ku -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
1 -X- _ O
tan -X- _ O
3 -X- _ O
ndi -X- _ O
4 -X- _ O
Notes -X- _ O
: -X- _ O
No -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
hypothesis.14 -X- _ O
. -X- _ O
00:01:02.728 -X- _ O
- -X- _ O
> -X- _ O
00:01:06.296 -X- _ O
ASR -X- _ O
su -X- _ O
14 -X- _ O
u -X- _ O
3 -X- _ O
ya -X- _ O
1 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nda -X- _ O
2 -X- _ O
= -X- _ O
na -X- _ O
1 -X- _ O
ba -X- _ O
42 -X- _ O
ndi -X- _ O
4 -X- _ O
su -X- _ O
14 -X- _ O
u -X- _ O
3 -X- _ O
ki -X- _ O
3 -X- _ O
ti -X- _ O
4 -X- _ O
ja -X- _ O
4 -X- _ O
xi -X- _ O
24 -X- _ O
= -X- _ O
ri -X- _ O
4 -X- _ O
sa -X- _ O
3 -X- _ O
kan -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
yu -X- _ O
1 -X- _ O
ku -X- _ O
1 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ba -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
3 -X- _ O
Exp -X- _ O
su -X- _ O
14 -X- _ O
u -X- _ O
3 -X- _ O
ya -X- _ O
1 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nda -X- _ O
2 -X- _ O
= -X- _ O
na -X- _ O
1 -X- _ O
ba -X- _ O
42 -X- _ O
tan -X- _ O
3 -X- _ O
ni -X- _ O
4 -X- _ O
su -X- _ O
14 -X- _ O
u -X- _ O
3 -X- _ O
ki -X- _ O
3 -X- _ O
ti -X- _ O
4 -X- _ O
ja -X- _ O
4 -X- _ O
xi -X- _ O
24 -X- _ O
= -X- _ O
ri -X- _ O
4 -X- _ O
, -X- _ O
sa -X- _ O
3 -X- _ O
kan -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
in -X- _ O
4 -X- _ O
yu -X- _ O
1 -X- _ O
ku -X- _ O
1 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ba -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
3 -X- _ O
, -X- _ O
Notes -X- _ O
: -X- _ O
ASR -X- _ B-TaskName
mistakenly -X- _ O
proposed -X- _ O
ndi -X- _ O
4 -X- _ O
for -X- _ O
tan -X- _ O
3 -X- _ O
ni -X- _ O
4 -X- _ O
.15 -X- _ O
* -X- _ O
. -X- _ O
00:01:06.296 -X- _ O
- -X- _ O
> -X- _ O
00:01:10.981 -X- _ O
ASR -X- _ O
tan -X- _ O
3 -X- _ O
ya -X- _ O
1 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nu -X- _ O
3 -X- _ O
su -X- _ O
4 -X- _ O
kun -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
1 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ti -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
sa -X- _ O
3 -X- _ O
ba -X- _ O
3 -X- _ O
xia -X- _ O
4 -X- _ O
an -X- _ O
4 -X- _ O
ku -X- _ O
3 -X- _ O
ta -X- _ O
' -X- _ O
3 -X- _ O
an -X- _ O
2 -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nu -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
kwa -X- _ O
1 -X- _ O
nda -X- _ O
3 -X- _ O
a -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
nda -X- _ O
' -X- _ O
3 -X- _ O
a -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
Exp -X- _ O
tan -X- _ O
3 -X- _ O
ya -X- _ O
1 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nu -X- _ O
3 -X- _ O
su -X- _ O
4 -X- _ O
kun -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
1 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ti -X- _ O
4 -X- _ O
ba -X- _ O
42 -X- _ O
sa -X- _ O
3 -X- _ O
ba -X- _ O
3 -X- _ O
xia -X- _ O
4 -X- _ O
an -X- _ O
4 -X- _ O
ku -X- _ O
3 -X- _ O
ta -X- _ O
' -X- _ O
3 -X- _ O
an -X- _ O
2 -X- _ O
= -X- _ O
e -X- _ O
4 -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ndi -X- _ O
4 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nu -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
kwa -X- _ O
1 -X- _ O
nda -X- _ O
3 -X- _ O
a -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
nda -X- _ O
' -X- _ O
3 -X- _ O
a -X- _ O
4 -X- _ O
i -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
Notes -X- _ O
: -X- _ O
No -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ O
hypothesis.16 -X- _ O
. -X- _ O
00:01:10.981 -X- _ O
- -X- _ O
> -X- _ O
00:01:14.768 -X- _ O
ASR -X- _ O
u -X- _ O
1 -X- _ O
xi -X- _ O
1 -X- _ O
an -X- _ O
4 -X- _ O
nda -X- _ O
1 -X- _ O
xa -X- _ O
' -X- _ O
1 -X- _ O
un -X- _ O
1 -X- _ O
metru -X- _ O
ka -X- _ O
1 -X- _ O
a -X- _ O
3 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
yo -X- _ O
2 -X- _ O
i -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
ndo -X- _ O
3 -X- _ O
o -X- _ O
3 -X- _ O
tan -X- _ O
3 -X- _ O
ko -X- _ O
4 -X- _ O
ko -X- _ O
13 -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
kwa -X- _ O
1 -X- _ O
nde -X- _ O
3 -X- _ O
e -X- _ O
3 -X- _ O
ni -X- _ O
1 -X- _ O
nu -X- _ O
3 -X- _ O
Exp -X- _ O
u -X- _ O
1 -X- _ O
xi -X- _ O
1 -X- _ O
an -X- _ O
4 -X- _ O
nda -X- _ O
1 -X- _ O
xa -X- _ O
' -X- _ O
1 -X- _ O
un -X- _ O
1 -X- _ O
metru -X- _ O
ka -X- _ O
1 -X- _ O
a -X- _ O
3 -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
yo -X- _ O
2 -X- _ O
i -X- _ O
3 -X- _ O
tun -X- _ O
4 -X- _ O
ndo -X- _ O
3 -X- _ O
o -X- _ O
3 -X- _ O
tan -X- _ O
3 -X- _ O
ko -X- _ O
4 -X- _ O
ko -X- _ O
13 -X- _ O
= -X- _ O
a -X- _ O
2 -X- _ O
kwa -X- _ O
1 -X- _ O
nda -X- _ O
3 -X- _ O
a -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
ni -X- _ O
1 -X- _ O
nu -X- _ O
3 -X- _ O
, -X- _ O
Notes -X- _ O
: -X- _ O
Not -X- _ O
only -X- _ O
did -X- _ O
ASR -X- _ O
recognize -X- _ O
the -X- _ O
Spanish -X- _ O
metru -X- _ O
borrowing -X- _ O
but -X- _ O
wrote -X- _ O
it -X- _ O
according -X- _ O
to -X- _ O
our -X- _ O
conventions -X- _ O
, -X- _ O
without -X- _ O
tone -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
correct -X- _ O
underlying -X- _ O
form -X- _ O
kwa -X- _ O
1 -X- _ O
nda -X- _ O
3 -X- _ O
a -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
( -X- _ O
progressive -X- _ O
of -X- _ O
' -X- _ O
to -X- _ O
climb -X- _ O
[ -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
vine -X- _ O
] -X- _ O
' -X- _ O
with -X- _ O
3sg -X- _ O
enclitic -X- _ O
for -X- _ O
inanimates -X- _ O
= -X- _ O
e -X- _ O
2 -X- _ O
) -X- _ O
surfaces -X- _ O
as -X- _ O
kwa -X- _ O
1 -X- _ O
nde -X- _ O
3 -X- _ O
e -X- _ O
2 -X- _ O
quite -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
ASR -X- _ O
hypothesis -X- _ O
of -X- _ O
kwa -X- _ O
1 -X- _ O
nde -X- _ O
3 -X- _ O
e -X- _ O
3 -X- _ O
, -X- _ O
which -X- _ O
exists -X- _ O
, -X- _ O
but -X- _ O
as -X- _ O
a -X- _ O
distinct -X- _ O
word -X- _ O
( -X- _ O
progressive -X- _ O
of -X- _ O
' -X- _ O
to -X- _ O
enter[pl]').17 -X- _ O
* -X- _ O
. -X- _ O
00:01:14.768 -X- _ O
- -X- _ O
> -X- _ O
00:01:18.281 -X- _ O
ASR -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ba -X- _ O
143 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nda -X- _ O
2 -X- _ O
= -X- _ O
na -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
1 -X- _ O
ndi -X- _ O
4 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nu -X- _ O
3 -X- _ O
su -X- _ O
4 -X- _ O
kun -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
1 -X- _ O
Exp -X- _ O
mi -X- _ O
4 -X- _ O
i -X- _ O
4 -X- _ O
ba -X- _ O
143 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nda -X- _ O
2 -X- _ O
= -X- _ O
na -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
e -X- _ O
1 -X- _ O
ndi -X- _ O
4 -X- _ O
xa -X- _ O
' -X- _ O
4 -X- _ O
nu -X- _ O
3 -X- _ O
su -X- _ O
4 -X- _ O
kun -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
a -X- _ O
1 -X- _ O
, -X- _ O
Notes -X- _ O
: -X- _ O
No -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
hypothesis -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
gratefully -X- _ O
acknowledge -X- _ O
the -X- _ O
following -X- _ O
support -X- _ O
for -X- _ O
documenting -X- _ O
and -X- _ O
studying -X- _ O
Yoloxóchitl -X- _ O
Mixtec -X- _ O
: -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
, -X- _ O
Documenting -X- _ O
Endangered -X- _ O
Languages -X- _ O
( -X- _ O
DEL -X- _ O
): -X- _ O
Awards -X- _ O
1761421 -X- _ O
, -X- _ O
1500595 -X- _ O
, -X- _ O
0966462 -X- _ O
( -X- _ O
Amith -X- _ O
, -X- _ O
PI -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
; -X- _ O
the -X- _ O
second -X- _ O
was -X- _ O
a -X- _ O
collaborative -X- _ O
project -X- _ O
with -X- _ O
SRI -X- _ O
International -X- _ O
, -X- _ O
Award -X- _ O
1500738 -X- _ O
, -X- _ O
Andreas -X- _ O
Kathol -X- _ O
, -X- _ O
PI -X- _ O
) -X- _ O
; -X- _ O
Endangered -X- _ O
Language -X- _ O
Documentation -X- _ O
Programme -X- _ O
: -X- _ O
Awards -X- _ O
MDP0201 -X- _ O
, -X- _ O
PPG0048 -X- _ O
( -X- _ O
Amith -X- _ O
, -X- _ O
PI -X- _ O
on -X- _ O
both -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
support -X- _ O
is -X- _ O
acknowledged -X- _ O
for -X- _ O
documenting -X- _ O
and -X- _ O
studying -X- _ O
Highland -X- _ O
Puebla -X- _ O
Nahuat -X- _ O
: -X- _ O
NSF -X- _ O
DEL -X- _ O
: -X- _ O
Awards -X- _ O
: -X- _ O
1401178 -X- _ O
, -X- _ O
0756536 -X- _ O
( -X- _ O
Amith -X- _ O
, -X- _ O
PI -X- _ O
on -X- _ O
both -X- _ O
awards -X- _ O
) -X- _ O
; -X- _ O
National -X- _ O
Endowment -X- _ O
for -X- _ O
the -X- _ O
Humanities -X- _ O
, -X- _ O
Preservation -X- _ O
and -X- _ O
Access -X- _ O
: -X- _ O
PD-50031 -X- _ O
- -X- _ O
14 -X- _ O
( -X- _ O
Amith -X- _ O
, -X- _ O
PI -X- _ O
) -X- _ O
; -X- _ O
Endangered -X- _ O
Language -X- _ O
Documentation -X- _ O
Programme -X- _ O
: -X- _ O
Award -X- _ O
MDP0272 -X- _ O
( -X- _ O
Amith -X- _ O
, -X- _ O
PI -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
the -X- _ O
Comisión -X- _ O
Nacional -X- _ O
para -X- _ O
el -X- _ O
Conocimiento -X- _ O
y -X- _ O
Uso -X- _ O
de -X- _ O
la -X- _ O
Biodiversidad -X- _ O
, -X- _ O
Mexico -X- _ O
( -X- _ O
Gerardo -X- _ O
Salazar -X- _ O
, -X- _ O
PI -X- _ O
; -X- _ O
Amith -X- _ O
, -X- _ O
co -X- _ O
- -X- _ O
PI -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
FOMA -X- _ O
FST -X- _ O
for -X- _ O
Yoloxóchitl -X- _ O
Mixtec -X- _ O
was -X- _ O
built -X- _ O
by -X- _ O
Jason -X- _ O
Lilley -X- _ O
, -X- _ O
Amith -X- _ O
, -X- _ O
and -X- _ O
Castillo -X- _ O
with -X- _ O
support -X- _ O
from -X- _ O
NSF -X- _ O
DEL -X- _ O
Award -X- _ O
1360670 -X- _ O
( -X- _ O
Christian -X- _ O
DiCanio -X- _ O
, -X- _ O
PI).Finally -X- _ O
, -X- _ O
the -X- _ O
authors -X- _ O
thank -X- _ O
Shinji -X- _ O
Watanabe -X- _ O
both -X- _ O
for -X- _ O
his -X- _ O
advice -X- _ O
and -X- _ O
guidance -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
key -X- _ O
role -X- _ O
he -X- _ O
played -X- _ O
in -X- _ O
bringing -X- _ O
together -X- _ O
a -X- _ O
field -X- _ O
linguist -X- _ O
, -X- _ O
a -X- _ O
native -X- _ O
speaker -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
computational -X- _ O
linguist -X- _ O
for -X- _ O
this -X- _ O
project -X- _ O
. -X- _ O

Most -X- _ O
language -X- _ O
understanding -X- _ O
models -X- _ O
in -X- _ O
taskoriented -X- _ O
dialog -X- _ O
systems -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
annotated -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
evaluated -X- _ O
in -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
distribution -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
system -X- _ O
failure -X- _ O
or -X- _ O
undesirable -X- _ O
output -X- _ O
when -X- _ O
being -X- _ O
exposed -X- _ O
to -X- _ O
natural -X- _ O
language -X- _ O
perturbation -X- _ O
or -X- _ O
variation -X- _ O
in -X- _ O
practice -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
comprehensive -X- _ O
evaluation -X- _ O
and -X- _ O
analysis -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
robustness -X- _ B-TaskName
of -X- _ I-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
models -X- _ I-TaskName
, -X- _ O
and -X- _ O
introduce -X- _ O
three -X- _ O
important -X- _ O
aspects -X- _ O
related -X- _ O
to -X- _ O
language -X- _ O
understanding -X- _ O
in -X- _ O
realworld -X- _ O
dialog -X- _ O
systems -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
language -X- _ O
variety -X- _ O
, -X- _ O
speech -X- _ O
characteristics -X- _ O
, -X- _ O
and -X- _ O
noise -X- _ O
perturbation -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
toolkit -X- _ O
LAUG -X- _ B-MethodName
to -X- _ O
approximate -X- _ O
natural -X- _ O
language -X- _ O
perturbations -X- _ O
for -X- _ O
testing -X- _ O
the -X- _ O
robustness -X- _ B-TaskName
issues -X- _ I-TaskName
in -X- _ I-TaskName
taskoriented -X- _ I-TaskName
dialog -X- _ I-TaskName
. -X- _ O
Four -X- _ O
data -X- _ O
augmentation -X- _ O
approaches -X- _ O
covering -X- _ O
the -X- _ O
three -X- _ O
aspects -X- _ O
are -X- _ O
assembled -X- _ O
in -X- _ O
LAUG -X- _ B-MethodName
, -X- _ O
which -X- _ O
reveals -X- _ O
critical -X- _ O
robustness -X- _ O
issues -X- _ O
in -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
augmented -X- _ O
dataset -X- _ O
through -X- _ O
LAUG -X- _ B-MethodName
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
facilitate -X- _ O
future -X- _ O
research -X- _ O
on -X- _ O
the -X- _ O
robustness -X- _ B-TaskName
testing -X- _ I-TaskName
of -X- _ I-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
in -X- _ I-TaskName
task -X- _ I-TaskName
- -X- _ I-TaskName
oriented -X- _ I-TaskName
dialog -X- _ I-TaskName
. -X- _ O
Recently -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
dialog -X- _ O
systems -X- _ O
have -X- _ O
been -X- _ O
attracting -X- _ O
more -X- _ O
and -X- _ O
more -X- _ O
research -X- _ O
efforts -X- _ O
( -X- _ O
Gao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
understanding -X- _ O
user -X- _ O
utterances -X- _ O
is -X- _ O
a -X- _ O
critical -X- _ O
precursor -X- _ O
to -X- _ O
the -X- _ O
success -X- _ O
of -X- _ O
such -X- _ O
dialog -X- _ O
systems -X- _ O
. -X- _ O
While -X- _ O
modern -X- _ O
neural -X- _ O
networks -X- _ O
have -X- _ O
achieved -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
language -X- _ O
understanding -X- _ O
( -X- _ O
LU -X- _ O
) -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Zhao -X- _ O
and -X- _ O
Feng -X- _ O
, -X- _ O
2018;Goo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Shah -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
their -X- _ O
robustness -X- _ O
to -X- _ O
changes -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
distribution -X- _ O
is -X- _ O
still -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
biggest -X- _ O
challenges -X- _ O
in -X- _ O
practical -X- _ O
use -X- _ O
. -X- _ O
Real -X- _ O
dialogs -X- _ O
between -X- _ O
human -X- _ O
participants -X- _ O
involve -X- _ O
language -X- _ O
phenomena -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
contribute -X- _ O
so -X- _ O
much -X- _ O
to -X- _ O
the -X- _ O
intent -X- _ O
of -X- _ O
communication -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1 -X- _ O
, -X- _ O
user -X- _ O
expressions -X- _ O
can -X- _ O
be -X- _ O
of -X- _ O
high -X- _ O
lexical -X- _ O
and -X- _ O
syntactic -X- _ O
diversity -X- _ O
when -X- _ O
a -X- _ O
system -X- _ O
is -X- _ O
deployed -X- _ O
to -X- _ O
users -X- _ O
; -X- _ O
typed -X- _ O
texts -X- _ O
may -X- _ O
differ -X- _ O
significantly -X- _ O
from -X- _ O
those -X- _ O
recognized -X- _ O
from -X- _ O
voice -X- _ O
speech -X- _ O
; -X- _ O
interaction -X- _ O
environments -X- _ O
may -X- _ O
be -X- _ O
full -X- _ O
of -X- _ O
chaos -X- _ O
and -X- _ O
even -X- _ O
users -X- _ O
themselves -X- _ O
may -X- _ O
introduce -X- _ O
irrelevant -X- _ O
noises -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
system -X- _ O
can -X- _ O
hardly -X- _ O
get -X- _ O
clean -X- _ O
user -X- _ O
input -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
neural -X- _ O
LU -X- _ O
models -X- _ O
are -X- _ O
vulnerable -X- _ O
to -X- _ O
these -X- _ O
natural -X- _ O
perturbations -X- _ O
that -X- _ O
are -X- _ O
legitimate -X- _ O
inputs -X- _ O
but -X- _ O
not -X- _ O
observed -X- _ O
in -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Bickmore -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
found -X- _ O
that -X- _ O
popular -X- _ O
conversational -X- _ O
assistants -X- _ O
frequently -X- _ O
failed -X- _ O
to -X- _ O
understand -X- _ O
real -X- _ O
health -X- _ O
- -X- _ O
related -X- _ O
scenarios -X- _ O
and -X- _ O
were -X- _ O
unable -X- _ O
to -X- _ O
deliver -X- _ O
adequate -X- _ O
responses -X- _ O
on -X- _ O
time -X- _ O
. -X- _ O
Although -X- _ O
many -X- _ O
studies -X- _ O
have -X- _ O
discussed -X- _ O
the -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
( -X- _ O
Ray -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Iyyer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Yoo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
systematic -X- _ O
studies -X- _ O
for -X- _ O
real -X- _ O
- -X- _ O
life -X- _ O
robustness -X- _ O
issues -X- _ O
and -X- _ O
corresponding -X- _ O
benchmarks -X- _ O
for -X- _ O
evaluating -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
dialog -X- _ O
systems -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
robustness -X- _ O
issues -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
the -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
from -X- _ O
three -X- _ O
aspects -X- _ O
: -X- _ O
language -X- _ O
variety -X- _ O
, -X- _ O
speech -X- _ O
characteristics -X- _ O
and -X- _ O
noise -X- _ O
perturbation -X- _ O
. -X- _ O
While -X- _ O
collecting -X- _ O
dialogs -X- _ O
from -X- _ O
deployed -X- _ O
systems -X- _ O
could -X- _ O
obtain -X- _ O
realistic -X- _ O
data -X- _ O
distribution -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
quite -X- _ O
costly -X- _ O
and -X- _ O
not -X- _ O
scalable -X- _ O
since -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
conversational -X- _ O
interactions -X- _ O
with -X- _ O
real -X- _ O
users -X- _ O
are -X- _ O
required -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
automatic -X- _ O
method -X- _ O
LAUG -X- _ B-MethodName
for -X- _ O
Language -X- _ B-MethodName
understanding -X- _ I-MethodName
AUGmentation -X- _ I-MethodName
in -X- _ O
this -X- _ O
paper -X- _ O
to -X- _ O
approximate -X- _ O
the -X- _ O
natural -X- _ O
perturbations -X- _ O
to -X- _ O
existing -X- _ O
data -X- _ O
. -X- _ O
LAUG -X- _ B-MethodName
is -X- _ O
a -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
testing -X- _ O
toolkit -X- _ O
on -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
composed -X- _ O
of -X- _ O
four -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
, -X- _ O
including -X- _ O
word -X- _ B-TaskName
perturbation -X- _ I-TaskName
, -X- _ O
text -X- _ B-TaskName
paraphrasing -X- _ I-TaskName
, -X- _ O
speech -X- _ B-TaskName
recognition -X- _ I-TaskName
, -X- _ O
and -X- _ O
speech -X- _ B-TaskName
disfluency -X- _ I-TaskName
. -X- _ O
We -X- _ O
instantiate -X- _ O
LAUG -X- _ B-MethodName
on -X- _ O
two -X- _ O
dialog -X- _ O
corporaFrames -X- _ B-DatasetName
( -X- _ O
El -X- _ O
Asri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
MultiWOZ -X- _ B-DatasetName
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
demonstrate -X- _ O
the -X- _ O
toolkit -X- _ O
's -X- _ O
effectiveness -X- _ O
. -X- _ O
Quality -X- _ O
evaluation -X- _ O
by -X- _ O
annotators -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
utterances -X- _ O
augmented -X- _ O
by -X- _ O
LAUG -X- _ B-MethodName
are -X- _ O
reasonable -X- _ O
and -X- _ O
appropriate -X- _ O
with -X- _ O
regards -X- _ O
to -X- _ O
each -X- _ O
augmentation -X- _ O
approach -X- _ O
's -X- _ O
target -X- _ O
. -X- _ O
A -X- _ O
number -X- _ O
of -X- _ O
LU -X- _ O
models -X- _ O
with -X- _ O
different -X- _ O
categories -X- _ O
and -X- _ O
training -X- _ O
paradigms -X- _ O
are -X- _ O
tested -X- _ O
as -X- _ O
base -X- _ O
models -X- _ O
with -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
analysis -X- _ O
. -X- _ O
Experiments -X- _ O
indicate -X- _ O
a -X- _ O
sharp -X- _ O
performance -X- _ O
decline -X- _ O
in -X- _ O
most -X- _ O
baselines -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
each -X- _ O
robustness -X- _ O
aspect -X- _ O
. -X- _ O
Real -X- _ O
user -X- _ O
evaluation -X- _ O
further -X- _ O
verifies -X- _ O
that -X- _ O
LAUG -X- _ B-MethodName
well -X- _ O
reflects -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
robustness -X- _ O
issues -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
toolkit -X- _ O
is -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
model -X- _ O
parameters -X- _ O
or -X- _ O
gradients -X- _ O
, -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
obtained -X- _ O
for -X- _ O
both -X- _ O
training -X- _ O
and -X- _ O
testing -X- _ O
to -X- _ O
build -X- _ O
a -X- _ O
robust -X- _ O
dialog -X- _ O
system -X- _ O
. -X- _ O
Our -X- _ O
contributions -X- _ O
can -X- _ O
be -X- _ O
summarized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
classify -X- _ O
the -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
systematically -X- _ O
into -X- _ O
three -X- _ O
aspects -X- _ O
that -X- _ O
occur -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
dialog -X- _ O
, -X- _ O
including -X- _ O
linguistic -X- _ O
variety -X- _ O
, -X- _ O
speech -X- _ O
characteristics -X- _ O
and -X- _ O
noise -X- _ O
perturbation -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
general -X- _ O
and -X- _ O
model -X- _ O
- -X- _ O
agnostic -X- _ O
toolkit -X- _ O
, -X- _ O
LAUG -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
an -X- _ O
integration -X- _ O
of -X- _ O
four -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
on -X- _ O
LU -X- _ O
that -X- _ O
covers -X- _ O
the -X- _ O
three -X- _ O
aspects -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
conduct -X- _ O
an -X- _ O
in -X- _ O
- -X- _ O
depth -X- _ O
analysis -X- _ O
of -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
on -X- _ O
two -X- _ O
dialog -X- _ O
corpora -X- _ O
with -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
baselines -X- _ O
and -X- _ O
standardized -X- _ O
evaluation -X- _ O
measures -X- _ O
. -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
Quality -X- _ O
and -X- _ O
user -X- _ O
evaluation -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
are -X- _ O
representative -X- _ O
of -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
noisy -X- _ O
data -X- _ O
, -X- _ O
therefore -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
future -X- _ O
research -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
in -X- _ I-TaskName
task -X- _ I-TaskName
- -X- _ I-TaskName
oriented -X- _ I-TaskName
dialog -X- _ I-TaskName
1 -X- _ O
. -X- _ O
We -X- _ O
summarize -X- _ O
several -X- _ O
common -X- _ O
interleaved -X- _ O
challenges -X- _ O
in -X- _ O
language -X- _ O
understanding -X- _ O
from -X- _ O
three -X- _ O
aspects -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
1b -X- _ O
: -X- _ O
Language -X- _ O
Variety -X- _ O
A -X- _ O
modern -X- _ O
dialog -X- _ O
system -X- _ O
in -X- _ O
a -X- _ O
text -X- _ O
form -X- _ O
has -X- _ O
to -X- _ O
interact -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
variety -X- _ O
of -X- _ O
real -X- _ O
users -X- _ O
. -X- _ O
The -X- _ O
user -X- _ O
utterances -X- _ O
can -X- _ O
be -X- _ O
characterized -X- _ O
by -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
linguistic -X- _ O
phenomena -X- _ O
with -X- _ O
a -X- _ O
long -X- _ O
tail -X- _ O
of -X- _ O
variations -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
spelling -X- _ O
, -X- _ O
vocabulary -X- _ O
, -X- _ O
lexical -X- _ O
/ -X- _ O
syntactic -X- _ O
/ -X- _ O
pragmatic -X- _ O
choice -X- _ O
( -X- _ O
Ray -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Ganhotra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
dialog -X- _ O
system -X- _ O
can -X- _ O
take -X- _ O
voice -X- _ O
input -X- _ O
or -X- _ O
typed -X- _ O
text -X- _ O
, -X- _ O
but -X- _ O
these -X- _ O
two -X- _ O
differ -X- _ O
in -X- _ O
many -X- _ O
ways -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
written -X- _ O
language -X- _ O
1 -X- _ O
The -X- _ O
data -X- _ O
, -X- _ O
toolkit -X- _ O
, -X- _ O
and -X- _ O
codes -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https -X- _ O
: -X- _ O
//github.com -X- _ O
/ -X- _ O
thu -X- _ O
- -X- _ O
coai -X- _ O
/ -X- _ O
LAUG -X- _ O
, -X- _ O
and -X- _ O
will -X- _ O
be -X- _ O
merged -X- _ O
into -X- _ O
https://github.com/thu-coai/ConvLab-2 -X- _ O
. -X- _ O
tends -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
complex -X- _ O
and -X- _ O
intricate -X- _ O
with -X- _ O
longer -X- _ O
sentences -X- _ O
and -X- _ O
many -X- _ O
subordinate -X- _ O
clauses -X- _ O
, -X- _ O
whereas -X- _ O
spoken -X- _ O
language -X- _ O
can -X- _ O
contain -X- _ O
repetitions -X- _ O
, -X- _ O
incomplete -X- _ O
sentences -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
corrections -X- _ O
and -X- _ O
interruptions -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a;Park -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b;Honal -X- _ O
and -X- _ O
Schultz -X- _ O
, -X- _ O
2003;Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).Noise -X- _ O
Perturbation -X- _ O
Most -X- _ O
dialog -X- _ O
systems -X- _ O
are -X- _ O
trained -X- _ O
only -X- _ O
on -X- _ O
noise -X- _ O
- -X- _ O
free -X- _ O
interactions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
various -X- _ O
noises -X- _ O
in -X- _ O
the -X- _ O
real -X- _ O
world -X- _ O
, -X- _ O
including -X- _ O
background -X- _ O
noise -X- _ O
, -X- _ O
channel -X- _ O
noise -X- _ O
, -X- _ O
misspelling -X- _ O
, -X- _ O
and -X- _ O
grammar -X- _ O
mistakes -X- _ O
( -X- _ O
Xu -X- _ O
and -X- _ O
Sarikaya -X- _ O
, -X- _ O
2014;Li -X- _ O
and -X- _ O
Qiu -X- _ O
, -X- _ O
2020;Yoo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012;Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
section -X- _ O
introduces -X- _ O
commonly -X- _ O
observed -X- _ O
out -X- _ O
- -X- _ O
ofdistribution -X- _ O
data -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
dialog -X- _ O
into -X- _ O
existing -X- _ O
corpora -X- _ O
. -X- _ O
We -X- _ O
approximate -X- _ O
natural -X- _ O
perturbations -X- _ O
in -X- _ O
an -X- _ O
automatic -X- _ O
way -X- _ O
instead -X- _ O
of -X- _ O
collecting -X- _ O
real -X- _ O
data -X- _ O
by -X- _ O
asking -X- _ O
users -X- _ O
to -X- _ O
converse -X- _ O
with -X- _ O
a -X- _ O
dialog -X- _ O
system -X- _ O
. -X- _ O
values -X- _ O
of -X- _ O
dialog -X- _ O
acts -X- _ O
are -X- _ O
not -X- _ O
modified -X- _ O
in -X- _ O
these -X- _ O
four -X- _ O
operations -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
slot -X- _ O
value -X- _ O
replacement -X- _ O
, -X- _ O
which -X- _ O
changes -X- _ O
the -X- _ O
utterance -X- _ O
and -X- _ O
label -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
to -X- _ O
test -X- _ O
model -X- _ O
's -X- _ O
generalization -X- _ O
to -X- _ O
unseen -X- _ O
entities -X- _ O
. -X- _ O
Some -X- _ O
randomly -X- _ O
picked -X- _ O
slot -X- _ O
values -X- _ O
are -X- _ O
replaced -X- _ O
by -X- _ O
unseen -X- _ O
values -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
slot -X- _ O
name -X- _ O
in -X- _ O
the -X- _ O
database -X- _ O
or -X- _ O
crawled -X- _ O
from -X- _ O
web -X- _ O
sources -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
, -X- _ O
" -X- _ O
Cambridge -X- _ O
" -X- _ O
is -X- _ O
replaced -X- _ O
by -X- _ O
" -X- _ O
Liverpool -X- _ O
" -X- _ O
, -X- _ O
where -X- _ O
both -X- _ O
belong -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
slot -X- _ O
name -X- _ O
" -X- _ O
dest -X- _ O
" -X- _ O
( -X- _ O
destination).Synonym -X- _ O
replacement -X- _ O
and -X- _ O
slot -X- _ O
value -X- _ O
replacement -X- _ O
aim -X- _ O
at -X- _ O
increasing -X- _ O
the -X- _ O
language -X- _ O
variety -X- _ O
, -X- _ O
while -X- _ O
random -X- _ O
word -X- _ O
insertion -X- _ O
/ -X- _ O
deletion -X- _ O
/ -X- _ O
swap -X- _ O
test -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
noise -X- _ O
perturbation -X- _ O
. -X- _ O
From -X- _ O
another -X- _ O
perspective -X- _ O
, -X- _ O
four -X- _ O
operations -X- _ O
from -X- _ O
EDA -X- _ O
perform -X- _ O
an -X- _ O
Invariance -X- _ O
test -X- _ O
, -X- _ O
while -X- _ O
slot -X- _ O
value -X- _ O
replacement -X- _ O
conducts -X- _ O
a -X- _ O
Directional -X- _ O
Expectation -X- _ O
test -X- _ O
according -X- _ O
to -X- _ O
CheckList -X- _ O
( -X- _ O
Ribeiro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).Text -X- _ O
Paraphrasing -X- _ O
The -X- _ O
target -X- _ O
of -X- _ O
text -X- _ O
paraphrasing -X- _ O
is -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
new -X- _ O
utterance -X- _ O
x -X- _ O
= -X- _ O
x -X- _ O
while -X- _ O
maintaining -X- _ O
its -X- _ O
dialog -X- _ O
act -X- _ O
unchanged -X- _ O
, -X- _ O
i.e. -X- _ O
y -X- _ O
= -X- _ O
y. -X- _ O
We -X- _ O
applied -X- _ O
SC -X- _ B-MethodName
- -X- _ I-MethodName
GPT -X- _ I-MethodName
, -X- _ O
a -X- _ O
finetuned -X- _ O
language -X- _ O
model -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
dialog -X- _ O
acts -X- _ O
, -X- _ O
to -X- _ O
paraphrase -X- _ O
the -X- _ O
sentences -X- _ O
as -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
it -X- _ O
characterizes -X- _ O
the -X- _ O
conditional -X- _ O
probability -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
x|y -X- _ O
) -X- _ O
= -X- _ O
K -X- _ O
k=1 -X- _ O
p -X- _ O
θ -X- _ O
( -X- _ O
x -X- _ O
k -X- _ O
|x -X- _ O
< -X- _ O
k -X- _ O
, -X- _ O
y -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
x -X- _ O
< -X- _ O
k -X- _ O
denotes -X- _ O
all -X- _ O
the -X- _ O
tokens -X- _ O
before -X- _ O
the -X- _ O
k -X- _ O
- -X- _ O
th -X- _ O
position -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
parameters -X- _ O
θ -X- _ O
are -X- _ O
trained -X- _ O
by -X- _ O
maximizing -X- _ O
the -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
of -X- _ O
p -X- _ O
θ -X- _ O
. -X- _ O
of -X- _ O
examples -X- _ O
that -X- _ O
consider -X- _ O
contextual -X- _ O
resolution -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
user -X- _ O
omits -X- _ O
to -X- _ O
claim -X- _ O
that -X- _ O
he -X- _ O
wants -X- _ O
a -X- _ O
train -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
utterance -X- _ O
since -X- _ O
he -X- _ O
has -X- _ O
mentioned -X- _ O
this -X- _ O
before -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
co -X- _ O
- -X- _ O
reference -X- _ O
and -X- _ O
ellipsis -X- _ O
frequently -X- _ O
occurs -X- _ O
in -X- _ O
user -X- _ O
utterances -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
different -X- _ O
encoding -X- _ O
strategies -X- _ O
during -X- _ O
paraphrasing -X- _ O
to -X- _ O
further -X- _ O
evaluate -X- _ O
each -X- _ O
model -X- _ O
's -X- _ O
capacity -X- _ O
for -X- _ O
context -X- _ O
resolution -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
user -X- _ O
mentions -X- _ O
a -X- _ O
certain -X- _ O
domain -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
in -X- _ O
a -X- _ O
dialog -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
insert -X- _ O
a -X- _ O
" -X- _ O
* -X- _ O
" -X- _ O
mark -X- _ O
into -X- _ O
the -X- _ O
sequential -X- _ O
dialog -X- _ O
act -X- _ O
y -X- _ O
to -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
user -X- _ O
tends -X- _ O
to -X- _ O
express -X- _ O
without -X- _ O
co -X- _ O
- -X- _ O
references -X- _ O
or -X- _ O
ellipsis -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Then -X- _ O
SC -X- _ B-MethodName
- -X- _ I-MethodName
GPT -X- _ I-MethodName
is -X- _ O
finetuned -X- _ O
on -X- _ O
the -X- _ O
processed -X- _ O
data -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
aware -X- _ O
of -X- _ O
dialog -X- _ O
context -X- _ O
when -X- _ O
generating -X- _ O
paraphrases -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
average -X- _ O
token -X- _ O
length -X- _ O
of -X- _ O
generated -X- _ O
utterances -X- _ O
with -X- _ O
/ -X- _ O
without -X- _ O
" -X- _ O
* -X- _ O
" -X- _ O
is -X- _ O
15.96/12.67 -X- _ O
respectively -X- _ O
after -X- _ O
SC -X- _ B-MethodName
- -X- _ I-MethodName
GPT -X- _ I-MethodName
's -X- _ O
finetuning -X- _ O
on -X- _ O
MultiWOZ.It -X- _ B-DatasetName
should -X- _ O
be -X- _ O
noted -X- _ O
that -X- _ O
slot -X- _ O
values -X- _ O
of -X- _ O
an -X- _ O
utterance -X- _ O
can -X- _ O
be -X- _ O
paraphrased -X- _ O
by -X- _ O
models -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
semantic -X- _ O
meaning -X- _ O
y -X- _ O
. -X- _ O
To -X- _ O
prevent -X- _ O
generating -X- _ O
irrelevant -X- _ O
sentences -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
automatic -X- _ B-TaskName
value -X- _ I-TaskName
detection -X- _ I-TaskName
in -X- _ O
paraphrases -X- _ O
with -X- _ O
original -X- _ O
slot -X- _ O
values -X- _ O
by -X- _ O
fuzzy -X- _ O
matching -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
replace -X- _ O
the -X- _ O
detected -X- _ O
values -X- _ O
in -X- _ O
bad -X- _ O
paraphrases -X- _ O
with -X- _ O
original -X- _ O
values -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
filter -X- _ O
out -X- _ O
paraphrases -X- _ O
that -X- _ O
have -X- _ O
missing -X- _ O
or -X- _ O
redundant -X- _ O
information -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
utterance -X- _ O
. -X- _ O
Speech -X- _ B-TaskName
Recognition -X- _ I-TaskName
We -X- _ O
simulate -X- _ O
the -X- _ O
speech -X- _ B-TaskName
recognition -X- _ I-TaskName
( -X- _ O
SR -X- _ B-TaskName
) -X- _ O
process -X- _ O
with -X- _ O
a -X- _ O
TTS -X- _ B-MethodName
- -X- _ I-MethodName
ASR -X- _ I-MethodName
pipeline -X- _ I-MethodName
( -X- _ O
Park -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
First -X- _ O
we -X- _ O
transfer -X- _ O
textual -X- _ O
user -X- _ O
utterance -X- _ O
x -X- _ O
to -X- _ O
its -X- _ O
audio -X- _ O
form -X- _ O
a -X- _ O
using -X- _ O
gTTS -X- _ B-MethodName
4 -X- _ I-MethodName
( -X- _ O
Oord -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
Text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Speech -X- _ O
system -X- _ O
. -X- _ O
Then -X- _ O
audio -X- _ O
data -X- _ O
is -X- _ O
translated -X- _ O
back -X- _ O
into -X- _ O
text -X- _ O
x -X- _ O
by -X- _ O
DeepSpeech2 -X- _ B-MethodName
( -X- _ O
Amodei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
Automatic -X- _ B-MethodName
Speech -X- _ I-MethodName
Recognition -X- _ I-MethodName
( -X- _ I-MethodName
ASR -X- _ I-MethodName
) -X- _ I-MethodName
system -X- _ I-MethodName
. -X- _ O
We -X- _ O
directly -X- _ O
use -X- _ O
the -X- _ O
released -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
DeepSpeech2 -X- _ B-MethodName
repository -X- _ O
5 -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
configuration -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
speech -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
Baidu -X- _ B-DatasetName
Internal -X- _ I-DatasetName
English -X- _ I-DatasetName
Dataset -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
CommonCrawl -X- _ B-DatasetName
Data -X- _ I-DatasetName
. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
some -X- _ O
typical -X- _ O
examples -X- _ O
of -X- _ O
our -X- _ O
SR -X- _ O
augmentation -X- _ O
. -X- _ O
ASR -X- _ B-TaskName
sometimes -X- _ O
wrongly -X- _ O
identifies -X- _ O
one -X- _ O
word -X- _ O
as -X- _ O
another -X- _ O
with -X- _ O
similar -X- _ O
pronunciation -X- _ O
. -X- _ O
Liaison -X- _ O
constantly -X- _ O
occurs -X- _ O
between -X- _ O
successive -X- _ O
words -X- _ O
. -X- _ O
Expressions -X- _ O
with -X- _ O
numbers -X- _ O
including -X- _ O
time -X- _ O
and -X- _ O
price -X- _ O
are -X- _ O
written -X- _ O
in -X- _ O
numerical -X- _ O
form -X- _ O
but -X- _ O
different -X- _ O
in -X- _ O
spoken -X- _ O
language -X- _ O
. -X- _ O
Since -X- _ O
SR -X- _ O
may -X- _ O
modify -X- _ O
the -X- _ O
slot -X- _ O
values -X- _ O
in -X- _ O
the -X- _ O
translated -X- _ O
utterances -X- _ O
, -X- _ O
fuzzy -X- _ O
value -X- _ O
detection -X- _ O
is -X- _ O
employed -X- _ O
here -X- _ O
to -X- _ O
handle -X- _ O
similar -X- _ O
sounds -X- _ O
and -X- _ O
liaison -X- _ O
problems -X- _ O
when -X- _ O
it -X- _ O
extracts -X- _ O
slot -X- _ O
values -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
semantic -X- _ O
label -X- _ O
y -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
replace -X- _ O
the -X- _ O
noisy -X- _ O
value -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
value -X- _ O
as -X- _ O
we -X- _ O
encourage -X- _ O
such -X- _ O
misrecognition -X- _ O
in -X- _ O
SR -X- _ O
, -X- _ O
thus -X- _ O
y -X- _ O
= -X- _ O
y -X- _ O
is -X- _ O
allowed -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
numerical -X- _ O
terms -X- _ O
are -X- _ O
normalized -X- _ O
to -X- _ O
deal -X- _ O
with -X- _ O
the -X- _ O
spoken -X- _ O
number -X- _ O
problem -X- _ O
. -X- _ O
Most -X- _ O
slot -X- _ O
values -X- _ O
could -X- _ O
be -X- _ O
relocated -X- _ O
by -X- _ O
our -X- _ O
automatic -X- _ B-TaskName
value -X- _ I-TaskName
detection -X- _ I-TaskName
rules -X- _ O
. -X- _ O
The -X- _ O
remainder -X- _ O
slot -X- _ O
values -X- _ O
which -X- _ O
vary -X- _ O
too -X- _ O
much -X- _ O
to -X- _ O
recognize -X- _ O
are -X- _ O
discarded -X- _ O
along -X- _ O
with -X- _ O
their -X- _ O
corresponding -X- _ O
labels -X- _ O
. -X- _ O
Speech -X- _ O
Disfluency -X- _ O
Disfluency -X- _ O
is -X- _ O
a -X- _ O
common -X- _ O
feature -X- _ O
of -X- _ O
spoken -X- _ O
language -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
categorization -X- _ O
of -X- _ O
disfluency -X- _ O
in -X- _ O
previous -X- _ O
works -X- _ O
( -X- _ O
Lickley -X- _ O
, -X- _ O
1995;Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
): -X- _ O
filled -X- _ O
pauses -X- _ O
, -X- _ O
repeats -X- _ O
, -X- _ O
restarts -X- _ O
, -X- _ O
and -X- _ O
repairs -X- _ O
. -X- _ O
Original -X- _ O
I -X- _ O
want -X- _ O
to -X- _ O
go -X- _ O
to -X- _ O
Cambridge -X- _ O
. -X- _ O
Pauses -X- _ O
I -X- _ O
want -X- _ O
to -X- _ O
um -X- _ O
go -X- _ O
to -X- _ O
uh -X- _ O
Cambridge -X- _ O
. -X- _ O
Repeats -X- _ O
I -X- _ O
, -X- _ O
I -X- _ O
want -X- _ O
to -X- _ O
go -X- _ O
to -X- _ O
, -X- _ O
go -X- _ O
to -X- _ O
Cambridge -X- _ O
. -X- _ O
Restarts -X- _ O
I -X- _ O
just -X- _ O
I -X- _ O
want -X- _ O
to -X- _ O
go -X- _ O
to -X- _ O
Cambridge -X- _ O
. -X- _ O
Repairs -X- _ O
I -X- _ O
want -X- _ O
to -X- _ O
go -X- _ O
to -X- _ O
Liverpool -X- _ O
, -X- _ O
sorry -X- _ O
I -X- _ O
mean -X- _ O
Cambridge -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
some -X- _ O
examples -X- _ O
of -X- _ O
SD -X- _ B-TaskName
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
Filler -X- _ O
words -X- _ O
( -X- _ O
" -X- _ O
um -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
uh -X- _ O
" -X- _ O
) -X- _ O
are -X- _ O
injected -X- _ O
into -X- _ O
the -X- _ O
sentence -X- _ O
to -X- _ O
present -X- _ O
pauses -X- _ O
. -X- _ O
Repeats -X- _ O
are -X- _ O
inserted -X- _ O
by -X- _ O
repeating -X- _ O
the -X- _ O
previous -X- _ O
word -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
approximate -X- _ O
the -X- _ O
real -X- _ O
distribution -X- _ O
of -X- _ O
disfluency -X- _ O
, -X- _ O
the -X- _ O
interruption -X- _ O
points -X- _ O
of -X- _ O
filled -X- _ O
pauses -X- _ O
and -X- _ O
repeats -X- _ O
are -X- _ O
predicted -X- _ O
by -X- _ O
a -X- _ O
Bi -X- _ B-MethodName
- -X- _ I-MethodName
LSTM+CRF -X- _ I-MethodName
model -X- _ O
( -X- _ O
Zayats -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
trained -X- _ O
on -X- _ O
an -X- _ O
annotated -X- _ O
dataset -X- _ O
SwitchBoard -X- _ B-DatasetName
( -X- _ O
Godfrey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
collected -X- _ O
from -X- _ O
real -X- _ O
human -X- _ O
talks -X- _ O
. -X- _ O
For -X- _ O
restarts -X- _ O
, -X- _ O
we -X- _ O
insert -X- _ O
false -X- _ O
start -X- _ O
terms -X- _ O
( -X- _ O
" -X- _ O
I -X- _ O
just -X- _ O
" -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
prefix -X- _ O
of -X- _ O
the -X- _ O
utterance -X- _ O
to -X- _ O
simulate -X- _ O
self -X- _ O
- -X- _ O
correction -X- _ O
. -X- _ O
In -X- _ O
LU -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
repairs -X- _ O
on -X- _ O
slot -X- _ O
values -X- _ O
to -X- _ O
fool -X- _ O
the -X- _ O
models -X- _ O
to -X- _ O
predict -X- _ O
wrong -X- _ O
labels -X- _ O
. -X- _ O
We -X- _ O
take -X- _ O
the -X- _ O
original -X- _ O
slot -X- _ O
value -X- _ O
as -X- _ O
Repair -X- _ O
( -X- _ O
" -X- _ O
Cambridge -X- _ O
" -X- _ O
) -X- _ O
and -X- _ O
take -X- _ O
another -X- _ O
value -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
slot -X- _ O
name -X- _ O
as -X- _ O
Reparandum -X- _ O
( -X- _ O
" -X- _ O
Liverpool -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
An -X- _ O
edit -X- _ O
term -X- _ O
( -X- _ O
" -X- _ O
sorry -X- _ O
, -X- _ O
I -X- _ O
mean -X- _ O
" -X- _ O
) -X- _ O
is -X- _ O
inserted -X- _ O
between -X- _ O
Repair -X- _ O
and -X- _ O
Reparandum -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
correction -X- _ O
. -X- _ O
The -X- _ O
filler -X- _ O
words -X- _ O
, -X- _ O
restart -X- _ O
terms -X- _ O
, -X- _ O
and -X- _ O
edit -X- _ O
terms -X- _ O
and -X- _ O
their -X- _ O
occurrence -X- _ O
frequency -X- _ O
are -X- _ O
all -X- _ O
sampled -X- _ O
from -X- _ O
their -X- _ O
distribution -X- _ O
in -X- _ O
SwitchBoard -X- _ B-DatasetName
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
keep -X- _ O
the -X- _ O
spans -X- _ O
of -X- _ O
slot -X- _ O
values -X- _ O
intact -X- _ O
, -X- _ O
each -X- _ O
span -X- _ O
is -X- _ O
regarded -X- _ O
as -X- _ O
one -X- _ O
whole -X- _ O
word -X- _ O
. -X- _ O
No -X- _ O
insertions -X- _ O
are -X- _ O
allowed -X- _ O
to -X- _ O
operate -X- _ O
inside -X- _ O
the -X- _ O
span -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
SD -X- _ B-TaskName
augmentation -X- _ O
do -X- _ O
not -X- _ O
change -X- _ O
the -X- _ O
original -X- _ O
semantic -X- _ O
and -X- _ O
labels -X- _ O
of -X- _ O
the -X- _ O
utterance -X- _ O
, -X- _ O
i.e. -X- _ O
y -X- _ O
= -X- _ O
y. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
we -X- _ O
adopt -X- _ O
Frames -X- _ B-DatasetName
6 -X- _ O
( -X- _ O
El -X- _ O
Asri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
MultiWOZ -X- _ B-DatasetName
( -X- _ O
Budzianowski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
two -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
dialog -X- _ O
datasets -X- _ O
where -X- _ O
semantic -X- _ O
labels -X- _ O
of -X- _ O
user -X- _ O
utterances -X- _ O
are -X- _ O
annotated -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
MultiWOZ -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
challenging -X- _ O
datasets -X- _ O
due -X- _ O
to -X- _ O
its -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
setting -X- _ O
and -X- _ O
complex -X- _ O
ontology -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
conduct -X- _ O
our -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
latest -X- _ O
annotation -X- _ O
- -X- _ O
enhanced -X- _ O
version -X- _ O
MultiWOZ -X- _ B-DatasetName
2.3 -X- _ I-DatasetName
( -X- _ O
Han -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
provides -X- _ O
cleaned -X- _ O
annotations -X- _ O
of -X- _ O
user -X- _ O
dialog -X- _ O
acts -X- _ O
( -X- _ O
i.e. -X- _ O
semantic -X- _ O
labels -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
dialog -X- _ O
act -X- _ O
consists -X- _ O
of -X- _ O
four -X- _ O
parts -X- _ O
: -X- _ O
domain -X- _ O
, -X- _ O
intent -X- _ O
, -X- _ O
slot -X- _ O
names -X- _ O
, -X- _ O
and -X- _ O
slot -X- _ O
values -X- _ O
. -X- _ O
The -X- _ O
statistics -X- _ O
of -X- _ O
two -X- _ O
datasets -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
The -X- _ O
data -X- _ O
are -X- _ O
augmented -X- _ O
with -X- _ O
the -X- _ O
inclusion -X- _ O
of -X- _ O
its -X- _ O
copies -X- _ O
, -X- _ O
leading -X- _ O
to -X- _ O
a -X- _ O
composite -X- _ O
of -X- _ O
all -X- _ O
4 -X- _ O
augmentation -X- _ O
types -X- _ O
with -X- _ O
equal -X- _ O
proportion -X- _ O
. -X- _ O
Other -X- _ O
setups -X- _ O
are -X- _ O
described -X- _ O
in -X- _ O
each -X- _ O
experiment -X- _ O
7 -X- _ O
. -X- _ O
Table -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
change -X- _ O
rates -X- _ O
in -X- _ O
different -X- _ O
as- -X- _ O
7 -X- _ O
See -X- _ O
appendix -X- _ O
for -X- _ O
the -X- _ O
hyperparameter -X- _ O
setting -X- _ O
of -X- _ O
LAUG.pects -X- _ B-MethodName
by -X- _ O
comparing -X- _ O
our -X- _ O
augmented -X- _ O
utterances -X- _ O
with -X- _ O
the -X- _ O
original -X- _ O
counterparts -X- _ O
. -X- _ O
We -X- _ O
could -X- _ O
find -X- _ O
each -X- _ O
augmentation -X- _ O
method -X- _ O
has -X- _ O
a -X- _ O
distinct -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
TP -X- _ B-TaskName
rewrites -X- _ O
the -X- _ O
text -X- _ O
without -X- _ O
changing -X- _ O
the -X- _ O
original -X- _ O
meaning -X- _ O
, -X- _ O
thus -X- _ O
lexical -X- _ O
and -X- _ O
syntactic -X- _ O
representations -X- _ O
dramatically -X- _ O
change -X- _ O
, -X- _ O
while -X- _ O
most -X- _ O
slot -X- _ O
values -X- _ O
remain -X- _ O
unchanged -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
SR -X- _ O
makes -X- _ O
the -X- _ O
lowest -X- _ O
change -X- _ O
rate -X- _ O
in -X- _ O
characters -X- _ O
and -X- _ O
words -X- _ O
but -X- _ O
modifies -X- _ O
the -X- _ O
most -X- _ O
slot -X- _ O
values -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
speech -X- _ O
misrecognition -X- _ O
. -X- _ O
To -X- _ O
ensure -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
our -X- _ O
augmented -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
human -X- _ O
annotation -X- _ O
on -X- _ O
1,000 -X- _ O
sampled -X- _ O
utterances -X- _ O
in -X- _ O
each -X- _ O
augmented -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
WOZ -X- _ I-DatasetName
. -X- _ O
We -X- _ O
ask -X- _ O
annotators -X- _ O
to -X- _ O
check -X- _ O
whether -X- _ O
our -X- _ O
augmented -X- _ O
utterances -X- _ O
are -X- _ O
reasonable -X- _ O
and -X- _ O
our -X- _ O
autodetected -X- _ O
value -X- _ O
annotations -X- _ O
are -X- _ O
correct -X- _ O
( -X- _ O
two -X- _ O
true -X- _ O
- -X- _ O
orfalse -X- _ O
questions -X- _ O
) -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
the -X- _ O
feature -X- _ O
of -X- _ O
each -X- _ O
augmentation -X- _ O
method -X- _ O
, -X- _ O
different -X- _ O
evaluation -X- _ O
protocols -X- _ O
are -X- _ O
used -X- _ O
. -X- _ O
For -X- _ O
TP -X- _ B-TaskName
and -X- _ O
SD -X- _ B-TaskName
, -X- _ O
annotators -X- _ O
check -X- _ O
whether -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
utterances -X- _ O
and -X- _ O
dialog -X- _ O
acts -X- _ O
are -X- _ O
unchanged -X- _ O
. -X- _ O
For -X- _ O
WP -X- _ B-TaskName
, -X- _ O
changing -X- _ O
slot -X- _ O
values -X- _ O
is -X- _ O
allowed -X- _ O
due -X- _ O
to -X- _ O
slot -X- _ O
value -X- _ O
replacement -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
slot -X- _ O
name -X- _ O
should -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O
For -X- _ O
SR -X- _ O
, -X- _ O
annotators -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
judge -X- _ O
on -X- _ O
the -X- _ O
similarity -X- _ O
of -X- _ O
pronunciation -X- _ O
rather -X- _ O
than -X- _ O
semantics -X- _ O
. -X- _ O
In -X- _ O
summary -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
high -X- _ O
scores -X- _ O
in -X- _ O
els -X- _ O
( -X- _ O
Liu -X- _ O
and -X- _ O
Lane -X- _ O
, -X- _ O
2016;Zhao -X- _ O
and -X- _ O
Feng -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
generate -X- _ O
a -X- _ O
dialog -X- _ O
act -X- _ O
containing -X- _ O
intent -X- _ O
and -X- _ O
slot -X- _ O
values -X- _ O
. -X- _ O
They -X- _ O
treat -X- _ O
LU -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
problem -X- _ O
and -X- _ O
transform -X- _ O
a -X- _ O
dialog -X- _ O
act -X- _ O
into -X- _ O
a -X- _ O
sequential -X- _ O
structure -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
2b -X- _ O
. -X- _ O
Five -X- _ O
base -X- _ O
models -X- _ O
with -X- _ O
different -X- _ O
categories -X- _ O
are -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
experiments -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
. -X- _ O
To -X- _ O
support -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
intent -X- _ O
setting -X- _ O
in -X- _ O
classificationbased -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
decouple -X- _ O
the -X- _ O
LU -X- _ B-TaskName
process -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
first -X- _ O
perform -X- _ O
domain -X- _ O
classification -X- _ O
and -X- _ O
intent -X- _ O
detection -X- _ O
, -X- _ O
then -X- _ O
concatenate -X- _ O
two -X- _ O
special -X- _ O
tokens -X- _ O
which -X- _ O
indicate -X- _ O
the -X- _ O
detected -X- _ O
domain -X- _ O
and -X- _ O
intent -X- _ O
( -X- _ O
e.g.[restaurant][inf -X- _ O
orm -X- _ O
] -X- _ O
) -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
, -X- _ O
and -X- _ O
last -X- _ O
encode -X- _ O
the -X- _ O
new -X- _ O
sequence -X- _ O
to -X- _ O
predict -X- _ O
slot -X- _ O
tags -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
way -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
address -X- _ O
overlapping -X- _ O
slot -X- _ O
values -X- _ O
when -X- _ O
values -X- _ O
are -X- _ O
shared -X- _ O
in -X- _ O
different -X- _ O
dialog -X- _ O
acts -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
robustness -X- _ O
testing -X- _ O
on -X- _ O
all -X- _ O
three -X- _ O
capacities -X- _ O
for -X- _ O
five -X- _ O
base -X- _ O
models -X- _ O
using -X- _ O
four -X- _ O
augmentation -X- _ O
methods -X- _ O
in -X- _ O
LAUG -X- _ B-MethodName
. -X- _ O
All -X- _ O
baselines -X- _ O
are -X- _ O
first -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
datasets -X- _ O
, -X- _ O
then -X- _ O
finetuned -X- _ O
on -X- _ O
the -X- _ O
augmented -X- _ O
datasets -X- _ O
. -X- _ O
Overall -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
measure -X- _ O
performance -X- _ O
on -X- _ O
Frames -X- _ B-DatasetName
and -X- _ O
MultiWOZ -X- _ B-DatasetName
is -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
. -X- _ O
All -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
over -X- _ O
5 -X- _ O
runs -X- _ O
, -X- _ O
and -X- _ O
averaged -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
. -X- _ O
Robustness -X- _ O
for -X- _ O
each -X- _ O
capacity -X- _ O
can -X- _ O
be -X- _ O
measured -X- _ O
by -X- _ O
performance -X- _ O
drops -X- _ O
on -X- _ O
the -X- _ O
corresponding -X- _ O
augmented -X- _ O
test -X- _ O
sets -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
achieve -X- _ O
some -X- _ O
performance -X- _ O
recovery -X- _ O
on -X- _ O
augmented -X- _ O
test -X- _ O
sets -X- _ O
after -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
, -X- _ O
while -X- _ O
keeping -X- _ O
a -X- _ O
comparable -X- _ O
result -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
LAUG -X- _ B-MethodName
in -X- _ O
improving -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
robustness -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
outperform -X- _ O
non -X- _ O
- -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
ones -X- _ O
on -X- _ O
both -X- _ O
original -X- _ O
and -X- _ O
augmented -X- _ O
test -X- _ O
sets -X- _ O
. -X- _ O
Classification -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
have -X- _ O
better -X- _ O
performance -X- _ O
and -X- _ O
are -X- _ O
more -X- _ O
robust -X- _ O
than -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
. -X- _ O
ToD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
, -X- _ O
the -X- _ O
state- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
model -X- _ O
which -X- _ O
was -X- _ O
further -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
dialog -X- _ O
data -X- _ O
, -X- _ O
has -X- _ O
comparable -X- _ O
performance -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
With -X- _ O
most -X- _ O
augmentation -X- _ O
methods -X- _ O
, -X- _ O
ToD -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
shows -X- _ O
slightly -X- _ O
better -X- _ O
robustness -X- _ O
than -X- _ O
BERT.Since -X- _ B-MethodName
the -X- _ O
data -X- _ O
volume -X- _ O
of -X- _ O
Frames -X- _ B-DatasetName
is -X- _ O
far -X- _ O
less -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
MultiWOZ -X- _ B-DatasetName
, -X- _ O
the -X- _ O
performance -X- _ O
improvement -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
on -X- _ O
Frames -X- _ B-DatasetName
is -X- _ O
larger -X- _ O
than -X- _ O
that -X- _ O
on -X- _ O
MultiWOZ -X- _ B-DatasetName
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
reason -X- _ O
, -X- _ O
augmented -X- _ O
training -X- _ O
data -X- _ O
benefits -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
performance -X- _ O
of -X- _ O
on -X- _ O
Ori -X- _ O
. -X- _ O
test -X- _ O
set -X- _ O
more -X- _ O
remarkably -X- _ O
in -X- _ O
Frames -X- _ B-DatasetName
where -X- _ O
data -X- _ O
is -X- _ O
not -X- _ O
sufficient -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
four -X- _ O
augmentation -X- _ O
methods -X- _ O
, -X- _ O
SR -X- _ O
has -X- _ O
the -X- _ O
largest -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
models -X- _ O
' -X- _ O
performance -X- _ O
, -X- _ O
and -X- _ O
SD -X- _ O
comes -X- _ O
the -X- _ O
second -X- _ O
. -X- _ O
The -X- _ O
dramatic -X- _ O
performance -X- _ O
drop -X- _ O
when -X- _ O
testing -X- _ O
on -X- _ O
SR -X- _ O
and -X- _ O
SD -X- _ O
data -X- _ O
indicates -X- _ O
that -X- _ O
robustness -X- _ O
for -X- _ O
speech -X- _ O
characteristics -X- _ O
may -X- _ O
be -X- _ O
the -X- _ O
most -X- _ O
challenging -X- _ O
issue -X- _ O
. -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
shows -X- _ O
how -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
GPT-2 -X- _ B-MethodName
changes -X- _ O
on -X- _ O
MultiWOZ -X- _ B-DatasetName
when -X- _ O
the -X- _ O
ratio -X- _ O
of -X- _ O
augmented -X- _ O
training -X- _ O
data -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
varies -X- _ O
from -X- _ O
0.1 -X- _ O
to -X- _ O
4.0 -X- _ O
. -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
on -X- _ O
augmented -X- _ O
test -X- _ O
sets -X- _ O
increase -X- _ O
when -X- _ O
there -X- _ O
are -X- _ O
more -X- _ O
augmented -X- _ O
data -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
augmented -X- _ O
test -X- _ O
sets -X- _ O
is -X- _ O
improved -X- _ O
when -X- _ O
augmentation -X- _ O
ratio -X- _ O
is -X- _ O
less -X- _ O
than -X- _ O
0.5 -X- _ O
but -X- _ O
becomes -X- _ O
almost -X- _ O
unchanged -X- _ O
after -X- _ O
0.5 -X- _ O
while -X- _ O
GPT-2 -X- _ B-MethodName
keeps -X- _ O
increasing -X- _ O
stably -X- _ O
. -X- _ O
This -X- _ O
result -X- _ O
shows -X- _ O
the -X- _ O
different -X- _ O
characteristics -X- _ O
between -X- _ O
classification -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
and -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
when -X- _ O
finetuned -X- _ O
with -X- _ O
augmented -X- _ O
data -X- _ O
. -X- _ O
Between -X- _ O
augmentation -X- _ O
approaches -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
study -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
each -X- _ O
augmentation -X- _ O
approach -X- _ O
in -X- _ O
LAUG -X- _ B-MethodName
, -X- _ O
we -X- _ O
test -X- _ O
the -X- _ O
performance -X- _ O
changes -X- _ O
when -X- _ O
one -X- _ O
augmentation -X- _ O
approach -X- _ O
is -X- _ O
removed -X- _ O
from -X- _ O
constructing -X- _ O
augmented -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Results -X- _ O
on -X- _ O
Mul -X- _ B-DatasetName
- -X- _ I-DatasetName
tiWOZ -X- _ I-DatasetName
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
10 -X- _ O
. -X- _ O
Original -X- _ O
EDA -X- _ O
consists -X- _ O
of -X- _ O
four -X- _ O
functions -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
Performance -X- _ O
differences -X- _ O
( -X- _ O
Diff -X- _ O
. -X- _ O
) -X- _ O
can -X- _ O
reflect -X- _ O
the -X- _ O
influences -X- _ O
of -X- _ O
those -X- _ O
components -X- _ O
in -X- _ O
Table -X- _ O
11a -X- _ O
. -X- _ O
The -X- _ O
additional -X- _ O
function -X- _ O
of -X- _ O
our -X- _ O
SC -X- _ O
- -X- _ O
EDA -X- _ O
is -X- _ O
slot -X- _ O
value -X- _ O
replacement -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
also -X- _ O
observe -X- _ O
an -X- _ O
increase -X- _ O
in -X- _ O
performance -X- _ O
when -X- _ O
it -X- _ O
is -X- _ O
removed -X- _ O
, -X- _ O
especially -X- _ O
for -X- _ O
MILU -X- _ B-MethodName
. -X- _ O
This -X- _ O
implies -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
in -X- _ O
detecting -X- _ O
unseen -X- _ O
entities -X- _ O
. -X- _ O
Table -X- _ O
11b -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
ablation -X- _ O
study -X- _ O
on -X- _ O
SD -X- _ B-TaskName
. -X- _ O
Among -X- _ O
the -X- _ O
four -X- _ O
types -X- _ O
of -X- _ O
disfluencies -X- _ O
described -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
repairs -X- _ O
has -X- _ O
the -X- _ O
largest -X- _ O
impact -X- _ O
on -X- _ O
models -X- _ O
' -X- _ O
performance -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
is -X- _ O
also -X- _ O
affected -X- _ O
by -X- _ O
pauses -X- _ O
but -X- _ O
to -X- _ O
a -X- _ O
less -X- _ O
extent -X- _ O
. -X- _ O
The -X- _ O
influences -X- _ O
of -X- _ O
repeats -X- _ O
and -X- _ O
restarts -X- _ O
are -X- _ O
small -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
neural -X- _ O
models -X- _ O
are -X- _ O
robust -X- _ O
to -X- _ O
handle -X- _ O
these -X- _ O
two -X- _ O
problems -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
test -X- _ O
whether -X- _ O
the -X- _ O
data -X- _ O
automatically -X- _ O
augmented -X- _ O
by -X- _ O
LAUG -X- _ O
can -X- _ O
reflect -X- _ O
and -X- _ O
alleviate -X- _ O
practical -X- _ O
robustness -X- _ O
problems -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
a -X- _ O
real -X- _ O
user -X- _ O
evaluation -X- _ O
. -X- _ O
We -X- _ O
collected -X- _ O
240 -X- _ O
speech -X- _ O
utterances -X- _ O
from -X- _ O
real -X- _ O
humans -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
sampled -X- _ O
120 -X- _ O
combinations -X- _ O
of -X- _ O
DA -X- _ O
from -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
MultiWOZ -X- _ B-DatasetName
. -X- _ O
Given -X- _ O
a -X- _ O
combination -X- _ O
, -X- _ O
each -X- _ O
user -X- _ O
was -X- _ O
asked -X- _ O
to -X- _ O
speak -X- _ O
two -X- _ O
utterances -X- _ O
with -X- _ O
different -X- _ O
expressions -X- _ O
, -X- _ O
in -X- _ O
their -X- _ O
own -X- _ O
language -X- _ O
habits -X- _ O
. -X- _ O
Then -X- _ O
the -X- _ O
audio -X- _ O
signals -X- _ O
were -X- _ O
recognized -X- _ O
into -X- _ O
text -X- _ O
using -X- _ O
DeepSpeech2 -X- _ O
, -X- _ O
thereby -X- _ O
constructing -X- _ O
a -X- _ O
new -X- _ O
test -X- _ O
set -X- _ O
in -X- _ O
real -X- _ O
scenarios -X- _ O
8 -X- _ O
. -X- _ O
Results -X- _ O
on -X- _ O
this -X- _ O
real -X- _ O
test -X- _ O
set -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
12 -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
real -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
substantially -X- _ O
lower -X- _ O
than -X- _ O
that -X- _ O
on -X- _ O
Ori -X- _ O
. -X- _ O
and -X- _ O
Avg -X- _ O
. -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
real -X- _ O
user -X- _ O
evaluation -X- _ O
is -X- _ O
much -X- _ O
more -X- _ O
challenging -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
multiple -X- _ O
robustness -X- _ O
issues -X- _ O
may -X- _ O
be -X- _ O
included -X- _ O
in -X- _ O
one -X- _ O
real -X- _ O
case -X- _ O
, -X- _ O
while -X- _ O
each -X- _ O
augmentation -X- _ O
method -X- _ O
in -X- _ O
LAUG -X- _ B-MethodName
evaluates -X- _ O
them -X- _ O
separately -X- _ O
. -X- _ O
Despite -X- _ O
the -X- _ O
difference -X- _ O
, -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
real -X- _ O
data -X- _ O
is -X- _ O
remarkably -X- _ O
improved -X- _ O
after -X- _ O
every -X- _ O
model -X- _ O
is -X- _ O
finetuned -X- _ O
on -X- _ O
the -X- _ O
augmented -X- _ O
data -X- _ O
, -X- _ O
verifying -X- _ O
that -X- _ O
LAUG -X- _ B-MethodName
effectively -X- _ O
enhances -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
robustness -X- _ O
. -X- _ O
Table -X- _ O
13 -X- _ O
investigates -X- _ O
which -X- _ O
error -X- _ O
type -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
made -X- _ O
on -X- _ O
the -X- _ O
real -X- _ O
test -X- _ O
set -X- _ O
by -X- _ O
manually -X- _ O
checking -X- _ O
all -X- _ O
the -X- _ O
error -X- _ O
outputs -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
Ori -X- _ O
. -X- _ O
" -X- _ O
Others -X- _ O
" -X- _ O
are -X- _ O
the -X- _ O
error -X- _ O
cases -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
caused -X- _ O
by -X- _ O
robustness -X- _ O
issues -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
poor -X- _ O
performance -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
observed -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
seriously -X- _ O
suffers -X- _ O
to -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
( -X- _ O
over -X- _ O
70 -X- _ O
% -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
almost -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
error -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
Language -X- _ O
Variety -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
there -X- _ O
are -X- _ O
more -X- _ O
diverse -X- _ O
expressions -X- _ O
in -X- _ O
real -X- _ O
user -X- _ O
evaluation -X- _ O
than -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
. -X- _ O
After -X- _ O
augmented -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
error -X- _ O
cases -X- _ O
of -X- _ O
Speech -X- _ O
Characteristics -X- _ O
and -X- _ O
Noise -X- _ O
Perturbation -X- _ O
is -X- _ O
relatively -X- _ O
decreased -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
Aug. -X- _ O
can -X- _ O
solve -X- _ O
these -X- _ O
two -X- _ O
kinds -X- _ O
of -X- _ O
problems -X- _ O
better -X- _ O
. -X- _ O
Noting -X- _ O
that -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
four -X- _ O
percentages -X- _ O
is -X- _ O
over -X- _ O
100 -X- _ O
% -X- _ O
since -X- _ O
25 -X- _ O
% -X- _ O
error -X- _ O
cases -X- _ O
involve -X- _ O
multiple -X- _ O
robustness -X- _ O
issues -X- _ O
. -X- _ O
This -X- _ O
again -X- _ O
demonstrates -X- _ O
that -X- _ O
real -X- _ O
user -X- _ O
evaluation -X- _ O
is -X- _ O
more -X- _ O
challenging -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
test -X- _ O
set -X- _ O
9 -X- _ O
. -X- _ O
Robustness -X- _ B-TaskName
in -X- _ I-TaskName
LU -X- _ I-TaskName
has -X- _ O
always -X- _ O
been -X- _ O
a -X- _ O
challenge -X- _ O
in -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
dialog -X- _ O
. -X- _ O
Several -X- _ O
studies -X- _ O
have -X- _ O
investigated -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
sensitivity -X- _ O
to -X- _ O
the -X- _ O
collected -X- _ O
data -X- _ O
distribution -X- _ O
, -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
prevent -X- _ O
models -X- _ O
from -X- _ O
overfitting -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
and -X- _ O
improve -X- _ O
robustness -X- _ O
in -X- _ O
the -X- _ O
real -X- _ O
world -X- _ O
. -X- _ O
Kang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
collected -X- _ O
dialogs -X- _ O
with -X- _ O
templates -X- _ O
and -X- _ O
paraphrased -X- _ O
with -X- _ O
crowdsourcing -X- _ O
to -X- _ O
achieve -X- _ O
high -X- _ O
coverage -X- _ O
and -X- _ O
diversity -X- _ O
in -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Dinan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
training -X- _ O
schema -X- _ O
that -X- _ O
involves -X- _ O
human -X- _ O
in -X- _ O
the -X- _ O
loop -X- _ O
in -X- _ O
dialog -X- _ O
systems -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
defense -X- _ O
against -X- _ O
human -X- _ O
attack -X- _ O
in -X- _ O
an -X- _ O
iterative -X- _ O
way -X- _ O
. -X- _ O
Ganhotra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
injected -X- _ O
natural -X- _ O
perturbation -X- _ O
into -X- _ O
the -X- _ O
dialog -X- _ O
history -X- _ O
manually -X- _ O
to -X- _ O
refine -X- _ O
over -X- _ O
- -X- _ O
controlled -X- _ O
data -X- _ O
generated -X- _ O
through -X- _ O
crowd -X- _ O
- -X- _ O
sourcing -X- _ O
. -X- _ O
All -X- _ O
these -X- _ O
methods -X- _ O
require -X- _ O
laborious -X- _ O
human -X- _ O
intervention -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
aims -X- _ O
to -X- _ O
provide -X- _ O
an -X- _ O
automatic -X- _ O
way -X- _ O
to -X- _ O
test -X- _ O
the -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
in -X- _ I-TaskName
task -X- _ I-TaskName
- -X- _ I-TaskName
oriented -X- _ I-TaskName
dialog -X- _ I-TaskName
. -X- _ O
Various -X- _ O
textual -X- _ O
adversarial -X- _ O
attacks -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
proposed -X- _ O
and -X- _ O
received -X- _ O
increasing -X- _ O
attentions -X- _ O
these -X- _ O
years -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
a -X- _ O
victim -X- _ O
model -X- _ O
. -X- _ O
Most -X- _ O
attack -X- _ O
methods -X- _ O
perform -X- _ O
whitebox -X- _ O
attacks -X- _ O
( -X- _ O
Papernot -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Ebrahimi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
's -X- _ O
internal -X- _ O
structure -X- _ O
or -X- _ O
gradient -X- _ O
signals -X- _ O
. -X- _ O
Even -X- _ O
some -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
attack -X- _ O
models -X- _ O
are -X- _ O
not -X- _ O
purely -X- _ O
" -X- _ O
black -X- _ O
- -X- _ O
box -X- _ O
" -X- _ O
, -X- _ O
which -X- _ O
require -X- _ O
the -X- _ O
prediction -X- _ O
scores -X- _ O
( -X- _ O
classification -X- _ O
probabilities -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
victim -X- _ O
model -X- _ O
( -X- _ O
Jin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Alzantot -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
all -X- _ O
these -X- _ O
methods -X- _ O
address -X- _ O
random -X- _ O
perturbation -X- _ O
but -X- _ O
do -X- _ O
not -X- _ O
consider -X- _ O
linguistic -X- _ O
phenomena -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
real -X- _ O
- -X- _ O
life -X- _ O
generalization -X- _ O
of -X- _ O
LU -X- _ O
models -X- _ O
. -X- _ O
While -X- _ O
data -X- _ O
augmentation -X- _ O
can -X- _ O
be -X- _ O
an -X- _ O
efficient -X- _ O
method -X- _ O
to -X- _ O
address -X- _ O
data -X- _ O
sparsity -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
generalization -X- _ O
abilities -X- _ O
and -X- _ O
measure -X- _ O
the -X- _ O
model -X- _ B-TaskName
robustness -X- _ I-TaskName
as -X- _ O
well -X- _ O
( -X- _ O
Eshghi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Paraphrasing -X- _ O
that -X- _ O
rewrites -X- _ O
the -X- _ O
utterances -X- _ O
in -X- _ O
dialog -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
get -X- _ O
diverse -X- _ O
representation -X- _ O
and -X- _ O
thus -X- _ O
enhancing -X- _ O
robustness -X- _ O
( -X- _ O
Ray -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Zhao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Iyyer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Word -X- _ O
- -X- _ O
level -X- _ O
operations -X- _ O
( -X- _ O
Kolomiyets -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011;Li -X- _ O
and -X- _ O
Qiu -X- _ O
, -X- _ O
2020;Wei -X- _ O
and -X- _ O
Zou -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
including -X- _ O
replacement -X- _ O
, -X- _ O
insertion -X- _ O
, -X- _ O
and -X- _ O
deletion -X- _ O
were -X- _ O
also -X- _ O
proposed -X- _ O
to -X- _ O
increase -X- _ O
language -X- _ O
variety -X- _ O
. -X- _ O
Other -X- _ O
studies -X- _ O
( -X- _ O
Shah -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Xu -X- _ O
and -X- _ O
Sarikaya -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
worked -X- _ O
on -X- _ O
the -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
vocabulary -X- _ O
problem -X- _ O
when -X- _ O
facing -X- _ O
unseen -X- _ O
user -X- _ O
expression -X- _ O
. -X- _ O
Some -X- _ O
other -X- _ O
research -X- _ O
focused -X- _ O
on -X- _ O
building -X- _ O
robust -X- _ O
spoken -X- _ O
language -X- _ O
understanding -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Henderson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012;Huang -X- _ O
and -X- _ O
Chen -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
from -X- _ O
audio -X- _ O
signals -X- _ O
beyond -X- _ O
text -X- _ O
transcripts -X- _ O
. -X- _ O
Simulating -X- _ O
ASR -X- _ B-TaskName
errors -X- _ O
( -X- _ O
Schatzmann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007;Park -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
and -X- _ O
speaker -X- _ O
disfluency -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b;Qader -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
promising -X- _ O
solutions -X- _ O
to -X- _ O
enhance -X- _ O
robustness -X- _ O
to -X- _ O
voice -X- _ O
input -X- _ O
when -X- _ O
only -X- _ O
textual -X- _ O
data -X- _ O
are -X- _ O
provided -X- _ O
. -X- _ O
As -X- _ O
most -X- _ O
work -X- _ O
tackles -X- _ O
LU -X- _ O
robustness -X- _ O
from -X- _ O
only -X- _ O
one -X- _ O
perspective -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
comprehensive -X- _ O
study -X- _ O
to -X- _ O
reveal -X- _ O
three -X- _ O
critical -X- _ O
issues -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
and -X- _ O
shed -X- _ O
light -X- _ O
on -X- _ O
a -X- _ O
thorough -X- _ O
robustness -X- _ O
evaluation -X- _ O
of -X- _ O
LU -X- _ B-TaskName
in -X- _ I-TaskName
dialog -X- _ I-TaskName
systems -X- _ I-TaskName
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
systematic -X- _ O
robustness -X- _ B-TaskName
evaluation -X- _ I-TaskName
of -X- _ I-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
( -X- _ I-TaskName
LU -X- _ I-TaskName
) -X- _ I-TaskName
in -X- _ I-TaskName
taskoriented -X- _ I-TaskName
dialog -X- _ I-TaskName
from -X- _ O
three -X- _ O
aspects -X- _ O
: -X- _ O
language -X- _ O
variety -X- _ O
, -X- _ O
speech -X- _ O
characteristics -X- _ O
, -X- _ O
and -X- _ O
noise -X- _ O
perturbation -X- _ O
. -X- _ O
Accordingly -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
four -X- _ O
data -X- _ O
augmentation -X- _ O
methods -X- _ O
to -X- _ O
approximate -X- _ O
these -X- _ O
language -X- _ O
phenomena -X- _ O
. -X- _ O
In -X- _ O
- -X- _ O
depth -X- _ O
experiments -X- _ O
and -X- _ O
analysis -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
MultiWOZ -X- _ B-DatasetName
and -X- _ O
Frames -X- _ B-DatasetName
, -X- _ O
with -X- _ O
both -X- _ O
classification -X- _ O
- -X- _ O
and -X- _ O
generation -X- _ O
- -X- _ O
based -X- _ O
LU -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
drop -X- _ O
of -X- _ O
all -X- _ O
models -X- _ O
on -X- _ O
augmented -X- _ O
test -X- _ O
data -X- _ O
indicates -X- _ O
that -X- _ O
these -X- _ O
robustness -X- _ O
issues -X- _ O
are -X- _ O
challenging -X- _ O
and -X- _ O
critical -X- _ O
, -X- _ O
while -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
are -X- _ O
relatively -X- _ O
more -X- _ O
robust -X- _ O
to -X- _ O
LU -X- _ O
. -X- _ O
Ablation -X- _ O
studies -X- _ O
are -X- _ O
carried -X- _ O
out -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
effect -X- _ O
and -X- _ O
orthogonality -X- _ O
of -X- _ O
each -X- _ O
augmentation -X- _ O
approach -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
conduct -X- _ O
a -X- _ O
real -X- _ O
user -X- _ O
evaluation -X- _ O
and -X- _ O
verifies -X- _ O
that -X- _ O
our -X- _ O
augmentation -X- _ O
methods -X- _ O
can -X- _ O
reflect -X- _ O
and -X- _ O
help -X- _ O
alleviate -X- _ O
real -X- _ O
robustness -X- _ O
problems -X- _ O
. -X- _ O
Existing -X- _ O
and -X- _ O
future -X- _ O
dialog -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
evaluated -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
robustness -X- _ O
with -X- _ O
our -X- _ O
toolkit -X- _ O
and -X- _ O
data -X- _ O
, -X- _ O
as -X- _ O
our -X- _ O
augmentation -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
depend -X- _ O
on -X- _ O
any -X- _ O
particular -X- _ O
LU -X- _ O
models -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
our -X- _ O
proposed -X- _ O
robustness -X- _ O
evaluation -X- _ O
scheme -X- _ O
is -X- _ O
extensible -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
four -X- _ O
approaches -X- _ O
in -X- _ O
LAUG -X- _ B-MethodName
, -X- _ O
more -X- _ O
methods -X- _ O
to -X- _ O
evaluate -X- _ O
LU -X- _ O
robustness -X- _ O
can -X- _ O
be -X- _ O
considered -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
. -X- _ O
As -X- _ O
for -X- _ O
hyperparameters -X- _ O
in -X- _ O
LAUG -X- _ B-MethodName
, -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
ratio -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
perturbation -X- _ I-HyperparameterName
number -X- _ I-HyperparameterName
to -X- _ I-HyperparameterName
text -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
α -X- _ B-HyperparameterName
= -X- _ O
n -X- _ O
/ -X- _ O
l -X- _ O
= -X- _ O
0.1 -X- _ B-HyperparameterValue
in -X- _ O
EDA -X- _ O
. -X- _ O
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
used -X- _ O
to -X- _ O
finetune -X- _ O
SC -X- _ B-MethodName
- -X- _ I-MethodName
GPT -X- _ I-MethodName
in -X- _ O
TP -X- _ O
is -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
epoch -X- _ I-HyperparameterName
is -X- _ O
5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
during -X- _ O
inference -X- _ O
is -X- _ O
5 -X- _ B-HyperparameterValue
. -X- _ O
In -X- _ O
SR -X- _ B-TaskName
, -X- _ O
the -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
in -X- _ O
DeepSpeech2 -X- _ O
is -X- _ O
set -X- _ O
to -X- _ O
50 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
Bi -X- _ B-MethodName
- -X- _ I-MethodName
LSTM+CRF -X- _ I-MethodName
in -X- _ O
SD -X- _ B-TaskName
is -X- _ O
1e-3 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
threshold -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
fuzzy -X- _ I-HyperparameterName
matching -X- _ I-HyperparameterName
in -X- _ O
automatic -X- _ B-TaskName
value -X- _ I-TaskName
detection -X- _ I-TaskName
is -X- _ O
set -X- _ O
to -X- _ O
0.9 -X- _ B-HyperparameterValue
in -X- _ O
TP -X- _ B-TaskName
and -X- _ O
0.7 -X- _ B-HyperparameterValue
in -X- _ O
SR.For -X- _ B-TaskName
hyperparameters -X- _ O
of -X- _ O
base -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
1e-4 -X- _ B-HyperparameterValue
for -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
1e-5 -X- _ B-HyperparameterValue
for -X- _ O
GPT2 -X- _ B-MethodName
, -X- _ O
and -X- _ O
1e-3 -X- _ B-HyperparameterName
for -X- _ O
MILU -X- _ B-MethodName
and -X- _ O
CopyNet -X- _ B-MethodName
. -X- _ O
The -X- _ O
beam -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
GPT2 -X- _ B-MethodName
and -X- _ O
CopyNet -X- _ B-MethodName
is -X- _ O
5 -X- _ B-HyperparameterValue
during -X- _ O
the -X- _ O
decoding -X- _ O
step -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
120 -X- _ O
sampled -X- _ O
DA -X- _ O
combinations -X- _ O
, -X- _ O
each -X- _ O
combination -X- _ O
contains -X- _ O
1 -X- _ O
to -X- _ O
3 -X- _ O
DAs -X- _ O
. -X- _ O
Users -X- _ O
can -X- _ O
organize -X- _ O
the -X- _ O
DAs -X- _ O
in -X- _ O
any -X- _ O
order -X- _ O
provided -X- _ O
that -X- _ O
they -X- _ O
describe -X- _ O
DAs -X- _ O
with -X- _ O
the -X- _ O
correct -X- _ O
meaning -X- _ O
so -X- _ O
as -X- _ O
to -X- _ O
imitate -X- _ O
diverse -X- _ O
user -X- _ O
expressions -X- _ O
in -X- _ O
real -X- _ O
scenarios -X- _ O
. -X- _ O
Users -X- _ O
are -X- _ O
also -X- _ O
asked -X- _ O
to -X- _ O
keep -X- _ O
natural -X- _ O
in -X- _ O
both -X- _ O
intonation -X- _ O
and -X- _ O
expression -X- _ O
, -X- _ O
and -X- _ O
communication -X- _ O
noise -X- _ O
caused -X- _ O
by -X- _ O
users -X- _ O
in -X- _ O
speech -X- _ O
and -X- _ O
language -X- _ O
is -X- _ O
included -X- _ O
during -X- _ O
collection -X- _ O
. -X- _ O
The -X- _ O
audios -X- _ O
are -X- _ O
recorded -X- _ O
by -X- _ O
users -X- _ O
' -X- _ O
PCs -X- _ O
under -X- _ O
their -X- _ O
real -X- _ O
environmental -X- _ O
noises -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
settings -X- _ O
of -X- _ O
DeepSpeech2 -X- _ B-MethodName
in -X- _ O
SR -X- _ O
to -X- _ O
recognize -X- _ O
the -X- _ O
collected -X- _ O
audios -X- _ O
. -X- _ O
After -X- _ O
automatic -X- _ B-TaskName
span -X- _ I-TaskName
detection -X- _ I-TaskName
( -X- _ O
also -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
SR -X- _ O
's -X- _ O
) -X- _ O
are -X- _ O
applied -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
human -X- _ O
check -X- _ O
and -X- _ O
annotation -X- _ O
to -X- _ O
ensure -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
labels -X- _ O
. -X- _ O
14 -X- _ O
: -X- _ O
Robustness -X- _ O
on -X- _ O
different -X- _ O
schemes -X- _ O
on -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
WOZ -X- _ I-DatasetName
. -X- _ O
The -X- _ O
coupled -X- _ O
scheme -X- _ O
predicts -X- _ O
dialog -X- _ O
acts -X- _ O
with -X- _ O
a -X- _ O
joint -X- _ O
tagging -X- _ O
scheme -X- _ O
; -X- _ O
the -X- _ O
decoupled -X- _ O
scheme -X- _ O
first -X- _ O
detects -X- _ O
domains -X- _ O
and -X- _ O
intents -X- _ O
, -X- _ O
then -X- _ O
recognizes -X- _ O
the -X- _ O
slot -X- _ O
tags -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
the -X- _ O
influence -X- _ O
of -X- _ O
training -X- _ O
/ -X- _ O
prediction -X- _ O
schemes -X- _ O
on -X- _ O
LU -X- _ B-TaskName
robustness -X- _ I-TaskName
. -X- _ O
As -X- _ O
described -X- _ O
in -X- _ O
Sec -X- _ O
. -X- _ O
4.3 -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
paper -X- _ O
, -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
classification -X- _ O
- -X- _ O
based -X- _ O
LU -X- _ O
models -X- _ O
is -X- _ O
decoupled -X- _ O
into -X- _ O
two -X- _ O
steps -X- _ O
to -X- _ O
handle -X- _ O
multiple -X- _ O
labels -X- _ O
: -X- _ O
one -X- _ O
for -X- _ O
domain -X- _ O
/ -X- _ O
intent -X- _ O
classification -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
for -X- _ O
slot -X- _ O
tagging -X- _ O
. -X- _ O
Another -X- _ O
strategy -X- _ O
is -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
cartesian -X- _ O
product -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
components -X- _ O
of -X- _ O
dialog -X- _ O
acts -X- _ O
, -X- _ O
which -X- _ O
yields -X- _ O
a -X- _ O
joint -X- _ O
tagging -X- _ O
scheme -X- _ O
as -X- _ O
presented -X- _ O
in -X- _ O
Con -X- _ O
- -X- _ O
vLab -X- _ O
. -X- _ O
To -X- _ O
give -X- _ O
an -X- _ O
intuitive -X- _ O
illustration -X- _ O
, -X- _ O
the -X- _ O
slot -X- _ O
tag -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
" -X- _ O
Los -X- _ O
" -X- _ O
becomes -X- _ O
" -X- _ O
Train -X- _ O
- -X- _ O
Inform -X- _ O
- -X- _ O
Depart -X- _ O
- -X- _ O
B -X- _ O
" -X- _ O
in -X- _ O
the -X- _ O
example -X- _ O
described -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
2 -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
paper -X- _ O
. -X- _ O
The -X- _ O
classificationbased -X- _ O
models -X- _ O
can -X- _ O
predict -X- _ O
the -X- _ O
dialog -X- _ O
acts -X- _ O
within -X- _ O
a -X- _ O
single -X- _ O
step -X- _ O
in -X- _ O
this -X- _ O
way -X- _ O
. -X- _ O
Table -X- _ O
14 -X- _ O
shows -X- _ O
that -X- _ O
MILU -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
gain -X- _ O
from -X- _ O
the -X- _ O
decoupled -X- _ O
scheme -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
decoupled -X- _ O
scheme -X- _ O
decreases -X- _ O
the -X- _ O
model -X- _ O
complexity -X- _ O
by -X- _ O
decomposing -X- _ O
the -X- _ O
output -X- _ O
space -X- _ O
. -X- _ O
Interestingly -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
consistency -X- _ O
between -X- _ O
two -X- _ O
models -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
robustness -X- _ O
. -X- _ O
MILU -X- _ B-MethodName
via -X- _ O
the -X- _ O
coupled -X- _ O
scheme -X- _ O
behaves -X- _ O
more -X- _ O
robustly -X- _ O
than -X- _ O
the -X- _ O
decoupled -X- _ O
counterpart -X- _ O
( -X- _ O
-2.61 -X- _ B-MetricValue
vs.-7.05 -X- _ B-MetricValue
) -X- _ O
, -X- _ O
while -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
the -X- _ O
decoupled -X- _ O
scheme -X- _ O
outperforms -X- _ O
its -X- _ O
coupled -X- _ O
version -X- _ O
in -X- _ O
robustness -X- _ O
( -X- _ O
-6.45 -X- _ B-MetricValue
vs. -X- _ O
-8.61 -X- _ B-MetricValue
) -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
benefits -X- _ O
from -X- _ O
the -X- _ O
decoupled -X- _ O
scheme -X- _ O
and -X- _ O
still -X- _ O
achieves -X- _ O
86.95 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
, -X- _ O
but -X- _ O
BERT -X- _ B-MethodName
training -X- _ O
with -X- _ O
the -X- _ O
coupled -X- _ O
scheme -X- _ O
seems -X- _ O
more -X- _ O
susceptible -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
both -X- _ O
MILU -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
recover -X- _ O
more -X- _ O
performance -X- _ O
by -X- _ O
the -X- _ O
proposed -X- _ O
decoupled -X- _ O
scheme -X- _ O
. -X- _ O
All -X- _ O
these -X- _ O
results -X- _ O
demonstrate -X- _ O
the -X- _ O
superiority -X- _ O
of -X- _ O
the -X- _ O
decoupled -X- _ O
scheme -X- _ O
in -X- _ O
classification -X- _ B-TaskName
- -X- _ I-TaskName
based -X- _ I-TaskName
LU -X- _ I-TaskName
models -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
15 -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
some -X- _ O
examples -X- _ O
of -X- _ O
augmented -X- _ O
utterances -X- _ O
in -X- _ O
MultiWOZ -X- _ B-DatasetName
. -X- _ O
In -X- _ O
terms -X- _ O
of -X- _ O
model -X- _ O
performance -X- _ O
, -X- _ O
MILU -X- _ B-MethodName
, -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
GPT-2 -X- _ B-MethodName
perform -X- _ O
well -X- _ O
on -X- _ O
WP -X- _ B-TaskName
and -X- _ O
TP -X- _ B-TaskName
in -X- _ O
the -X- _ O
example -X- _ O
while -X- _ O
Copy -X- _ B-DatasetName
- -X- _ I-DatasetName
Net -X- _ I-DatasetName
misses -X- _ O
some -X- _ O
dialog -X- _ O
acts -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
SR -X- _ O
utterance -X- _ O
, -X- _ O
only -X- _ O
BERT -X- _ B-MethodName
obtains -X- _ O
all -X- _ O
the -X- _ O
correct -X- _ O
labels -X- _ O
. -X- _ O
MILU -X- _ B-MethodName
and -X- _ O
Copynet -X- _ O
both -X- _ O
fail -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
changed -X- _ O
value -X- _ O
spans -X- _ O
" -X- _ O
lester -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
thirteen -X- _ O
forty -X- _ O
five -X- _ O
" -X- _ O
. -X- _ O
Copynet -X- _ B-MethodName
's -X- _ O
copy -X- _ O
mechanism -X- _ O
is -X- _ O
fully -X- _ O
confused -X- _ O
by -X- _ O
recognition -X- _ O
error -X- _ O
and -X- _ O
even -X- _ O
predicts -X- _ O
discontinuous -X- _ O
slot -X- _ O
values -X- _ O
. -X- _ O
GPT-2 -X- _ B-MethodName
successfully -X- _ O
finds -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
numerical -X- _ O
time -X- _ O
but -X- _ O
misses -X- _ O
" -X- _ O
leseter -X- _ O
" -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
SD -X- _ O
utterance -X- _ O
, -X- _ O
the -X- _ O
repair -X- _ O
term -X- _ O
fools -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
example -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
performs -X- _ O
quite -X- _ O
well -X- _ O
while -X- _ O
MILU -X- _ B-MethodName
and -X- _ O
Copy -X- _ B-MethodName
- -X- _ I-MethodName
Net -X- _ I-MethodName
expose -X- _ O
some -X- _ O
of -X- _ O
their -X- _ O
defects -X- _ O
in -X- _ O
robustness -X- _ O
. -X- _ O
Table -X- _ O
16 -X- _ O
shows -X- _ O
some -X- _ O
examples -X- _ O
from -X- _ O
real -X- _ O
user -X- _ O
evaluation -X- _ O
. -X- _ O
In -X- _ O
case-1 -X- _ O
, -X- _ O
the -X- _ O
user -X- _ O
says -X- _ O
" -X- _ O
seventeen -X- _ O
o'clock -X- _ O
" -X- _ O
while -X- _ O
time -X- _ O
is -X- _ O
always -X- _ O
represented -X- _ O
in -X- _ O
numeric -X- _ O
formats -X- _ O
( -X- _ O
e.g. -X- _ O
" -X- _ O
17:00 -X- _ O
" -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
typical -X- _ O
Speech -X- _ O
Characteristics -X- _ O
problem -X- _ O
. -X- _ O
Case-2 -X- _ O
could -X- _ O
be -X- _ O
regarded -X- _ O
as -X- _ O
a -X- _ O
Speech -X- _ O
Characteristics -X- _ O
or -X- _ O
Noise -X- _ O
Perturbation -X- _ O
case -X- _ O
because -X- _ O
" -X- _ O
please -X- _ O
" -X- _ O
is -X- _ O
wrongly -X- _ O
recognized -X- _ O
as -X- _ O
" -X- _ O
police -X- _ O
" -X- _ O
by -X- _ O
ASR -X- _ B-TaskName
models -X- _ O
. -X- _ O
Case-3 -X- _ O
is -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
Language -X- _ O
Variety -X- _ O
, -X- _ O
the -X- _ O
user -X- _ O
expresses -X- _ O
the -X- _ O
request -X- _ O
of -X- _ O
getting -X- _ O
ticket -X- _ O
price -X- _ O
in -X- _ O
a -X- _ O
different -X- _ O
way -X- _ O
comparing -X- _ O
to -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
MILU -X- _ B-MethodName
and -X- _ O
BERT -X- _ B-MethodName
failed -X- _ O
in -X- _ O
most -X- _ O
of -X- _ O
these -X- _ O
cases -X- _ O
but -X- _ O
fixed -X- _ O
some -X- _ O
error -X- _ O
after -X- _ O
augmented -X- _ O
training -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
partly -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
NSFC -X- _ O
projects -X- _ O
( -X- _ O
Key -X- _ O
project -X- _ O
with -X- _ O
No -X- _ O
. -X- _ O
61936010 -X- _ O
and -X- _ O
regular -X- _ O
project -X- _ O
with -X- _ O
No -X- _ O
. -X- _ O
61876096 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
was -X- _ O
also -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Guoqiang -X- _ O
Institute -X- _ O
of -X- _ O
Tsinghua -X- _ O
University -X- _ O
, -X- _ O
with -X- _ O
Grant -X- _ O
No -X- _ O
. -X- _ O
2019GQG1 -X- _ O
and -X- _ O
2020GQG0005 -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
colleagues -X- _ O
from -X- _ O
HUAWEI -X- _ O
for -X- _ O
their -X- _ O
constant -X- _ O
support -X- _ O
and -X- _ O
valuable -X- _ O
discussion -X- _ O
. -X- _ O

Modern -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
mostly -X- _ O
built -X- _ O
upon -X- _ O
backbones -X- _ O
stacking -X- _ O
selfattention -X- _ O
and -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layers -X- _ O
in -X- _ O
an -X- _ O
interleaved -X- _ O
order -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
beyond -X- _ O
this -X- _ O
stereotyped -X- _ O
layer -X- _ O
pattern -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
improve -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
by -X- _ O
exploiting -X- _ O
layer -X- _ O
variety -X- _ O
from -X- _ O
two -X- _ O
aspects -X- _ O
: -X- _ O
the -X- _ O
layer -X- _ O
type -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
layer -X- _ O
order -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
besides -X- _ O
the -X- _ O
original -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layers -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
convolution -X- _ O
into -X- _ O
the -X- _ O
layer -X- _ O
type -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
experimentally -X- _ O
found -X- _ O
beneficial -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
beyond -X- _ O
the -X- _ O
original -X- _ O
interleaved -X- _ O
order -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
more -X- _ O
layer -X- _ O
orders -X- _ O
to -X- _ O
discover -X- _ O
more -X- _ O
powerful -X- _ O
architectures -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
introduced -X- _ O
layer -X- _ O
variety -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
large -X- _ O
architecture -X- _ O
space -X- _ O
of -X- _ O
more -X- _ O
than -X- _ O
billions -X- _ O
of -X- _ O
candidates -X- _ O
, -X- _ O
while -X- _ O
training -X- _ O
a -X- _ O
single -X- _ O
candidate -X- _ O
model -X- _ O
from -X- _ O
scratch -X- _ O
already -X- _ O
requires -X- _ O
huge -X- _ O
computation -X- _ O
cost -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
not -X- _ O
affordable -X- _ O
to -X- _ O
search -X- _ O
such -X- _ O
a -X- _ O
space -X- _ O
by -X- _ O
directly -X- _ O
training -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
candidate -X- _ O
models -X- _ O
. -X- _ O
To -X- _ O
solve -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
a -X- _ O
supernet -X- _ O
from -X- _ O
which -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
all -X- _ O
candidate -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
inherited -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
adopt -X- _ O
an -X- _ O
evolutionary -X- _ O
algorithm -X- _ O
guided -X- _ O
by -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
accuracy -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
optimal -X- _ O
architecture -X- _ O
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
show -X- _ O
that -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
model -X- _ O
obtained -X- _ O
by -X- _ O
our -X- _ O
method -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
its -X- _ O
variants -X- _ O
on -X- _ O
various -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
achieves -X- _ O
78.8 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
GLUE -X- _ B-MetricName
testing -X- _ O
set -X- _ O
, -X- _ O
1.8 -X- _ B-MetricValue
higher -X- _ O
than -X- _ O
the -X- _ O
strong -X- _ O
baseline -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
. -X- _ O
1 -X- _ O
In -X- _ O
recent -X- _ O
years -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
representative -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
GPT-3 -X- _ B-MethodName
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
have -X- _ O
gained -X- _ O
great -X- _ O
success -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a;Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
backbone -X- _ O
architectures -X- _ O
of -X- _ O
these -X- _ O
models -X- _ O
mostly -X- _ O
adopt -X- _ O
a -X- _ O
stereotyped -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O
Except -X- _ O
BERT -X- _ B-MethodName
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
Masked -X- _ O
Language -X- _ O
Modeling -X- _ O
objective -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
other -X- _ O
models -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
Replaced -X- _ O
Token -X- _ O
Detection -X- _ O
objective -X- _ O
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
save -X- _ O
computation -X- _ O
cost -X- _ O
. -X- _ O
layer -X- _ O
pattern -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
feedforward -X- _ O
layers -X- _ O
are -X- _ O
arrayed -X- _ O
in -X- _ O
an -X- _ O
interleaved -X- _ O
order -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
evidence -X- _ O
supporting -X- _ O
that -X- _ O
this -X- _ O
layer -X- _ O
pattern -X- _ O
is -X- _ O
optimal -X- _ O
( -X- _ O
Press -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
consider -X- _ O
a -X- _ O
straightforward -X- _ O
and -X- _ O
interesting -X- _ O
question -X- _ O
: -X- _ O
Could -X- _ O
we -X- _ O
change -X- _ O
the -X- _ O
layer -X- _ O
pattern -X- _ O
to -X- _ O
improve -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models?We -X- _ O
attempt -X- _ O
to -X- _ O
answer -X- _ O
this -X- _ O
question -X- _ O
by -X- _ O
exploiting -X- _ O
more -X- _ O
layer -X- _ O
variety -X- _ O
from -X- _ O
two -X- _ O
aspects -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1(a -X- _ O
): -X- _ O
the -X- _ O
layer -X- _ O
type -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
layer -X- _ O
order -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
consider -X- _ O
the -X- _ O
layer -X- _ O
types -X- _ O
. -X- _ O
In -X- _ O
previous -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
most -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
layer -X- _ O
set -X- _ O
contains -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layer -X- _ O
for -X- _ O
capturing -X- _ O
global -X- _ O
information -X- _ O
and -X- _ O
the -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layer -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
transformation -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
some -X- _ O
recent -X- _ O
works -X- _ O
have -X- _ O
unveiled -X- _ O
that -X- _ O
some -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
heads -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
tend -X- _ O
to -X- _ O
learn -X- _ O
local -X- _ O
dependencies -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
inherent -X- _ O
property -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
( -X- _ O
Kovaleva -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Brunner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
, -X- _ O
incurring -X- _ O
computation -X- _ O
redundancy -X- _ O
for -X- _ O
capturing -X- _ O
local -X- _ O
information -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
convolution -X- _ O
is -X- _ O
a -X- _ O
local -X- _ O
operator -X- _ O
( -X- _ O
LeCun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1998;Krizhevsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012;Simonyan -X- _ O
and -X- _ O
Zisserman -X- _ O
, -X- _ O
2015;He -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
has -X- _ O
shown -X- _ O
effectiveness -X- _ O
on -X- _ O
extracting -X- _ O
local -X- _ O
information -X- _ O
for -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Kim -X- _ O
, -X- _ O
2014;Kalchbrenner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2019b -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
augment -X- _ O
the -X- _ O
layer -X- _ O
set -X- _ O
by -X- _ O
including -X- _ O
convolution -X- _ O
for -X- _ O
local -X- _ O
information -X- _ O
extraction -X- _ O
. -X- _ O
For -X- _ O
layer -X- _ O
orders -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
adopt -X- _ O
an -X- _ O
interleaved -X- _ O
order -X- _ O
to -X- _ O
arrange -X- _ O
the -X- _ O
different -X- _ O
types -X- _ O
of -X- _ O
layers -X- _ O
. -X- _ O
Differently -X- _ O
, -X- _ O
Press -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
presented -X- _ O
the -X- _ O
sandwich -X- _ O
order -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
stacking -X- _ O
consecutive -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layers -X- _ O
at -X- _ O
the -X- _ O
bottom -X- _ O
and -X- _ O
top -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
while -X- _ O
keeping -X- _ O
the -X- _ O
interleaved -X- _ O
order -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
. -X- _ O
It -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
the -X- _ O
sandwich -X- _ O
order -X- _ O
can -X- _ O
bring -X- _ O
improvement -X- _ O
on -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
, -X- _ O
indicating -X- _ O
the -X- _ O
layer -X- _ O
order -X- _ O
contributes -X- _ O
to -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Press -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
did -X- _ O
not -X- _ O
show -X- _ O
the -X- _ O
generalization -X- _ O
capability -X- _ O
of -X- _ O
this -X- _ O
order -X- _ O
to -X- _ O
other -X- _ O
tasks -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
large -X- _ O
room -X- _ O
for -X- _ O
exploring -X- _ O
more -X- _ O
effective -X- _ O
orders -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
the -X- _ O
different -X- _ O
layer -X- _ O
variety -X- _ O
designs -X- _ O
of -X- _ O
existing -X- _ O
models -X- _ O
in -X- _ O
Figure -X- _ O
1(b -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019)/ELECTRA -X- _ B-MethodName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
Dynamic -X- _ B-MethodName
- -X- _ I-MethodName
Conv -X- _ I-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
Sandwich -X- _ B-MethodName
( -X- _ O
Press -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Their -X- _ O
performance -X- _ O
is -X- _ O
summarized -X- _ O
in -X- _ O
Figure -X- _ O
1(c -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
layer -X- _ O
variety -X- _ O
significantly -X- _ O
influences -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
claim -X- _ O
it -X- _ O
is -X- _ O
necessary -X- _ O
to -X- _ O
investigate -X- _ O
layer -X- _ O
variety -X- _ O
for -X- _ O
promoting -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
to -X- _ O
perform -X- _ O
such -X- _ O
investigation -X- _ O
for -X- _ O
a -X- _ O
common -X- _ O
model -X- _ O
backbone -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
with -X- _ O
24 -X- _ O
layers -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
evaluate -X- _ O
performance -X- _ O
of -X- _ O
every -X- _ O
candidate -X- _ O
within -X- _ O
an -X- _ O
architecture -X- _ O
space -X- _ O
of -X- _ O
3 -X- _ O
24 -X- _ O
≈ -X- _ O
2.8 -X- _ O
× -X- _ O
10 -X- _ O
11 -X- _ O
candidates -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
a -X- _ O
single -X- _ O
language -X- _ O
model -X- _ O
already -X- _ O
needs -X- _ O
to -X- _ O
consume -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
computation -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
2400 -X- _ O
P100 -X- _ O
GPU -X- _ O
days -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
It -X- _ O
is -X- _ O
barely -X- _ O
affordable -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
such -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
model -X- _ O
candidates -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
To -X- _ O
reduce -X- _ O
the -X- _ O
computation -X- _ O
cost -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
recent -X- _ O
works -X- _ O
on -X- _ O
Neural -X- _ O
Architecture -X- _ O
Search -X- _ O
( -X- _ O
NAS -X- _ O
) -X- _ O
( -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
supernet -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
layer -X- _ O
variety -X- _ O
discussed -X- _ O
above -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
it -X- _ O
with -X- _ O
Masked -X- _ O
Language -X- _ O
Modeling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
objective -X- _ O
. -X- _ O
After -X- _ O
obtaining -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
supernet -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
an -X- _ O
evolutionary -X- _ O
algorithm -X- _ O
guided -X- _ O
by -X- _ O
MLM -X- _ O
evaluation -X- _ O
accuracy -X- _ B-MetricName
to -X- _ O
search -X- _ O
an -X- _ O
effective -X- _ O
architecture -X- _ O
with -X- _ O
specific -X- _ O
layer -X- _ O
variety -X- _ O
. -X- _ O
We -X- _ O
call -X- _ O
the -X- _ O
resulted -X- _ O
model -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
. -X- _ O
Extensive -X- _ O
experiments -X- _ O
show -X- _ O
that -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
outperforms -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
its -X- _ O
variants -X- _ O
. -X- _ O
The -X- _ O
contributions -X- _ O
of -X- _ O
our -X- _ O
paper -X- _ O
are -X- _ O
two -X- _ O
- -X- _ O
fold -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
exploit -X- _ O
layer -X- _ O
variety -X- _ O
w.r.t -X- _ O
. -X- _ O
both -X- _ O
layer -X- _ O
types -X- _ O
and -X- _ O
orders -X- _ O
for -X- _ O
pretrained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
convolutions -X- _ O
and -X- _ O
layer -X- _ O
orders -X- _ O
both -X- _ O
benefit -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
hope -X- _ O
our -X- _ O
observations -X- _ O
would -X- _ O
facilitate -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
lauguage -X- _ O
models -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
our -X- _ O
obtained -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
shows -X- _ O
superiority -X- _ O
over -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
its -X- _ O
variants -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ O
small -X- _ O
achieves -X- _ O
79.8 -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
testing -X- _ O
set -X- _ O
, -X- _ O
1.8 -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
ELECTRAsmall -X- _ B-MethodName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
Language -X- _ O
Models -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
achieved -X- _ O
great -X- _ O
success -X- _ O
and -X- _ O
promoted -X- _ O
the -X- _ O
development -X- _ O
of -X- _ O
NLP -X- _ O
techniques -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
separate -X- _ O
word -X- _ O
representation -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
, -X- _ O
McCann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
and -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018b -X- _ O
) -X- _ O
propose -X- _ O
CoVe -X- _ B-MethodName
and -X- _ O
ELMo -X- _ B-MethodName
respectively -X- _ O
which -X- _ O
both -X- _ O
utilize -X- _ O
LSTM -X- _ O
( -X- _ O
Hochreiter -X- _ O
and -X- _ O
Schmidhuber -X- _ O
, -X- _ O
1997 -X- _ O
) -X- _ O
to -X- _ O
generate -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
. -X- _ O
Later -X- _ O
, -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
introduce -X- _ O
GPT -X- _ B-MethodName
that -X- _ O
changes -X- _ O
the -X- _ O
backbone -X- _ O
to -X- _ O
transformers -X- _ O
where -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layers -X- _ O
are -X- _ O
arrayed -X- _ O
interleavedly -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
propose -X- _ O
generative -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objectives -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
continues -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
layer -X- _ O
set -X- _ O
and -X- _ O
order -X- _ O
for -X- _ O
backbone -X- _ O
but -X- _ O
employs -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objectives -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
Masked -X- _ O
Language -X- _ O
Modeling -X- _ O
and -X- _ O
Next -X- _ O
Sentence -X- _ O
Prediction -X- _ O
. -X- _ O
Then -X- _ O
more -X- _ O
works -X- _ O
introduce -X- _ O
new -X- _ O
effective -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objectives -X- _ O
, -X- _ O
like -X- _ O
Generalized -X- _ O
Autoregressive -X- _ O
Pretraining -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
Span -X- _ O
Boundary -X- _ O
Objective -X- _ O
( -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Replaced -X- _ O
Token -X- _ O
Detection -X- _ O
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Besides -X- _ O
designing -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objectives -X- _ O
, -X- _ O
some -X- _ O
other -X- _ O
works -X- _ O
try -X- _ O
to -X- _ O
extend -X- _ O
BERT -X- _ B-MethodName
by -X- _ O
incorporating -X- _ O
knowledge -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Xiong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
or -X- _ O
with -X- _ O
multiple -X- _ O
languages -X- _ O
Conneau -X- _ O
and -X- _ O
Lample -X- _ O
, -X- _ O
2019;Chi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
works -X- _ O
utilize -X- _ O
the -X- _ O
stereotyped -X- _ O
layer -X- _ O
pattern -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
unnecessarily -X- _ O
optimal -X- _ O
( -X- _ O
Press -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
inspiring -X- _ O
us -X- _ O
to -X- _ O
further -X- _ O
investigate -X- _ O
more -X- _ O
layer -X- _ O
variety -X- _ O
to -X- _ O
improve -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
exploit -X- _ O
layer -X- _ O
variety -X- _ O
from -X- _ O
both -X- _ O
the -X- _ O
layer -X- _ O
type -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
layer -X- _ O
order -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
Neural -X- _ O
Architecture -X- _ O
Search -X- _ O
Manually -X- _ O
designing -X- _ O
neural -X- _ O
architecture -X- _ O
is -X- _ O
a -X- _ O
time -X- _ O
- -X- _ O
consuming -X- _ O
and -X- _ O
error -X- _ O
- -X- _ O
prone -X- _ O
process -X- _ O
( -X- _ O
Elsken -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
solve -X- _ O
this -X- _ O
, -X- _ O
many -X- _ O
neural -X- _ O
architecture -X- _ O
search -X- _ O
algorithms -X- _ O
are -X- _ O
proposed -X- _ O
. -X- _ O
Pioneering -X- _ O
works -X- _ O
utilize -X- _ O
reinforcement -X- _ O
learning -X- _ O
( -X- _ O
Zoph -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2017;Baker -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
or -X- _ O
evolutionary -X- _ O
algorithm -X- _ O
( -X- _ O
Real -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
sample -X- _ O
architecture -X- _ O
candidates -X- _ O
and -X- _ O
train -X- _ O
them -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
which -X- _ O
demand -X- _ O
huge -X- _ O
computation -X- _ O
that -X- _ O
ordinary -X- _ O
researchers -X- _ O
can -X- _ O
not -X- _ O
afford -X- _ O
. -X- _ O
To -X- _ O
reduce -X- _ O
computation -X- _ O
cost -X- _ O
, -X- _ O
recent -X- _ O
methods -X- _ O
( -X- _ O
Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Brock -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Bender -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a;Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
adopt -X- _ O
a -X- _ O
weight -X- _ O
sharing -X- _ O
strategy -X- _ O
that -X- _ O
a -X- _ O
supernet -X- _ O
subsuming -X- _ O
all -X- _ O
architectures -X- _ O
is -X- _ O
trained -X- _ O
only -X- _ O
once -X- _ O
and -X- _ O
all -X- _ O
architecture -X- _ O
candidates -X- _ O
can -X- _ O
inherit -X- _ O
their -X- _ O
weights -X- _ O
from -X- _ O
the -X- _ O
supernet -X- _ O
. -X- _ O
Despite -X- _ O
the -X- _ O
boom -X- _ O
of -X- _ O
NAS -X- _ O
research -X- _ O
, -X- _ O
most -X- _ O
works -X- _ O
focus -X- _ O
on -X- _ O
computer -X- _ O
vision -X- _ O
tasks -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Ghiasi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
NAS -X- _ O
on -X- _ O
NLP -X- _ O
is -X- _ O
not -X- _ O
fully -X- _ O
investigated -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
So -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
search -X- _ O
architectures -X- _ O
of -X- _ O
transformers -X- _ O
for -X- _ O
translation -X- _ O
tasks -X- _ O
. -X- _ O
leverage -X- _ O
differentiable -X- _ O
neural -X- _ O
architecture -X- _ O
to -X- _ O
automatically -X- _ O
compress -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
task -X- _ O
- -X- _ O
oriented -X- _ O
knowledge -X- _ O
distillation -X- _ O
for -X- _ O
specific -X- _ O
tasks -X- _ O
. -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
utilize -X- _ O
architecture -X- _ O
search -X- _ O
to -X- _ O
improve -X- _ O
models -X- _ O
based -X- _ O
on -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
for -X- _ O
the -X- _ O
relation -X- _ O
classification -X- _ O
task -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
methods -X- _ O
only -X- _ O
focus -X- _ O
on -X- _ O
specific -X- _ O
tasks -X- _ O
or -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
phase -X- _ O
. -X- _ O
Besides -X- _ O
, -X- _ O
Khetan -X- _ O
and -X- _ O
Karnin -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
employ -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
loss -X- _ O
to -X- _ O
help -X- _ O
prune -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
but -X- _ O
their -X- _ O
method -X- _ O
can -X- _ O
not -X- _ O
find -X- _ O
new -X- _ O
architectures -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
them -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
use -X- _ O
NAS -X- _ O
to -X- _ O
help -X- _ O
explore -X- _ O
new -X- _ O
architectures -X- _ O
in -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
scenario -X- _ O
for -X- _ O
general -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O
An -X- _ O
overview -X- _ O
of -X- _ O
our -X- _ O
approach -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
define -X- _ O
the -X- _ O
layer -X- _ O
variety -X- _ O
to -X- _ O
introduce -X- _ O
a -X- _ O
large -X- _ O
architecture -X- _ O
search -X- _ O
space -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
a -X- _ O
supernet -X- _ O
subsuming -X- _ O
all -X- _ O
candidate -X- _ O
architectures -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
an -X- _ O
evolutionary -X- _ O
algorithm -X- _ O
guided -X- _ O
by -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
MLM -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
accuracy -X- _ O
to -X- _ O
search -X- _ O
an -X- _ O
effective -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
what -X- _ O
follows -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
give -X- _ O
detailed -X- _ O
descriptions -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1(a -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
layer -X- _ O
variety -X- _ O
contains -X- _ O
two -X- _ O
aspects -X- _ O
: -X- _ O
layer -X- _ O
type -X- _ O
and -X- _ O
layer -X- _ O
order -X- _ O
, -X- _ O
both -X- _ O
of -X- _ O
which -X- _ O
are -X- _ O
important -X- _ O
for -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
but -X- _ O
not -X- _ O
exploited -X- _ O
before -X- _ O
. -X- _ O
The -X- _ O
layer -X- _ O
type -X- _ O
set -X- _ O
of -X- _ O
current -X- _ O
BERTlike -X- _ B-MethodName
models -X- _ O
consists -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
for -X- _ O
information -X- _ O
communication -X- _ O
and -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
for -X- _ O
nonlinear -X- _ O
transformation -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
global -X- _ O
operator -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
needs -X- _ O
to -X- _ O
take -X- _ O
as -X- _ O
input -X- _ O
all -X- _ O
tokens -X- _ O
to -X- _ O
compute -X- _ O
attention -X- _ O
weights -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
inefficient -X- _ O
in -X- _ O
capturing -X- _ O
local -X- _ O
information -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
. -X- _ O
We -X- _ O
notice -X- _ O
that -X- _ O
convolution -X- _ O
( -X- _ O
LeCun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1998;Krizhevsky -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
local -X- _ O
operator -X- _ O
, -X- _ O
has -X- _ O
been -X- _ O
successfully -X- _ O
applied -X- _ O
in -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
Zeng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Kim -X- _ O
, -X- _ O
2014;Kalchbrenner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2019b -X- _ O
. -X- _ O
A -X- _ O
typical -X- _ O
example -X- _ O
is -X- _ O
the -X- _ O
dynamic -X- _ O
convolution -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
summarization -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
augment -X- _ O
the -X- _ O
layer -X- _ O
type -X- _ O
set -X- _ O
by -X- _ O
introducing -X- _ O
dynamic -X- _ O
convolution -X- _ O
as -X- _ O
a -X- _ O
new -X- _ O
layer -X- _ O
type -X- _ O
. -X- _ O
The -X- _ O
layer -X- _ O
set -X- _ O
considered -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
thus -X- _ O
contains -X- _ O
three -X- _ O
types -X- _ O
of -X- _ O
layers -X- _ O
, -X- _ O
L -X- _ O
type -X- _ O
= -X- _ O
{ -X- _ O
L -X- _ O
SA -X- _ O
, -X- _ O
L -X- _ O
FF -X- _ O
, -X- _ O
L -X- _ O
DC -X- _ O
} -X- _ O
, -X- _ O
( -X- _ O
1)where -X- _ O
the -X- _ O
set -X- _ O
elements -X- _ O
denote -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
feedforward -X- _ O
and -X- _ O
dynamic -X- _ O
convolution -X- _ O
layers -X- _ O
respectively -X- _ O
. -X- _ O
See -X- _ O
Appendix -X- _ O
for -X- _ O
more -X- _ O
detailed -X- _ O
formulation -X- _ O
description -X- _ O
on -X- _ O
them -X- _ O
. -X- _ O
Layer -X- _ O
Order -X- _ O
The -X- _ O
other -X- _ O
variety -X- _ O
aspect -X- _ O
is -X- _ O
layer -X- _ O
order -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
order -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
is -X- _ O
the -X- _ O
interleaved -X- _ O
order -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
model -X- _ O
with -X- _ O
24 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
interleaved -X- _ O
order -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
by -X- _ O
the -X- _ O
following -X- _ O
list,[L -X- _ O
SA -X- _ O
1 -X- _ O
, -X- _ O
L -X- _ O
FF -X- _ O
2 -X- _ O
, -X- _ O
L -X- _ O
SA -X- _ O
3 -X- _ O
, -X- _ O
L -X- _ O
FF -X- _ O
4 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
L -X- _ O
SA -X- _ O
23 -X- _ O
, -X- _ O
L -X- _ O
FF -X- _ O
24 -X- _ O
] -X- _ O
. -X- _ O
( -X- _ O
2)Similarly -X- _ O
, -X- _ O
the -X- _ O
sandwich -X- _ O
order -X- _ O
( -X- _ O
Press -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
as -X- _ O
} -X- _ O
The -X- _ O
accuracy -X- _ B-MetricName
is -X- _ O
used -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
evolutionary -X- _ O
algorithm -X- _ O
for -X- _ O
generating -X- _ O
new -X- _ O
candidate -X- _ O
models.~After -X- _ O
T -X- _ O
iterations -X- _ O
, -X- _ O
the -X- _ O
candidate -X- _ O
with -X- _ O
best -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
accuracy -X- _ B-MetricName
is -X- _ O
output -X- _ O
as -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
. -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
can -X- _ O
be -X- _ O
scaled -X- _ O
up -X- _ O
to -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
medium -X- _ I-MethodName
/ -X- _ I-MethodName
base -X- _ I-MethodName
with -X- _ O
larger -X- _ O
hidden -X- _ O
size -X- _ O
. -X- _ O
Beyond -X- _ O
the -X- _ O
above -X- _ O
manually -X- _ O
designed -X- _ O
orders -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
neural -X- _ O
architecture -X- _ O
search -X- _ O
to -X- _ O
identify -X- _ O
more -X- _ O
effective -X- _ O
layer -X- _ O
orders -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
order -X- _ O
to -X- _ O
be -X- _ O
discovered -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
as[L -X- _ O
1 -X- _ O
, -X- _ O
L -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
L -X- _ O
i -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
L -X- _ O
N -X- _ O
] -X- _ O
, -X- _ O
( -X- _ O
4)where -X- _ O
L -X- _ B-HyperparameterName
i -X- _ O
∈ -X- _ O
L -X- _ O
type -X- _ O
and -X- _ O
N -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
. -X- _ O
Here -X- _ O
, -X- _ O
N -X- _ B-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
24 -X- _ B-HyperparameterValue
, -X- _ O
following -X- _ O
common -X- _ O
practice -X- _ O
. -X- _ O
The -X- _ O
layer -X- _ O
variety -X- _ O
introduced -X- _ O
above -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
huge -X- _ O
architecture -X- _ O
space -X- _ O
of -X- _ O
3 -X- _ O
24 -X- _ O
≈ -X- _ O
2.8 -X- _ O
× -X- _ O
10 -X- _ O
11 -X- _ O
candidate -X- _ O
models -X- _ O
to -X- _ O
be -X- _ O
explored -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
affordable -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
every -X- _ O
candidate -X- _ O
model -X- _ O
in -X- _ O
the -X- _ O
space -X- _ O
from -X- _ O
scratch -X- _ O
to -X- _ O
evaluate -X- _ O
their -X- _ O
performance -X- _ O
since -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
procedure -X- _ O
requires -X- _ O
huge -X- _ O
computations -X- _ O
. -X- _ O
To -X- _ O
reduce -X- _ O
the -X- _ O
search -X- _ O
computations -X- _ O
, -X- _ O
recent -X- _ O
NAS -X- _ O
works -X- _ O
( -X- _ O
Pham -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
exploit -X- _ O
a -X- _ O
weight -X- _ O
sharing -X- _ O
strategy -X- _ O
. -X- _ O
It -X- _ O
first -X- _ O
trains -X- _ O
a -X- _ O
supernet -X- _ O
subsuming -X- _ O
all -X- _ O
candidate -X- _ O
architectures -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
each -X- _ O
candidate -X- _ O
architecture -X- _ O
can -X- _ O
inherit -X- _ O
its -X- _ O
weights -X- _ O
from -X- _ O
the -X- _ O
trained -X- _ O
supernet -X- _ O
to -X- _ O
avoid -X- _ O
training -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
this -X- _ O
strategy -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
a -X- _ O
supernet -X- _ O
where -X- _ O
each -X- _ O
layer -X- _ O
contains -X- _ O
all -X- _ O
types -X- _ O
of -X- _ O
layers -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
feedforward -X- _ O
, -X- _ O
and -X- _ O
dynamic -X- _ O
convolution -X- _ O
. -X- _ O
The -X- _ O
supernet -X- _ O
architecture -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
asA -X- _ O
= -X- _ O
[ -X- _ O
{ -X- _ O
L -X- _ O
SA -X- _ O
1 -X- _ O
, -X- _ O
L -X- _ O
FF -X- _ O
1 -X- _ O
, -X- _ O
L -X- _ O
DC -X- _ O
1 -X- _ O
} -X- _ O
, -X- _ O
{ -X- _ O
L -X- _ O
SA -X- _ O
2 -X- _ O
, -X- _ O
L -X- _ O
FF -X- _ O
2 -X- _ O
, -X- _ O
L -X- _ O
DC -X- _ O
2 -X- _ O
} -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
{ -X- _ O
L -X- _ O
SA -X- _ O
N -X- _ O
, -X- _ O
L -X- _ O
FF -X- _ O
N -X- _ O
, -X- _ O
L -X- _ O
DC -X- _ O
N -X- _ O
} -X- _ O
] -X- _ O
.(5)Masked -X- _ O
Language -X- _ O
Modeling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
utilized -X- _ O
as -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objective -X- _ O
to -X- _ O
pretrain -X- _ O
the -X- _ O
supernet -X- _ O
since -X- _ O
MLM -X- _ O
accuracy -X- _ B-MetricName
can -X- _ O
reflect -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Most -X- _ O
weight -X- _ O
sharing -X- _ O
approaches -X- _ O
on -X- _ O
NAS -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
; -X- _ O
train -X- _ O
and -X- _ O
optimize -X- _ O
the -X- _ O
full -X- _ O
supernet -X- _ O
: -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
each -X- _ O
layer -X- _ O
is -X- _ O
the -X- _ O
weighted -X- _ O
sum -X- _ O
of -X- _ O
all -X- _ O
types -X- _ O
of -X- _ O
candidate -X- _ O
layers -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
guarantee -X- _ O
the -X- _ O
sampled -X- _ O
single -X- _ O
type -X- _ O
of -X- _ O
layer -X- _ O
also -X- _ O
works -X- _ O
( -X- _ O
Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).To -X- _ O
handle -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
randomly -X- _ O
sample -X- _ O
a -X- _ O
submodel -X- _ O
from -X- _ O
the -X- _ O
supernet -X- _ O
to -X- _ O
participate -X- _ O
in -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
propagation -X- _ O
per -X- _ O
training -X- _ O
step -X- _ O
( -X- _ O
Cai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
sampled -X- _ O
submodel -X- _ O
architecture -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
asa -X- _ O
= -X- _ O
[ -X- _ O
L -X- _ O
1 -X- _ O
, -X- _ O
L -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
L -X- _ O
i -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
L -X- _ O
N -X- _ O
] -X- _ O
, -X- _ O
( -X- _ O
6)where -X- _ O
L -X- _ O
i -X- _ O
∈ -X- _ O
L -X- _ O
type -X- _ O
∼ -X- _ O
U -X- _ O
with -X- _ O
uniform -X- _ O
probability -X- _ O
distribution -X- _ O
P -X- _ O
r -X- _ O
= -X- _ O
1/3 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
method -X- _ O
, -X- _ O
the -X- _ O
optimized -X- _ O
supernet -X- _ O
weights -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
for -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
: -X- _ O
T -X- _ O
do -X- _ O
S -X- _ O
MLM -X- _ O
i−1 -X- _ O
: -X- _ O
= -X- _ O
∅ -X- _ O
; -X- _ O
for -X- _ O
a -X- _ O
in -X- _ O
S -X- _ O
i−1 -X- _ O
do -X- _ O
MLM -X- _ O
a -X- _ O
val -X- _ O
: -X- _ O
= -X- _ O
Inference(N -X- _ O
( -X- _ O
a -X- _ O
, -X- _ O
W -X- _ O
A -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
D -X- _ O
val -X- _ O
) -X- _ O
; -X- _ O
S -X- _ O
MLM -X- _ O
i−1 -X- _ O
: -X- _ O
= -X- _ O
S -X- _ O
MLM -X- _ O
i−1 -X- _ O
∪ -X- _ O
MLM -X- _ O
a -X- _ O
val -X- _ O
; -X- _ O
S -X- _ O
topk -X- _ O
: -X- _ O
= -X- _ O
Update(S -X- _ O
topk -X- _ O
, -X- _ O
S -X- _ O
i−1 -X- _ O
, -X- _ O
S -X- _ O
MLM -X- _ O
i−1 -X- _ O
) -X- _ O
; -X- _ O
S -X- _ O
cro -X- _ O
: -X- _ O
= -X- _ O
Crossover(S -X- _ O
topk -X- _ O
, -X- _ O
N -X- _ O
cro -X- _ O
) -X- _ O
; -X- _ O
S -X- _ O
mut -X- _ O
: -X- _ O
= -X- _ O
Mutation(S -X- _ O
topk -X- _ O
, -X- _ O
N -X- _ O
mut -X- _ O
, -X- _ O
p -X- _ O
) -X- _ O
; -X- _ O
S -X- _ O
i -X- _ O
: -X- _ O
= -X- _ O
S -X- _ O
cro -X- _ O
∪ -X- _ O
S -X- _ O
mut -X- _ O
; -X- _ O
return -X- _ O
a -X- _ O
* -X- _ O
= -X- _ O
argmax -X- _ O
a∈S -X- _ O
topk -X- _ O
MLM -X- _ O
a -X- _ O
val -X- _ O
; -X- _ O
as -X- _ O
W -X- _ O
A -X- _ O
= -X- _ O
argmin -X- _ O
W -X- _ O
E -X- _ O
a∼U -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
[ -X- _ O
L -X- _ O
pre−train -X- _ O
( -X- _ O
N -X- _ O
( -X- _ O
a -X- _ O
, -X- _ O
W -X- _ O
( -X- _ O
a)))],(7)where -X- _ O
W -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
submodel -X- _ O
weights -X- _ O
inherited -X- _ O
from -X- _ O
the -X- _ O
supernet -X- _ O
, -X- _ O
N -X- _ O
means -X- _ O
the -X- _ O
submodel -X- _ O
with -X- _ O
specific -X- _ O
architecture -X- _ O
and -X- _ O
weights -X- _ O
, -X- _ O
L -X- _ O
pre−train -X- _ O
denotes -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
MLM -X- _ O
loss -X- _ O
and -X- _ O
a -X- _ O
∼ -X- _ O
U -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
means -X- _ O
a -X- _ O
is -X- _ O
uniformly -X- _ O
sampled -X- _ O
from -X- _ O
A. -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
recent -X- _ O
NAS -X- _ O
works -X- _ O
( -X- _ O
Elsken -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Guo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
an -X- _ O
evolutionary -X- _ O
algorithm -X- _ O
( -X- _ O
EA -X- _ O
) -X- _ O
to -X- _ O
search -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Previously -X- _ O
Real -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
utilized -X- _ O
an -X- _ O
evolutionary -X- _ O
method -X- _ O
in -X- _ O
NAS -X- _ O
but -X- _ O
they -X- _ O
trained -X- _ O
each -X- _ O
candidate -X- _ O
model -X- _ O
from -X- _ O
scratch -X- _ O
which -X- _ O
is -X- _ O
costly -X- _ O
and -X- _ O
inefficient -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
thanks -X- _ O
to -X- _ O
the -X- _ O
supernet -X- _ O
mentioned -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
need -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
candidate -X- _ O
models -X- _ O
from -X- _ O
scratch -X- _ O
since -X- _ O
their -X- _ O
weights -X- _ O
can -X- _ O
be -X- _ O
inherited -X- _ O
from -X- _ O
the -X- _ O
supernet -X- _ O
. -X- _ O
Next -X- _ O
problem -X- _ O
is -X- _ O
how -X- _ O
to -X- _ O
select -X- _ O
indicator -X- _ O
of -X- _ O
the -X- _ O
candidate -X- _ O
models -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
EA -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
search -X- _ O
a -X- _ O
general -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
to -X- _ O
benefit -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
specific -X- _ O
task -X- _ O
. -X- _ O
Traditional -X- _ O
NAS -X- _ O
methods -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
use -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
as -X- _ O
the -X- _ O
objective -X- _ O
to -X- _ O
search -X- _ O
for -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
models -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
work -X- _ O
by -X- _ O
Khetan -X- _ O
and -X- _ O
Karnin -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
BooksCorpus -X- _ B-DatasetName
is -X- _ O
no -X- _ O
longer -X- _ O
publicly -X- _ O
available -X- _ O
. -X- _ O
To -X- _ O
ease -X- _ O
reproduction -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
models -X- _ O
on -X- _ O
OpenWebText -X- _ B-DatasetName
( -X- _ O
Gokaslan -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
is -X- _ O
open -X- _ O
- -X- _ O
sourced -X- _ O
and -X- _ O
of -X- _ O
similar -X- _ O
size -X- _ O
with -X- _ O
the -X- _ O
corpus -X- _ O
used -X- _ O
by -X- _ O
BERT -X- _ B-DatasetName
. -X- _ O
When -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
the -X- _ O
supernet -X- _ O
, -X- _ O
we -X- _ O
leave -X- _ O
2 -X- _ O
% -X- _ O
data -X- _ O
as -X- _ O
our -X- _ O
validation -X- _ O
set -X- _ O
for -X- _ O
evolutionary -X- _ O
search -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
Datasets -X- _ O
To -X- _ O
compare -X- _ O
our -X- _ O
model -X- _ O
with -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
on -X- _ O
GLUE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
including -X- _ O
various -X- _ O
tasks -X- _ O
for -X- _ O
general -X- _ O
language -X- _ O
understanding -X- _ O
, -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
1.1/2.0 -X- _ I-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016(Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018 -X- _ O
for -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
. -X- _ O
See -X- _ O
Appendix -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
of -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
different -X- _ O
model -X- _ O
sizes -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
" -X- _ O
small -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
medium -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
base -X- _ O
" -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
layer -X- _ O
number -X- _ O
of -X- _ O
24 -X- _ B-HyperparameterValue
but -X- _ O
different -X- _ O
hidden -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
, -X- _ O
384 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
768 -X- _ B-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
The -X- _ O
detailed -X- _ O
hyperparameters -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Appendix -X- _ O
. -X- _ O
To -X- _ O
reduce -X- _ O
training -X- _ O
cost -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
the -X- _ O
supernet -X- _ O
only -X- _ O
in -X- _ O
small -X- _ O
size -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
layer -X- _ O
number -X- _ O
of -X- _ O
models -X- _ O
in -X- _ O
medium -X- _ O
and -X- _ O
base -X- _ O
sizes -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
small -X- _ O
- -X- _ O
sized -X- _ O
one -X- _ O
, -X- _ O
the -X- _ O
obtained -X- _ O
architecture -X- _ O
of -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
can -X- _ O
be -X- _ O
easily -X- _ O
scaled -X- _ O
up -X- _ O
to -X- _ O
the -X- _ O
ones -X- _ O
of -X- _ O
medium -X- _ O
and -X- _ O
base -X- _ O
sizes -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterValue
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
supernet -X- _ O
with -X- _ O
MLM -X- _ O
loss -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-4 -X- _ B-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
128 -X- _ B-HyperparameterValue
, -X- _ O
max -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
128 -X- _ B-HyperparameterValue
and -X- _ O
pre -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
step -X- _ I-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ O
2 -X- _ B-HyperparameterValue
million -X- _ I-HyperparameterValue
. -X- _ O
See -X- _ O
Appendix -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
. -X- _ O
Evaluation -X- _ O
Setup -X- _ O
To -X- _ O
compare -X- _ O
with -X- _ O
other -X- _ O
pretrained -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
searched -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
architecture -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
from -X- _ O
scratch -X- _ O
on -X- _ O
the -X- _ O
Open -X- _ B-DatasetName
- -X- _ I-DatasetName
WebText -X- _ I-DatasetName
( -X- _ O
Gokaslan -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
using -X- _ O
Re -X- _ O
- -X- _ O
placed -X- _ O
Token -X- _ O
Detection -X- _ O
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
since -X- _ O
it -X- _ O
can -X- _ O
save -X- _ O
computation -X- _ O
cost -X- _ O
. -X- _ O
We -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
on -X- _ O
GLUE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016(Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018 -X- _ O
downstream -X- _ O
tasks -X- _ O
with -X- _ O
most -X- _ O
hyperparameters -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
those -X- _ O
of -X- _ O
ELECTRA -X- _ B-MethodName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
fair -X- _ O
comparison -X- _ O
. -X- _ O
For -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
, -X- _ O
the -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
Matthews -X- _ B-MetricName
correlation -X- _ I-MetricName
for -X- _ O
CoLA -X- _ B-DatasetName
, -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
for -X- _ O
STS -X- _ B-DatasetName
, -X- _ O
and -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
other -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
averaged -X- _ O
to -X- _ O
get -X- _ O
GLUE -X- _ O
score -X- _ O
. -X- _ O
We -X- _ O
utilize -X- _ O
evaluation -X- _ O
metrics -X- _ O
of -X- _ O
Exact -X- _ B-MetricName
- -X- _ I-MetricName
Match -X- _ I-MetricName
( -X- _ O
EM -X- _ B-MetricName
) -X- _ O
and -X- _ O
F1 -X- _ B-MetricName
for -X- _ O
SQuAD -X- _ B-DatasetName
1.1/2.0 -X- _ I-DatasetName
. -X- _ O
Some -X- _ O
of -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
datasets -X- _ O
are -X- _ O
small -X- _ O
, -X- _ O
and -X- _ O
consequently -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
may -X- _ O
vary -X- _ O
substantially -X- _ O
for -X- _ O
different -X- _ O
random -X- _ O
seeds -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
ELECTRA -X- _ B-MethodName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
median -X- _ O
of -X- _ O
10 -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
runs -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
pretrained -X- _ O
model -X- _ O
for -X- _ O
each -X- _ O
result -X- _ O
. -X- _ O
See -X- _ O
Appendix -X- _ O
for -X- _ O
more -X- _ O
evaluation -X- _ O
details -X- _ O
. -X- _ O
Layer -X- _ O
Variety -X- _ O
Various -X- _ O
models -X- _ O
are -X- _ O
constructed -X- _ O
with -X- _ O
different -X- _ O
layer -X- _ O
variety -X- _ O
designs -X- _ O
, -X- _ O
and -X- _ O
their -X- _ O
results -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
development -X- _ O
set -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
layer -X- _ O
types -X- _ O
, -X- _ O
if -X- _ O
only -X- _ O
two -X- _ O
layer -X- _ O
types -X- _ O
are -X- _ O
provided -X- _ O
, -X- _ O
selecting -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
yields -X- _ O
the -X- _ O
best -X- _ O
result -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
always -X- _ O
achieve -X- _ O
performance -X- _ O
higher -X- _ O
than -X- _ O
80 -X- _ B-MetricValue
under -X- _ O
different -X- _ O
search -X- _ O
methods -X- _ O
. -X- _ O
With -X- _ O
only -X- _ O
dynamic -X- _ O
convolution -X- _ O
and -X- _ O
feedforward -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
drops -X- _ O
dramatically -X- _ O
to -X- _ O
around -X- _ O
65 -X- _ B-MetricValue
. -X- _ O
Surprisingly -X- _ O
, -X- _ O
without -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
, -X- _ O
the -X- _ O
layer -X- _ O
set -X- _ O
of -X- _ O
dynamic -X- _ O
convolution -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
can -X- _ O
still -X- _ O
achieve -X- _ O
relatively -X- _ O
good -X- _ O
score -X- _ O
, -X- _ O
near -X- _ O
80 -X- _ B-MetricValue
. -X- _ O
When -X- _ O
using -X- _ O
all -X- _ O
the -X- _ O
three -X- _ O
layer -X- _ O
types -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
the -X- _ O
best -X- _ O
81.8 -X- _ B-MetricValue
score -X- _ O
, -X- _ O
1.4 -X- _ B-MetricValue
higher -X- _ O
than -X- _ O
the -X- _ O
strong -X- _ O
baseline -X- _ O
ELECTRA -X- _ B-MethodName
( -X- _ O
80.4 -X- _ B-MetricValue
) -X- _ O
and -X- _ O
0.6 -X- _ B-MetricValue
higher -X- _ O
than -X- _ O
the -X- _ O
model -X- _ O
searched -X- _ O
with -X- _ O
only -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
feedforward -X- _ O
( -X- _ O
81.2 -X- _ B-MetricValue
) -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
effective -X- _ O
to -X- _ O
augment -X- _ O
the -X- _ O
layer -X- _ O
type -X- _ O
set -X- _ O
by -X- _ O
including -X- _ O
convolution -X- _ O
to -X- _ O
extract -X- _ O
local -X- _ O
information -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
layer -X- _ O
orders -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
layer -X- _ O
types -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
with -X- _ O
either -X- _ O
EA -X- _ O
or -X- _ O
randomly -X- _ O
searched -X- _ O
orders -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
those -X- _ O
with -X- _ O
randomly -X- _ O
sampled -X- _ O
orders -X- _ O
, -X- _ O
reflecting -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
investigating -X- _ O
layer -X- _ O
orders -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
layer -X- _ O
types -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
, -X- _ O
the -X- _ O
EA -X- _ O
searched -X- _ O
model -X- _ O
obtains -X- _ O
81.2 -X- _ B-MetricValue
score -X- _ O
, -X- _ O
improving -X- _ O
BERT -X- _ B-MethodName
/ -X- _ O
ELECTRA -X- _ B-MethodName
by -X- _ O
6.1/0.8 -X- _ B-MetricValue
as -X- _ O
well -X- _ O
as -X- _ O
Sandwich -X- _ B-MethodName
by -X- _ O
2.6 -X- _ B-MetricValue
. -X- _ O
Blue -X- _ O
and -X- _ O
yellow -X- _ O
dots -X- _ O
denote -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
top -X- _ O
10 -X- _ O
candidates -X- _ O
for -X- _ O
each -X- _ O
method -X- _ O
respectively -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
plots -X- _ O
mean -X- _ O
their -X- _ O
averages -X- _ O
. -X- _ O
each -X- _ O
design -X- _ O
of -X- _ O
layer -X- _ O
type -X- _ O
set -X- _ O
, -X- _ O
the -X- _ O
order -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
one -X- _ O
among -X- _ O
5 -X- _ O
randomly -X- _ O
generated -X- _ O
orders -X- _ O
that -X- _ O
are -X- _ O
estimated -X- _ O
by -X- _ O
training -X- _ O
models -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
" -X- _ O
Randomly -X- _ O
searched -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
EA -X- _ O
searched -X- _ O
" -X- _ O
are -X- _ O
both -X- _ O
supernet -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
candidate -X- _ O
models -X- _ O
are -X- _ O
inherited -X- _ O
from -X- _ O
the -X- _ O
supernet -X- _ O
. -X- _ O
" -X- _ O
Randomly -X- _ O
searched -X- _ O
" -X- _ O
produces -X- _ O
candidate -X- _ O
models -X- _ O
at -X- _ O
random -X- _ O
for -X- _ O
estimation -X- _ O
while -X- _ O
" -X- _ O
EA -X- _ O
searched -X- _ O
" -X- _ O
generates -X- _ O
candidate -X- _ O
models -X- _ O
with -X- _ O
evolutionary -X- _ O
algorithm -X- _ O
guided -X- _ O
by -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
MLM -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
With -X- _ O
the -X- _ O
same -X- _ O
layer -X- _ O
types -X- _ O
, -X- _ O
EA -X- _ O
searched -X- _ O
orders -X- _ O
are -X- _ O
generally -X- _ O
better -X- _ O
than -X- _ O
randomly -X- _ O
searched -X- _ O
ones -X- _ O
while -X- _ O
the -X- _ O
randomly -X- _ O
searched -X- _ O
ones -X- _ O
are -X- _ O
generally -X- _ O
better -X- _ O
than -X- _ O
random -X- _ O
ones -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
plots -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trianing -X- _ O
MLM -X- _ O
evaluation -X- _ O
accuracy -X- _ B-MetricName
over -X- _ O
search -X- _ O
iterations -X- _ O
with -X- _ O
both -X- _ O
random -X- _ O
and -X- _ O
evolutionary -X- _ O
search -X- _ O
methods -X- _ O
. -X- _ O
It -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
evolutionary -X- _ O
search -X- _ O
is -X- _ O
obviously -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
random -X- _ O
search -X- _ O
, -X- _ O
demonstrating -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
evolutionary -X- _ O
search -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
When -X- _ O
running -X- _ O
the -X- _ O
evolutionary -X- _ O
method -X- _ O
with -X- _ O
different -X- _ O
seeds -X- _ O
, -X- _ O
we -X- _ O
see -X- _ O
that -X- _ O
the -X- _ O
resulting -X- _ O
models -X- _ O
prefer -X- _ O
stacking -X- _ O
dynamic -X- _ O
convolutions -X- _ O
at -X- _ O
the -X- _ O
bottom -X- _ O
two -X- _ O
layers -X- _ O
for -X- _ O
extracting -X- _ O
local -X- _ O
information -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
at -X- _ O
the -X- _ O
top -X- _ O
layer -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
global -X- _ O
information -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
these -X- _ O
observation -X- _ O
, -X- _ O
for -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
, -X- _ O
if -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
bottom -X- _ O
two -X- _ O
layers -X- _ O
with -X- _ O
dynamic -X- _ O
convolutions -X- _ O
or -X- _ O
the -X- _ O
top -X- _ O
layer -X- _ O
with -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
improved -X- _ O
by -X- _ O
0.3 -X- _ B-MetricValue
or -X- _ O
0.5 -X- _ B-MetricValue
respectively -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
development -X- _ O
set -X- _ O
. -X- _ O
If -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
bottom -X- _ O
8 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
with -X- _ O
manually -X- _ O
designed -X- _ O
' -X- _ O
ccsfccsf -X- _ O
' -X- _ O
( -X- _ O
' -X- _ O
c -X- _ O
' -X- _ O
, -X- _ O
's -X- _ O
' -X- _ O
and -X- _ O
' -X- _ O
f -X- _ O
' -X- _ O
denote -X- _ O
dynamic -X- _ O
convolution -X- _ O
, -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
and -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layers -X- _ O
, -X- _ O
respectively -X- _ O
) -X- _ O
and -X- _ O
replace -X- _ O
the -X- _ O
top -X- _ O
8 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
with -X- _ O
manually -X- _ O
designed -X- _ O
' -X- _ O
ssfsssfs -X- _ O
' -X- _ O
together -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
0.7 -X- _ B-MetricValue
performance -X- _ O
improvement -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
helpful -X- _ O
to -X- _ O
stack -X- _ O
dynamic -X- _ O
convolution -X- _ O
at -X- _ O
the -X- _ O
bottom -X- _ O
and -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
at -X- _ O
the -X- _ O
top -X- _ O
. -X- _ O
We -X- _ O
only -X- _ O
investigate -X- _ O
layer -X- _ O
variety -X- _ O
and -X- _ O
search -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
small -X- _ O
- -X- _ O
sized -X- _ O
setting -X- _ O
to -X- _ O
save -X- _ O
computation -X- _ O
cost -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
interesting -X- _ O
to -X- _ O
know -X- _ O
whether -X- _ O
the -X- _ O
searched -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
generalized -X- _ O
to -X- _ O
larger -X- _ O
models -X- _ O
with -X- _ O
large -X- _ O
hidden -X- _ O
size -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
For -X- _ O
larger -X- _ O
model -X- _ O
size -X- _ O
" -X- _ O
medium -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
base -X- _ O
" -X- _ O
, -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERTs -X- _ I-MethodName
still -X- _ O
outperform -X- _ O
other -X- _ O
baseline -X- _ O
models -X- _ O
, -X- _ O
demonstrating -X- _ O
the -X- _ O
good -X- _ O
generalization -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
with -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
pretrained -X- _ O
models -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
; -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
testing -X- _ O
set -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
1.1/2.0 -X- _ I-DatasetName
to -X- _ O
show -X- _ O
its -X- _ O
advantages -X- _ O
. -X- _ O
Although -X- _ O
more -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
/ -X- _ O
steps -X- _ O
and -X- _ O
lager -X- _ O
model -X- _ O
size -X- _ O
can -X- _ O
significantly -X- _ O
help -X- _ O
improve -X- _ O
performance -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
computation -X- _ O
resource -X- _ O
limit -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
our -X- _ O
models -X- _ O
in -X- _ O
small -X- _ O
/ -X- _ O
medium -X- _ O
/ -X- _ O
base -X- _ O
sizes -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
OpenWebText -X- _ B-DatasetName
( -X- _ O
Gokaslan -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
evaluating -X- _ O
models -X- _ O
with -X- _ O
more -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
/ -X- _ O
steps -X- _ O
and -X- _ O
larger -X- _ O
model -X- _ O
size -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
list -X- _ O
some -X- _ O
knowledge -X- _ O
distillation -X- _ O
methods -X- _ O
for -X- _ O
comparison -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
note -X- _ O
that -X- _ O
these -X- _ O
methods -X- _ O
rely -X- _ O
on -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
large -X- _ O
teacher -X- _ O
network -X- _ O
and -X- _ O
thus -X- _ O
are -X- _ O
orthogonal -X- _ O
to -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
other -X- _ O
methods -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
presents -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
testing -X- _ O
set -X- _ O
. -X- _ O
It -X- _ O
shows -X- _ O
that -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
outperforms -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
with -X- _ O
similar -X- _ O
model -X- _ O
size -X- _ O
. -X- _ O
Remarkably -X- _ O
, -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
/ -X- _ I-MethodName
base -X- _ I-MethodName
achieve -X- _ O
79.8/85.1 -X- _ B-MetricValue
, -X- _ O
1.8/1.6 -X- _ B-MetricValue
higher -X- _ O
than -X- _ O
strong -X- _ O
baselines -X- _ O
ELECTRAsmall -X- _ B-MethodName
/ -X- _ I-MethodName
base -X- _ I-MethodName
. -X- _ O
Even -X- _ O
compared -X- _ O
with -X- _ O
knowledge -X- _ O
distillation -X- _ O
based -X- _ O
model -X- _ O
MobileBERT -X- _ B-MethodName
, -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
medium -X- _ I-MethodName
still -X- _ O
outperforms -X- _ O
it -X- _ O
by -X- _ O
0.3 -X- _ B-MetricValue
. -X- _ O
Since -X- _ O
there -X- _ O
is -X- _ O
nearly -X- _ O
no -X- _ O
single -X- _ O
model -X- _ O
submission -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
leaderboard -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
compare -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
with -X- _ O
other -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
sets -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
outperforms -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
significantly -X- _ O
, -X- _ O
like -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
73.7 -X- _ B-MetricName
versus -X- _ O
69.4 -X- _ B-MetricName
on -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
. -X- _ O
However -X- _ O
, -X- _ O
when -X- _ O
we -X- _ O
generalize -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
to -X- _ O
base -X- _ O
size -X- _ O
, -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
and -X- _ O
ELECTRA -X- _ B-MethodName
with -X- _ O
base -X- _ O
size -X- _ O
is -X- _ O
narrower -X- _ O
than -X- _ O
that -X- _ O
with -X- _ O
small -X- _ O
size -X- _ O
. -X- _ O
One -X- _ O
reason -X- _ O
may -X- _ O
be -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
is -X- _ O
searched -X- _ O
by -X- _ O
our -X- _ O
method -X- _ O
while -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
is -X- _ O
only -X- _ O
generalized -X- _ O
from -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
- -X- _ I-MethodName
small -X- _ I-MethodName
with -X- _ O
larger -X- _ O
hidden -X- _ O
size -X- _ O
. -X- _ O
We -X- _ O
are -X- _ O
the -X- _ O
first -X- _ O
to -X- _ O
exploit -X- _ O
layer -X- _ O
variety -X- _ O
for -X- _ O
improving -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
from -X- _ O
two -X- _ O
aspects -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
layer -X- _ O
types -X- _ O
and -X- _ O
layer -X- _ O
orders -X- _ O
. -X- _ O
For -X- _ O
layer -X- _ O
types -X- _ O
, -X- _ O
we -X- _ O
augment -X- _ O
the -X- _ O
layer -X- _ O
type -X- _ O
set -X- _ O
by -X- _ O
including -X- _ O
convolution -X- _ O
for -X- _ O
local -X- _ O
information -X- _ O
extraction -X- _ O
. -X- _ O
For -X- _ O
layer -X- _ O
orders -X- _ O
, -X- _ O
beyond -X- _ O
the -X- _ O
stereotyped -X- _ O
interleaved -X- _ O
one -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
more -X- _ O
effective -X- _ O
orders -X- _ O
by -X- _ O
using -X- _ O
an -X- _ O
evolutionary -X- _ O
based -X- _ O
search -X- _ O
algorithm -X- _ O
. -X- _ O
Experiment -X- _ O
results -X- _ O
show -X- _ O
our -X- _ O
obtained -X- _ O
model -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
outperforms -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
its -X- _ O
variants -X- _ O
on -X- _ O
various -X- _ O
downstream -X- _ O
tasks.program -X- _ O
and -X- _ O
Google -X- _ O
Cloud -X- _ O
Research -X- _ O
Credits -X- _ O
Program -X- _ O
for -X- _ O
the -X- _ O
support -X- _ O
of -X- _ O
computational -X- _ O
resources -X- _ O
. -X- _ O
Daojian -X- _ O
Zeng -X- _ O
, -X- _ O
Kang -X- _ O
Liu -X- _ O
, -X- _ O
Siwei -X- _ O
Lai -X- _ O
, -X- _ O
Guangyou -X- _ O
Zhou -X- _ O
, -X- _ O
and -X- _ O
Jun -X- _ O
Zhao -X- _ O
. -X- _ O
2014 -X- _ O
For -X- _ O
a -X- _ O
layer -X- _ O
, -X- _ O
assume -X- _ O
its -X- _ O
input -X- _ O
is -X- _ O
I -X- _ O
∈ -X- _ O
R -X- _ O
s×c -X- _ O
and -X- _ O
output -X- _ O
is -X- _ O
O -X- _ O
∈ -X- _ O
R -X- _ O
s×c -X- _ O
, -X- _ O
where -X- _ O
s -X- _ O
is -X- _ O
the -X- _ O
sequence -X- _ O
length -X- _ O
and -X- _ O
c -X- _ O
is -X- _ O
the -X- _ O
hidden -X- _ O
size -X- _ O
( -X- _ O
channel -X- _ O
dimension -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
simplicity -X- _ O
, -X- _ O
c -X- _ O
takes -X- _ O
the -X- _ O
same -X- _ O
value -X- _ O
for -X- _ O
the -X- _ O
input -X- _ O
and -X- _ O
output -X- _ O
. -X- _ O
Self -X- _ O
- -X- _ O
Attention -X- _ O
The -X- _ O
self -X- _ O
- -X- _ O
Attention -X- _ O
layer -X- _ O
, -X- _ O
also -X- _ O
known -X- _ O
as -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
transforms -X- _ O
the -X- _ O
input -X- _ O
by -X- _ O
three -X- _ O
linear -X- _ O
transformations -X- _ O
into -X- _ O
the -X- _ O
key -X- _ O
K -X- _ O
, -X- _ O
query -X- _ O
Q -X- _ O
and -X- _ O
value -X- _ O
V -X- _ O
vectors -X- _ O
respectively -X- _ O
, -X- _ O
K -X- _ O
= -X- _ O
Reshape(IW -X- _ O
K -X- _ O
+ -X- _ O
b -X- _ O
K -X- _ O
) -X- _ O
Q -X- _ O
= -X- _ O
Reshape(IW -X- _ O
Q -X- _ O
+ -X- _ O
b -X- _ O
Q -X- _ O
) -X- _ O
V -X- _ O
= -X- _ O
Reshape(IW -X- _ O
V -X- _ O
+ -X- _ O
b -X- _ O
V -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
9)whereK -X- _ O
, -X- _ O
Q -X- _ O
, -X- _ O
V -X- _ O
∈ -X- _ O
R -X- _ O
h×s×d -X- _ O
, -X- _ O
W -X- _ O
K -X- _ O
, -X- _ O
W -X- _ O
Q -X- _ O
, -X- _ O
W -X- _ O
V -X- _ O
∈ -X- _ O
R -X- _ O
c×c -X- _ O
, -X- _ O
and -X- _ O
b -X- _ O
K -X- _ O
, -X- _ O
b -X- _ O
Q -X- _ O
, -X- _ O
b -X- _ O
V -X- _ O
∈ -X- _ O
R -X- _ O
c -X- _ O
. -X- _ O
Notice -X- _ O
that -X- _ O
h -X- _ B-HyperparameterName
× -X- _ O
d -X- _ B-HyperparameterName
= -X- _ O
cwhere -X- _ O
h -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
and -X- _ O
d -X- _ B-HyperparameterName
is -X- _ O
the -X- _ O
head -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
above -X- _ O
K -X- _ O
and -X- _ O
Q -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
compute -X- _ O
their -X- _ O
similarity -X- _ O
matrix -X- _ O
M -X- _ O
which -X- _ O
is -X- _ O
then -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
new -X- _ O
value -X- _ O
V -X- _ O
: -X- _ O
M -X- _ O
= -X- _ O
Softmax(KQ -X- _ B-HyperparameterValue
/ -X- _ O
√ -X- _ O
d -X- _ O
) -X- _ O
V -X- _ O
= -X- _ O
Reshape(M -X- _ O
V -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
10)where -X- _ O
M -X- _ O
∈ -X- _ O
R -X- _ O
h×s×s -X- _ O
and -X- _ O
V -X- _ O
∈ -X- _ O
R -X- _ O
s×c -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
a -X- _ O
linear -X- _ O
transformation -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
exchange -X- _ O
information -X- _ O
between -X- _ O
different -X- _ O
heads -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
shortcut -X- _ O
connection -X- _ O
and -X- _ O
layer -X- _ O
normalization -X- _ O
, -X- _ O
O -X- _ O
= -X- _ O
Norm(V -X- _ B-HyperparameterValue
W -X- _ O
O -X- _ O
+ -X- _ O
b -X- _ O
O -X- _ O
+ -X- _ O
I),(11)whereW -X- _ O
O -X- _ O
∈ -X- _ O
R -X- _ O
c×c -X- _ O
and -X- _ O
b -X- _ O
O -X- _ O
∈ -X- _ O
R -X- _ O
c -X- _ O
.Feed -X- _ O
- -X- _ O
Forward -X- _ O
The -X- _ O
feed -X- _ O
- -X- _ O
forward -X- _ O
layer -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
includes -X- _ O
two -X- _ O
linear -X- _ O
transformations -X- _ O
with -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
linear -X- _ O
activation -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
shortcut -X- _ O
connection -X- _ O
and -X- _ O
layer -X- _ O
normalization -X- _ O
, -X- _ O
N -X- _ O
= -X- _ O
GELU(IW -X- _ B-HyperparameterValue
1 -X- _ O
+ -X- _ O
b -X- _ O
1 -X- _ O
) -X- _ O
O -X- _ O
= -X- _ O
Norm(N -X- _ O
W -X- _ O
2 -X- _ O
+ -X- _ O
b -X- _ O
2 -X- _ O
+ -X- _ O
I),(12)where -X- _ O
W -X- _ O
1 -X- _ O
∈ -X- _ O
R -X- _ O
c×rc -X- _ O
and -X- _ O
W -X- _ O
2 -X- _ O
∈ -X- _ O
R -X- _ O
rc×c -X- _ O
with -X- _ O
a -X- _ O
ratio -X- _ O
r. -X- _ O
GELU(• -X- _ B-HyperparameterValue
) -X- _ O
denotes -X- _ O
the -X- _ O
Gaussian -X- _ O
Error -X- _ O
Linear -X- _ O
Unit -X- _ O
( -X- _ O
Hendrycks -X- _ O
and -X- _ O
Gimpel -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
the -X- _ O
vanilla -X- _ O
dynamic -X- _ O
convolution -X- _ O
that -X- _ O
directly -X- _ O
generates -X- _ O
dynamic -X- _ O
kernel -X- _ O
from -X- _ O
V -X- _ O
∈ -X- _ O
R -X- _ O
s×c -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
supplement -X- _ O
a -X- _ O
separate -X- _ O
convolution -X- _ O
( -X- _ O
Howard -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
with -X- _ O
depthwise -X- _ O
weights -X- _ O
W -X- _ O
Dep -X- _ O
∈ -X- _ O
R -X- _ O
k×c -X- _ O
( -X- _ O
k -X- _ O
is -X- _ O
the -X- _ O
convolution -X- _ O
kernel -X- _ O
size -X- _ O
, -X- _ O
set -X- _ O
as -X- _ O
9 -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
) -X- _ O
and -X- _ O
pointwise -X- _ O
weights -X- _ O
W -X- _ O
Poi -X- _ O
∈ -X- _ O
R -X- _ O
c×c -X- _ O
to -X- _ O
extract -X- _ O
local -X- _ O
information -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
following -X- _ O
kernel -X- _ O
generation -X- _ O
. -X- _ O
Denoting -X- _ O
the -X- _ O
output -X- _ O
as -X- _ O
S -X- _ O
∈ -X- _ O
R -X- _ O
s×c -X- _ O
, -X- _ O
the -X- _ O
separate -X- _ O
convolution -X- _ O
can -X- _ O
be -X- _ O
formulated -X- _ O
asS -X- _ O
i -X- _ O
, -X- _ O
: -X- _ O
= -X- _ O
 -X- _ O
 -X- _ O
k -X- _ O
j=1 -X- _ O
W -X- _ O
Dep -X- _ O
j -X- _ O
, -X- _ O
: -X- _ O
• -X- _ O
V -X- _ O
i+j− -X- _ O
k+1 -X- _ O
2 -X- _ O
, -X- _ O
: -X- _ O
 -X- _ O
 -X- _ O
W -X- _ O
Poi -X- _ O
. -X- _ O
( -X- _ O
14)Then -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
separate -X- _ O
convolution -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
generate -X- _ O
dynamic -X- _ O
kernels -X- _ O
, -X- _ O
D -X- _ O
= -X- _ O
Softmax(Reshape(SW -X- _ O
Dyn -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
15)where -X- _ O
W -X- _ O
Dyn -X- _ O
∈ -X- _ O
R -X- _ O
c×hk -X- _ O
and -X- _ O
D -X- _ O
∈ -X- _ O
R -X- _ O
h×s×k -X- _ O
. -X- _ O
Then -X- _ O
lightweight -X- _ O
convolution -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
reshaped -X- _ O
V -X- _ O
= -X- _ O
Reshape(V -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
h×s×d -X- _ O
. -X- _ O
The -X- _ O
output -X- _ O
C -X- _ O
∈ -X- _ O
R -X- _ O
h×s×d -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
asC -X- _ O
p -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
: -X- _ O
= -X- _ O
k -X- _ O
j=1 -X- _ O
D -X- _ O
p -X- _ O
, -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
• -X- _ O
V -X- _ O
p -X- _ O
, -X- _ O
i+j− -X- _ O
k+1 -X- _ O
2 -X- _ O
, -X- _ O
: -X- _ O
.(16)Finally -X- _ O
, -X- _ O
C -X- _ O
is -X- _ O
reshaped -X- _ O
to -X- _ O
C -X- _ O
= -X- _ O
Reshape(C -X- _ O
) -X- _ O
∈ -X- _ O
R -X- _ O
s×c -X- _ O
and -X- _ O
a -X- _ O
linear -X- _ O
transformer -X- _ O
is -X- _ O
applied -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
information -X- _ O
among -X- _ O
multiple -X- _ O
heads -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
short -X- _ O
connection -X- _ O
and -X- _ O
layer -X- _ O
normalization -X- _ O
, -X- _ O
O -X- _ O
= -X- _ O
Norm(C -X- _ O
W -X- _ O
Out -X- _ O
+ -X- _ O
b -X- _ O
Out -X- _ O
+ -X- _ O
I),(17)where -X- _ O
W -X- _ O
Out -X- _ O
∈ -X- _ O
R -X- _ O
c×c -X- _ O
and -X- _ O
b -X- _ O
Out -X- _ O
∈ -X- _ O
R -X- _ O
c -X- _ O
. -X- _ O
Introduced -X- _ O
by -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
General -X- _ B-DatasetName
Language -X- _ I-DatasetName
Understanding -X- _ I-DatasetName
Evaluation -X- _ I-DatasetName
( -X- _ O
GLUE -X- _ B-DatasetName
) -X- _ O
benchmark -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
nine -X- _ O
tasks -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
, -X- _ O
where -X- _ O
testing -X- _ O
set -X- _ O
labels -X- _ O
are -X- _ O
hidden -X- _ O
and -X- _ O
predictions -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
submitted -X- _ O
to -X- _ O
the -X- _ O
evaluation -X- _ O
server -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
provide -X- _ O
details -X- _ O
about -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
below -X- _ O
. -X- _ O
CoLA -X- _ B-DatasetName
The -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
of -X- _ I-DatasetName
Linguistic -X- _ I-DatasetName
Acceptability -X- _ I-DatasetName
( -X- _ O
Warstadt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
binary -X- _ B-TaskName
single -X- _ I-TaskName
- -X- _ I-TaskName
sentence -X- _ I-TaskName
classification -X- _ I-TaskName
dataset -X- _ O
for -X- _ O
predicting -X- _ O
whether -X- _ O
an -X- _ O
sentence -X- _ O
is -X- _ O
grammatical -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
The -X- _ O
samples -X- _ O
are -X- _ O
from -X- _ O
books -X- _ O
and -X- _ O
journal -X- _ O
articles -X- _ O
on -X- _ O
linguistic -X- _ O
theory -X- _ O
. -X- _ O
MRPC -X- _ O
The -X- _ O
Microsoft -X- _ B-DatasetName
Research -X- _ I-DatasetName
Paraphrase -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
two -X- _ O
sentences -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
extracted -X- _ O
from -X- _ O
online -X- _ O
news -X- _ O
sources -X- _ O
with -X- _ O
human -X- _ O
annotations -X- _ O
. -X- _ O
MNLI -X- _ B-DatasetName
The -X- _ I-DatasetName
Multi -X- _ I-DatasetName
- -X- _ I-DatasetName
Genre -X- _ I-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O
Each -X- _ O
pair -X- _ O
has -X- _ O
a -X- _ O
premise -X- _ O
sentence -X- _ O
and -X- _ O
a -X- _ O
hypothesis -X- _ O
sentence -X- _ O
, -X- _ O
requiring -X- _ O
models -X- _ O
to -X- _ O
predict -X- _ O
its -X- _ O
relationships -X- _ O
containing -X- _ O
ententailment -X- _ O
, -X- _ O
contradiction -X- _ O
or -X- _ O
neutral -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
from -X- _ O
ten -X- _ O
distinct -X- _ O
genres -X- _ O
of -X- _ O
spoken -X- _ O
and -X- _ O
written -X- _ O
English -X- _ O
. -X- _ O
SST -X- _ B-DatasetName
The -X- _ O
Stanford -X- _ B-DatasetName
Sentiment -X- _ I-DatasetName
Treebank -X- _ I-DatasetName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
dataset -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
a -X- _ O
sentence -X- _ O
is -X- _ O
positive -X- _ O
or -X- _ O
negative -X- _ O
in -X- _ O
sentiment -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
is -X- _ O
from -X- _ O
movie -X- _ O
reviews -X- _ O
with -X- _ O
human -X- _ O
annotations -X- _ O
. -X- _ O
( -X- _ O
Giampiccolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
RTE5 -X- _ B-DatasetName
( -X- _ O
Bentivogli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O
QNLI -X- _ B-DatasetName
Question -X- _ B-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
is -X- _ O
a -X- _ O
dataset -X- _ O
converted -X- _ O
from -X- _ O
The -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
An -X- _ O
example -X- _ O
is -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
a -X- _ O
context -X- _ O
sentence -X- _ O
and -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
requiring -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
context -X- _ O
sentence -X- _ O
contains -X- _ O
the -X- _ O
answer -X- _ O
to -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
. -X- _ O
QQP -X- _ B-DatasetName
The -X- _ O
Quora -X- _ B-DatasetName
Question -X- _ I-DatasetName
Pairs -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
the -X- _ O
dataset -X- _ O
from -X- _ O
Quora -X- _ O
, -X- _ O
requiring -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
questions -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
STS -X- _ B-DatasetName
The -X- _ O
Semantic -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Similarity -X- _ I-DatasetName
Benchmark -X- _ O
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
with -X- _ O
human -X- _ O
- -X- _ O
annotated -X- _ O
similarity -X- _ O
score -X- _ O
on -X- _ O
a -X- _ O
1 -X- _ O
- -X- _ O
5 -X- _ O
scare -X- _ O
. -X- _ O
WNLI -X- _ B-DatasetName
Winograd -X- _ B-DatasetName
NLI -X- _ I-DatasetName
( -X- _ O
Levesque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
small -X- _ O
dataset -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
issues -X- _ O
with -X- _ O
the -X- _ O
construction -X- _ O
of -X- _ O
this -X- _ O
dataset -X- _ O
4 -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
this -X- _ O
dataset -X- _ O
is -X- _ O
exclude -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
for -X- _ O
comparison -X- _ O
as -X- _ O
BERT -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
etc -X- _ O
. -X- _ O
The -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ O
( -X- _ O
SQuAD -X- _ O
1.1 -X- _ O
) -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
more -X- _ O
than -X- _ O
100 -X- _ O
K -X- _ O
questions -X- _ O
which -X- _ O
all -X- _ O
can -X- _ O
be -X- _ O
answered -X- _ O
by -X- _ O
locating -X- _ O
a -X- _ O
span -X- _ O
of -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
corresponding -X- _ O
context -X- _ O
passage -X- _ O
. -X- _ O
Besides -X- _ O
this -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
upgraded -X- _ O
version -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
supplements -X- _ O
it -X- _ O
with -X- _ O
over -X- _ O
50 -X- _ O
K -X- _ O
unanswerable -X- _ O
questions -X- _ O
. -X- _ O
For -X- _ O
supernet -X- _ O
, -X- _ O
We -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
it -X- _ O
for -X- _ O
2 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
hyperparameters -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
using -X- _ O
Masked -X- _ O
Language -X- _ O
Modeling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objective -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
objective -X- _ O
masks -X- _ O
15 -X- _ O
% -X- _ O
input -X- _ O
tokens -X- _ O
that -X- _ O
require -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
. -X- _ O
The -X- _ O
reason -X- _ O
to -X- _ O
use -X- _ O
this -X- _ O
objective -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
MLM -X- _ O
valida-4 -X- _ O
https://gluebenchmark.com/faq -X- _ O
tion -X- _ O
accuracy -X- _ B-MetricName
can -X- _ O
reflect -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
models -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).For -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
LV -X- _ B-MethodName
- -X- _ I-MethodName
BERTs -X- _ I-MethodName
and -X- _ O
other -X- _ O
compared -X- _ O
baselines -X- _ O
like -X- _ O
DynamicConv -X- _ B-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
Sandwich -X- _ B-MethodName
( -X- _ O
Press -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
from -X- _ O
scratch -X- _ O
, -X- _ O
we -X- _ O
utilize -X- _ O
Replaced -X- _ O
Token -X- _ O
Detection -X- _ O
( -X- _ O
RTE -X- _ O
) -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objective -X- _ O
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
objective -X- _ O
employs -X- _ O
a -X- _ O
small -X- _ O
generator -X- _ O
to -X- _ O
predict -X- _ O
masked -X- _ O
tokens -X- _ O
and -X- _ O
utilize -X- _ O
a -X- _ O
larger -X- _ O
discriminator -X- _ O
to -X- _ O
determine -X- _ O
predicted -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
generator -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
original -X- _ O
ones -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
RTE -X- _ O
can -X- _ O
help -X- _ O
save -X- _ O
computation -X- _ O
cost -X- _ O
but -X- _ O
achieve -X- _ O
good -X- _ O
performance -X- _ O
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
models -X- _ O
for -X- _ O
1 -X- _ O
M -X- _ O
steps -X- _ O
, -X- _ O
mostly -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
as -X- _ O
ELEC -X- _ B-MethodName
- -X- _ I-MethodName
TRA -X- _ I-MethodName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
set -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
sequence -X- _ O
length -X- _ O
128 -X- _ O
that -X- _ O
can -X- _ O
help -X- _ O
us -X- _ O
save -X- _ O
computation -X- _ O
cost -X- _ O
. -X- _ O
For -X- _ O
downstream -X- _ O
task -X- _ O
SQuAD -X- _ B-DatasetName
1.1/2.0 -X- _ I-DatasetName
that -X- _ O
needs -X- _ O
longer -X- _ O
input -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
more -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
the -X- _ O
sequence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
to -X- _ O
learn -X- _ O
the -X- _ O
position -X- _ O
embedding -X- _ O
before -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
The -X- _ O
hyperparameters -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
For -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
ELECTRA -X- _ B-MethodName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
See -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
The -X- _ O
different -X- _ O
searched -X- _ O
architectures -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
comments -X- _ O
and -X- _ O
suggestions -X- _ O
. -X- _ O
This -X- _ O
research -X- _ O
/ -X- _ O
project -X- _ O
is -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
National -X- _ O
Research -X- _ O
Foundation -X- _ O
, -X- _ O
Singapore -X- _ O
under -X- _ O
its -X- _ O
AI -X- _ O
Singapore -X- _ O
Programme -X- _ O
( -X- _ O
AISG -X- _ O
Award -X- _ O
No -X- _ O
: -X- _ O
AISG-100E/-2019 -X- _ O
- -X- _ O
035 -X- _ O
) -X- _ O
. -X- _ O
Jiashi -X- _ O
Feng -X- _ O
was -X- _ O
partially -X- _ O
supported -X- _ O
by -X- _ O
MOE2017 -X- _ O
- -X- _ O
T2 -X- _ O
- -X- _ O
2 -X- _ O
- -X- _ O
151 -X- _ O
, -X- _ O
NUS -X- _ O
ECRA -X- _ O
FY17 -X- _ O
P08 -X- _ O
and -X- _ O
CRP20 -X- _ O
- -X- _ O
2017 -X- _ O
- -X- _ O
0006 -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
also -X- _ O
thank -X- _ O
Quanhong -X- _ O
Fu -X- _ O
and -X- _ O
Jian -X- _ O
Liang -X- _ O
for -X- _ O
the -X- _ O
help -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
technical -X- _ O
writing -X- _ O
aspect -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
The -X- _ O
computational -X- _ O
work -X- _ O
for -X- _ O
this -X- _ O
article -X- _ O
was -X- _ O
partially -X- _ O
performed -X- _ O
on -X- _ O
resources -X- _ O
of -X- _ O
the -X- _ O
National -X- _ O
Supercomputing -X- _ O
Centre -X- _ O
, -X- _ O
Singapore -X- _ O
( -X- _ O
https://www.nscc.sg -X- _ O
) -X- _ O
. -X- _ O
Weihao -X- _ O
Yu -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
TPU -X- _ O
Research -X- _ O
Cloud -X- _ O
( -X- _ O
TRC -X- _ O
) -X- _ O

This -X- _ O
paper -X- _ O
presents -X- _ O
a -X- _ O
technical -X- _ O
report -X- _ O
of -X- _ O
our -X- _ O
submission -X- _ O
to -X- _ O
the -X- _ O
4th -X- _ O
task -X- _ O
of -X- _ O
SemEval-2021 -X- _ O
, -X- _ O
titled -X- _ O
: -X- _ O
Reading -X- _ B-TaskName
Comprehension -X- _ I-TaskName
of -X- _ I-TaskName
Abstract -X- _ I-TaskName
Meaning -X- _ I-TaskName
. -X- _ O
In -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
question -X- _ O
given -X- _ O
a -X- _ O
context -X- _ O
. -X- _ O
Usually -X- _ O
, -X- _ O
contexts -X- _ O
are -X- _ O
very -X- _ O
lengthy -X- _ O
and -X- _ O
require -X- _ O
a -X- _ O
large -X- _ O
receptive -X- _ O
field -X- _ O
from -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
common -X- _ O
contextualized -X- _ O
language -X- _ O
models -X- _ O
like -X- _ O
BERT -X- _ B-MethodName
miss -X- _ O
fine -X- _ O
representation -X- _ O
and -X- _ O
performance -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
limited -X- _ O
capacity -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
. -X- _ O
To -X- _ O
tackle -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
longformer -X- _ B-MethodName
model -X- _ O
to -X- _ O
better -X- _ O
process -X- _ O
the -X- _ O
sequences -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
utilized -X- _ O
the -X- _ O
method -X- _ O
proposed -X- _ O
in -X- _ O
the -X- _ O
longformer -X- _ B-MethodName
benchmark -X- _ O
on -X- _ O
wikihop -X- _ O
dataset -X- _ O
which -X- _ O
improved -X- _ O
the -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
our -X- _ O
task -X- _ O
data -X- _ O
from -X- _ O
( -X- _ O
23.01 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
22.95 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
achieved -X- _ O
by -X- _ O
the -X- _ O
baselines -X- _ O
for -X- _ O
subtask -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
to -X- _ O
( -X- _ O
70.30 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
64.38 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
Reading -X- _ B-TaskName
comprehension -X- _ I-TaskName
is -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
understand -X- _ O
a -X- _ O
passage -X- _ O
either -X- _ O
by -X- _ O
human -X- _ O
or -X- _ O
machine -X- _ O
. -X- _ O
One -X- _ O
of -X- _ O
the -X- _ O
great -X- _ O
benchmarks -X- _ O
to -X- _ O
evaluate -X- _ O
this -X- _ O
ability -X- _ O
is -X- _ O
to -X- _ O
try -X- _ O
to -X- _ O
answer -X- _ O
specific -X- _ O
questions -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
passage -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
this -X- _ O
problem -X- _ O
can -X- _ O
contain -X- _ O
single -X- _ O
or -X- _ O
multiple -X- _ O
documents -X- _ O
as -X- _ O
context -X- _ O
( -X- _ O
containing -X- _ O
relevant -X- _ O
information -X- _ O
needed -X- _ O
to -X- _ O
understand -X- _ O
and -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
( -X- _ O
a -X- _ O
sentence -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
asking -X- _ O
parameter -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
an -X- _ O
answer -X- _ O
( -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
parameter -X- _ O
value -X- _ O
of -X- _ O
the -X- _ O
question).In -X- _ O
the -X- _ O
Task -X- _ O
of -X- _ O
Reading -X- _ B-TaskName
Comprehension -X- _ I-TaskName
of -X- _ I-TaskName
Abstract -X- _ I-TaskName
Meaning -X- _ I-TaskName
( -X- _ O
ReCAM -X- _ B-TaskName
) -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
one -X- _ O
passage -X- _ O
as -X- _ O
a -X- _ O
context -X- _ O
, -X- _ O
one -X- _ O
question -X- _ O
and -X- _ O
five -X- _ O
candidate -X- _ O
answers -X- _ O
( -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
context -X- _ O
and -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
. -X- _ O
You -X- _ O
can -X- _ O
see -X- _ O
a -X- _ O
sample -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
instance -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
passage -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
with -X- _ O
a -X- _ O
missing -X- _ O
word -X- _ O
that -X- _ O
should -X- _ O
be -X- _ O
filled -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
passage -X- _ O
, -X- _ O
and -X- _ O
five -X- _ O
candidate -X- _ O
answers -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
... -X- _ O
observers -X- _ O
have -X- _ O
even -X- _ O
named -X- _ O
it -X- _ O
after -X- _ O
him -X- _ O
, -X- _ O
" -X- _ O
Abenomics -X- _ O
" -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
three -X- _ O
key -X- _ O
pillars -X- _ O
-the -X- _ O
" -X- _ O
three -X- _ O
arrows -X- _ O
" -X- _ O
of -X- _ O
monetary -X- _ O
policy -X- _ O
, -X- _ O
fiscal -X- _ O
stimulus -X- _ O
and -X- _ O
structural -X- _ O
reforms -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
ensure -X- _ O
long -X- _ O
- -X- _ O
term -X- _ O
sustainable -X- _ O
growth -X- _ O
in -X- _ O
the -X- _ O
world -X- _ O
's -X- _ O
third -X- _ O
- -X- _ O
largest -X- _ O
economy -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
weekend -X- _ O
's -X- _ O
upper -X- _ O
house -X- _ O
elections -X- _ O
... -X- _ O
Question -X- _ O
Abenomics -X- _ O
: -X- _ O
The -X- _ O
@Placeholder -X- _ O
and -X- _ O
the -X- _ O
risks -X- _ O
Answer -X- _ O
( -X- _ O
A -X- _ O
) -X- _ O
chances -X- _ O
( -X- _ O
B -X- _ O
) -X- _ O
prospective -X- _ O
( -X- _ O
C -X- _ O
) -X- _ O
security -X- _ O
( -X- _ O
D -X- _ O
) -X- _ O
objectives -X- _ O
( -X- _ O
E -X- _ O
) -X- _ O
threats -X- _ O
The -X- _ O
task -X- _ O
divides -X- _ O
into -X- _ O
two -X- _ O
subtasks -X- _ O
: -X- _ O
imperceptibility -X- _ O
and -X- _ O
non -X- _ O
- -X- _ O
specificity -X- _ O
( -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021).• -X- _ O
imperceptibility -X- _ O
: -X- _ O
this -X- _ O
level -X- _ O
of -X- _ O
abstract -X- _ O
words -X- _ O
refers -X- _ O
to -X- _ O
ideas -X- _ O
and -X- _ O
concepts -X- _ O
that -X- _ O
are -X- _ O
distant -X- _ O
from -X- _ O
immediate -X- _ O
perception -X- _ O
; -X- _ O
such -X- _ O
as -X- _ O
culture -X- _ O
, -X- _ O
economics -X- _ O
, -X- _ O
and -X- _ O
politics.• -X- _ O
non -X- _ O
- -X- _ O
specificity -X- _ O
: -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
concrete -X- _ O
words -X- _ O
, -X- _ O
this -X- _ O
subtask -X- _ O
includes -X- _ O
more -X- _ O
abstract -X- _ O
words -X- _ O
which -X- _ O
focus -X- _ O
on -X- _ O
a -X- _ O
different -X- _ O
type -X- _ O
of -X- _ O
definition -X- _ O
; -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
concrete -X- _ O
word -X- _ O
like -X- _ O
' -X- _ O
cow -X- _ O
' -X- _ O
could -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
an -X- _ O
' -X- _ O
animal -X- _ O
' -X- _ O
which -X- _ O
is -X- _ O
considered -X- _ O
as -X- _ O
a -X- _ O
more -X- _ O
abstract -X- _ O
word -X- _ O
( -X- _ O
Changizi -X- _ O
, -X- _ O
2008).The -X- _ O
main -X- _ O
challenges -X- _ O
of -X- _ O
this -X- _ O
task -X- _ O
are -X- _ O
the -X- _ O
abstract -X- _ O
meaning -X- _ O
concept -X- _ O
representation -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
machine -X- _ O
reading -X- _ O
comprehension -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
main -X- _ O
reason -X- _ O
we -X- _ O
have -X- _ O
utilized -X- _ O
contextualized -X- _ O
language -X- _ O
representation -X- _ O
models -X- _ O
to -X- _ O
tackle -X- _ O
abstract -X- _ O
meaning -X- _ O
representation -X- _ O
problems -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
deep -X- _ O
contextualized -X- _ O
architecture -X- _ O
to -X- _ O
model -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
is -X- _ O
also -X- _ O
capable -X- _ O
of -X- _ O
considering -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
passage -X- _ O
as -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
more -X- _ O
than -X- _ O
five -X- _ O
candidate -X- _ O
answers -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
long -X- _ B-MethodName
document -X- _ I-MethodName
transformer -X- _ I-MethodName
model -X- _ O
( -X- _ O
Longformer -X- _ B-MethodName
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
no -X- _ O
limitation -X- _ O
is -X- _ O
considered -X- _ O
in -X- _ O
context -X- _ O
passage -X- _ O
length -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
evaluated -X- _ O
this -X- _ O
model -X- _ O
both -X- _ O
on -X- _ O
subtask-1 -X- _ O
and -X- _ O
subtask-2 -X- _ O
which -X- _ O
resulted -X- _ O
in -X- _ O
70 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
64 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
, -X- _ O
respectively -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
about -X- _ O
40 -X- _ B-MetricValue
% -X- _ I-MetricValue
improvement -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
Gated -X- _ B-MethodName
Attention -X- _ I-MethodName
( -X- _ O
GA -X- _ B-MethodName
) -X- _ O
model -X- _ O
( -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021).The -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Section -X- _ O
2 -X- _ O
describes -X- _ O
the -X- _ O
related -X- _ O
works -X- _ O
and -X- _ O
the -X- _ O
background -X- _ O
. -X- _ O
Section -X- _ O
3 -X- _ O
includes -X- _ O
the -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
method -X- _ O
. -X- _ O
Section -X- _ O
4 -X- _ O
contains -X- _ O
the -X- _ O
evaluation -X- _ O
metrics -X- _ O
used -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
brief -X- _ O
discussion -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
then -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
conclusion -X- _ O
and -X- _ O
future -X- _ O
works -X- _ O
in -X- _ O
section -X- _ O
5 -X- _ O
. -X- _ O
Many -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
, -X- _ O
from -X- _ O
pipeline -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
to -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
ones -X- _ O
. -X- _ O
Each -X- _ O
module -X- _ O
is -X- _ O
also -X- _ O
well -X- _ O
- -X- _ O
investigated -X- _ O
from -X- _ O
rule -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
to -X- _ O
deep -X- _ O
learning -X- _ O
ones -X- _ O
. -X- _ O
Despite -X- _ O
various -X- _ O
configurations -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
to -X- _ O
model -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
systems -X- _ O
consist -X- _ O
of -X- _ O
three -X- _ O
modules -X- _ O
( -X- _ O
Baradaran -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020):• -X- _ O
Language -X- _ O
representation -X- _ O
: -X- _ O
this -X- _ O
module -X- _ O
is -X- _ O
responsible -X- _ O
to -X- _ O
encode -X- _ O
the -X- _ O
inputs -X- _ O
. -X- _ O
Context -X- _ O
, -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
answer -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
represented -X- _ O
as -X- _ O
numeric -X- _ O
values -X- _ O
for -X- _ O
computational -X- _ O
algorithms -X- _ O
to -X- _ O
be -X- _ O
usable -X- _ O
on -X- _ O
them -X- _ O
. -X- _ O
Dense -X- _ O
vectorized -X- _ O
representations -X- _ O
are -X- _ O
the -X- _ O
most -X- _ O
popular -X- _ O
methods -X- _ O
, -X- _ O
which -X- _ O
allow -X- _ O
us -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
machine -X- _ O
learning -X- _ O
algorithms.• -X- _ O
Reasoning -X- _ O
: -X- _ O
this -X- _ O
module -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
find -X- _ O
demonstrations -X- _ O
of -X- _ O
why -X- _ O
the -X- _ O
answer -X- _ O
is -X- _ O
assumed -X- _ O
to -X- _ O
be -X- _ O
valid -X- _ O
. -X- _ O
It -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
limiter -X- _ O
for -X- _ O
searchable -X- _ O
context.• -X- _ O
Prediction -X- _ O
: -X- _ O
this -X- _ O
module -X- _ O
aims -X- _ O
to -X- _ O
generate -X- _ O
, -X- _ O
retrieve -X- _ O
or -X- _ O
select -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
description -X- _ O
. -X- _ O
Recent -X- _ O
studies -X- _ O
are -X- _ O
provided -X- _ O
as -X- _ O
follows -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
these -X- _ O
modules -X- _ O
that -X- _ O
the -X- _ O
last -X- _ O
two -X- _ O
modules -X- _ O
have -X- _ O
been -X- _ O
merged -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
end -X- _ O
, -X- _ O
the -X- _ O
longformer -X- _ O
model -X- _ O
is -X- _ O
presented -X- _ O
as -X- _ O
our -X- _ O
mainstay -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
One -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
problems -X- _ O
in -X- _ O
NLP -X- _ O
is -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O
The -X- _ O
earliest -X- _ O
models -X- _ O
for -X- _ O
word -X- _ O
representation -X- _ O
in -X- _ O
the -X- _ O
time -X- _ O
of -X- _ O
deep -X- _ O
learning -X- _ O
were -X- _ O
the -X- _ O
models -X- _ O
proposed -X- _ O
in -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
utilized -X- _ O
the -X- _ O
weights -X- _ O
learned -X- _ O
for -X- _ O
an -X- _ O
auxiliary -X- _ O
task -X- _ O
( -X- _ O
a -X- _ O
simplified -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
language -X- _ O
modeling -X- _ O
) -X- _ O
for -X- _ O
word -X- _ O
representation -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
methods -X- _ O
proposed -X- _ O
in -X- _ O
( -X- _ O
Le -X- _ O
and -X- _ O
Mikolov -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
utilized -X- _ O
a -X- _ O
similar -X- _ O
structure -X- _ O
for -X- _ O
sentence -X- _ O
, -X- _ O
paragraph -X- _ O
, -X- _ O
or -X- _ O
document -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O
While -X- _ O
these -X- _ O
methods -X- _ O
were -X- _ O
quite -X- _ O
effective -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
using -X- _ O
neural -X- _ O
language -X- _ O
models -X- _ O
as -X- _ O
a -X- _ O
way -X- _ O
of -X- _ O
word -X- _ O
representation -X- _ O
results -X- _ O
in -X- _ O
much -X- _ O
better -X- _ O
, -X- _ O
and -X- _ O
context -X- _ O
- -X- _ O
aware -X- _ O
representations -X- _ O
. -X- _ O
In -X- _ O
( -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
language -X- _ O
models -X- _ O
as -X- _ O
sentence -X- _ O
encoders -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
significant -X- _ O
performance -X- _ O
improvement -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
used -X- _ O
language -X- _ O
models -X- _ O
directly -X- _ O
as -X- _ O
word -X- _ O
representations -X- _ O
, -X- _ O
which -X- _ O
resulted -X- _ O
in -X- _ O
significant -X- _ O
improvements -X- _ O
. -X- _ O
In -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
a -X- _ O
transformer -X- _ O
model -X- _ O
was -X- _ O
trained -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
of -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
resulted -X- _ O
in -X- _ O
significant -X- _ O
improvements -X- _ O
, -X- _ O
surpassing -X- _ O
human -X- _ O
performance -X- _ O
in -X- _ O
many -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
One -X- _ O
of -X- _ O
the -X- _ O
shortcomings -X- _ O
of -X- _ O
transformers -X- _ O
is -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
a -X- _ O
memory -X- _ O
mechanism -X- _ O
, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
( -X- _ O
theoretically -X- _ O
) -X- _ O
lower -X- _ O
receptive -X- _ O
field -X- _ O
compared -X- _ O
with -X- _ O
LSTMs -X- _ O
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
this -X- _ O
shortcoming -X- _ O
was -X- _ O
addressed -X- _ O
by -X- _ O
improving -X- _ O
the -X- _ O
self -X- _ O
attention -X- _ O
mechanism -X- _ O
in -X- _ O
transformers -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
would -X- _ O
have -X- _ O
a -X- _ O
( -X- _ O
theoretically -X- _ O
) -X- _ O
unbounded -X- _ O
receptive -X- _ O
field -X- _ O
. -X- _ O
More -X- _ O
details -X- _ O
are -X- _ O
presented -X- _ O
later -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O
Natural -X- _ O
language -X- _ O
understanding -X- _ O
( -X- _ O
NLU -X- _ O
) -X- _ O
is -X- _ O
an -X- _ O
umbrella -X- _ O
term -X- _ O
, -X- _ O
referring -X- _ O
to -X- _ O
any -X- _ O
tasks -X- _ O
that -X- _ O
require -X- _ O
machine -X- _ O
comprehension -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
other -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
NLU -X- _ O
requires -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
understand -X- _ O
and -X- _ O
reason -X- _ O
about -X- _ O
the -X- _ O
data -X- _ O
( -X- _ O
Semaan -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
great -X- _ O
progress -X- _ O
has -X- _ O
been -X- _ O
made -X- _ O
in -X- _ O
this -X- _ O
field -X- _ O
by -X- _ O
using -X- _ O
contextual -X- _ O
word -X- _ O
representation -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
found -X- _ O
that -X- _ O
designing -X- _ O
the -X- _ O
model -X- _ O
itself -X- _ O
must -X- _ O
not -X- _ O
be -X- _ O
neglected -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
that -X- _ O
utilizing -X- _ O
a -X- _ O
transfer -X- _ O
learning -X- _ O
setting -X- _ O
to -X- _ O
share -X- _ O
knowledge -X- _ O
between -X- _ O
different -X- _ O
NLU -X- _ O
tasks -X- _ O
results -X- _ O
in -X- _ O
better -X- _ O
performance -X- _ O
with -X- _ O
fewer -X- _ O
data -X- _ O
and -X- _ O
fewer -X- _ O
parameters -X- _ O
( -X- _ O
Pilault -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
proves -X- _ O
a -X- _ O
significant -X- _ O
similarity -X- _ O
between -X- _ O
these -X- _ O
tasks -X- _ O
. -X- _ O
Deep -X- _ O
contextualized -X- _ O
language -X- _ O
models -X- _ O
like -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
have -X- _ O
been -X- _ O
well -X- _ O
investi -X- _ O
- -X- _ O
gated -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
and -X- _ O
achieved -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
various -X- _ O
tasks -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
suffer -X- _ O
from -X- _ O
performance -X- _ O
limitations -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layer -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
quadratic -X- _ O
space -X- _ O
and -X- _ O
time -X- _ O
complexity -X- _ O
concerning -X- _ O
the -X- _ O
sequence -X- _ O
length -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
this -X- _ O
model -X- _ O
removes -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layer -X- _ O
from -X- _ O
the -X- _ O
base -X- _ O
language -X- _ O
models -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
limitation -X- _ O
resolves -X- _ O
and -X- _ O
the -X- _ O
complexity -X- _ O
scales -X- _ O
to -X- _ O
linear -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
compared -X- _ O
to -X- _ O
basic -X- _ O
models -X- _ O
, -X- _ O
they -X- _ O
have -X- _ O
added -X- _ O
a -X- _ O
global -X- _ O
attention -X- _ O
layer -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
end -X- _ O
which -X- _ O
significantly -X- _ O
outperforms -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
on -X- _ O
long -X- _ O
document -X- _ O
( -X- _ O
passage -X- _ O
) -X- _ O
tasks -X- _ O
and -X- _ O
competitive -X- _ O
on -X- _ O
normal -X- _ O
documents -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
this -X- _ O
configuration -X- _ O
increases -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
both -X- _ O
normal -X- _ O
and -X- _ O
lengthy -X- _ O
inputs -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
a -X- _ O
good -X- _ O
alternative -X- _ O
for -X- _ O
tasks -X- _ O
containing -X- _ O
large -X- _ O
inputs -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
is -X- _ O
also -X- _ O
evaluated -X- _ O
on -X- _ O
a -X- _ O
similar -X- _ O
task -X- _ O
on -X- _ O
WikiHop -X- _ O
dataset -X- _ O
( -X- _ O
Welbl -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
improved -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
accuracy -X- _ O
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
mentioned -X- _ O
in -X- _ O
section -X- _ O
1 -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
passage -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
answers -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
among -X- _ O
the -X- _ O
candidates -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
benchmark -X- _ O
to -X- _ O
evaluate -X- _ O
how -X- _ O
well -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
comprehend -X- _ O
the -X- _ O
abstract -X- _ O
meaning -X- _ O
. -X- _ O
To -X- _ O
do -X- _ O
so -X- _ O
, -X- _ O
we -X- _ O
considered -X- _ O
an -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
deep -X- _ O
learning -X- _ O
architecture -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
transformer -X- _ O
architecture -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
contextual -X- _ O
word -X- _ O
embeddings -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
transformer -X- _ O
to -X- _ O
better -X- _ O
discover -X- _ O
and -X- _ O
encode -X- _ O
the -X- _ O
information -X- _ O
contained -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
both -X- _ O
subtasks -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
architecture -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
figure -X- _ O
1 -X- _ O
, -X- _ O
although -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
experiment -X- _ O
on -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
. -X- _ O
The -X- _ O
word -X- _ O
representation -X- _ O
models -X- _ O
are -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
for -X- _ O
better -X- _ O
performance -X- _ O
. -X- _ O
The -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
procedure -X- _ O
could -X- _ O
allow -X- _ O
us -X- _ O
to -X- _ O
extract -X- _ O
additional -X- _ O
, -X- _ O
taskrelated -X- _ O
information -X- _ O
which -X- _ O
could -X- _ O
result -X- _ O
in -X- _ O
better -X- _ O
accuracy -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
phase -X- _ O
. -X- _ O
To -X- _ O
model -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
let -X- _ O
c -X- _ O
= -X- _ O
{ -X- _ O
c -X- _ O
1 -X- _ O
, -X- _ O
c -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
c -X- _ O
I -X- _ O
} -X- _ O
denote -X- _ O
the -X- _ O
passage -X- _ O
as -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
where -X- _ O
c -X- _ O
i -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
token -X- _ O
( -X- _ O
word -X- _ O
or -X- _ O
subword -X- _ O
, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
tokenization -X- _ O
technique -X- _ O
used -X- _ O
) -X- _ O
and -X- _ O
I -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
considered -X- _ O
as -X- _ O
q -X- _ O
= -X- _ O
{ -X- _ O
q -X- _ O
1 -X- _ O
, -X- _ O
q -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
q -X- _ O
K -X- _ O
} -X- _ O
where -X- _ O
K -X- _ O
denotes -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
q -X- _ O
k -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
k -X- _ O
th -X- _ O
token -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
Each -X- _ O
answer -X- _ O
also -X- _ O
denotes -X- _ O
as -X- _ O
e -X- _ O
j -X- _ O
which -X- _ O
is -X- _ O
only -X- _ O
one -X- _ O
abstract -X- _ O
word -X- _ O
( -X- _ O
j -X- _ O
∈ -X- _ O
{ -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
5 -X- _ O
} -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
concate -X- _ O
- -X- _ O
nate -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
candidates -X- _ O
as -X- _ O
: -X- _ O
a -X- _ O
= -X- _ O
[ -X- _ O
q -X- _ O
; -X- _ O
e -X- _ O
1 -X- _ O
; -X- _ O
e -X- _ O
2 -X- _ O
; -X- _ O
... -X- _ O
; -X- _ O
e -X- _ O
5 -X- _ O
] -X- _ O
.(1)The -X- _ O
size -X- _ O
of -X- _ O
this -X- _ O
sequence -X- _ O
is -X- _ O
A -X- _ O
= -X- _ O
K -X- _ O
+ -X- _ O
5 -X- _ O
as -X- _ O
we -X- _ O
have -X- _ O
only -X- _ O
5 -X- _ O
candidates -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
this -X- _ O
can -X- _ O
be -X- _ O
an -X- _ O
arbitrary -X- _ O
length -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
we -X- _ O
introduce -X- _ O
special -X- _ O
tokens -X- _ O
to -X- _ O
separate -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
candidates -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
the -X- _ O
tokens -X- _ O
< -X- _ O
s -X- _ O
> -X- _ O
and -X- _ O
< -X- _ O
/s -X- _ O
> -X- _ O
for -X- _ O
separating -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
< -X- _ O
q -X- _ O
> -X- _ O
and -X- _ O
< -X- _ O
/q -X- _ O
> -X- _ O
for -X- _ O
separating -X- _ O
the -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
tokens -X- _ O
< -X- _ O
ent -X- _ O
> -X- _ O
and -X- _ O
< -X- _ O
/ent -X- _ O
> -X- _ O
for -X- _ O
separating -X- _ O
the -X- _ O
candidates -X- _ O
from -X- _ O
each -X- _ O
other -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
multiple -X- _ O
passages -X- _ O
, -X- _ O
all -X- _ O
passages -X- _ O
are -X- _ O
concatenated -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
single -X- _ O
context -X- _ O
. -X- _ O
These -X- _ O
tokens -X- _ O
are -X- _ O
randomly -X- _ O
initialized -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
Longformer -X- _ B-MethodName
model -X- _ O
introduced -X- _ O
in -X- _ O
( -X- _ O
Beltagy -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
contextual -X- _ O
embedding -X- _ O
model -X- _ O
in -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
context -X- _ O
could -X- _ O
be -X- _ O
too -X- _ O
long -X- _ O
, -X- _ O
we -X- _ O
split -X- _ O
the -X- _ O
context -X- _ O
sequence -X- _ O
to -X- _ O
separate -X- _ O
chunks -X- _ O
. -X- _ O
Each -X- _ O
chunk -X- _ O
length -X- _ O
is -X- _ O
equal -X- _ O
to -X- _ O
maximum -X- _ O
sequence -X- _ O
length -X- _ O
the -X- _ O
model -X- _ O
could -X- _ O
accept -X- _ O
appending -X- _ O
the -X- _ O
sequence -X- _ O
a -X- _ O
; -X- _ O
in -X- _ O
fact -X- _ O
, -X- _ O
model -X- _ O
max -X- _ O
length -X- _ O
= -X- _ O
len(chunk)+len(a -X- _ O
) -X- _ O
. -X- _ O
If -X- _ O
c -X- _ O
l -X- _ O
denote -X- _ O
each -X- _ O
chunk -X- _ O
, -X- _ O
this -X- _ O
sequence -X- _ O
could -X- _ O
be -X- _ O
showed -X- _ O
as -X- _ O
: -X- _ O
b -X- _ O
= -X- _ O
[ -X- _ O
c -X- _ O
l -X- _ O
; -X- _ O
a](2)where -X- _ O
the -X- _ O
full -X- _ O
context -X- _ O
is -X- _ O
c -X- _ O
= -X- _ O
{ -X- _ O
c -X- _ O
1 -X- _ O
, -X- _ O
c -X- _ O
2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
c -X- _ O
L -X- _ O
} -X- _ O
, -X- _ O
and -X- _ O
L -X- _ O
is -X- _ O
the -X- _ O
last -X- _ O
chunk -X- _ O
. -X- _ O
The -X- _ O
size -X- _ O
of -X- _ O
this -X- _ O
sequence -X- _ O
is -X- _ O
B -X- _ O
so -X- _ O
B -X- _ O
= -X- _ O
L -X- _ O
+ -X- _ O
A.After -X- _ O
feeding -X- _ O
the -X- _ O
input -X- _ O
b -X- _ O
to -X- _ O
the -X- _ O
Longformer -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
a -X- _ O
global -X- _ O
attention -X- _ O
only -X- _ O
on -X- _ O
a -X- _ O
( -X- _ O
concatenated -X- _ O
question -X- _ O
and -X- _ O
answer -X- _ O
candidates -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
rest -X- _ O
is -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
longformer -X- _ O
model -X- _ O
utilizes -X- _ O
a -X- _ O
base -X- _ O
model -X- _ O
( -X- _ O
like -X- _ O
RoBERTa -X- _ B-MethodName
without -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layer -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
this -X- _ O
as -X- _ O
basemodel -X- _ O
function -X- _ O
that -X- _ O
outputs -X- _ O
the -X- _ O
encoded -X- _ O
sequence -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
If -X- _ O
GAttn -X- _ B-MethodName
denotes -X- _ O
the -X- _ O
global -X- _ O
attention -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
: -X- _ O
d -X- _ O
i -X- _ O
= -X- _ O
basemodel(b -X- _ O
) -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
g -X- _ O
i -X- _ O
= -X- _ O
GAttn(d -X- _ O
i -X- _ O
) -X- _ O
.1(i -X- _ O
∈ -X- _ O
A -X- _ O
) -X- _ O
( -X- _ O
4)where -X- _ O
d -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
raw -X- _ O
output -X- _ O
vector -X- _ O
for -X- _ O
each -X- _ O
input -X- _ O
token -X- _ O
. -X- _ O
The -X- _ O
global -X- _ O
attention -X- _ O
function -X- _ O
is -X- _ O
applied -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
question -X- _ O
or -X- _ O
answer -X- _ O
candidate -X- _ O
token -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
outputs -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
candidates -X- _ O
tokens -X- _ O
, -X- _ O
i.e. -X- _ O
we -X- _ O
have -X- _ O
: -X- _ O
h -X- _ O
j -X- _ O
= -X- _ O
GAttn(a -X- _ O
, -X- _ O
c -X- _ O
l -X- _ O
) -X- _ O
( -X- _ O
5)Figure -X- _ O
1 -X- _ O
: -X- _ O
The -X- _ O
model -X- _ O
architecture -X- _ O
. -X- _ O
The -X- _ O
concatenated -X- _ O
input -X- _ O
vector -X- _ O
will -X- _ O
be -X- _ O
encoded -X- _ O
using -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
( -X- _ O
like -X- _ O
RoBERTa -X- _ B-MethodName
without -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layer -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
global -X- _ O
attention -X- _ O
( -X- _ O
Luong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
candidate -X- _ O
answers -X- _ O
representations -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
passage -X- _ O
as -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
The -X- _ O
logit -X- _ O
( -X- _ O
score -X- _ O
) -X- _ O
of -X- _ O
each -X- _ O
ent -X- _ O
token -X- _ O
will -X- _ O
be -X- _ O
calculated -X- _ O
using -X- _ O
a -X- _ O
linear -X- _ O
transformation -X- _ O
function -X- _ O
, -X- _ O
then -X- _ O
the -X- _ O
prediction -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
answer -X- _ O
candidates -X- _ O
( -X- _ O
ent -X- _ O
tokens -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
outputted -X- _ O
using -X- _ O
a -X- _ O
softmax -X- _ B-HyperparameterValue
layer -X- _ I-HyperparameterValue
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
logit -X- _ O
of -X- _ O
each -X- _ O
candidate -X- _ O
( -X- _ O
< -X- _ O
ent -X- _ O
> -X- _ O
tokens -X- _ O
) -X- _ O
as -X- _ O
x -X- _ O
j -X- _ O
( -X- _ O
x -X- _ O
j -X- _ O
= -X- _ O
h -X- _ O
j -X- _ O
if -X- _ O
j -X- _ O
correspond -X- _ O
to -X- _ O
a -X- _ O
candidate -X- _ O
) -X- _ O
, -X- _ O
average -X- _ O
over -X- _ O
different -X- _ O
chunks -X- _ O
, -X- _ O
and -X- _ O
apply -X- _ O
a -X- _ O
linear -X- _ O
transformation -X- _ O
: -X- _ O
f -X- _ O
j -X- _ O
= -X- _ O
v -X- _ O
T -X- _ O
x -X- _ O
j -X- _ O
( -X- _ O
6)where -X- _ O
the -X- _ O
vector -X- _ O
v -X- _ O
is -X- _ O
trainable -X- _ O
, -X- _ O
and -X- _ O
f -X- _ O
j -X- _ O
is -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
each -X- _ O
candidate -X- _ O
. -X- _ O
And -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
over -X- _ O
the -X- _ O
candidates -X- _ O
will -X- _ O
be -X- _ O
calculated -X- _ O
using -X- _ O
a -X- _ O
softmax -X- _ B-HyperparameterValue
layer -X- _ I-HyperparameterValue
on -X- _ O
the -X- _ O
logits -X- _ O
. -X- _ O
The -X- _ O
predicted -X- _ O
answer -X- _ O
is -X- _ O
the -X- _ O
argmax -X- _ O
of -X- _ O
the -X- _ O
softmax -X- _ O
output -X- _ O
. -X- _ O
we -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
loss -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
only -X- _ O
participated -X- _ O
in -X- _ O
the -X- _ O
second -X- _ O
subtask -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
evaluate -X- _ O
our -X- _ O
model -X- _ O
on -X- _ O
both -X- _ O
subtasks -X- _ O
here -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
explain -X- _ O
our -X- _ O
configurations -X- _ O
for -X- _ O
utilizing -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
other -X- _ O
baselines -X- _ O
which -X- _ O
are -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
base -X- _ O
as -X- _ O
an -X- _ O
alternative -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
Gate -X- _ B-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
( -X- _ I-MethodName
GA -X- _ I-MethodName
) -X- _ I-MethodName
as -X- _ O
our -X- _ O
task -X- _ O
baseline -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
a -X- _ O
brief -X- _ O
discussion -X- _ O
will -X- _ O
be -X- _ O
done -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
Popular -X- _ O
metrics -X- _ O
to -X- _ O
evaluate -X- _ O
these -X- _ O
models -X- _ O
are -X- _ O
F1 -X- _ B-MetricName
, -X- _ O
EM -X- _ B-MetricName
( -X- _ O
Exact -X- _ B-MetricName
Match -X- _ I-MetricName
or -X- _ O
accuracy -X- _ B-MetricName
) -X- _ O
, -X- _ O
and -X- _ O
MRR -X- _ B-MetricName
( -X- _ O
Mean -X- _ B-MetricName
Reciprocal -X- _ I-MetricName
Rank -X- _ I-MetricName
) -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
precision -X- _ B-MetricName
and -X- _ O
recall -X- _ B-MetricName
in -X- _ O
our -X- _ O
task -X- _ O
are -X- _ O
equal -X- _ O
, -X- _ O
so -X- _ O
F1 -X- _ B-MetricName
= -X- _ O
Precision -X- _ B-MetricName
= -X- _ O
Recall -X- _ B-MetricName
. -X- _ O
Also -X- _ O
, -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
EM -X- _ B-MetricName
are -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O
And -X- _ O
, -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
MRR -X- _ B-MetricName
is -X- _ O
optional -X- _ O
, -X- _ O
so -X- _ O
the -X- _ O
metrics -X- _ O
used -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
result -X- _ O
are -X- _ O
the -X- _ O
accuracy -X- _ O
and -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
. -X- _ O
The -X- _ O
baseline -X- _ O
model -X- _ O
( -X- _ O
GA -X- _ B-MethodName
) -X- _ O
is -X- _ O
trained -X- _ O
for -X- _ O
30 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
each -X- _ O
epoch -X- _ O
containing -X- _ O
101 -X- _ B-HyperparameterValue
mini -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
batches -X- _ I-HyperparameterName
. -X- _ O
The -X- _ O
train -X- _ B-HyperparameterName
batch -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O
Dropout -X- _ B-HyperparameterName
with -X- _ O
the -X- _ O
rate -X- _ O
of -X- _ O
0.5 -X- _ B-HyperparameterValue
is -X- _ O
also -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
hidden -X- _ O
states -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
0.001 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
dimensionality -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
the -X- _ I-HyperparameterName
GloVe -X- _ I-HyperparameterName
embedding -X- _ I-HyperparameterName
is -X- _ O
300 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
128 -X- _ B-HyperparameterValue
. -X- _ O
Training -X- _ O
and -X- _ O
evaluation -X- _ O
take -X- _ O
about -X- _ O
2 -X- _ O
hours -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
v100 -X- _ O
GPU -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
configuration -X- _ O
as -X- _ O
our -X- _ O
method -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
global -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
output -X- _ O
vector -X- _ O
of -X- _ O
each -X- _ O
chunk -X- _ O
as -X- _ O
our -X- _ O
final -X- _ O
vector -X- _ O
to -X- _ O
be -X- _ O
linearly -X- _ O
transformed -X- _ O
into -X- _ O
single -X- _ O
logit -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
softmax -X- _ B-HyperparameterValue
layer -X- _ I-HyperparameterValue
using -X- _ O
the -X- _ O
crossentropy -X- _ O
loss -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
the -X- _ O
logit -X- _ O
is -X- _ O
averaged -X- _ O
over -X- _ O
different -X- _ O
chunks -X- _ O
, -X- _ O
before -X- _ O
applying -X- _ O
the -X- _ O
linear -X- _ O
transformation -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
here -X- _ O
is -X- _ O
bounded -X- _ O
to -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ I-HyperparameterValue
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
includes -X- _ O
the -X- _ O
n -X- _ O
2 -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
base -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
it -X- _ O
on -X- _ O
each -X- _ O
subtask -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
introduced -X- _ O
in -X- _ O
section -X- _ O
3 -X- _ O
for -X- _ O
both -X- _ O
subtasks -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
was -X- _ O
initialized -X- _ O
using -X- _ O
the -X- _ O
Longformer -X- _ B-MethodName
- -X- _ O
base -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
weights -X- _ O
, -X- _ O
then -X- _ O
finetuned -X- _ O
in -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
subtasks -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
issues -X- _ O
, -X- _ O
the -X- _ O
model -X- _ B-HyperparameterName
max -X- _ I-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
set -X- _ O
to -X- _ O
4096 -X- _ B-HyperparameterValue
tokens -X- _ I-HyperparameterValue
which -X- _ O
are -X- _ O
sufficient -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
used -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
- -X- _ O
large -X- _ O
tokenizer -X- _ O
to -X- _ O
tokenize -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
as -X- _ O
the -X- _ O
Longformer -X- _ B-MethodName
model -X- _ O
has -X- _ O
been -X- _ O
trained -X- _ O
on -X- _ O
using -X- _ O
this -X- _ O
configuration -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
maximum -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
3e-5 -X- _ B-HyperparameterValue
using -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
with -X- _ O
beta2=0.98 -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
then -X- _ O
assumed -X- _ O
the -X- _ O
validation -X- _ O
check -X- _ O
interval -X- _ O
to -X- _ O
250 -X- _ O
which -X- _ O
indicates -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
gradient -X- _ O
updates -X- _ O
between -X- _ O
checking -X- _ O
validation -X- _ O
loss -X- _ O
. -X- _ O
And -X- _ O
a -X- _ O
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
has -X- _ O
been -X- _ O
considered -X- _ O
to -X- _ O
regularize -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
avoid -X- _ O
overfitting -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
for -X- _ O
15 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
model -X- _ O
takes -X- _ O
about -X- _ O
six -X- _ O
hours -X- _ O
, -X- _ O
and -X- _ O
inference -X- _ O
takes -X- _ O
about -X- _ O
nine -X- _ O
seconds -X- _ O
for -X- _ O
each -X- _ O
sample -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
V100 -X- _ O
GPU -X- _ O
. -X- _ O
Subtask1 -X- _ O
measures -X- _ O
imperceptibility -X- _ O
abstract -X- _ O
level -X- _ O
of -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O
This -X- _ O
subtask -X- _ O
includes -X- _ O
3227 -X- _ O
training -X- _ O
samples -X- _ O
, -X- _ O
837 -X- _ O
validation -X- _ O
samples -X- _ O
, -X- _ O
and -X- _ O
2025 -X- _ O
test -X- _ O
samples -X- _ O
. -X- _ O
The -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
biggest -X- _ O
sample -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
context -X- _ O
length -X- _ O
is -X- _ O
about -X- _ O
2000 -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
achieved -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
70 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
which -X- _ O
improves -X- _ O
our -X- _ O
baseline -X- _ O
by -X- _ O
about -X- _ O
40 -X- _ B-MetricValue
percent -X- _ I-MetricValue
. -X- _ O
Table -X- _ O
2 -X- _ O
showed -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
subtask -X- _ O
. -X- _ O
Subtask2 -X- _ O
measures -X- _ O
the -X- _ O
non -X- _ B-TaskName
- -X- _ I-TaskName
specificity -X- _ I-TaskName
level -X- _ I-TaskName
of -X- _ I-TaskName
abstract -X- _ I-TaskName
meaning -X- _ I-TaskName
in -X- _ I-TaskName
reading -X- _ I-TaskName
comprehension -X- _ I-TaskName
. -X- _ O
It -X- _ O
in -X- _ O
- -X- _ O
cludes -X- _ O
3318 -X- _ O
training -X- _ O
samples -X- _ O
, -X- _ O
851 -X- _ O
validation -X- _ O
samples -X- _ O
, -X- _ O
and -X- _ O
2017 -X- _ O
test -X- _ O
samples -X- _ O
. -X- _ O
The -X- _ O
best -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
the -X- _ O
validation -X- _ O
set -X- _ O
is -X- _ O
64 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
Table -X- _ O
3 -X- _ O
showed -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
this -X- _ O
subtask -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
two -X- _ O
baselines -X- _ O
to -X- _ O
find -X- _ O
out -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
using -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
rather -X- _ O
than -X- _ O
a -X- _ O
simple -X- _ O
RNN -X- _ B-MethodName
model -X- _ O
. -X- _ O
Although -X- _ O
this -X- _ O
task -X- _ O
offers -X- _ O
a -X- _ O
higher -X- _ O
level -X- _ O
of -X- _ O
representation -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
models -X- _ O
is -X- _ O
helpful -X- _ O
, -X- _ O
and -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
higher -X- _ O
chance -X- _ O
of -X- _ O
modeling -X- _ O
such -X- _ O
abstract -X- _ O
concepts -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
on -X- _ O
subtask2 -X- _ O
are -X- _ O
weaker -X- _ O
than -X- _ O
subtask1 -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
This -X- _ O
can -X- _ O
be -X- _ O
the -X- _ O
consequence -X- _ O
of -X- _ O
limited -X- _ O
semantic -X- _ O
representation -X- _ O
for -X- _ O
abstract -X- _ O
word -X- _ O
which -X- _ O
indicates -X- _ O
the -X- _ O
subtask2 -X- _ O
includes -X- _ O
more -X- _ O
abstract -X- _ O
words -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
abstract -X- _ O
level -X- _ O
; -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
' -X- _ O
animal -X- _ O
' -X- _ O
could -X- _ O
be -X- _ O
matched -X- _ O
to -X- _ O
any -X- _ O
animal -X- _ O
, -X- _ O
like -X- _ O
' -X- _ O
cat -X- _ O
' -X- _ O
or -X- _ O
' -X- _ O
dog -X- _ O
' -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
word -X- _ O
' -X- _ O
entity -X- _ O
' -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
be -X- _ O
represented -X- _ O
as -X- _ O
it -X- _ O
could -X- _ O
be -X- _ O
matched -X- _ O
to -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
. -X- _ O
And -X- _ O
the -X- _ O
model -X- _ O
faces -X- _ O
a -X- _ O
limitation -X- _ O
in -X- _ O
the -X- _ O
knowledge -X- _ O
representation -X- _ O
. -X- _ O
Another -X- _ O
assumption -X- _ O
could -X- _ O
be -X- _ O
the -X- _ O
data -X- _ O
enrichment -X- _ O
that -X- _ O
these -X- _ O
model -X- _ O
has -X- _ O
been -X- _ O
trained -X- _ O
on -X- _ O
. -X- _ O
As -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
available -X- _ O
texts -X- _ O
for -X- _ O
training -X- _ O
consist -X- _ O
of -X- _ O
concrete -X- _ O
words -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
language -X- _ O
understanding -X- _ O
to -X- _ O
less -X- _ O
abstract -X- _ O
words -X- _ O
to -X- _ O
achieve -X- _ O
a -X- _ O
better -X- _ O
result -X- _ O
. -X- _ O
Comparing -X- _ O
our -X- _ O
method -X- _ O
which -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
longformer -X- _ B-MethodName
model -X- _ O
to -X- _ O
usual -X- _ O
language -X- _ O
models -X- _ O
like -X- _ O
BERT -X- _ B-MethodName
indicates -X- _ O
a -X- _ O
new -X- _ O
insight -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
passage -X- _ O
length -X- _ O
and -X- _ O
the -X- _ O
attention -X- _ O
mechanism -X- _ O
. -X- _ O
Popular -X- _ O
language -X- _ O
models -X- _ O
like -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
use -X- _ O
a -X- _ O
n -X- _ O
2 -X- _ O
attention -X- _ O
which -X- _ O
requires -X- _ O
a -X- _ O
large -X- _ O
receptive -X- _ O
field -X- _ O
to -X- _ O
represent -X- _ O
long -X- _ O
passages -X- _ O
. -X- _ O
This -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
performance -X- _ O
limitation -X- _ O
which -X- _ O
bounds -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
up -X- _ O
to -X- _ O
512 -X- _ O
tokens -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
the -X- _ O
longformer -X- _ B-MethodName
global -X- _ O
attention -X- _ O
mechanism -X- _ O
relaxes -X- _ O
this -X- _ O
limitation -X- _ O
as -X- _ O
we -X- _ O
only -X- _ O
need -X- _ O
to -X- _ O
pay -X- _ O
attention -X- _ O
to -X- _ O
a -X- _ O
small -X- _ O
factor -X- _ O
of -X- _ O
context -X- _ O
and -X- _ O
more -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
local -X- _ O
window -X- _ O
. -X- _ O
So -X- _ O
the -X- _ O
receptive -X- _ O
field -X- _ O
will -X- _ O
not -X- _ O
overflow -X- _ O
and -X- _ O
saves -X- _ O
the -X- _ O
necessary -X- _ O
information -X- _ O
to -X- _ O
better -X- _ O
represent -X- _ O
the -X- _ O
language -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
analyzed -X- _ O
the -X- _ O
errors -X- _ O
that -X- _ O
mostly -X- _ O
affect -X- _ O
our -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
think -X- _ O
that -X- _ O
the -X- _ O
problem -X- _ O
is -X- _ O
the -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
well -X- _ O
- -X- _ O
suited -X- _ O
in -X- _ O
our -X- _ O
method -X- _ O
i.e. -X- _ O
concatenating -X- _ O
the -X- _ O
context -X- _ O
, -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
answer -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
disadvantage -X- _ O
of -X- _ O
concatenating -X- _ O
the -X- _ O
candidate -X- _ O
answers -X- _ O
to -X- _ O
each -X- _ O
other -X- _ O
is -X- _ O
the -X- _ O
missing -X- _ O
fine -X- _ O
contextual -X- _ O
representation -X- _ O
as -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
consume -X- _ O
the -X- _ O
position -X- _ O
embedding -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
incorrect -X- _ O
candidates -X- _ O
register -X- _ O
additional -X- _ O
noise -X- _ O
to -X- _ O
each -X- _ O
word -X- _ O
representation -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
placeholder -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
shown -X- _ O
how -X- _ O
different -X- _ O
approaches -X- _ O
can -X- _ O
be -X- _ O
leveraged -X- _ O
to -X- _ O
machine -X- _ B-TaskName
reading -X- _ I-TaskName
comprehension -X- _ I-TaskName
of -X- _ I-TaskName
abstract -X- _ I-TaskName
meaning -X- _ I-TaskName
. -X- _ O
We -X- _ O
reformulated -X- _ O
the -X- _ O
longformer -X- _ B-MethodName
model -X- _ O
to -X- _ O
learn -X- _ O
abstract -X- _ B-TaskName
meaning -X- _ I-TaskName
as -X- _ I-TaskName
a -X- _ I-TaskName
new -X- _ I-TaskName
level -X- _ I-TaskName
of -X- _ I-TaskName
semantic -X- _ I-TaskName
in -X- _ I-TaskName
machine -X- _ I-TaskName
reading -X- _ I-TaskName
comprehension -X- _ I-TaskName
. -X- _ O
This -X- _ O
method -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
improved -X- _ O
by -X- _ O
taking -X- _ O
advantage -X- _ O
of -X- _ O
external -X- _ O
knowledge -X- _ O
and -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
model -X- _ O
architectures -X- _ O
that -X- _ O
optimize -X- _ O
the -X- _ O
current -X- _ O
baseline -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
our -X- _ O
contribution -X- _ O
in -X- _ O
SemEval-2021 -X- _ B-DatasetName
Task -X- _ O
1 -X- _ O
: -X- _ B-TaskName
Lexical -X- _ I-TaskName
Complexity -X- _ I-TaskName
Prediction -X- _ I-TaskName
, -X- _ O
where -X- _ O
we -X- _ O
integrate -X- _ O
linguistic -X- _ O
, -X- _ O
statistical -X- _ O
, -X- _ O
and -X- _ O
semantic -X- _ O
properties -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
and -X- _ O
its -X- _ O
context -X- _ O
as -X- _ O
features -X- _ O
within -X- _ O
a -X- _ O
Machine -X- _ O
Learning -X- _ O
( -X- _ O
ML -X- _ O
) -X- _ O
framework -X- _ O
for -X- _ O
predicting -X- _ O
lexical -X- _ O
complexity -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
BERT -X- _ B-MethodName
contextualized -X- _ I-MethodName
word -X- _ I-MethodName
embeddings -X- _ I-MethodName
to -X- _ O
represent -X- _ O
the -X- _ O
semantic -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
and -X- _ O
its -X- _ O
context -X- _ O
. -X- _ O
We -X- _ O
participated -X- _ O
in -X- _ O
the -X- _ O
sub -X- _ O
- -X- _ O
task -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
complexity -X- _ O
score -X- _ O
of -X- _ O
single -X- _ O
words -X- _ O
. -X- _ O
Over -X- _ O
the -X- _ O
last -X- _ O
decade -X- _ O
, -X- _ O
automated -X- _ O
methods -X- _ O
for -X- _ O
detecting -X- _ O
complex -X- _ O
words -X- _ O
have -X- _ O
been -X- _ O
developed -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
beginning -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
assumed -X- _ O
that -X- _ B-MetricName
lexical -X- _ I-MetricName
complexity -X- _ I-MetricName
is -X- _ O
binary -X- _ O
, -X- _ O
words -X- _ O
are -X- _ O
either -X- _ O
" -X- _ O
difficult -X- _ O
" -X- _ O
or -X- _ O
" -X- _ O
not -X- _ O
difficult -X- _ O
" -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
Complex -X- _ B-TaskName
Word -X- _ I-TaskName
Identification -X- _ I-TaskName
( -X- _ O
CWI -X- _ O
) -X- _ O
shared -X- _ O
task -X- _ O
referred -X- _ O
to -X- _ O
binary -X- _ O
identification -X- _ O
of -X- _ O
complex -X- _ O
words -X- _ O
( -X- _ O
Zampieri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
limitation -X- _ O
of -X- _ O
this -X- _ O
assumption -X- _ O
is -X- _ O
that -X- _ O
a -X- _ O
word -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
decision -X- _ O
boundary -X- _ O
is -X- _ O
considered -X- _ O
to -X- _ O
be -X- _ O
as -X- _ O
complex -X- _ O
as -X- _ O
one -X- _ O
farther -X- _ O
apart -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
three -X- _ O
years -X- _ O
ago -X- _ O
, -X- _ O
the -X- _ O
CWI -X- _ B-TaskName
included -X- _ O
an -X- _ O
additional -X- _ O
probabilistic -X- _ O
classification -X- _ O
task -X- _ O
where -X- _ O
the -X- _ O
participants -X- _ O
were -X- _ O
asked -X- _ O
to -X- _ O
give -X- _ O
a -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
given -X- _ O
target -X- _ O
word -X- _ O
in -X- _ O
particular -X- _ O
context -X- _ O
being -X- _ O
complex -X- _ O
( -X- _ O
Štajner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).Recently -X- _ O
, -X- _ O
CompLex -X- _ B-DatasetName
, -X- _ O
a -X- _ O
new -X- _ O
English -X- _ O
corpus -X- _ O
for -X- _ O
lexical -X- _ O
complexity -X- _ O
prediction -X- _ O
was -X- _ O
introduced -X- _ O
( -X- _ O
Shardlow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
corpus -X- _ O
is -X- _ O
annotated -X- _ O
using -X- _ O
a -X- _ O
5 -X- _ O
- -X- _ O
point -X- _ O
Likert -X- _ B-MetricName
scale -X- _ I-MetricName
( -X- _ O
1 -X- _ O
- -X- _ O
5 -X- _ O
) -X- _ O
( -X- _ O
corresponding -X- _ O
to -X- _ O
very -X- _ O
easy -X- _ O
, -X- _ O
easy -X- _ O
, -X- _ O
neutral -X- _ O
, -X- _ O
difficult -X- _ O
, -X- _ O
and -X- _ O
very -X- _ O
difficult -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
covers -X- _ O
3 -X- _ O
genres -X- _ O
: -X- _ O
Bible -X- _ O
translation -X- _ O
, -X- _ O
European -X- _ O
Pariliament -X- _ O
proceedings -X- _ O
, -X- _ O
and -X- _ O
biomedical -X- _ O
articles -X- _ O
. -X- _ O
SemEval-2021 -X- _ B-DatasetName
( -X- _ O
Task -X- _ O
1 -X- _ O
) -X- _ O
shared -X- _ O
task -X- _ O
on -X- _ B-TaskName
Lexical -X- _ I-TaskName
Complexity -X- _ I-TaskName
Prediction -X- _ I-TaskName
( -X- _ I-TaskName
LCP -X- _ I-TaskName
) -X- _ O
( -X- _ O
Shardlow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021a -X- _ O
, -X- _ O
b -X- _ O
) -X- _ O
provided -X- _ O
the -X- _ O
participants -X- _ O
with -X- _ O
Complex -X- _ O
and -X- _ O
defined -X- _ O
two -X- _ O
sub -X- _ O
- -X- _ O
tasks -X- _ O
: -X- _ O
predicting -X- _ O
the -X- _ O
com -X- _ O
- -X- _ O
plexity -X- _ O
score -X- _ O
of -X- _ O
single -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
predicting -X- _ O
the -X- _ O
complexity -X- _ O
score -X- _ O
of -X- _ O
multi -X- _ O
- -X- _ O
word -X- _ O
expressions -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
our -X- _ O
system -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
sub -X- _ O
- -X- _ O
task -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
complexity -X- _ O
score -X- _ O
of -X- _ O
single -X- _ O
words -X- _ O
. -X- _ O
Our -X- _ O
system -X- _ O
incorporates -X- _ O
linguistic -X- _ O
, -X- _ O
statistical -X- _ O
, -X- _ O
and -X- _ O
semantic -X- _ O
properties -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
and -X- _ O
its -X- _ O
context -X- _ O
as -X- _ O
features -X- _ O
within -X- _ O
a -X- _ O
Machine -X- _ O
Learning -X- _ O
( -X- _ O
ML -X- _ O
) -X- _ O
framework -X- _ O
for -X- _ O
predicting -X- _ O
lexical -X- _ O
complexity -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
is -X- _ O
organized -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
First -X- _ O
, -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
features -X- _ O
from -X- _ O
previous -X- _ O
works -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
adopted -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
our -X- _ O
feature -X- _ O
sets -X- _ O
, -X- _ O
the -X- _ O
feature -X- _ O
selection -X- _ O
process -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
trial -X- _ O
data -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
Our -X- _ O
system -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
data -X- _ O
are -X- _ O
detailed -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
conclusions -X- _ O
in -X- _ O
Section -X- _ O
5 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
shortly -X- _ O
describe -X- _ O
linguistic -X- _ O
, -X- _ O
statistical -X- _ O
, -X- _ O
and -X- _ O
semantic -X- _ O
features -X- _ O
which -X- _ O
were -X- _ O
encoded -X- _ O
as -X- _ O
features -X- _ O
in -X- _ O
previous -X- _ O
complexity -X- _ O
prediction -X- _ O
tasks -X- _ O
and -X- _ O
were -X- _ O
integrated -X- _ O
in -X- _ O
our -X- _ O
system -X- _ O
. -X- _ O
Linguistics -X- _ O
features -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Part -X- _ O
- -X- _ O
Of -X- _ O
- -X- _ O
Speech -X- _ O
( -X- _ O
POS -X- _ O
) -X- _ O
tag -X- _ O
, -X- _ O
dependency -X- _ O
parsing -X- _ O
relations -X- _ O
, -X- _ O
and -X- _ O
syllable -X- _ O
counts -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
statistical -X- _ O
features -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
word -X- _ O
length -X- _ O
and -X- _ O
word -X- _ O
frequency -X- _ O
, -X- _ O
have -X- _ O
been -X- _ O
widely -X- _ O
used -X- _ O
for -X- _ O
predicting -X- _ O
lexical -X- _ B-MetricName
complexity -X- _ I-MetricName
( -X- _ O
Mukherjee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Ronzano -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016;Alfter -X- _ O
and -X- _ O
Pilán -X- _ O
, -X- _ O
2018;Gooding -X- _ O
and -X- _ O
Kochmar -X- _ O
, -X- _ O
2018;Hartmann -X- _ O
and -X- _ O
Dos -X- _ O
Santos -X- _ O
, -X- _ O
2018;Kajiwara -X- _ O
and -X- _ O
Komachi -X- _ O
, -X- _ O
2018;Wani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Some -X- _ O
of -X- _ O
these -X- _ O
works -X- _ O
found -X- _ O
WordNet -X- _ B-MethodName
( -X- _ O
Miller -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
as -X- _ O
a -X- _ O
valuable -X- _ O
source -X- _ O
of -X- _ O
lexical -X- _ O
features -X- _ O
. -X- _ O
The -X- _ O
main -X- _ O
extracted -X- _ O
feature -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
synsets -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
information -X- _ O
on -X- _ O
hypernyms -X- _ O
, -X- _ O
hyponyms -X- _ O
, -X- _ O
holonym -X- _ O
, -X- _ O
and -X- _ O
meronym -X- _ O
is -X- _ O
useful -X- _ O
( -X- _ O
Gooding -X- _ O
and -X- _ O
Kochmar -X- _ O
, -X- _ O
2018;Hartmann -X- _ O
and -X- _ O
Dos -X- _ O
Santos -X- _ O
, -X- _ O
2018;Wani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).Semantic -X- _ O
features -X- _ O
were -X- _ O
commonly -X- _ O
encoded -X- _ O
using -X- _ O
word -X- _ O
embedding -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
words -X- _ O
( -X- _ O
Kuru -X- _ O
, -X- _ O
2016;AbuRa'ed -X- _ O
and -X- _ O
Sag -X- _ O
- -X- _ O
gion -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
word -X- _ O
embeddings -X- _ O
were -X- _ O
generated -X- _ O
using -X- _ O
Word2Vec -X- _ B-MethodName
context -X- _ O
- -X- _ O
independent -X- _ O
models -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Word2Vec -X- _ B-MethodName
models -X- _ O
combine -X- _ O
different -X- _ O
senses -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
into -X- _ O
one -X- _ O
single -X- _ O
vector -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
recently -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
growing -X- _ O
interest -X- _ O
in -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
generates -X- _ O
context -X- _ O
- -X- _ O
dependent -X- _ O
embeddings -X- _ O
that -X- _ O
allow -X- _ O
a -X- _ O
word -X- _ O
to -X- _ O
have -X- _ O
several -X- _ O
vector -X- _ O
representations -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
context -X- _ O
in -X- _ O
which -X- _ O
it -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
previous -X- _ O
works -X- _ O
that -X- _ O
only -X- _ O
use -X- _ O
context -X- _ O
- -X- _ O
independent -X- _ O
embeddings -X- _ O
, -X- _ O
our -X- _ O
system -X- _ O
uses -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
based -X- _ O
contextdependent -X- _ O
embeddings -X- _ O
. -X- _ O
We -X- _ O
adopt -X- _ O
a -X- _ O
supervised -X- _ O
Machine -X- _ O
Learning -X- _ O
( -X- _ O
ML -X- _ O
) -X- _ O
approach -X- _ O
for -X- _ O
lexical -X- _ B-TaskName
complexity -X- _ I-TaskName
prediction -X- _ I-TaskName
. -X- _ O
The -X- _ O
first -X- _ O
step -X- _ O
in -X- _ O
a -X- _ O
classifier -X- _ O
training -X- _ O
is -X- _ O
to -X- _ O
determine -X- _ O
which -X- _ O
text -X- _ O
characteristics -X- _ O
are -X- _ O
relevant -X- _ O
and -X- _ O
how -X- _ O
those -X- _ O
features -X- _ O
are -X- _ O
coded -X- _ O
. -X- _ O
We -X- _ O
next -X- _ O
detail -X- _ O
how -X- _ O
the -X- _ O
semantic -X- _ O
properties -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
linguistic -X- _ O
and -X- _ O
statistical -X- _ O
properties -X- _ O
found -X- _ O
useful -X- _ O
in -X- _ O
prior -X- _ O
work -X- _ O
, -X- _ O
are -X- _ O
encoded -X- _ O
as -X- _ O
features -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
our -X- _ O
feature -X- _ O
analysis -X- _ O
procedure -X- _ O
and -X- _ O
the -X- _ O
supervised -X- _ O
ML -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
features -X- _ O
in -X- _ O
our -X- _ O
model -X- _ O
are -X- _ O
divided -X- _ O
into -X- _ O
3 -X- _ O
sets -X- _ O
: -X- _ O
linguistic -X- _ O
, -X- _ O
statistical -X- _ O
and -X- _ O
semantic -X- _ O
. -X- _ O
Our -X- _ O
dataset -X- _ O
contains -X- _ O
three -X- _ O
corpora -X- _ O
: -X- _ O
Bible -X- _ B-DatasetName
, -X- _ I-DatasetName
Europarl -X- _ I-DatasetName
, -X- _ I-DatasetName
and -X- _ I-DatasetName
Biomedical -X- _ I-DatasetName
, -X- _ O
to -X- _ O
add -X- _ O
variation -X- _ O
. -X- _ O
Since -X- _ O
each -X- _ O
corpus -X- _ O
has -X- _ O
its -X- _ O
own -X- _ O
unique -X- _ O
linguistic -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
encode -X- _ O
the -X- _ O
text -X- _ O
source -X- _ O
by -X- _ O
three -X- _ O
binary -X- _ O
features -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
our -X- _ O
linguistic -X- _ O
features -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
information -X- _ O
extracted -X- _ O
from -X- _ O
a -X- _ O
POS -X- _ O
tagger -X- _ O
. -X- _ O
Our -X- _ O
linguistic -X- _ O
properties -X- _ O
include -X- _ O
two -X- _ O
families -X- _ O
of -X- _ O
properties -X- _ O
: -X- _ O
morphological -X- _ O
and -X- _ O
syntactical -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
encode -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
POS -X- _ O
. -X- _ O
The -X- _ O
POS -X- _ O
is -X- _ O
extracted -X- _ O
by -X- _ O
the -X- _ O
Spacy -X- _ B-MethodName
's -X- _ O
statistical -X- _ O
POS -X- _ O
tagger -X- _ O
1 -X- _ O
. -X- _ O
Each -X- _ O
possible -X- _ O
POS -X- _ O
tag -X- _ O
is -X- _ O
represented -X- _ O
as -X- _ O
a -X- _ O
binary -X- _ O
feature -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
12 -X- _ O
tags -X- _ O
from -X- _ O
the -X- _ O
Universal -X- _ O
POS -X- _ O
tags -X- _ O
2 -X- _ O
: -X- _ O
ADJ -X- _ O
, -X- _ O
ADP -X- _ O
, -X- _ O
ADV -X- _ O
, -X- _ O
CONJ -X- _ O
, -X- _ O
DET -X- _ O
, -X- _ O
NOUN -X- _ O
, -X- _ O
NUM -X- _ O
, -X- _ O
PRT -X- _ O
, -X- _ O
PRON -X- _ O
, -X- _ O
VERB -X- _ O
and -X- _ O
X -X- _ O
( -X- _ O
other -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
an -X- _ O
additional -X- _ O
feature -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
syllables -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
is -X- _ O
encoded -X- _ O
3 -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
punctuation -X- _ O
marks -X- _ O
and -X- _ O
stopwords -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
( -X- _ O
two -X- _ O
features).Next -X- _ O
, -X- _ O
we -X- _ O
represent -X- _ O
syntactic -X- _ O
forms -X- _ O
by -X- _ O
POS -X- _ O
patterns -X- _ O
. -X- _ O
The -X- _ O
POS -X- _ O
pattern -X- _ O
refers -X- _ O
to -X- _ O
seven -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
and -X- _ O
three -X- _ O
words -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
it -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
is -X- _ O
encoded -X- _ O
by -X- _ O
12 -X- _ O
binary -X- _ O
features -X- _ O
, -X- _ O
resulting -X- _ O
with -X- _ O
84 -X- _ O
features -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
measure -X- _ O
the -X- _ O
polysemy -X- _ O
degree -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
using -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
senses -X- _ O
in -X- _ O
WordNet -X- _ B-MethodName
. -X- _ O
We -X- _ O
obtain -X- _ O
two -X- _ O
lexical -X- _ O
features -X- _ O
: -X- _ O
number -X- _ O
of -X- _ O
synsets -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
and -X- _ O
number -X- _ O
of -X- _ O
synsets -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
given -X- _ O
its -X- _ O
POS -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
some -X- _ O
statistical -X- _ O
features -X- _ O
based -X- _ O
on -X- _ O
frequency -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
target -X- _ O
word -X- _ O
length -X- _ O
and -X- _ O
sentence -X- _ O
length -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
frequency -X- _ O
using -X- _ O
Google -X- _ B-MethodName
N -X- _ I-MethodName
- -X- _ I-MethodName
gram -X- _ I-MethodName
4 -X- _ I-MethodName
word -X- _ I-MethodName
frequencies -X- _ I-MethodName
. -X- _ O
We -X- _ O
encode -X- _ O
the -X- _ O
logarithm -X- _ O
of -X- _ O
this -X- _ O
frequency -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
to -X- _ O
speed -X- _ O
the -X- _ O
ML -X- _ O
algorithm -X- _ O
's -X- _ O
convergence -X- _ O
( -X- _ O
three -X- _ O
features -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
represent -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
surrounding -X- _ O
context -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
by -X- _ O
vectors -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
semantic -X- _ O
space -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
semantic -X- _ O
space -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
a -X- _ O
bidirectional -X- _ B-MethodName
transformer -X- _ I-MethodName
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
containing -X- _ O
the -X- _ O
Toronto -X- _ B-DatasetName
Book -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
and -X- _ O
Wikipedia -X- _ B-DatasetName
using -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
and -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
contextualizing -X- _ O
vectors -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
semantic -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
by -X- _ O
averaging -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
vectors -X- _ O
of -X- _ O
seven -X- _ O
words -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
and -X- _ O
three -X- _ O
words -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
it -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
our -X- _ O
semantic -X- _ O
representation -X- _ O
add -X- _ O
768 -X- _ O
features -X- _ O
( -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
BERT -X- _ O
output -X- _ O
layer).To -X- _ O
extract -X- _ O
additional -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
two -X- _ O
machine -X- _ O
learning -X- _ O
algorithm -X- _ O
: -X- _ O
K -X- _ B-MethodName
- -X- _ I-MethodName
Means -X- _ I-MethodName
and -X- _ I-MethodName
k -X- _ I-MethodName
- -X- _ I-MethodName
Nearest -X- _ I-MethodName
Neighbors -X- _ I-MethodName
( -X- _ I-MethodName
KNN -X- _ I-MethodName
) -X- _ I-MethodName
algorithm -X- _ I-MethodName
. -X- _ O
K -X- _ B-MethodName
- -X- _ I-MethodName
Means -X- _ I-MethodName
is -X- _ O
an -X- _ O
unsupervised -X- _ O
learning -X- _ O
algorithm -X- _ O
used -X- _ O
for -X- _ O
clustering -X- _ O
. -X- _ O
It -X- _ O
takes -X- _ O
the -X- _ O
unlabeled -X- _ O
dataset -X- _ O
and -X- _ O
tries -X- _ O
to -X- _ O
group -X- _ O
them -X- _ O
into -X- _ O
k -X- _ O
number -X- _ O
of -X- _ O
clusters -X- _ O
. -X- _ O
We -X- _ O
encode -X- _ O
the -X- _ O
K -X- _ B-MethodName
- -X- _ I-MethodName
Mean -X- _ I-MethodName
results -X- _ O
by -X- _ O
four -X- _ O
binary -X- _ O
features -X- _ O
, -X- _ O
a -X- _ O
feature -X- _ O
per -X- _ O
cluster -X- _ O
( -X- _ O
k=4 -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
the -X- _ O
KNN -X- _ B-MethodName
algorithm -X- _ O
are -X- _ O
encoded -X- _ O
similarly -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
KNN -X- _ O
is -X- _ O
a -X- _ O
supervised -X- _ O
learning -X- _ O
algorithm -X- _ O
used -X- _ O
for -X- _ O
classification -X- _ O
. -X- _ O
It -X- _ O
takes -X- _ O
the -X- _ O
labeled -X- _ O
dataset -X- _ O
and -X- _ O
uses -X- _ O
it -X- _ O
to -X- _ O
learn -X- _ O
how -X- _ O
to -X- _ O
label -X- _ O
other -X- _ O
sentences -X- _ O
. -X- _ O
KNN -X- _ B-MethodName
classifies -X- _ O
an -X- _ O
unseen -X- _ O
sentence -X- _ O
using -X- _ O
it -X- _ O
k -X- _ B-MethodName
nearest -X- _ I-MethodName
neighbors -X- _ I-MethodName
voting -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
four -X- _ O
complexity -X- _ B-HyperparameterName
classes -X- _ O
: -X- _ O
0 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
0.25 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
0.26 -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
0.5 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
0.51 -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
0.75 -X- _ I-HyperparameterValue
, -X- _ I-HyperparameterValue
0.76 -X- _ I-HyperparameterValue
- -X- _ I-HyperparameterValue
1 -X- _ I-HyperparameterValue
. -X- _ O
For -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
above -X- _ O
feature -X- _ O
sets -X- _ O
, -X- _ O
we -X- _ O
tried -X- _ O
to -X- _ O
filter -X- _ O
out -X- _ O
non -X- _ O
- -X- _ O
relevant -X- _ O
features -X- _ O
using -X- _ O
several -X- _ O
approaches -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
discharged -X- _ O
features -X- _ O
that -X- _ O
decrease -X- _ O
the -X- _ O
system -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
the -X- _ O
POS -X- _ B-MethodName
pattern -X- _ I-MethodName
features -X- _ O
, -X- _ O
the -X- _ O
WordNet -X- _ B-MethodName
features -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
K -X- _ B-MethodName
- -X- _ I-MethodName
Means -X- _ I-MethodName
and -X- _ I-MethodName
KNN -X- _ I-MethodName
features -X- _ O
. -X- _ O
We -X- _ O
were -X- _ O
left -X- _ O
with -X- _ O
794 -X- _ O
features -X- _ O
. -X- _ O
These -X- _ O
features -X- _ O
were -X- _ O
selected -X- _ O
using -X- _ O
the -X- _ O
Linear -X- _ B-MethodName
Regression -X- _ I-MethodName
algorithm -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
also -X- _ O
selected -X- _ O
as -X- _ O
a -X- _ O
baseline -X- _ O
algorithm -X- _ O
by -X- _ O
the -X- _ O
task -X- _ O
organizers -X- _ O
. -X- _ O
To -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
systems -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
additional -X- _ O
ML -X- _ O
algorithms -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
SVM -X- _ B-MethodName
and -X- _ O
XGBoost -X- _ B-MethodName
( -X- _ O
see -X- _ O
more -X- _ O
details -X- _ O
in -X- _ O
Section -X- _ O
3.3).Next -X- _ O
, -X- _ O
since -X- _ O
correlated -X- _ O
features -X- _ O
do -X- _ O
not -X- _ O
carry -X- _ O
unique -X- _ O
information -X- _ O
and -X- _ O
may -X- _ O
interfere -X- _ O
the -X- _ O
learning -X- _ O
, -X- _ O
we -X- _ O
tried -X- _ O
to -X- _ O
discharge -X- _ O
highly -X- _ O
correlated -X- _ O
features -X- _ O
. -X- _ O
We -X- _ O
implemented -X- _ O
this -X- _ O
approach -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
iterative -X- _ O
process -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
is -X- _ O
the -X- _ O
desired -X- _ O
final -X- _ O
number -X- _ O
of -X- _ O
features -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
an -X- _ O
initial -X- _ O
correlation -X- _ O
threshold -X- _ O
( -X- _ O
0.9 -X- _ O
) -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
calculate -X- _ O
the -X- _ O
features -X- _ O
' -X- _ O
pairwise -X- _ O
correlation -X- _ O
and -X- _ O
features -X- _ O
with -X- _ O
correlation -X- _ O
above -X- _ O
the -X- _ O
threshold -X- _ O
are -X- _ O
removed -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
still -X- _ O
have -X- _ O
more -X- _ O
features -X- _ O
than -X- _ O
desired -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
lower -X- _ O
the -X- _ O
correlation -X- _ B-HyperparameterName
threshold -X- _ I-HyperparameterName
( -X- _ O
by -X- _ O
10 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
) -X- _ O
and -X- _ O
repeat -X- _ O
the -X- _ O
process -X- _ O
. -X- _ O
This -X- _ O
approach -X- _ O
improved -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
SVM -X- _ B-MethodName
and -X- _ O
Linear -X- _ B-MethodName
Regression -X- _ I-MethodName
models -X- _ O
( -X- _ O
selecting -X- _ O
97 -X- _ O
features -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
did -X- _ O
not -X- _ O
increase -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
XGBOOST -X- _ B-MethodName
method -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
we -X- _ O
also -X- _ O
tried -X- _ O
to -X- _ O
filter -X- _ O
out -X- _ O
feature -X- _ O
using -X- _ O
the -X- _ O
principal -X- _ B-MethodName
component -X- _ I-MethodName
analysis -X- _ I-MethodName
( -X- _ I-MethodName
PCA -X- _ I-MethodName
) -X- _ I-MethodName
feature -X- _ O
selection -X- _ O
method -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O
PCA -X- _ B-MethodName
aims -X- _ O
to -X- _ O
pick -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
features -X- _ O
that -X- _ O
retains -X- _ O
as -X- _ O
much -X- _ O
information -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
full -X- _ O
data -X- _ O
as -X- _ O
possible -X- _ O
. -X- _ O
PCA -X- _ B-MethodName
was -X- _ O
performed -X- _ O
both -X- _ O
on -X- _ O
the -X- _ O
full -X- _ O
feature -X- _ O
list -X- _ O
and -X- _ O
on -X- _ O
specific -X- _ O
features -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
features -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
was -X- _ O
not -X- _ O
successful -X- _ O
. -X- _ O
Some -X- _ O
of -X- _ O
the -X- _ O
classification -X- _ O
models -X- _ O
had -X- _ O
low -X- _ O
performance -X- _ O
using -X- _ O
such -X- _ O
amount -X- _ O
of -X- _ O
features -X- _ O
( -X- _ O
794 -X- _ O
features -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
filleted -X- _ O
features -X- _ O
by -X- _ O
calculating -X- _ O
their -X- _ O
correlation -X- _ O
with -X- _ O
the -X- _ O
complexity -X- _ O
score -X- _ O
and -X- _ O
discarding -X- _ O
features -X- _ O
with -X- _ O
low -X- _ O
correlation -X- _ O
( -X- _ O
less -X- _ O
than -X- _ O
0.072 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
resulted -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
list -X- _ O
of -X- _ O
101 -X- _ O
features:• -X- _ O
Biomedical -X- _ O
corpus -X- _ O
indicator -X- _ O
• -X- _ O
94 -X- _ O
features -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
vector -X- _ O
It -X- _ O
is -X- _ O
interesting -X- _ O
to -X- _ O
note -X- _ O
that -X- _ O
even -X- _ O
though -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
12 -X- _ O
POS -X- _ O
tags -X- _ O
, -X- _ O
only -X- _ O
2 -X- _ O
are -X- _ O
informative -X- _ O
for -X- _ O
the -X- _ O
complexity -X- _ O
prediction -X- _ O
task -X- _ O
. -X- _ O
Considering -X- _ O
the -X- _ O
source -X- _ O
text -X- _ O
indicators -X- _ O
, -X- _ O
the -X- _ O
third -X- _ O
Bible -X- _ O
indicator -X- _ O
is -X- _ O
not -X- _ O
useful -X- _ O
. -X- _ O
Out -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
768 -X- _ O
features -X- _ O
, -X- _ O
only -X- _ O
94 -X- _ O
remained -X- _ O
( -X- _ O
12.2 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
vector).The -X- _ O
BERT -X- _ B-MethodName
representation -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
generated -X- _ O
by -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
representation -X- _ O
model -X- _ O
. -X- _ O
These -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
different -X- _ O
datasets -X- _ O
of -X- _ O
various -X- _ O
domains -X- _ O
. -X- _ O
Since -X- _ O
one -X- _ O
of -X- _ O
our -X- _ O
corpora -X- _ O
is -X- _ O
from -X- _ O
the -X- _ O
Biomedical -X- _ O
domain -X- _ O
, -X- _ O
we -X- _ O
examined -X- _ O
the -X- _ O
system -X- _ O
performance -X- _ O
using -X- _ O
the -X- _ O
domain -X- _ O
specific -X- _ O
BioBERT -X- _ B-MethodName
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
a -X- _ O
comparison -X- _ O
between -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
our -X- _ O
system -X- _ O
using -X- _ O
the -X- _ O
classic -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
BioBERT -X- _ B-MethodName
( -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
left -X- _ O
and -X- _ O
BioBERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
right -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
columns -X- _ O
show -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
for -X- _ O
different -X- _ O
text -X- _ O
sources -X- _ O
. -X- _ O
The -X- _ O
red -X- _ O
line -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
error -X- _ O
rate -X- _ O
. -X- _ O
Columns -X- _ O
from -X- _ O
left -X- _ O
to -X- _ O
right -X- _ O
: -X- _ B-DatasetName
Bible -X- _ I-DatasetName
, -X- _ I-DatasetName
Biomedical -X- _ I-DatasetName
, -X- _ I-DatasetName
and -X- _ I-DatasetName
Europarl -X- _ I-DatasetName
. -X- _ O
Surprisingly -X- _ O
, -X- _ O
the -X- _ O
error -X- _ O
rate -X- _ O
of -X- _ O
the -X- _ O
BioBERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
Biomedical -X- _ O
domain -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
that -X- _ O
of -X- _ O
the -X- _ O
classic -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
error -X- _ O
for -X- _ O
both -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
( -X- _ O
∼ -X- _ O
0.69 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
combined -X- _ O
the -X- _ O
features -X- _ O
in -X- _ O
a -X- _ O
supervised -X- _ O
classification -X- _ O
framework -X- _ O
using -X- _ O
five -X- _ O
ML -X- _ O
methods -X- _ O
: -X- _ O
Linear -X- _ B-MethodName
Regression -X- _ I-MethodName
, -X- _ I-MethodName
Supported -X- _ I-MethodName
Vector -X- _ I-MethodName
Machine -X- _ I-MethodName
( -X- _ I-MethodName
SVM -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ I-MethodName
XGBoost -X- _ I-MethodName
( -X- _ I-MethodName
XGB -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ I-MethodName
KNN -X- _ I-MethodName
, -X- _ I-MethodName
and -X- _ I-MethodName
Stacking -X- _ I-MethodName
( -X- _ I-MethodName
Stack -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O
We -X- _ O
trained -X- _ O
the -X- _ O
ML -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
train -X- _ O
set -X- _ O
and -X- _ O
evaluated -X- _ O
their -X- _ O
performances -X- _ O
on -X- _ O
the -X- _ O
trial -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
ran -X- _ O
these -X- _ O
ML -X- _ O
methods -X- _ O
by -X- _ O
the -X- _ O
scikit -X- _ B-MethodName
- -X- _ I-MethodName
learn -X- _ I-MethodName
open -X- _ O
- -X- _ O
source -X- _ O
machine -X- _ O
- -X- _ O
learning -X- _ O
package -X- _ O
in -X- _ O
python -X- _ O
5 -X- _ O
( -X- _ O
Pedregosa -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
using -X- _ O
the -X- _ O
default -X- _ O
parameters -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
the -X- _ O
different -X- _ O
ML -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
feature -X- _ O
set -X- _ O
of -X- _ O
101 -X- _ O
features -X- _ O
, -X- _ O
as -X- _ O
described -X- _ O
above -X- _ O
. -X- _ O
The -X- _ O
MAE -X- _ B-MethodName
is -X- _ O
omitted -X- _ O
from -X- _ O
the -X- _ O
table -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
similar -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
ML -X- _ O
algorithms -X- _ O
( -X- _ O
0.01 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
differences -X- _ O
between -X- _ O
the -X- _ O
algorithms -X- _ O
were -X- _ O
not -X- _ O
so -X- _ O
substantial -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
next -X- _ O
report -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
all -X- _ O
these -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
To -X- _ O
increase -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
our -X- _ O
train -X- _ O
set -X- _ O
for -X- _ O
the -X- _ O
test -X- _ O
phase -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
both -X- _ O
the -X- _ O
train -X- _ O
and -X- _ O
trial -X- _ O
sets -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
final -X- _ O
model -X- _ O
. -X- _ O
To -X- _ O
analyze -X- _ O
our -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
converted -X- _ O
the -X- _ O
complexity -X- _ O
scores -X- _ O
to -X- _ O
labels -X- _ O
following -X- _ O
Shardlow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
descriptors -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
classification -X- _ O
confusion -X- _ O
matrix -X- _ O
of -X- _ O
the -X- _ O
XGBoost -X- _ B-MethodName
algorithm -X- _ O
. -X- _ O
Each -X- _ O
column -X- _ O
of -X- _ O
the -X- _ O
matrix -X- _ O
represents -X- _ O
the -X- _ O
instances -X- _ O
in -X- _ O
a -X- _ O
predicted -X- _ O
class -X- _ O
while -X- _ O
each -X- _ O
row -X- _ O
represents -X- _ O
the -X- _ O
instances -X- _ O
in -X- _ O
an -X- _ O
actual -X- _ O
class -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
the -X- _ O
classification -X- _ B-MetricName
errors -X- _ I-MetricName
( -X- _ O
18.54 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
were -X- _ O
due -X- _ O
to -X- _ O
incorrect -X- _ O
classification -X- _ O
of -X- _ O
very -X- _ O
easy -X- _ O
words -X- _ O
as -X- _ O
easy -X- _ O
. -X- _ O
There -X- _ O
were -X- _ O
also -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
opposite -X- _ O
direction -X- _ O
( -X- _ O
4.36 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
classifications -X- _ O
were -X- _ O
between -X- _ O
neutral -X- _ O
and -X- _ O
easy -X- _ O
in -X- _ O
both -X- _ O
directions -X- _ O
( -X- _ O
7.42 -X- _ B-MetricValue
% -X- _ I-MetricValue
+ -X- _ I-MetricValue
6.43 -X- _ I-MetricValue
% -X- _ I-MetricValue
= -X- _ I-MetricValue
13.85 -X- _ I-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
the -X- _ O
5 -X- _ O
th -X- _ O
class -X- _ O
, -X- _ O
very -X- _ O
difficult -X- _ O
, -X- _ O
does -X- _ O
not -X- _ O
appear -X- _ O
in -X- _ O
the -X- _ O
confusion -X- _ O
matrix -X- _ O
since -X- _ O
there -X- _ O
are -X- _ O
not -X- _ O
any -X- _ O
very -X- _ O
difficult -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
and -X- _ O
the -X- _ O
system -X- _ O
did -X- _ O
not -X- _ O
classified -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
as -X- _ O
very -X- _ O
difficult -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
implemented -X- _ O
a -X- _ O
system -X- _ O
that -X- _ O
incorporates -X- _ O
linguistic -X- _ O
, -X- _ O
statistical -X- _ O
, -X- _ O
and -X- _ O
semantic -X- _ O
features -X- _ O
to -X- _ O
predict -X- _ O
lexical -X- _ O
complexity -X- _ O
of -X- _ O
target -X- _ O
word -X- _ O
in -X- _ O
context -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
semantic -X- _ O
space -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
word -X- _ O
and -X- _ O
its -X- _ O
context -X- _ O
. -X- _ O
We -X- _ O
investigated -X- _ O
several -X- _ O
feature -X- _ O
selection -X- _ O
approaches -X- _ O
and -X- _ O
used -X- _ O
various -X- _ O
supervised -X- _ O
algorithms -X- _ O
. -X- _ O
Even -X- _ O
though -X- _ O
our -X- _ O
system -X- _ O
was -X- _ O
not -X- _ O
highly -X- _ O
ranked -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
presented -X- _ O
ideas -X- _ O
can -X- _ O
be -X- _ O
useful -X- _ O
for -X- _ O
future -X- _ O
research -X- _ O
on -X- _ O
lexical -X- _ B-TaskName
complexity -X- _ I-TaskName
prediction -X- _ I-TaskName
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
think -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
a -X- _ O
powerful -X- _ O
model -X- _ O
that -X- _ O
should -X- _ O
be -X- _ O
explored -X- _ O
. -X- _ O
Perhaps -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
BERT -X- _ B-MethodName
for -X- _ O
the -X- _ O
complexity -X- _ O
prediction -X- _ O
task -X- _ O
would -X- _ O
increase -X- _ O
the -X- _ O
system -X- _ O
performance -X- _ O
. -X- _ O

We -X- _ O
investigate -X- _ O
the -X- _ O
less -X- _ O
- -X- _ O
explored -X- _ O
task -X- _ O
of -X- _ O
generating -X- _ B-TaskName
open -X- _ I-TaskName
- -X- _ I-TaskName
ended -X- _ I-TaskName
questions -X- _ I-TaskName
that -X- _ I-TaskName
are -X- _ I-TaskName
typically -X- _ I-TaskName
answered -X- _ I-TaskName
by -X- _ I-TaskName
multiple -X- _ I-TaskName
sentences -X- _ I-TaskName
. -X- _ O
We -X- _ O
first -X- _ O
define -X- _ O
a -X- _ O
new -X- _ O
question -X- _ O
type -X- _ O
ontology -X- _ O
which -X- _ O
differentiates -X- _ O
the -X- _ O
nuanced -X- _ O
nature -X- _ O
of -X- _ O
questions -X- _ O
better -X- _ O
than -X- _ O
widely -X- _ O
used -X- _ O
question -X- _ O
words -X- _ O
. -X- _ O
A -X- _ O
new -X- _ O
dataset -X- _ O
with -X- _ O
4 -X- _ O
, -X- _ O
959 -X- _ O
questions -X- _ O
is -X- _ O
labeled -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
new -X- _ O
ontology -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
question -X- _ B-TaskName
type -X- _ I-TaskName
- -X- _ I-TaskName
aware -X- _ I-TaskName
question -X- _ I-TaskName
generation -X- _ I-TaskName
framework -X- _ O
, -X- _ O
augmented -X- _ O
by -X- _ O
a -X- _ O
semantic -X- _ B-TaskName
graph -X- _ I-TaskName
representation -X- _ I-TaskName
, -X- _ O
to -X- _ O
jointly -X- _ O
predict -X- _ O
question -X- _ O
focuses -X- _ O
and -X- _ O
produce -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
this -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
use -X- _ O
both -X- _ O
exemplars -X- _ O
and -X- _ O
automatically -X- _ O
generated -X- _ O
templates -X- _ O
to -X- _ O
improve -X- _ O
controllability -X- _ O
and -X- _ O
diversity -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
two -X- _ O
newly -X- _ O
collected -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
datasets -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
model -X- _ O
improves -X- _ O
question -X- _ O
quality -X- _ O
over -X- _ O
competitive -X- _ O
comparisons -X- _ O
based -X- _ O
on -X- _ O
automatic -X- _ O
metrics -X- _ O
. -X- _ O
Human -X- _ O
judges -X- _ O
also -X- _ O
rate -X- _ O
our -X- _ O
model -X- _ O
outputs -X- _ O
highly -X- _ O
in -X- _ O
answerability -X- _ B-MetricName
, -X- _ O
coverage -X- _ B-MetricName
of -X- _ I-MetricName
scope -X- _ I-MetricName
, -X- _ O
and -X- _ O
overall -X- _ B-MetricName
quality -X- _ I-MetricName
. -X- _ O
Finally -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
variants -X- _ O
with -X- _ O
templates -X- _ O
can -X- _ O
produce -X- _ O
questions -X- _ O
with -X- _ O
enhanced -X- _ O
controllability -X- _ O
and -X- _ O
diversity -X- _ O
. -X- _ O
Question -X- _ B-TaskName
- -X- _ I-TaskName
asking -X- _ I-TaskName
has -X- _ O
long -X- _ O
served -X- _ O
as -X- _ O
an -X- _ O
effective -X- _ O
instrument -X- _ O
for -X- _ O
knowledge -X- _ B-TaskName
learning -X- _ I-TaskName
( -X- _ O
Andre -X- _ O
, -X- _ O
1979;Tobin -X- _ O
, -X- _ O
1990 -X- _ O
) -X- _ O
and -X- _ O
assessing -X- _ O
learning -X- _ O
progress -X- _ O
( -X- _ O
Holme -X- _ O
, -X- _ O
2003;Downing -X- _ O
and -X- _ O
Yudkowsky -X- _ O
, -X- _ O
2009;Livingston -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
the -X- _ O
widely -X- _ O
studied -X- _ O
task -X- _ O
of -X- _ O
generating -X- _ O
factoid -X- _ O
questions -X- _ O
that -X- _ O
inquire -X- _ O
about -X- _ O
" -X- _ O
one -X- _ O
bit -X- _ O
" -X- _ O
of -X- _ O
information -X- _ O
( -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Duan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
interested -X- _ O
in -X- _ O
generating -X- _ B-TaskName
open -X- _ I-TaskName
- -X- _ I-TaskName
ended -X- _ I-TaskName
questions -X- _ I-TaskName
that -X- _ I-TaskName
require -X- _ I-TaskName
deep -X- _ I-TaskName
comprehension -X- _ I-TaskName
and -X- _ I-TaskName
long -X- _ I-TaskName
- -X- _ I-TaskName
form -X- _ I-TaskName
answers -X- _ I-TaskName
( -X- _ O
Labutov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
Such -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
questions -X- _ O
are -X- _ O
valuable -X- _ O
in -X- _ O
education -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
to -X- _ O
facilitate -X- _ O
complex -X- _ O
knowledge -X- _ O
acquisition -X- _ O
( -X- _ O
Lai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
nurture -X- _ O
reasoning -X- _ O
skills -X- _ O
( -X- _ O
Shapley -X- _ O
, -X- _ O
2000 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
in -X- _ O
other -X- _ O
applications -X- _ O
like -X- _ O
improving -X- _ O
search -X- _ O
engines -X- _ O
( -X- _ O
Han -X- _ O
Input -X- _ O
: -X- _ O
It -X- _ O
's -X- _ O
a -X- _ O
difficult -X- _ O
task -X- _ O
to -X- _ O
undertake -X- _ O
. -X- _ O
Teenagers -X- _ O
tend -X- _ O
to -X- _ O
identify -X- _ O
gangs -X- _ O
with -X- _ O
" -X- _ O
fitting -X- _ O
" -X- _ O
in -X- _ O
. -X- _ O
Peer -X- _ O
pressure -X- _ O
plays -X- _ O
a -X- _ O
large -X- _ O
part -X- _ O
in -X- _ O
it -X- _ O
and -X- _ O
sometimes -X- _ O
teenagers -X- _ O
have -X- _ O
problems -X- _ O
with -X- _ O
their -X- _ O
own -X- _ O
identity -X- _ O
being -X- _ O
part -X- _ O
of -X- _ O
a -X- _ O
gang -X- _ O
deals -X- _ O
with -X- _ O
those -X- _ O
issues -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
provides -X- _ O
a -X- _ O
little -X- _ O
bit -X- _ O
of -X- _ O
respect -X- _ O
on -X- _ O
the -X- _ O
street -X- _ O
... -X- _ O
Figure -X- _ O
1 -X- _ O
: -X- _ O
Open -X- _ O
- -X- _ O
ended -X- _ O
questions -X- _ O
generated -X- _ O
by -X- _ O
different -X- _ O
models -X- _ O
after -X- _ O
reading -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
BART -X- _ B-MethodName
decoded -X- _ O
with -X- _ O
nucleus -X- _ O
sampling -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
BART -X- _ B-MethodName
that -X- _ O
considers -X- _ O
different -X- _ O
question -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
our -X- _ O
type -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
generator -X- _ I-MethodName
TPLGEN -X- _ I-MethodName
, -X- _ O
that -X- _ O
predicts -X- _ O
focuses -X- _ O
and -X- _ O
operates -X- _ O
with -X- _ O
generated -X- _ O
templates -X- _ O
( -X- _ O
to -X- _ O
the -X- _ O
left -X- _ O
of -X- _ O
the -X- _ O
arrows -X- _ O
) -X- _ O
. -X- _ O
Questions -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
have -X- _ O
diverse -X- _ O
TYPEs -X- _ O
. -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
building -X- _ O
open -X- _ B-MethodName
- -X- _ I-MethodName
domain -X- _ I-MethodName
dialogue -X- _ I-MethodName
systems -X- _ I-MethodName
( -X- _ O
Shum -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).Significant -X- _ O
progress -X- _ O
has -X- _ O
been -X- _ O
made -X- _ O
in -X- _ O
generating -X- _ O
factoid -X- _ O
questions -X- _ O
( -X- _ O
Zhang -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019;Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b;Su -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
yet -X- _ O
new -X- _ O
challenges -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
addressed -X- _ O
for -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
questions -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
specifying -X- _ O
the -X- _ O
question -X- _ O
type -X- _ O
is -X- _ O
crucial -X- _ O
for -X- _ O
constructing -X- _ O
meaningful -X- _ O
questions -X- _ O
( -X- _ O
Graesser -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
. -X- _ O
Question -X- _ O
words -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
why -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
when -X- _ O
" -X- _ O
are -X- _ O
generally -X- _ O
seen -X- _ O
as -X- _ O
being -X- _ O
indicative -X- _ O
of -X- _ O
types -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
underspecify -X- _ O
the -X- _ O
conceptual -X- _ O
content -X- _ O
of -X- _ O
questions -X- _ O
( -X- _ O
Olney -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
Using -X- _ O
Figure -X- _ O
1 -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
different -X- _ O
question -X- _ O
words -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
both -X- _ O
" -X- _ O
how -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
what -X- _ O
" -X- _ O
, -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
inquiring -X- _ O
about -X- _ O
procedures -X- _ O
. -X- _ O
It -X- _ O
thus -X- _ O
calls -X- _ O
for -X- _ O
a -X- _ O
new -X- _ O
question -X- _ O
type -X- _ O
ontology -X- _ O
that -X- _ O
can -X- _ O
precisely -X- _ O
capture -X- _ O
the -X- _ O
conceptual -X- _ O
nature -X- _ O
of -X- _ O
questions -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
constructing -X- _ O
questions -X- _ O
from -X- _ O
a -X- _ O
text -X- _ O
with -X- _ O
multiple -X- _ O
sentences -X- _ O
needs -X- _ O
to -X- _ O
focus -X- _ O
on -X- _ O
its -X- _ O
central -X- _ O
concepts -X- _ O
or -X- _ O
phenomena -X- _ O
that -X- _ O
necessitate -X- _ O
extensive -X- _ O
descriptions -X- _ O
. -X- _ O
New -X- _ O
representations -X- _ O
are -X- _ O
needed -X- _ O
to -X- _ O
capture -X- _ O
such -X- _ O
content -X- _ O
as -X- _ O
question -X- _ O
focus(es -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
go -X- _ O
beyond -X- _ O
existing -X- _ O
methods -X- _ O
that -X- _ O
rely -X- _ O
on -X- _ O
entities -X- _ O
and -X- _ O
their -X- _ O
neighboring -X- _ O
words -X- _ O
( -X- _ O
Du -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
are -X- _ O
effective -X- _ O
for -X- _ O
generating -X- _ O
factoid -X- _ O
questions -X- _ O
. -X- _ O
Third -X- _ O
, -X- _ O
encouraging -X- _ O
the -X- _ O
diversity -X- _ O
of -X- _ O
generated -X- _ O
questions -X- _ O
( -X- _ O
Sultan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
is -X- _ O
less -X- _ O
explored -X- _ O
but -X- _ O
critical -X- _ O
for -X- _ O
real -X- _ O
world -X- _ O
applications -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
various -X- _ O
questions -X- _ O
should -X- _ O
be -X- _ O
proposed -X- _ O
to -X- _ O
gauge -X- _ O
how -X- _ O
well -X- _ O
students -X- _ O
grasp -X- _ O
the -X- _ O
knowledge -X- _ O
of -X- _ O
complex -X- _ O
subjects -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
challenges -X- _ O
of -X- _ O
generating -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
questions -X- _ O
from -X- _ O
input -X- _ O
consisting -X- _ O
of -X- _ O
multiple -X- _ O
sentences -X- _ O
. -X- _ O
We -X- _ O
first -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
question -X- _ O
type -X- _ O
ontology -X- _ O
, -X- _ O
drawn -X- _ O
upon -X- _ O
researches -X- _ O
in -X- _ O
cognitive -X- _ O
science -X- _ O
and -X- _ O
psychology -X- _ O
( -X- _ O
Graesser -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1992 -X- _ O
) -X- _ O
, -X- _ O
to -X- _ O
capture -X- _ O
deeper -X- _ O
levels -X- _ O
of -X- _ O
cognition -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
causal -X- _ B-TaskName
reasoning -X- _ I-TaskName
and -X- _ I-TaskName
judgments -X- _ I-TaskName
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
new -X- _ O
ontology -X- _ O
, -X- _ O
we -X- _ O
collect -X- _ O
and -X- _ O
annotate -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
4,959 -X- _ O
questions -X- _ O
to -X- _ O
benefit -X- _ O
research -X- _ O
in -X- _ O
both -X- _ O
question -X- _ O
generation -X- _ O
and -X- _ O
answering -X- _ O
. -X- _ O
1 -X- _ O
We -X- _ O
then -X- _ O
design -X- _ O
a -X- _ O
type -X- _ O
- -X- _ O
aware -X- _ O
framework -X- _ O
to -X- _ O
jointly -X- _ O
predict -X- _ O
question -X- _ O
focuses -X- _ O
( -X- _ O
what -X- _ O
to -X- _ O
ask -X- _ O
about -X- _ O
) -X- _ O
and -X- _ O
generate -X- _ O
questions -X- _ O
( -X- _ O
how -X- _ O
to -X- _ O
ask -X- _ O
it -X- _ O
) -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
pipeline -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
framework -X- _ O
is -X- _ O
built -X- _ O
on -X- _ O
large -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ B-MethodName
BART -X- _ I-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
uses -X- _ O
shared -X- _ O
representations -X- _ O
to -X- _ O
jointly -X- _ O
conduct -X- _ O
question -X- _ O
focus -X- _ O
prediction -X- _ O
and -X- _ O
question -X- _ O
generation -X- _ O
while -X- _ O
learning -X- _ O
taskspecific -X- _ O
knowledge -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
further -X- _ O
augmented -X- _ O
by -X- _ O
a -X- _ O
semantic -X- _ B-MethodName
graph -X- _ I-MethodName
that -X- _ O
leverages -X- _ O
both -X- _ O
semantic -X- _ O
roles -X- _ O
and -X- _ O
dependency -X- _ O
relations -X- _ O
, -X- _ O
facilitating -X- _ O
long -X- _ O
text -X- _ O
comprehension -X- _ O
to -X- _ O
pinpoint -X- _ O
salient -X- _ O
concepts -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
producing -X- _ O
various -X- _ O
types -X- _ O
of -X- _ O
questions -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
two -X- _ O
model -X- _ O
variants -X- _ O
that -X- _ O
use -X- _ O
templates -X- _ O
to -X- _ O
improve -X- _ O
controllability -X- _ O
and -X- _ O
generation -X- _ O
diversity -X- _ O
: -X- _ O
one -X- _ O
using -X- _ O
pre -X- _ O
- -X- _ O
identified -X- _ O
exemplars -X- _ O
, -X- _ O
the -X- _ O
other -X- _ O
employing -X- _ O
generated -X- _ O
templates -X- _ O
to -X- _ O
guide -X- _ O
question -X- _ B-TaskName
writing -X- _ I-TaskName
, -X- _ O
with -X- _ O
sample -X- _ O
outputs -X- _ O
displayed -X- _ O
in -X- _ O
Figure -X- _ O
1.For -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
collect -X- _ O
two -X- _ O
new -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
datasets -X- _ O
consisting -X- _ O
of -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
questions -X- _ O
with -X- _ O
answers -X- _ O
from -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
Yahoo -X- _ B-DatasetName
Answers -X- _ I-DatasetName
2 -X- _ I-DatasetName
L6 -X- _ I-DatasetName
dataset -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
popular -X- _ O
question -X- _ O
- -X- _ O
asking -X- _ O
communities -X- _ O
on -X- _ O
Reddit -X- _ B-DatasetName
3 -X- _ I-DatasetName
, -X- _ O
consisting -X- _ O
of -X- _ O
291 -X- _ O
K -X- _ O
and -X- _ O
720 -X- _ O
K -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pairs -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
existing -X- _ O
popular -X- _ O
QA -X- _ O
datasets -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
MS -X- _ B-DatasetName
MARCO -X- _ I-DatasetName
( -X- _ O
Bajaj -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
questions -X- _ O
in -X- _ O
our -X- _ O
datasets -X- _ O
ask -X- _ O
about -X- _ O
complex -X- _ O
phenomena -X- _ O
and -X- _ O
perplexing -X- _ O
social -X- _ O
issues -X- _ O
that -X- _ O
seek -X- _ O
solutions -X- _ O
expressed -X- _ O
in -X- _ O
a -X- _ O
long -X- _ O
form -X- _ O
. -X- _ O
Automatic -X- _ O
metrics -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
type -X- _ B-MethodName
- -X- _ I-MethodName
aware -X- _ I-MethodName
question -X- _ I-MethodName
generation -X- _ I-MethodName
model -X- _ O
outperforms -X- _ O
competitive -X- _ O
comparisons -X- _ O
, -X- _ O
highlighting -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
semantic -X- _ B-MethodName
graph -X- _ I-MethodName
- -X- _ I-MethodName
augmented -X- _ I-MethodName
representation -X- _ I-MethodName
and -X- _ I-MethodName
joint -X- _ I-MethodName
modeling -X- _ I-MethodName
of -X- _ O
focus -X- _ O
prediction -X- _ O
and -X- _ O
question -X- _ O
generation -X- _ O
. -X- _ O
Human -X- _ O
judges -X- _ O
also -X- _ O
confirm -X- _ O
that -X- _ O
questions -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
model -X- _ O
have -X- _ O
better -X- _ O
overall -X- _ O
quality -X- _ O
. -X- _ O
Adding -X- _ O
templates -X- _ B-MethodName
further -X- _ O
promotes -X- _ O
question -X- _ O
diversity -X- _ O
, -X- _ O
as -X- _ O
evaluated -X- _ O
by -X- _ O
both -X- _ O
automatic -X- _ O
evaluation -X- _ O
and -X- _ O
human -X- _ O
assessment -X- _ O
. -X- _ O
Question -X- _ B-TaskName
generation -X- _ I-TaskName
has -X- _ O
long -X- _ O
been -X- _ O
studied -X- _ O
to -X- _ O
reduce -X- _ O
human -X- _ O
efforts -X- _ O
in -X- _ O
constructing -X- _ O
questions -X- _ O
for -X- _ O
knowledge -X- _ O
learning -X- _ O
evaluation -X- _ O
( -X- _ O
Mitkov -X- _ O
and -X- _ O
Ha -X- _ O
, -X- _ O
2003;Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O
Early -X- _ O
work -X- _ O
relies -X- _ O
on -X- _ O
syntactic -X- _ B-MethodName
transformation -X- _ I-MethodName
to -X- _ O
convert -X- _ O
declarative -X- _ O
sentences -X- _ O
to -X- _ O
questions -X- _ O
( -X- _ O
Heilman -X- _ O
and -X- _ O
Smith -X- _ O
, -X- _ O
2010;Chali -X- _ O
and -X- _ O
Hasan -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
Recent -X- _ O
advancements -X- _ O
rely -X- _ O
on -X- _ O
sequence -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
sequence -X- _ O
models -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
question -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
sentence -X- _ O
or -X- _ O
paragraph -X- _ O
by -X- _ O
considering -X- _ O
the -X- _ O
focus -X- _ O
, -X- _ O
type -X- _ O
, -X- _ O
and -X- _ O
general -X- _ O
- -X- _ O
specific -X- _ O
relations -X- _ O
of -X- _ O
questions -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b;Krishna -X- _ O
and -X- _ O
Iyyer -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
question -X- _ O
likelihoods -X- _ O
and -X- _ O
rewards -X- _ O
are -X- _ O
designed -X- _ O
to -X- _ O
steer -X- _ O
them -X- _ O
toward -X- _ O
being -X- _ O
addressed -X- _ O
by -X- _ O
the -X- _ O
given -X- _ O
answers -X- _ O
( -X- _ O
Zhou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a;Zhang -X- _ O
and -X- _ O
Bansal -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Attempts -X- _ O
are -X- _ O
also -X- _ O
made -X- _ O
toward -X- _ O
creating -X- _ O
complex -X- _ O
questions -X- _ O
that -X- _ O
require -X- _ O
multi -X- _ B-TaskName
- -X- _ I-TaskName
hop -X- _ I-TaskName
reasoning -X- _ I-TaskName
over -X- _ O
the -X- _ O
given -X- _ O
text -X- _ O
, -X- _ O
and -X- _ O
graph -X- _ O
- -X- _ O
based -X- _ O
representations -X- _ O
have -X- _ O
been -X- _ O
an -X- _ O
enabling -X- _ O
tool -X- _ O
to -X- _ O
facilitate -X- _ O
the -X- _ O
access -X- _ O
to -X- _ O
both -X- _ O
entities -X- _ O
and -X- _ O
relations -X- _ O
( -X- _ O
Pan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Su -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
our -X- _ O
model -X- _ O
also -X- _ O
enhances -X- _ O
the -X- _ O
input -X- _ O
with -X- _ O
a -X- _ O
semantic -X- _ B-MethodName
graph -X- _ I-MethodName
, -X- _ O
it -X- _ O
boasts -X- _ O
a -X- _ O
richer -X- _ O
representation -X- _ O
by -X- _ O
including -X- _ O
both -X- _ O
dependency -X- _ O
and -X- _ O
semantic -X- _ O
relations -X- _ O
, -X- _ O
with -X- _ O
predicted -X- _ O
question -X- _ O
focuses -X- _ O
highlighted -X- _ O
via -X- _ O
extra -X- _ B-MethodName
node -X- _ I-MethodName
embeddings -X- _ I-MethodName
. -X- _ O
Moreover -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
separate -X- _ O
layer -X- _ O
of -X- _ O
cross -X- _ O
attentions -X- _ O
that -X- _ O
is -X- _ O
dedicated -X- _ O
to -X- _ O
the -X- _ O
semantic -X- _ O
graph -X- _ O
, -X- _ O
while -X- _ O
prior -X- _ O
work -X- _ O
uses -X- _ O
the -X- _ O
same -X- _ O
set -X- _ O
of -X- _ O
attentions -X- _ O
to -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
concatenated -X- _ O
text -X- _ O
and -X- _ O
graph -X- _ O
representations -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
data -X- _ O
- -X- _ O
driven -X- _ O
nature -X- _ O
of -X- _ O
question -X- _ O
generation -X- _ O
and -X- _ O
answering -X- _ O
tasks -X- _ O
, -X- _ O
recent -X- _ O
studies -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
availability -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
QA -X- _ O
datasets -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
MS -X- _ B-DatasetName
MARCO -X- _ I-DatasetName
( -X- _ O
Bajaj -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
HotpotQA -X- _ B-DatasetName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
DROP -X- _ B-DatasetName
( -X- _ O
Dua -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
inter -X- _ O
alia -X- _ O
. -X- _ O
These -X- _ O
corpora -X- _ O
mainly -X- _ O
contain -X- _ O
factoid -X- _ O
questions -X- _ O
, -X- _ O
while -X- _ O
our -X- _ O
newly -X- _ O
collected -X- _ O
datasets -X- _ O
are -X- _ O
not -X- _ O
only -X- _ O
larger -X- _ O
in -X- _ O
size -X- _ O
but -X- _ O
also -X- _ O
comprise -X- _ O
significantly -X- _ O
more -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
questions -X- _ O
for -X- _ O
querying -X- _ O
reasons -X- _ O
and -X- _ O
procedures -X- _ O
. -X- _ O
A -X- _ O
dataset -X- _ O
closer -X- _ O
to -X- _ O
ours -X- _ O
is -X- _ O
ELI5 -X- _ B-DatasetName
, -X- _ O
which -X- _ O
also -X- _ O
obtains -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
questionanswer -X- _ O
pairs -X- _ O
from -X- _ O
Reddit -X- _ B-DatasetName
, -X- _ O
while -X- _ O
one -X- _ O
of -X- _ O
our -X- _ O
datasets -X- _ O
includes -X- _ O
more -X- _ O
Reddit -X- _ O
communities -X- _ O
and -X- _ O
thus -X- _ O
covers -X- _ O
a -X- _ O
wider -X- _ O
range -X- _ O
of -X- _ O
topics -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
is -X- _ O
more -X- _ O
inline -X- _ O
with -X- _ O
generating -X- _ O
deeper -X- _ O
questions -X- _ O
with -X- _ O
responses -X- _ O
that -X- _ O
span -X- _ O
over -X- _ O
multiple -X- _ O
sentences -X- _ O
, -X- _ O
where -X- _ O
manually -X- _ O
constructed -X- _ O
templates -X- _ O
are -X- _ O
found -X- _ O
effective -X- _ O
( -X- _ O
Olney -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Labutov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
use -X- _ O
crowdsourcing -X- _ O
to -X- _ O
collect -X- _ O
question -X- _ O
templates -X- _ O
based -X- _ O
on -X- _ O
an -X- _ O
ontology -X- _ O
derived -X- _ O
from -X- _ O
Wikipedia -X- _ O
and -X- _ O
Freebase -X- _ O
topics -X- _ O
. -X- _ O
Different -X- _ O
from -X- _ O
the -X- _ O
topic -X- _ O
- -X- _ O
based -X- _ O
ontology -X- _ O
, -X- _ O
our -X- _ O
question -X- _ O
types -X- _ O
are -X- _ O
more -X- _ O
aligned -X- _ O
with -X- _ O
cognitive -X- _ O
levels -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
our -X- _ O
templates -X- _ O
are -X- _ O
automatically -X- _ O
learned -X- _ O
from -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Recent -X- _ O
work -X- _ O
Daumé -X- _ O
III -X- _ O
, -X- _ O
2018 -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
focuses -X- _ O
on -X- _ O
asking -X- _ O
clarification -X- _ O
questions -X- _ O
based -X- _ O
on -X- _ O
both -X- _ O
retrieval -X- _ O
and -X- _ O
generation -X- _ O
models -X- _ O
. -X- _ O
As -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
no -X- _ O
suitable -X- _ O
framework -X- _ O
for -X- _ O
diverse -X- _ O
types -X- _ O
of -X- _ O
questions -X- _ O
, -X- _ O
this -X- _ O
work -X- _ O
aims -X- _ O
to -X- _ O
fill -X- _ O
the -X- _ O
gap -X- _ O
by -X- _ O
introducing -X- _ O
type -X- _ O
- -X- _ O
aware -X- _ O
generation -X- _ O
models -X- _ O
which -X- _ O
optionally -X- _ O
leverage -X- _ O
question -X- _ O
templates -X- _ O
for -X- _ O
better -X- _ O
controllability -X- _ O
. -X- _ O
Generating -X- _ O
diverse -X- _ O
questions -X- _ O
is -X- _ O
much -X- _ O
less -X- _ O
studied -X- _ O
, -X- _ O
with -X- _ O
existing -X- _ O
approaches -X- _ O
mainly -X- _ O
focusing -X- _ O
on -X- _ B-MethodName
entity -X- _ I-MethodName
replacement -X- _ I-MethodName
( -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
sampling -X- _ B-MethodName
decoding -X- _ I-MethodName
( -X- _ O
Sultan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
post -X- _ B-MethodName
- -X- _ I-MethodName
filtering -X- _ I-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
produced -X- _ O
diversity -X- _ O
is -X- _ O
driven -X- _ O
by -X- _ O
word -X- _ O
choice -X- _ O
and -X- _ O
syntax -X- _ O
variation -X- _ O
, -X- _ O
with -X- _ O
little -X- _ O
ability -X- _ O
to -X- _ O
control -X- _ O
on -X- _ O
question -X- _ O
types -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
focus -X- _ O
of -X- _ O
this -X- _ O
work.3 -X- _ O
Data -X- _ O
Collection -X- _ O
and -X- _ O
Question -X- _ O
Type -X- _ O
Annotation -X- _ O
To -X- _ O
collect -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
questions -X- _ O
, -X- _ O
we -X- _ O
resort -X- _ O
to -X- _ O
online -X- _ O
forums -X- _ O
with -X- _ O
active -X- _ O
question -X- _ O
- -X- _ O
asking -X- _ O
discussions -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
we -X- _ O
gather -X- _ O
and -X- _ O
clean -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pairs -X- _ O
from -X- _ O
Reddit -X- _ O
and -X- _ O
Yahoo -X- _ O
Answers -X- _ O
, -X- _ O
to -X- _ O
train -X- _ O
generators -X- _ O
that -X- _ O
construct -X- _ O
questions -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
corresponding -X- _ O
answer -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
Question -X- _ O
Type -X- _ O
Description -X- _ O
( -X- _ O
asking -X- _ O
for -X- _ O
... -X- _ O
)VERIFICATION -X- _ O
the -X- _ O
truthfulness -X- _ O
of -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept -X- _ O
. -X- _ O
DISJUNCTIVE -X- _ O
the -X- _ O
true -X- _ O
one -X- _ O
given -X- _ O
multiple -X- _ O
events -X- _ O
or -X- _ O
concepts -X- _ O
, -X- _ O
where -X- _ O
comparison -X- _ O
among -X- _ O
options -X- _ O
is -X- _ O
not -X- _ O
needed -X- _ O
. -X- _ O
CONCEPT -X- _ O
a -X- _ O
definition -X- _ O
of -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept -X- _ O
. -X- _ O
EXTENT -X- _ O
the -X- _ O
extent -X- _ O
or -X- _ O
quantity -X- _ O
of -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept -X- _ O
. -X- _ O
EXAMPLE -X- _ O
example(s -X- _ O
) -X- _ O
or -X- _ O
instance(s -X- _ O
) -X- _ O
of -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept -X- _ O
. -X- _ O
COMPARISON -X- _ O
comparison -X- _ O
among -X- _ O
multiple -X- _ O
events -X- _ O
or -X- _ O
concepts -X- _ O
. -X- _ O
CAUSE -X- _ O
the -X- _ O
cause -X- _ O
or -X- _ O
reason -X- _ O
for -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept -X- _ O
. -X- _ O
CONSEQUENCE -X- _ O
the -X- _ O
consequences -X- _ O
or -X- _ O
results -X- _ O
of -X- _ O
an -X- _ O
event -X- _ O
. -X- _ O
PROCEDURAL -X- _ O
the -X- _ O
procedures -X- _ O
, -X- _ O
tools -X- _ O
, -X- _ O
or -X- _ O
methods -X- _ O
by -X- _ O
which -X- _ O
a -X- _ O
certain -X- _ O
outcome -X- _ O
is -X- _ O
achieved -X- _ O
. -X- _ O
JUDGMENTAL -X- _ O
the -X- _ O
opinions -X- _ O
of -X- _ O
the -X- _ O
answerer -X- _ O
's -X- _ O
own -X- _ O
. -X- _ O
We -X- _ O
choose -X- _ O
five -X- _ O
popular -X- _ O
Reddit -X- _ O
communities -X- _ O
: -X- _ O
r -X- _ O
/ -X- _ O
AskHistorians -X- _ O
, -X- _ O
r -X- _ O
/ -X- _ O
Ask -X- _ O
Politics -X- _ O
, -X- _ O
r -X- _ O
/ -X- _ O
askscience -X- _ O
, -X- _ O
r -X- _ O
/ -X- _ O
explainlikeimfive -X- _ O
, -X- _ O
and -X- _ O
r -X- _ O
/ -X- _ O
AskReddit -X- _ O
, -X- _ O
where -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
questions -X- _ O
are -X- _ O
actively -X- _ O
asked -X- _ O
. -X- _ O
The -X- _ O
original -X- _ O
posts -X- _ O
( -X- _ O
OPs -X- _ O
) -X- _ O
are -X- _ O
extracted -X- _ O
, -X- _ O
with -X- _ O
their -X- _ O
titles -X- _ O
becoming -X- _ O
questions -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
keep -X- _ O
the -X- _ O
best -X- _ O
answer -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
karma -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
upvotes -X- _ O
minus -X- _ O
downvotes -X- _ O
) -X- _ O
if -X- _ O
it -X- _ O
is -X- _ O
greater -X- _ O
than -X- _ O
1 -X- _ O
. -X- _ O
A -X- _ O
second -X- _ O
dataset -X- _ O
with -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pairs -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
Yahoo -X- _ B-DatasetName
Answers -X- _ I-DatasetName
L6 -X- _ I-DatasetName
corpus -X- _ O
4 -X- _ O
, -X- _ O
which -X- _ O
covers -X- _ O
a -X- _ O
broader -X- _ O
range -X- _ O
of -X- _ O
topics -X- _ O
than -X- _ O
the -X- _ O
Reddit -X- _ B-DatasetName
data -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
question -X- _ O
, -X- _ O
the -X- _ O
best -X- _ O
answer -X- _ O
is -X- _ O
rated -X- _ O
by -X- _ O
the -X- _ O
user -X- _ O
who -X- _ O
raises -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
Preprocessing -X- _ O
. -X- _ O
To -X- _ O
ensure -X- _ O
both -X- _ O
questions -X- _ O
and -X- _ O
answers -X- _ O
are -X- _ O
well -X- _ O
- -X- _ O
formed -X- _ O
, -X- _ O
human -X- _ O
inspection -X- _ O
is -X- _ O
conducted -X- _ O
in -X- _ O
multiple -X- _ O
iterations -X- _ O
to -X- _ O
design -X- _ O
rules -X- _ O
to -X- _ O
filter -X- _ O
out -X- _ O
improper -X- _ O
samples -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
we -X- _ O
discard -X- _ O
samples -X- _ O
whose -X- _ O
answers -X- _ O
have -X- _ O
less -X- _ O
than -X- _ O
15 -X- _ O
content -X- _ O
words -X- _ O
to -X- _ O
avoid -X- _ O
the -X- _ O
inclusion -X- _ O
of -X- _ O
factoid -X- _ O
question -X- _ O
. -X- _ O
More -X- _ O
details -X- _ O
are -X- _ O
provided -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
Ultimately -X- _ O
, -X- _ O
719,988 -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pairs -X- _ O
are -X- _ O
kept -X- _ O
for -X- _ O
Reddit -X- _ O
, -X- _ O
and -X- _ O
290,611 -X- _ O
for -X- _ O
Yahoo -X- _ O
. -X- _ O
Each -X- _ O
dataset -X- _ O
is -X- _ O
then -X- _ O
divided -X- _ O
into -X- _ O
train -X- _ O
, -X- _ O
validation -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
with -X- _ O
a -X- _ O
90%/5%/5 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
split -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
lengths -X- _ O
of -X- _ O
questions -X- _ O
and -X- _ O
answers -X- _ O
are -X- _ O
14.5 -X- _ O
and -X- _ O
117.8 -X- _ O
for -X- _ O
Reddit -X- _ O
, -X- _ O
and -X- _ O
12.2 -X- _ O
and -X- _ O
123.6 -X- _ O
for -X- _ O
Yahoo -X- _ O
. -X- _ O
Our -X- _ O
question -X- _ O
type -X- _ O
ontology -X- _ O
is -X- _ O
adopted -X- _ O
and -X- _ O
modified -X- _ O
from -X- _ O
Olney -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
18 -X- _ O
categories -X- _ O
are -X- _ O
originally -X- _ O
proposed -X- _ O
for -X- _ O
knowledge -X- _ O
learning -X- _ O
as -X- _ O
- -X- _ O
sessment -X- _ O
. -X- _ O
We -X- _ O
recruited -X- _ O
6 -X- _ O
native -X- _ O
English -X- _ O
speakers -X- _ O
for -X- _ O
three -X- _ O
rounds -X- _ O
of -X- _ O
question -X- _ O
type -X- _ O
annotation -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
the -X- _ O
annotators -X- _ O
' -X- _ O
feedback -X- _ O
after -X- _ O
each -X- _ O
round -X- _ O
, -X- _ O
we -X- _ O
refine -X- _ O
the -X- _ O
definitions -X- _ O
, -X- _ O
merge -X- _ O
ambiguous -X- _ O
types -X- _ O
, -X- _ O
and -X- _ O
delete -X- _ O
inapplicable -X- _ O
categories -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
an -X- _ O
initial -X- _ O
EXPECTATION -X- _ O
type -X- _ O
is -X- _ O
merged -X- _ O
into -X- _ O
CAUSE -X- _ O
due -X- _ O
to -X- _ O
their -X- _ O
similarities -X- _ O
in -X- _ O
seeking -X- _ O
causality -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
10 -X- _ O
types -X- _ O
are -X- _ O
preserved -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
, -X- _ O
our -X- _ O
ontology -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
better -X- _ O
capture -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
questions -X- _ O
than -X- _ O
question -X- _ O
words -X- _ O
. -X- _ O
Annotating -X- _ O
Questions -X- _ O
with -X- _ O
Types -X- _ O
. -X- _ O
After -X- _ O
the -X- _ O
annotation -X- _ O
guideline -X- _ O
is -X- _ O
finalized -X- _ O
, -X- _ O
we -X- _ O
ask -X- _ O
the -X- _ O
same -X- _ O
set -X- _ O
of -X- _ O
annotators -X- _ O
to -X- _ O
label -X- _ O
5,000 -X- _ O
( -X- _ O
2 -X- _ O
× -X- _ O
2,500 -X- _ O
) -X- _ O
randomly -X- _ O
sampled -X- _ O
questions -X- _ O
from -X- _ O
both -X- _ O
Reddit -X- _ O
and -X- _ O
Yahoo -X- _ O
's -X- _ O
training -X- _ O
sets -X- _ O
. -X- _ O
Each -X- _ O
question -X- _ O
is -X- _ O
labeled -X- _ O
by -X- _ O
two -X- _ O
annotators -X- _ O
, -X- _ O
with -X- _ O
disagreements -X- _ O
resolved -X- _ O
through -X- _ O
discussions -X- _ O
. -X- _ O
After -X- _ O
removing -X- _ O
samples -X- _ O
without -X- _ O
consensus -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
dataset -X- _ O
consists -X- _ O
of -X- _ O
4 -X- _ O
, -X- _ O
959 -X- _ O
questions -X- _ O
. -X- _ O
EXAMPLE -X- _ O
questions -X- _ O
are -X- _ O
most -X- _ O
prevalent -X- _ O
, -X- _ O
comprising -X- _ O
23.4 -X- _ O
% -X- _ O
of -X- _ O
samples -X- _ O
, -X- _ O
while -X- _ O
only -X- _ O
2.6 -X- _ O
% -X- _ O
are -X- _ O
CONSEQUENCE -X- _ O
questions -X- _ O
. -X- _ O
A -X- _ O
Krippendorff -X- _ O
's -X- _ O
α -X- _ O
of -X- _ O
0.67 -X- _ O
is -X- _ O
obtained -X- _ O
for -X- _ O
all -X- _ O
samples -X- _ O
, -X- _ O
indicating -X- _ O
a -X- _ O
reasonable -X- _ O
agreement -X- _ O
level -X- _ O
. -X- _ O
The -X- _ O
annotation -X- _ O
guideline -X- _ O
and -X- _ O
examples -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
type -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
12 -X- _ O
in -X- _ O
Appendix -X- _ O
A.Training -X- _ O
Question -X- _ O
Type -X- _ O
Classifiers -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
type -X- _ O
- -X- _ O
aware -X- _ O
question -X- _ O
generation -X- _ O
model -X- _ O
requires -X- _ O
a -X- _ O
specified -X- _ O
type -X- _ O
as -X- _ O
input -X- _ O
, -X- _ O
here -X- _ O
we -X- _ O
describe -X- _ O
how -X- _ O
to -X- _ O
build -X- _ O
two -X- _ O
question -X- _ O
type -X- _ O
classifiers -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
γ -X- _ O
q -X- _ O
, -X- _ O
that -X- _ O
labels -X- _ O
a -X- _ O
type -X- _ O
by -X- _ O
reading -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
provide -X- _ O
question -X- _ O
type -X- _ O
labels -X- _ O
during -X- _ O
training -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
γ -X- _ O
a -X- _ O
, -X- _ O
that -X- _ O
predicts -X- _ O
a -X- _ O
type -X- _ O
for -X- _ O
use -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
answer -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
is -X- _ O
used -X- _ O
during -X- _ O
test -X- _ O
. -X- _ O
Both -X- _ O
classifiers -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
prediction -X- _ O
layer -X- _ O
is -X- _ O
built -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
BOS -X- _ O
] -X- _ O
token -X- _ O
to -X- _ O
output -X- _ O
question -X- _ O
type -X- _ O
probabilities -X- _ O
. -X- _ O
γ -X- _ O
q -X- _ O
achieves -X- _ O
a -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
score -X- _ O
of -X- _ O
0.80 -X- _ B-MetricValue
on -X- _ O
a -X- _ O
reserved -X- _ O
test -X- _ O
set -X- _ O
, -X- _ O
with -X- _ O
data -X- _ O
splits -X- _ O
detailed -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O
To -X- _ O
train -X- _ O
γ -X- _ O
a -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
annotated -X- _ O
questions -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
γ -X- _ O
q -X- _ O
on -X- _ O
unlabeled -X- _ O
questions -X- _ O
in -X- _ O
Reddit -X- _ O
and -X- _ O
Yahoo -X- _ O
and -X- _ O
include -X- _ O
samples -X- _ O
whose -X- _ O
type -X- _ O
prediction -X- _ B-MetricName
confidence -X- _ I-MetricName
score -X- _ I-MetricName
is -X- _ O
above -X- _ O
0.9 -X- _ B-MetricValue
. -X- _ O
We -X- _ O
train -X- _ O
one -X- _ O
γ -X- _ O
a -X- _ O
for -X- _ O
each -X- _ O
dataset -X- _ O
. -X- _ O
γ -X- _ O
a -X- _ O
obtains -X- _ O
macro -X- _ B-MetricName
F1 -X- _ I-MetricName
scores -X- _ O
of -X- _ O
0.48 -X- _ B-MetricValue
and -X- _ O
0.46 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
same -X- _ O
reserved -X- _ O
test -X- _ O
set -X- _ O
over -X- _ O
all -X- _ O
types -X- _ O
after -X- _ O
training -X- _ O
on -X- _ O
Yahoo -X- _ O
and -X- _ O
Reddit -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
After -X- _ O
running -X- _ O
γ -X- _ O
q -X- _ O
on -X- _ O
both -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
Reddit -X- _ O
has -X- _ O
significantly -X- _ O
more -X- _ O
EXAMPLE -X- _ O
questions -X- _ O
( -X- _ O
43.8 -X- _ O
% -X- _ O
of -X- _ O
all -X- _ O
samples -X- _ O
) -X- _ O
. -X- _ O
Yahoo -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
more -X- _ O
balanced -X- _ O
, -X- _ O
with -X- _ O
PROCEDURAL -X- _ O
questions -X- _ O
being -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
type -X- _ O
( -X- _ O
19.9 -X- _ O
% -X- _ O
of -X- _ O
all -X- _ O
samples -X- _ O
) -X- _ O
. -X- _ O
Distri- -X- _ O
butions -X- _ O
of -X- _ O
question -X- _ O
types -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
in -X- _ O
Appendix -X- _ O
B.4 -X- _ O
Type -X- _ B-TaskName
- -X- _ I-TaskName
aware -X- _ I-TaskName
Open -X- _ I-TaskName
- -X- _ I-TaskName
ended -X- _ I-TaskName
Question -X- _ I-TaskName
GenerationIn -X- _ I-TaskName
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
our -X- _ O
type -X- _ B-TaskName
- -X- _ I-TaskName
aware -X- _ I-TaskName
question -X- _ I-TaskName
generation -X- _ I-TaskName
framework -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
takes -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
sentence -X- _ O
text -X- _ O
and -X- _ O
a -X- _ O
predicted -X- _ O
question -X- _ O
type -X- _ O
. -X- _ O
Built -X- _ O
on -X- _ O
shared -X- _ O
input -X- _ O
representations -X- _ O
, -X- _ O
it -X- _ O
first -X- _ O
detects -X- _ O
question -X- _ O
focuses -X- _ O
from -X- _ O
a -X- _ O
semantic -X- _ O
graph -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
generates -X- _ O
the -X- _ O
question -X- _ O
( -X- _ O
§ -X- _ O
4.1).We -X- _ O
also -X- _ O
propose -X- _ O
two -X- _ O
model -X- _ O
variants -X- _ O
that -X- _ O
consider -X- _ O
automatically -X- _ O
extracted -X- _ O
template -X- _ O
exemplars -X- _ O
or -X- _ O
generated -X- _ O
templates -X- _ O
to -X- _ O
achieve -X- _ O
controllability -X- _ O
( -X- _ O
§ -X- _ O
4.2 -X- _ O
) -X- _ O
, -X- _ O
enabling -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
diverse -X- _ O
questions -X- _ O
. -X- _ O
Our -X- _ O
generator -X- _ O
is -X- _ O
built -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
facilitate -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
salient -X- _ O
content -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
focuses -X- _ O
) -X- _ O
to -X- _ O
raise -X- _ O
questions -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
augment -X- _ O
the -X- _ O
encoder -X- _ O
with -X- _ O
a -X- _ O
semantic -X- _ O
graph -X- _ O
that -X- _ O
consists -X- _ O
of -X- _ O
both -X- _ O
dependency -X- _ O
relations -X- _ O
and -X- _ O
semantic -X- _ O
roles -X- _ O
, -X- _ O
capturing -X- _ O
semantic -X- _ O
relations -X- _ O
over -X- _ O
different -X- _ O
scopes -X- _ O
with -X- _ O
varying -X- _ O
granularities -X- _ O
. -X- _ O
Question -X- _ O
focuses -X- _ O
are -X- _ O
first -X- _ O
detected -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
semantic -X- _ B-MethodName
graph -X- _ I-MethodName
, -X- _ O
which -X- _ O
then -X- _ O
guide -X- _ O
question -X- _ O
generation -X- _ O
via -X- _ O
cross -X- _ O
- -X- _ O
attentions -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
Although -X- _ O
the -X- _ O
joint -X- _ O
modeling -X- _ O
of -X- _ O
focus -X- _ B-TaskName
prediction -X- _ I-TaskName
and -X- _ I-TaskName
question -X- _ I-TaskName
generation -X- _ I-TaskName
has -X- _ O
been -X- _ O
studied -X- _ O
before -X- _ O
, -X- _ O
our -X- _ O
design -X- _ O
differs -X- _ O
by -X- _ O
using -X- _ O
shared -X- _ O
representations -X- _ O
consisting -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
and -X- _ O
semantic -X- _ O
graph -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
focuses -X- _ O
are -X- _ O
included -X- _ O
through -X- _ O
gating -X- _ O
mechanisms -X- _ O
, -X- _ O
whereas -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
e.g. -X- _ O
Pan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
simply -X- _ O
employs -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
learning -X- _ O
. -X- _ O
Below -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
describe -X- _ O
constructing -X- _ O
the -X- _ O
semantic -X- _ B-MethodName
graph -X- _ I-MethodName
- -X- _ I-MethodName
augmented -X- _ I-MethodName
encoder -X- _ I-MethodName
, -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
joint -X- _ O
modeling -X- _ O
of -X- _ O
two -X- _ O
tasks -X- _ O
. -X- _ O
Improving -X- _ O
Long -X- _ O
Text -X- _ O
Comprehension -X- _ O
with -X- _ O
Semantic -X- _ B-MethodName
Graph -X- _ I-MethodName
. -X- _ O
To -X- _ O
construct -X- _ O
the -X- _ O
semantic -X- _ B-MethodName
graph -X- _ I-MethodName
, -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
, -X- _ O
we -X- _ O
start -X- _ O
with -X- _ O
obtaining -X- _ O
its -X- _ O
dependency -X- _ O
tree -X- _ O
using -X- _ O
Stanford -X- _ B-MethodName
CoreNLP -X- _ I-MethodName
( -X- _ O
Manning -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
better -X- _ O
highlight -X- _ O
core -X- _ O
concepts -X- _ O
, -X- _ O
we -X- _ O
discard -X- _ O
less -X- _ O
important -X- _ O
relations -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
auxiliaries -X- _ O
. -X- _ O
The -X- _ O
full -X- _ O
list -X- _ O
is -X- _ O
included -X- _ O
in -X- _ O
Appendix -X- _ O
C. -X- _ O
Since -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
detect -X- _ O
central -X- _ O
concepts -X- _ O
that -X- _ O
are -X- _ O
well -X- _ O
connected -X- _ O
with -X- _ O
many -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
remove -X- _ O
relations -X- _ O
on -X- _ O
the -X- _ O
edges -X- _ O
to -X- _ O
minimize -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
to -X- _ O
learn -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
as -X- _ O
semantic -X- _ O
roles -X- _ O
can -X- _ O
indicate -X- _ O
main -X- _ O
entities -X- _ O
( -X- _ O
Mannem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
semantic -X- _ O
roles -X- _ O
and -X- _ O
their -X- _ O
relations -X- _ O
with -X- _ B-MethodName
AllenNLP -X- _ I-MethodName
( -X- _ O
Shi -X- _ O
and -X- _ O
Lin -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
merge -X- _ O
the -X- _ O
two -X- _ O
sources -X- _ O
of -X- _ O
information -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
an -X- _ O
edge -X- _ O
in -X- _ O
the -X- _ O
dependency -X- _ O
tree -X- _ O
to -X- _ O
connect -X- _ O
the -X- _ O
head -X- _ O
word -X- _ O
of -X- _ O
the -X- _ O
predicate -X- _ O
and -X- _ O
the -X- _ O
head -X- _ O
word -X- _ O
of -X- _ O
each -X- _ O
semantic -X- _ O
role -X- _ O
. -X- _ O
To -X- _ O
build -X- _ O
a -X- _ O
connected -X- _ O
graph -X- _ O
from -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
sentence -X- _ O
input -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
an -X- _ O
edge -X- _ O
between -X- _ O
each -X- _ O
sentence -X- _ O
's -X- _ O
last -X- _ O
token -X- _ O
and -X- _ O
the -X- _ O
next -X- _ O
sentence -X- _ O
's -X- _ O
first -X- _ O
token -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
merge -X- _ O
nodes -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
surface -X- _ O
forms -X- _ O
or -X- _ O
with -X- _ O
corefered -X- _ O
mentions -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
that -X- _ O
both -X- _ O
dependency -X- _ O
and -X- _ O
semantic -X- _ O
relations -X- _ O
are -X- _ O
encoded -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
graph -X- _ O
for -X- _ O
question -X- _ O
generation -X- _ O
, -X- _ O
and -X- _ O
with -X- _ O
enhanced -X- _ O
connectivity -X- _ O
of -X- _ O
the -X- _ O
constructed -X- _ O
graph -X- _ O
, -X- _ O
our -X- _ O
design -X- _ O
can -X- _ O
better -X- _ O
signal -X- _ O
content -X- _ O
salience -X- _ O
. -X- _ O
Joint -X- _ B-MethodName
Modeling -X- _ I-MethodName
with -X- _ O
Cross -X- _ O
- -X- _ O
attentions -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
predicted -X- _ O
question -X- _ O
type -X- _ O
t -X- _ O
and -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
sentence -X- _ O
textx -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
n -X- _ O
} -X- _ O
, -X- _ O
the -X- _ B-MethodName
BART -X- _ I-MethodName
encoder -X- _ O
builds -X- _ O
the -X- _ O
contextual -X- _ O
representation -X- _ O
H -X- _ O
= -X- _ O
{ -X- _ O
h -X- _ O
0 -X- _ O
, -X- _ O
h -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
h -X- _ O
n -X- _ O
} -X- _ O
at -X- _ O
the -X- _ O
last -X- _ O
layer -X- _ O
, -X- _ O
where -X- _ O
h -X- _ O
0 -X- _ O
is -X- _ O
for -X- _ O
t. -X- _ O
To -X- _ O
encode -X- _ O
the -X- _ O
semantic -X- _ O
graph -X- _ O
, -X- _ O
we -X- _ O
initialize -X- _ O
the -X- _ O
node -X- _ O
representation -X- _ O
for -X- _ O
node -X- _ O
v -X- _ O
i -X- _ O
by -X- _ O
taking -X- _ O
the -X- _ O
average -X- _ O
contextual -X- _ O
representations -X- _ O
of -X- _ O
its -X- _ O
tokens -X- _ O
and -X- _ O
appending -X- _ O
four -X- _ O
bits -X- _ O
encoding -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
nodes -X- _ O
( -X- _ O
capped -X- _ O
at -X- _ O
10 -X- _ O
) -X- _ O
that -X- _ O
are -X- _ O
merged -X- _ O
into -X- _ O
v -X- _ O
i -X- _ O
, -X- _ O
to -X- _ O
add -X- _ O
frequency -X- _ O
information -X- _ O
. -X- _ O
This -X- _ O
step -X- _ O
yields -X- _ O
new -X- _ O
node -X- _ O
representations -X- _ O
v -X- _ O
( -X- _ O
0 -X- _ O
) -X- _ O
i -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
apply -X- _ O
graph -X- _ B-MethodName
attention -X- _ I-MethodName
networks -X- _ I-MethodName
( -X- _ O
GATs -X- _ O
) -X- _ O
( -X- _ O
Veličković -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
of -X- _ O
L -X- _ O
layers -X- _ O
to -X- _ O
update -X- _ O
the -X- _ O
representations -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
v -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
i -X- _ O
= -X- _ O
j∈Ni -X- _ O
a -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
W -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
v -X- _ O
( -X- _ O
l−1 -X- _ O
) -X- _ O
j -X- _ O
( -X- _ O
1)where -X- _ O
W -X- _ O
( -X- _ O
l -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
learnable -X- _ O
parameter -X- _ O
for -X- _ O
the -X- _ O
l -X- _ O
- -X- _ O
th -X- _ O
layer -X- _ O
, -X- _ O
and -X- _ O
N -X- _ O
i -X- _ O
denotes -X- _ O
the -X- _ O
neighbors -X- _ O
of -X- _ O
v -X- _ O
i -X- _ O
. -X- _ O
The -X- _ O
attention -X- _ O
score -X- _ O
a -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
is -X- _ O
calculated -X- _ O
as -X- _ O
in -X- _ O
GATs -X- _ B-MethodName
. -X- _ O
We -X- _ O
use -X- _ O
L -X- _ O
= -X- _ O
2 -X- _ O
for -X- _ O
experiments -X- _ O
. -X- _ O
To -X- _ O
predict -X- _ O
focuses -X- _ O
, -X- _ O
the -X- _ O
final -X- _ O
node -X- _ O
representation -X- _ O
v -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
i -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
following -X- _ O
feedforward -X- _ B-MethodName
network -X- _ I-MethodName
, -X- _ O
yielding -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
v -X- _ O
i -X- _ O
being -X- _ O
a -X- _ O
focus -X- _ O
as -X- _ O
:p -X- _ O
f -X- _ O
ocus -X- _ O
( -X- _ O
v -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
) -X- _ O
= -X- _ O
σ(W -X- _ O
1 -X- _ O
tanh(W -X- _ O
2 -X- _ O
v -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
i -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
2)where -X- _ O
W -X- _ O
1 -X- _ O
and -X- _ O
W -X- _ O
2 -X- _ O
are -X- _ O
learnable -X- _ O
parameters -X- _ O
. -X- _ O
Bias -X- _ O
terms -X- _ O
are -X- _ O
omitted -X- _ O
for -X- _ O
simplicity -X- _ O
. -X- _ O
We -X- _ O
construct -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
labels -X- _ O
by -X- _ O
treating -X- _ O
a -X- _ O
node -X- _ O
as -X- _ O
a -X- _ O
focus -X- _ O
if -X- _ O
it -X- _ O
contains -X- _ O
words -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
To -X- _ O
generate -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
gating -X- _ O
mechanism -X- _ O
to -X- _ O
inform -X- _ O
the -X- _ O
focus -X- _ O
prediction -X- _ O
results -X- _ O
, -X- _ O
where -X- _ O
new -X- _ O
node -X- _ O
representations -X- _ O
after -X- _ O
being -X- _ O
weighted -X- _ O
by -X- _ O
the -X- _ O
focus -X- _ O
probability -X- _ O
are -X- _ O
: -X- _ O
v -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
i -X- _ O
= -X- _ O
g -X- _ O
i -X- _ O
v -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
i -X- _ O
g -X- _ O
i -X- _ O
= -X- _ O
p -X- _ O
f -X- _ O
ocus -X- _ O
( -X- _ O
v -X- _ O
i -X- _ O
= -X- _ O
1)(3)Our -X- _ O
model -X- _ O
benefits -X- _ O
from -X- _ O
both -X- _ O
large -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
hybrid -X- _ O
semantic -X- _ O
graphs -X- _ O
by -X- _ O
adding -X- _ O
a -X- _ O
separate -X- _ O
cross -X- _ O
attention -X- _ O
for -X- _ O
node -X- _ O
presentations -X- _ O
in -X- _ O
each -X- _ O
BART -X- _ B-MethodName
decoder -X- _ O
layer -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
design -X- _ O
separate -X- _ O
cross -X- _ O
attentions -X- _ O
to -X- _ O
attend -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
BART -X- _ B-MethodName
encoder -X- _ O
, -X- _ O
yielding -X- _ O
z -X- _ O
e -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
node -X- _ O
representations -X- _ O
V -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
, -X- _ O
producing -X- _ O
z -X- _ O
v -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
formulated -X- _ O
as -X- _ O
: -X- _ O
z -X- _ O
e -X- _ O
= -X- _ O
LN(z -X- _ O
s -X- _ O
+ -X- _ O
Attn(z -X- _ O
s -X- _ O
, -X- _ O
H -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
4)z -X- _ O
v -X- _ O
= -X- _ O
LN(z -X- _ O
e -X- _ O
+ -X- _ O
Attn(z -X- _ O
e -X- _ O
, -X- _ O
V -X- _ O
( -X- _ O
L -X- _ O
) -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
5 -X- _ O
) -X- _ O
z -X- _ O
= -X- _ O
LN(z -X- _ O
v -X- _ O
+ -X- _ O
FFN(z -X- _ O
v -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
6)where -X- _ O
z -X- _ O
s -X- _ O
denotes -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
self -X- _ O
attentions -X- _ O
for -X- _ O
the -X- _ O
current -X- _ O
layer -X- _ O
, -X- _ O
and -X- _ O
z -X- _ O
is -X- _ O
the -X- _ O
output -X- _ O
for -X- _ O
the -X- _ O
layer -X- _ O
. -X- _ O
Attn(• -X- _ O
, -X- _ O
• -X- _ O
) -X- _ O
denotes -X- _ O
the -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
operation -X- _ O
as -X- _ O
in -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
FFN(• -X- _ O
) -X- _ O
a -X- _ O
feedforward -X- _ O
layer -X- _ O
, -X- _ O
and -X- _ O
LN(• -X- _ O
) -X- _ O
is -X- _ O
layer -X- _ O
normalization -X- _ O
. -X- _ O
Our -X- _ O
final -X- _ O
training -X- _ O
objective -X- _ O
accounts -X- _ O
for -X- _ O
both -X- _ O
focus -X- _ O
prediction -X- _ O
and -X- _ O
question -X- _ O
generation -X- _ O
objectives -X- _ O
with -X- _ O
equal -X- _ O
weights -X- _ O
. -X- _ O
An -X- _ O
important -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
to -X- _ O
enable -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
questions -X- _ O
of -X- _ O
diverse -X- _ O
types -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
simply -X- _ O
adding -X- _ O
question -X- _ O
type -X- _ O
as -X- _ O
input -X- _ O
is -X- _ O
insufficient -X- _ O
( -X- _ O
discussed -X- _ O
in -X- _ O
§ -X- _ O
5 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
thus -X- _ O
propose -X- _ O
to -X- _ O
leverage -X- _ O
question -X- _ O
templates -X- _ O
to -X- _ O
gain -X- _ O
stronger -X- _ O
controllability -X- _ O
. -X- _ O
Below -X- _ O
we -X- _ O
first -X- _ O
present -X- _ O
how -X- _ O
to -X- _ O
automatically -X- _ O
extract -X- _ O
templates -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
introduce -X- _ O
two -X- _ O
model -X- _ O
variants -X- _ O
that -X- _ O
are -X- _ O
built -X- _ O
on -X- _ O
the -X- _ O
JOINTGEN -X- _ B-MethodName
framework -X- _ O
: -X- _ O
EXPLGEN -X- _ B-MethodName
uses -X- _ O
exemplar -X- _ O
templates -X- _ O
to -X- _ O
guide -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
generate -X- _ O
questions -X- _ O
of -X- _ O
selected -X- _ O
types -X- _ O
, -X- _ O
and -X- _ O
TPLGEN -X- _ B-MethodName
adds -X- _ O
an -X- _ O
extra -X- _ O
step -X- _ O
to -X- _ O
first -X- _ O
generate -X- _ O
type -X- _ O
- -X- _ O
specific -X- _ O
templates -X- _ O
. -X- _ O
Template -X- _ O
Extraction -X- _ O
. -X- _ O
While -X- _ O
collecting -X- _ O
templates -X- _ O
specific -X- _ O
to -X- _ O
a -X- _ O
given -X- _ O
type -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
ensure -X- _ O
they -X- _ O
remain -X- _ O
topic -X- _ O
- -X- _ O
independent -X- _ O
to -X- _ O
be -X- _ O
generalizable -X- _ O
to -X- _ O
different -X- _ O
domains -X- _ O
. -X- _ O
To -X- _ O
this -X- _ O
end -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
a -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
with -X- _ O
a -X- _ O
template -X- _ O
token -X- _ O
that -X- _ O
indicates -X- _ O
its -X- _ O
syntax -X- _ O
function -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
[ -X- _ O
V -X- _ O
] -X- _ O
for -X- _ O
a -X- _ O
verb -X- _ O
, -X- _ O
if -X- _ O
it -X- _ O
appears -X- _ O
in -X- _ O
the -X- _ O
answer -X- _ O
after -X- _ O
lemmatization -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
consider -X- _ O
topically -X- _ O
related -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
questions -X- _ O
, -X- _ O
by -X- _ O
calculating -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
semantic -X- _ O
similarities -X- _ O
based -X- _ O
on -X- _ O
Numberbatch -X- _ B-MethodName
word -X- _ I-MethodName
embeddings -X- _ I-MethodName
( -X- _ O
Speer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
found -X- _ O
to -X- _ O
perform -X- _ O
better -X- _ O
on -X- _ O
our -X- _ O
datasets -X- _ O
than -X- _ O
other -X- _ O
embeddings -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
with -X- _ O
the -X- _ O
template -X- _ O
token -X- _ O
. -X- _ O
This -X- _ O
process -X- _ O
is -X- _ O
repeated -X- _ O
until -X- _ O
80 -X- _ O
% -X- _ O
of -X- _ O
content -X- _ O
words -X- _ O
in -X- _ O
questions -X- _ O
are -X- _ O
replaced -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
noun -X- _ O
phrase -X- _ O
, -X- _ O
adjective -X- _ O
phrase -X- _ O
, -X- _ O
and -X- _ O
adverb -X- _ O
phrase -X- _ O
, -X- _ O
if -X- _ O
its -X- _ O
head -X- _ O
word -X- _ O
has -X- _ O
been -X- _ O
replaced -X- _ O
, -X- _ O
the -X- _ O
whole -X- _ O
phrase -X- _ O
is -X- _ O
transformed -X- _ O
into -X- _ O
a -X- _ O
phrase -X- _ O
type -X- _ O
token -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
a -X- _ O
question -X- _ O
" -X- _ O
What -X- _ O
are -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
global -X- _ O
warming -X- _ O
and -X- _ O
climate -X- _ O
change -X- _ O
? -X- _ O
" -X- _ O
becomes -X- _ O
" -X- _ O
What -X- _ O
are -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
[ -X- _ O
NP -X- _ O
] -X- _ O
and -X- _ O
[ -X- _ O
NP]?"Exemplars -X- _ B-MethodName
for -X- _ I-MethodName
Guidance -X- _ I-MethodName
( -X- _ I-MethodName
EXPLGEN -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O
Our -X- _ O
first -X- _ O
model -X- _ O
variant -X- _ O
considers -X- _ O
adding -X- _ O
a -X- _ O
template -X- _ O
exemplar -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
type -X- _ O
as -X- _ O
additional -X- _ O
input -X- _ O
, -X- _ O
which -X- _ O
provide -X- _ O
more -X- _ O
specific -X- _ O
information -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
generated -X- _ O
questions -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
shows -X- _ O
one -X- _ O
such -X- _ O
example -X- _ O
. -X- _ O
To -X- _ O
identify -X- _ O
exemplars -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
templates -X- _ O
with -X- _ O
frequencies -X- _ O
above -X- _ O
20 -X- _ O
on -X- _ O
Yahoo -X- _ O
and -X- _ O
50 -X- _ O
on -X- _ O
Reddit -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
manually -X- _ O
inspect -X- _ O
these -X- _ O
templates -X- _ O
and -X- _ O
remove -X- _ O
the -X- _ O
ones -X- _ O
with -X- _ O
topic -X- _ O
- -X- _ O
specific -X- _ O
words -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
66 -X- _ O
exemplars -X- _ O
for -X- _ O
all -X- _ O
types -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
10 -X- _ O
in -X- _ O
Appendix -X- _ O
D.During -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
choose -X- _ O
the -X- _ O
exemplar -X- _ O
that -X- _ O
has -X- _ O
the -X- _ O
lowest -X- _ O
edit -X- _ O
distance -X- _ O
with -X- _ O
the -X- _ O
question -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
used -X- _ O
for -X- _ O
training -X- _ O
an -X- _ O
exemplar -X- _ O
selector -X- _ O
based -X- _ O
on -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
During -X- _ O
testing -X- _ O
, -X- _ O
the -X- _ O
exemplar -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
selector -X- _ O
score -X- _ O
is -X- _ O
used -X- _ O
. -X- _ O
The -X- _ O
accuracy -X- _ O
of -X- _ O
the -X- _ O
exemplar -X- _ O
selector -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
type -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
11 -X- _ O
in -X- _ O
Appendix -X- _ O
D. -X- _ O
We -X- _ O
further -X- _ O
propose -X- _ O
another -X- _ O
model -X- _ O
variant -X- _ O
where -X- _ O
we -X- _ O
generate -X- _ O
a -X- _ O
new -X- _ O
template -X- _ O
and -X- _ O
feed -X- _ O
it -X- _ O
( -X- _ O
instead -X- _ O
of -X- _ O
an -X- _ O
exemplar -X- _ O
template -X- _ O
as -X- _ O
in -X- _ O
EXPLGEN -X- _ O
) -X- _ O
as -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
generation -X- _ O
input -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
reuse -X- _ O
EXPLGEN -X- _ B-MethodName
to -X- _ O
learn -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
target -X- _ O
template -X- _ O
, -X- _ O
as -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
template -X- _ O
extraction -X- _ O
procedure -X- _ O
. -X- _ O
During -X- _ O
question -X- _ O
realization -X- _ O
, -X- _ O
TPLGEN -X- _ B-MethodName
uses -X- _ O
a -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
generator -X- _ I-MethodName
that -X- _ O
takes -X- _ O
as -X- _ O
input -X- _ O
the -X- _ O
question -X- _ O
type -X- _ O
, -X- _ O
the -X- _ O
input -X- _ O
text -X- _ O
, -X- _ O
the -X- _ O
generated -X- _ O
template -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
predicted -X- _ O
as -X- _ O
focuses -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
separate -X- _ O
cross -X- _ O
attentions -X- _ O
to -X- _ O
attend -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
focused -X- _ O
words -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
how -X- _ O
node -X- _ O
representations -X- _ O
are -X- _ O
attended -X- _ O
in -X- _ O
JOINTGEN.We -X- _ B-MethodName
recognize -X- _ O
that -X- _ O
having -X- _ O
separate -X- _ O
stages -X- _ O
of -X- _ O
exemplar -X- _ O
selection -X- _ O
and -X- _ O
template -X- _ O
generation -X- _ O
introduces -X- _ O
extra -X- _ O
model -X- _ O
training -X- _ O
cost -X- _ O
and -X- _ O
potential -X- _ O
errors -X- _ O
in -X- _ O
the -X- _ O
pipeline -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
focuses -X- _ O
on -X- _ O
improving -X- _ O
the -X- _ O
controllability -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
diversity -X- _ O
of -X- _ O
question -X- _ O
generation -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
will -X- _ O
leave -X- _ O
the -X- _ O
building -X- _ O
of -X- _ O
more -X- _ O
efficient -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Comparisons -X- _ O
and -X- _ O
Metrics -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
with -X- _ O
DEEPQG -X- _ B-MethodName
( -X- _ O
Pan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
uses -X- _ O
dependency -X- _ O
graphs -X- _ O
for -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
question -X- _ O
generation -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
compare -X- _ O
with -X- _ O
BART -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
finetuned -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
datasets -X- _ O
as -X- _ O
in -X- _ O
our -X- _ O
models -X- _ O
, -X- _ O
by -X- _ O
using -X- _ O
inputs -X- _ O
of -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
answer -X- _ O
( -X- _ B-MethodName
BART -X- _ I-MethodName
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
answer -X- _ O
and -X- _ O
a -X- _ O
predicted -X- _ O
question -X- _ O
word -X- _ O
( -X- _ O
BART+QWORD -X- _ B-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
the -X- _ O
answer -X- _ O
and -X- _ O
a -X- _ O
predicted -X- _ O
question -X- _ O
type -X- _ O
( -X- _ O
BART+QTYPE -X- _ B-MethodName
) -X- _ O
. -X- _ O
For -X- _ O
BART+QWORD -X- _ B-MethodName
, -X- _ O
the -X- _ O
question -X- _ O
word -X- _ O
is -X- _ O
predicted -X- _ O
by -X- _ O
a -X- _ O
RoBERTa -X- _ B-MethodName
classifier -X- _ O
that -X- _ O
considers -X- _ O
the -X- _ O
answer -X- _ O
and -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
our -X- _ O
training -X- _ O
sets -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
and -X- _ O
use -X- _ O
9 -X- _ O
categories -X- _ O
of -X- _ O
question -X- _ O
words -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
our -X- _ O
models -X- _ O
and -X- _ O
BART+QTYPE -X- _ B-MethodName
, -X- _ O
the -X- _ O
most -X- _ O
confident -X- _ O
type -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
classifier -X- _ O
γ -X- _ O
a -X- _ O
( -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
reads -X- _ O
in -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
To -X- _ O
test -X- _ O
the -X- _ O
efficacy -X- _ O
of -X- _ O
semantic -X- _ B-MethodName
graphs -X- _ I-MethodName
, -X- _ O
we -X- _ O
further -X- _ O
compare -X- _ O
with -X- _ O
a -X- _ O
variant -X- _ O
of -X- _ O
JOINTGEN -X- _ B-MethodName
that -X- _ O
only -X- _ O
uses -X- _ O
the -X- _ O
flat -X- _ O
Transformer -X- _ B-MethodName
for -X- _ O
focus -X- _ O
prediction -X- _ O
and -X- _ O
question -X- _ O
generation -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
JOINTGEN -X- _ B-MethodName
w/o -X- _ O
graph -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
the -X- _ O
generated -X- _ O
questions -X- _ O
with -X- _ O
BLEU -X- _ B-MetricName
( -X- _ O
Papineni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
, -X- _ O
METEOR -X- _ B-MetricName
( -X- _ O
Lavie -X- _ O
and -X- _ O
Agarwal -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ROUGE -X- _ B-MetricName
- -X- _ I-MetricName
L -X- _ I-MetricName
( -X- _ O
Lin -X- _ O
, -X- _ O
2004 -X- _ O
having -X- _ O
structured -X- _ O
representation -X- _ O
is -X- _ O
useful -X- _ O
for -X- _ O
focus -X- _ O
detection -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
question -X- _ O
generation -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
a -X- _ O
huge -X- _ O
performance -X- _ O
gap -X- _ O
between -X- _ O
DEEPQG -X- _ B-MethodName
and -X- _ O
systems -X- _ O
based -X- _ O
on -X- _ O
BART -X- _ B-MethodName
, -X- _ O
signifying -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
leveraging -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
for -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
question -X- _ O
generation -X- _ O
. -X- _ O
Meanwhile -X- _ O
, -X- _ O
adding -X- _ O
question -X- _ O
types -X- _ O
helps -X- _ O
BART -X- _ B-MethodName
generate -X- _ O
more -X- _ O
relevant -X- _ O
questions -X- _ O
than -X- _ O
using -X- _ O
question -X- _ O
words -X- _ O
, -X- _ O
indicating -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
our -X- _ O
new -X- _ O
question -X- _ O
type -X- _ O
ontology -X- _ O
. -X- _ O
Notably -X- _ O
, -X- _ O
our -X- _ O
template -X- _ O
- -X- _ O
based -X- _ O
generators -X- _ O
, -X- _ O
EX -X- _ B-MethodName
- -X- _ I-MethodName
PLGEN -X- _ I-MethodName
and -X- _ O
TPLGEN -X- _ B-MethodName
, -X- _ O
which -X- _ O
are -X- _ O
trained -X- _ O
to -X- _ O
comply -X- _ O
with -X- _ O
the -X- _ O
given -X- _ O
templates -X- _ O
, -X- _ O
still -X- _ O
produce -X- _ O
comparable -X- _ O
scores -X- _ O
. -X- _ O
This -X- _ O
highlights -X- _ O
the -X- _ O
possibility -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
generated -X- _ O
questions -X- _ O
' -X- _ O
types -X- _ O
and -X- _ O
syntax -X- _ O
as -X- _ O
demonstrated -X- _ O
by -X- _ O
the -X- _ O
templates -X- _ O
, -X- _ O
without -X- _ O
performance -X- _ O
loss -X- _ O
. -X- _ O
Question -X- _ O
Diversity -X- _ O
Evaluation -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
exam- -X- _ O
2 -X- _ O
3 -X- _ O
4 -X- _ O
5 -X- _ O
6 -X- _ O
7 -X- _ O
8 -X- _ O
9 -X- _ O
# -X- _ O
of -X- _ O
Given -X- _ O
Types -X- _ O
ine -X- _ O
the -X- _ O
controllability -X- _ O
of -X- _ O
models -X- _ O
by -X- _ O
specifying -X- _ O
different -X- _ O
question -X- _ O
types -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
The -X- _ O
top -X- _ O
9 -X- _ O
confident -X- _ O
types -X- _ O
6 -X- _ O
predicted -X- _ O
by -X- _ O
our -X- _ O
type -X- _ O
predictor -X- _ O
γ -X- _ O
a -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
our -X- _ O
models -X- _ O
, -X- _ O
producing -X- _ O
9 -X- _ O
questions -X- _ O
for -X- _ O
evaluation -X- _ O
. -X- _ O
For -X- _ B-MethodName
BART -X- _ I-MethodName
, -X- _ O
we -X- _ O
use -X- _ B-HyperparameterName
nucleus -X- _ I-HyperparameterName
sampling -X- _ I-HyperparameterName
( -X- _ O
Holtzman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
with -X- _ B-HyperparameterName
k -X- _ I-HyperparameterName
= -X- _ O
10 -X- _ B-HyperparameterValue
and -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
0.7 -X- _ B-HyperparameterValue
to -X- _ O
sample -X- _ O
diverse -X- _ O
questions -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
calculate -X- _ O
the -X- _ O
question -X- _ B-MetricName
type -X- _ I-MetricName
accuracy -X- _ I-MetricName
by -X- _ O
comparing -X- _ O
whether -X- _ O
the -X- _ O
types -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
questions -X- _ O
match -X- _ O
the -X- _ O
specified -X- _ O
ones -X- _ O
, -X- _ O
with -X- _ O
types -X- _ O
labeled -X- _ O
by -X- _ O
our -X- _ O
classifier -X- _ O
γ -X- _ O
q -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
numbers -X- _ O
of -X- _ O
unique -X- _ O
question -X- _ O
types -X- _ O
in -X- _ O
the -X- _ O
9 -X- _ O
generated -X- _ O
questions -X- _ O
per -X- _ O
sample -X- _ O
, -X- _ O
with -X- _ O
higher -X- _ O
number -X- _ O
indicating -X- _ O
better -X- _ O
controllability -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
pairwise -X- _ B-MetricName
BLEU-4 -X- _ I-MetricName
( -X- _ O
Cho -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
by -X- _ O
computing -X- _ O
the -X- _ O
BLEU-4 -X- _ B-MetricName
between -X- _ O
pairwise -X- _ O
generated -X- _ O
questions -X- _ O
per -X- _ O
sample -X- _ O
, -X- _ O
where -X- _ O
lower -X- _ O
values -X- _ O
suggest -X- _ O
higher -X- _ O
content -X- _ O
diversity -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
our -X- _ O
EXPLGEN -X- _ B-MethodName
and -X- _ O
TPLGEN -X- _ B-MethodName
can -X- _ O
generate -X- _ O
questions -X- _ O
with -X- _ O
diverse -X- _ O
types -X- _ O
and -X- _ O
content -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
by -X- _ O
the -X- _ O
significantly -X- _ O
higher -X- _ O
numbers -X- _ O
of -X- _ O
unique -X- _ O
types -X- _ O
than -X- _ O
all -X- _ O
comparisons -X- _ O
and -X- _ O
lower -X- _ O
pairwise -X- _ O
BLEU -X- _ B-MetricName
scores -X- _ O
than -X- _ O
comparisons -X- _ O
except -X- _ O
for -X- _ O
BART -X- _ B-MethodName
with -X- _ O
nucleus -X- _ B-HyperparameterName
sampling -X- _ I-HyperparameterName
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
This -X- _ O
implies -X- _ O
stronger -X- _ O
type -X- _ O
control -X- _ O
by -X- _ O
template -X- _ O
- -X- _ O
based -X- _ O
generators -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
BART+QTYPE -X- _ B-MethodName
and -X- _ O
JOINTGEN -X- _ B-MethodName
which -X- _ O
only -X- _ O
use -X- _ O
the -X- _ O
question -X- _ O
type -X- _ O
token -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
Results -X- _ O
on -X- _ O
numbers -X- _ O
of -X- _ O
unique -X- _ O
types -X- _ O
by -X- _ O
varying -X- _ O
numbers -X- _ O
of -X- _ O
question -X- _ O
types -X- _ O
specified -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
are -X- _ O
displayed -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
where -X- _ O
EXPLGEN -X- _ B-MethodName
and -X- _ O
TPLGEN -X- _ B-MethodName
maintain -X- _ O
steady -X- _ O
controllability -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
our -X- _ O
question -X- _ O
type -X- _ O
ontology -X- _ O
provides -X- _ O
a -X- _ O
new -X- _ O
perspective -X- _ O
for -X- _ O
question -X- _ O
diversity -X- _ O
evaluation -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
comparisons -X- _ O
, -X- _ O
although -X- _ O
BART -X- _ B-MethodName
with -X- _ O
nucleus -X- _ B-HyperparameterName
sampling -X- _ I-HyperparameterName
and -X- _ O
BART+QWORD -X- _ B-MethodName
both -X- _ O
have -X- _ O
low -X- _ O
pairwise -X- _ B-MetricName
BLEU -X- _ I-MetricName
, -X- _ O
the -X- _ O
types -X- _ O
of -X- _ O
questions -X- _ O
they -X- _ O
can -X- _ O
generate -X- _ O
are -X- _ O
limited -X- _ O
. -X- _ O
Question -X- _ O
Diversity -X- _ O
. -X- _ O
We -X- _ O
hire -X- _ O
three -X- _ O
annotators -X- _ O
who -X- _ O
have -X- _ O
participated -X- _ O
in -X- _ O
our -X- _ O
question -X- _ O
type -X- _ O
annotation -X- _ O
study -X- _ O
to -X- _ O
evaluate -X- _ O
80 -X- _ O
groups -X- _ O
of -X- _ O
questions -X- _ O
generated -X- _ O
by -X- _ O
four -X- _ O
selected -X- _ O
models -X- _ O
on -X- _ O
each -X- _ O
dataset -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
group -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
sample -X- _ O
an -X- _ O
answer -X- _ O
and -X- _ O
indicate -X- _ O
three -X- _ O
most -X- _ O
probably -X- _ O
question -X- _ O
types -X- _ O
to -X- _ O
each -X- _ O
model -X- _ O
, -X- _ O
to -X- _ O
generate -X- _ O
three -X- _ O
corresponding -X- _ O
questions -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
sample -X- _ O
, -X- _ O
the -X- _ O
annotators -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
rank -X- _ O
the -X- _ O
four -X- _ O
models -X- _ O
from -X- _ O
1 -X- _ O
( -X- _ O
highest -X- _ O
) -X- _ O
to -X- _ O
4 -X- _ O
( -X- _ O
lowest -X- _ O
) -X- _ O
on -X- _ O
three -X- _ O
aspects -X- _ O
of -X- _ O
diversities -X- _ O
: -X- _ O
type -X- _ O
- -X- _ O
whether -X- _ O
the -X- _ O
three -X- _ O
generated -X- _ O
questions -X- _ O
have -X- _ O
different -X- _ O
types -X- _ O
, -X- _ O
syntax -X- _ O
- -X- _ O
whether -X- _ O
they -X- _ O
use -X- _ O
different -X- _ O
syntax -X- _ O
, -X- _ O
and -X- _ O
answer -X- _ O
content -X- _ O
- -X- _ O
whether -X- _ O
the -X- _ O
three -X- _ O
questions -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
addressed -X- _ O
with -X- _ O
different -X- _ O
answers -X- _ O
. -X- _ O
Ties -X- _ O
are -X- _ O
allowed -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
human -X- _ O
judges -X- _ O
rate -X- _ O
questions -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
EXPLGEN -X- _ B-MethodName
and -X- _ O
TPLGEN -X- _ B-MethodName
as -X- _ O
having -X- _ O
greater -X- _ O
diversities -X- _ O
over -X- _ O
all -X- _ O
aspects -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
syntax -X- _ O
diversity -X- _ O
on -X- _ O
Reddit -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
two -X- _ O
model -X- _ O
variants -X- _ O
, -X- _ O
questions -X- _ O
by -X- _ O
TPLGEN -X- _ B-MethodName
yield -X- _ O
more -X- _ O
diverse -X- _ O
answers -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
our -X- _ O
observation -X- _ O
, -X- _ B-MethodName
TPLGEN -X- _ I-MethodName
uses -X- _ O
automatically -X- _ O
generated -X- _ O
templates -X- _ O
to -X- _ O
produce -X- _ O
more -X- _ O
focused -X- _ O
questions -X- _ O
with -X- _ O
different -X- _ O
answers -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
EXPLGEN -X- _ B-MethodName
which -X- _ O
employs -X- _ O
exemplars -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
the -X- _ O
promise -X- _ O
of -X- _ O
using -X- _ O
automatically -X- _ O
generated -X- _ O
templates -X- _ O
to -X- _ O
create -X- _ O
questions -X- _ O
that -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
addressed -X- _ O
with -X- _ O
different -X- _ O
answers -X- _ O
. -X- _ O
Besides -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
more -X- _ O
sample -X- _ O
outputs -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
where -X- _ O
EXPLGEN -X- _ B-MethodName
and -X- _ O
TPLGEN -X- _ B-MethodName
exhibit -X- _ O
stronger -X- _ O
controllability -X- _ O
than -X- _ O
JOINTGEN -X- _ B-MethodName
. -X- _ O
Question -X- _ O
Content -X- _ O
Quality -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
set -X- _ O
of -X- _ O
human -X- _ O
judges -X- _ O
to -X- _ O
evaluate -X- _ O
another -X- _ O
80 -X- _ O
groups -X- _ O
of -X- _ O
questions -X- _ O
output -X- _ O
by -X- _ O
five -X- _ O
selected -X- _ O
models -X- _ O
and -X- _ O
the -X- _ O
reference -X- _ O
. -X- _ O
Three -X- _ O
aspects -X- _ O
are -X- _ O
rated -X- _ O
from -X- _ O
1 -X- _ O
( -X- _ O
worst)Answer -X- _ O
: -X- _ O
My -X- _ O
sister -X- _ O
in -X- _ O
law -X- _ O
and -X- _ O
her -X- _ O
husband -X- _ O
" -X- _ O
genetically -X- _ O
modified -X- _ O
" -X- _ O
their -X- _ O
second -X- _ O
child -X- _ O
because -X- _ O
the -X- _ O
first -X- _ O
has -X- _ O
EB -X- _ O
. -X- _ O
They -X- _ O
eliminated -X- _ O
that -X- _ O
and -X- _ O
had -X- _ O
a -X- _ O
baby -X- _ O
that -X- _ O
gets -X- _ O
to -X- _ O
live -X- _ O
pain -X- _ O
free -X- _ O
. -X- _ O
Under -X- _ O
the -X- _ O
right -X- _ O
circumstances -X- _ O
, -X- _ O
I -X- _ O
'm -X- _ O
all -X- _ O
for -X- _ O
it -X- _ O
... -X- _ O
Figure -X- _ O
4 -X- _ O
: -X- _ O
Sample -X- _ O
outputs -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
given -X- _ O
different -X- _ O
question -X- _ O
types -X- _ O
. -X- _ O
Spans -X- _ O
that -X- _ O
belong -X- _ O
to -X- _ O
the -X- _ O
exemplars -X- _ O
or -X- _ O
the -X- _ O
generated -X- _ O
templates -X- _ O
are -X- _ O
colored -X- _ O
with -X- _ O
blue -X- _ O
. -X- _ O
Generated -X- _ O
questions -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
match -X- _ O
the -X- _ O
given -X- _ O
type -X- _ O
are -X- _ O
marked -X- _ O
by -X- _ O
strikethrough.to -X- _ O
5 -X- _ O
( -X- _ O
best -X- _ O
): -X- _ O
appropriateness -X- _ O
- -X- _ O
whether -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
semantically -X- _ O
correct -X- _ O
, -X- _ O
without -X- _ O
considering -X- _ O
the -X- _ O
answer -X- _ O
; -X- _ O
answerability -X- _ O
- -X- _ O
whether -X- _ O
the -X- _ O
question -X- _ O
can -X- _ O
be -X- _ O
addressed -X- _ O
by -X- _ O
the -X- _ O
given -X- _ O
answer -X- _ O
; -X- _ O
and -X- _ O
scopewhether -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
a -X- _ O
longer -X- _ O
span -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
( -X- _ O
global -X- _ O
scope -X- _ O
) -X- _ O
or -X- _ O
focuses -X- _ O
on -X- _ O
local -X- _ O
content -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
one -X- _ O
phrase -X- _ O
or -X- _ O
one -X- _ O
sentence -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
ask -X- _ O
the -X- _ O
annotators -X- _ O
to -X- _ O
rank -X- _ O
questions -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
overall -X- _ O
quality -X- _ O
and -X- _ O
preferences -X- _ O
, -X- _ O
with -X- _ O
ties -X- _ O
allowed -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
our -X- _ O
JOINTGEN -X- _ B-MethodName
model -X- _ O
produces -X- _ O
questions -X- _ O
with -X- _ O
better -X- _ O
answerability -X- _ O
and -X- _ O
that -X- _ O
cover -X- _ O
broader -X- _ O
content -X- _ O
in -X- _ O
the -X- _ O
answers -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
rated -X- _ O
as -X- _ O
the -X- _ O
best -X- _ O
in -X- _ O
more -X- _ O
than -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
evaluation -X- _ O
instances -X- _ O
on -X- _ O
both -X- _ O
datasets -X- _ O
. -X- _ O
Between -X- _ O
BART+QWORD -X- _ B-MethodName
and -X- _ O
BART+QTYPE -X- _ B-MethodName
, -X- _ O
human -X- _ O
judges -X- _ O
rate -X- _ O
the -X- _ O
system -X- _ O
outputs -X- _ O
that -X- _ O
conditioned -X- _ O
on -X- _ O
our -X- _ O
question -X- _ O
types -X- _ O
to -X- _ O
have -X- _ O
better -X- _ O
overall -X- _ O
quality -X- _ O
. -X- _ O
Does -X- _ O
focus -X- _ O
prediction -X- _ O
correlate -X- _ O
with -X- _ O
question -X- _ O
quality -X- _ O
? -X- _ O
We -X- _ O
first -X- _ O
investigate -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
focus -X- _ O
prediction -X- _ O
and -X- _ O
question -X- _ O
generation -X- _ O
by -X- _ O
using -X- _ O
our -X- _ O
joint -X- _ O
model -X- _ O
JOINTGEN -X- _ B-MethodName
. -X- _ O
As -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
from -X- _ O
Figure -X- _ O
5 -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
strong -X- _ O
correlation -X- _ O
between -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
of -X- _ O
focus -X- _ O
prediction -X- _ O
and -X- _ O
BLEU-4 -X- _ B-MetricName
as -X- _ O
well -X- _ O
We -X- _ O
also -X- _ O
show -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
and -X- _ O
BLEU-4 -X- _ B-MetricName
for -X- _ O
selected -X- _ O
question -X- _ O
types -X- _ O
on -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
Figure -X- _ O
5 -X- _ O
, -X- _ O
again -X- _ O
demonstrating -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
focus -X- _ O
detection -X- _ O
on -X- _ O
question -X- _ O
quality -X- _ O
. -X- _ O
When -X- _ O
do -X- _ O
our -X- _ O
models -X- _ O
fail -X- _ O
to -X- _ O
respect -X- _ O
the -X- _ O
given -X- _ O
types -X- _ O
? -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
insights -X- _ O
into -X- _ O
which -X- _ O
types -X- _ O
of -X- _ O
questions -X- _ O
are -X- _ O
challenging -X- _ O
to -X- _ O
generate -X- _ O
by -X- _ O
using -X- _ O
our -X- _ O
template -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
EXPLGEN -X- _ B-MethodName
and -X- _ O
TPLGEN -X- _ B-MethodName
. -X- _ O
Both -X- _ O
variants -X- _ O
frequently -X- _ O
fail -X- _ O
to -X- _ O
respect -X- _ O
the -X- _ O
given -X- _ O
question -X- _ O
type -X- _ O
of -X- _ O
VERIFICATION -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
cases -X- _ O
they -X- _ O
often -X- _ O
produce -X- _ O
JUDGEMENTAL -X- _ O
questions -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
tend -X- _ O
to -X- _ O
confuse -X- _ O
EXAMPLE -X- _ O
and -X- _ O
EXTENT -X- _ O
with -X- _ O
CONCEPT -X- _ O
questions -X- _ O
. -X- _ O
After -X- _ O
manually -X- _ O
inspecting -X- _ O
50 -X- _ O
generated -X- _ O
questions -X- _ O
for -X- _ O
the -X- _ O
aforementioned -X- _ O
three -X- _ O
types -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
many -X- _ O
of -X- _ O
them -X- _ O
can -X- _ O
be -X- _ O
labeled -X- _ O
with -X- _ O
both -X- _ O
types -X- _ O
, -X- _ O
thus -X- _ O
creating -X- _ O
confusion -X- _ O
for -X- _ O
our -X- _ O
classifier -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
" -X- _ O
What -X- _ O
are -X- _ O
the -X- _ O
import -X- _ O
restrictions -X- _ O
in -X- _ O
the -X- _ O
US -X- _ O
? -X- _ O
" -X- _ O
can -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
either -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
new -X- _ O
question -X- _ O
type -X- _ O
ontology -X- _ O
which -X- _ O
better -X- _ O
captures -X- _ O
the -X- _ O
nuances -X- _ O
of -X- _ O
questions -X- _ O
to -X- _ O
support -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
question -X- _ O
generation -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
annotate -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
with -X- _ O
4,959 -X- _ O
questions -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
proposed -X- _ O
ontology -X- _ O
. -X- _ O
We -X- _ O
describe -X- _ O
a -X- _ O
joint -X- _ O
question -X- _ O
focus -X- _ O
detection -X- _ O
and -X- _ O
question -X- _ O
generation -X- _ O
framework -X- _ O
with -X- _ O
a -X- _ O
novel -X- _ O
semantic -X- _ B-TaskName
graphaugmented -X- _ I-TaskName
representation -X- _ I-TaskName
, -X- _ O
which -X- _ O
is -X- _ O
directly -X- _ O
built -X- _ O
on -X- _ O
large -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
this -X- _ O
framework -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
enhance -X- _ O
the -X- _ O
controllability -X- _ O
and -X- _ O
diversity -X- _ O
of -X- _ O
generated -X- _ O
questions -X- _ O
by -X- _ O
employing -X- _ O
template -X- _ O
exemplars -X- _ O
or -X- _ O
automatically -X- _ O
generated -X- _ O
templates -X- _ O
. -X- _ O
Experiments -X- _ O
on -X- _ O
two -X- _ O
large -X- _ O
datasets -X- _ O
show -X- _ O
that -X- _ O
questions -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
models -X- _ O
have -X- _ O
better -X- _ O
quality -X- _ O
and -X- _ O
higher -X- _ O
diversity -X- _ O
than -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
comparisons -X- _ O
, -X- _ O
with -X- _ O
similar -X- _ O
results -X- _ O
rated -X- _ O
by -X- _ O
human -X- _ O
judges -X- _ O
. -X- _ O
Large -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
heterogeneous -X- _ O
web -X- _ O
data -X- _ O
are -X- _ O
shown -X- _ O
to -X- _ O
encode -X- _ O
biases -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
potentially -X- _ O
harmful -X- _ O
for -X- _ O
marginalized -X- _ O
populations -X- _ O
. -X- _ O
While -X- _ O
the -X- _ O
automatically -X- _ O
learned -X- _ O
templates -X- _ O
improve -X- _ O
controllability -X- _ O
in -X- _ O
question -X- _ O
generation -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
recognize -X- _ O
that -X- _ O
our -X- _ O
system -X- _ O
might -X- _ O
be -X- _ O
misused -X- _ O
to -X- _ O
create -X- _ O
questions -X- _ O
that -X- _ O
contain -X- _ O
objectionable -X- _ O
content -X- _ O
. -X- _ O
We -X- _ O
therefore -X- _ O
advocate -X- _ O
cautious -X- _ O
and -X- _ O
responsible -X- _ O
practices -X- _ O
in -X- _ O
real -X- _ O
- -X- _ O
world -X- _ O
deployment -X- _ O
. -X- _ O
Our -X- _ O
data -X- _ O
collection -X- _ O
process -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
new -X- _ O
datasets -X- _ O
involves -X- _ O
removing -X- _ O
samples -X- _ O
with -X- _ O
abusive -X- _ O
languages -X- _ O
and -X- _ O
human -X- _ O
inspection -X- _ O
on -X- _ O
random -X- _ O
samples -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
data -X- _ O
volume -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
not -X- _ O
exhaustively -X- _ O
verify -X- _ O
that -X- _ O
all -X- _ O
records -X- _ O
are -X- _ O
free -X- _ O
of -X- _ O
potentially -X- _ O
offensive -X- _ O
content -X- _ O
. -X- _ O
Data -X- _ O
Filtering -X- _ O
. -X- _ O
After -X- _ O
collecting -X- _ O
the -X- _ O
raw -X- _ O
data -X- _ O
from -X- _ O
Yahoo -X- _ O
and -X- _ O
Reddit -X- _ O
, -X- _ O
we -X- _ O
design -X- _ O
rules -X- _ O
to -X- _ O
filter -X- _ O
out -X- _ O
ill -X- _ O
- -X- _ O
formed -X- _ O
answers -X- _ O
and -X- _ O
questions -X- _ O
. -X- _ O
These -X- _ O
rules -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
human -X- _ O
inspection -X- _ O
on -X- _ O
random -X- _ O
samples -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
and -X- _ O
confirm -X- _ O
that -X- _ O
samples -X- _ O
are -X- _ O
all -X- _ O
clean -X- _ O
and -X- _ O
contain -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
questions -X- _ O
. -X- _ O
Rules -X- _ O
for -X- _ O
Data -X- _ O
Cleaning -X- _ O
-The -X- _ O
question -X- _ O
has -X- _ O
URL -X- _ O
links.-The -X- _ O
question -X- _ O
has -X- _ O
more -X- _ O
than -X- _ O
1 -X- _ O
sentence -X- _ O
or -X- _ O
does -X- _ O
not -X- _ O
end -X- _ O
with -X- _ O
a -X- _ O
question -X- _ O
mark.-The -X- _ O
question -X- _ O
has -X- _ O
less -X- _ O
than -X- _ O
4 -X- _ O
words -X- _ O
or -X- _ O
less -X- _ O
than -X- _ O
1 -X- _ O
content -X- _ O
word.-The -X- _ O
question -X- _ O
does -X- _ O
not -X- _ O
start -X- _ O
with -X- _ O
wh -X- _ O
- -X- _ O
words -X- _ O
: -X- _ O
what -X- _ O
, -X- _ O
why -X- _ O
, -X- _ O
how -X- _ O
, -X- _ O
which -X- _ O
, -X- _ O
where -X- _ O
, -X- _ O
who -X- _ O
, -X- _ O
when -X- _ O
; -X- _ O
yes -X- _ O
- -X- _ O
no -X- _ O
words -X- _ O
: -X- _ O
is -X- _ O
, -X- _ O
are -X- _ O
, -X- _ O
was -X- _ O
, -X- _ O
were -X- _ O
, -X- _ O
will -X- _ O
, -X- _ O
would -X- _ O
, -X- _ O
do -X- _ O
, -X- _ O
does -X- _ O
, -X- _ O
did -X- _ O
, -X- _ O
can -X- _ O
, -X- _ O
could -X- _ O
, -X- _ O
should -X- _ O
, -X- _ O
has -X- _ O
, -X- _ O
have -X- _ O
; -X- _ O
or -X- _ O
frequent -X- _ O
words -X- _ O
for -X- _ O
conditions -X- _ O
: -X- _ O
if -X- _ O
, -X- _ O
in -X- _ O
, -X- _ O
for -X- _ O
, -X- _ O
to -X- _ O
, -X- _ O
as -X- _ O
, -X- _ O
at.-The -X- _ O
answer -X- _ O
has -X- _ O
less -X- _ O
than -X- _ O
15 -X- _ O
content -X- _ O
words.-The -X- _ O
answer -X- _ O
has -X- _ O
less -X- _ O
content -X- _ O
words -X- _ O
than -X- _ O
the -X- _ O
question.-The -X- _ O
answer -X- _ O
has -X- _ O
more -X- _ O
than -X- _ O
30 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
as -X- _ O
digit -X- _ O
letters.-The -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
answer -X- _ O
have -X- _ O
less -X- _ O
than -X- _ O
2 -X- _ O
overlapping -X- _ O
content -X- _ O
words.-The -X- _ O
question -X- _ O
or -X- _ O
the -X- _ O
answer -X- _ O
contains -X- _ O
abusive -X- _ O
words -X- _ O
from -X- _ O
Google -X- _ O
's -X- _ O
" -X- _ O
what -X- _ O
do -X- _ O
you -X- _ O
need -X- _ O
" -X- _ O
project -X- _ O
7 -X- _ O
.-The -X- _ O
question -X- _ O
or -X- _ O
the -X- _ O
answer -X- _ O
has -X- _ O
emoticons -X- _ O
8 -X- _ O
. -X- _ O
-The -X- _ O
question -X- _ O
or -X- _ O
the -X- _ O
answer -X- _ O
has -X- _ O
3 -X- _ O
consecutive -X- _ O
punctuation.-The -X- _ O
question -X- _ O
or -X- _ O
the -X- _ O
answer -X- _ O
has -X- _ O
3 -X- _ O
consecutive -X- _ O
fully -X- _ O
uppercased -X- _ O
words.-The -X- _ O
question -X- _ O
has -X- _ O
more -X- _ O
than -X- _ O
90 -X- _ O
% -X- _ O
of -X- _ O
title -X- _ O
- -X- _ O
case -X- _ O
words -X- _ O
or -X- _ O
the -X- _ O
answer -X- _ O
has -X- _ O
more -X- _ O
than -X- _ O
30 -X- _ O
% -X- _ O
of -X- _ O
title -X- _ O
- -X- _ O
case -X- _ O
words.-The -X- _ O
question -X- _ O
has -X- _ O
more -X- _ O
than -X- _ O
1 -X- _ O
unique -X- _ O
word -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
English -X- _ O
dictionary -X- _ O
or -X- _ O
the -X- _ O
answer -X- _ O
has -X- _ O
more -X- _ O
than -X- _ O
2 -X- _ O
unique -X- _ O
words -X- _ O
not -X- _ O
in -X- _ O
the -X- _ O
English -X- _ O
dictionary -X- _ O
9 -X- _ O
. -X- _ O
Question -X- _ O
Type -X- _ O
Annotation -X- _ O
. -X- _ O
We -X- _ O
include -X- _ O
the -X- _ O
definition -X- _ O
and -X- _ O
corresponding -X- _ O
examples -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
type -X- _ O
in -X- _ O
the -X- _ O
annotation -X- _ O
guideline -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
12 -X- _ O
. -X- _ O
We -X- _ O
allow -X- _ O
annotators -X- _ O
to -X- _ O
label -X- _ O
a -X- _ O
question -X- _ O
with -X- _ O
two -X- _ O
types -X- _ O
if -X- _ O
they -X- _ O
can -X- _ O
not -X- _ O
decide -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
. -X- _ O
All -X- _ O
recruited -X- _ O
annotators -X- _ O
are -X- _ O
U.S. -X- _ O
college -X- _ O
students -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
paid -X- _ O
$ -X- _ O
15 -X- _ O
per -X- _ O
hour -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
it -X- _ O
takes -X- _ O
3.5 -X- _ O
hours -X- _ O
to -X- _ O
annotate -X- _ O
1000 -X- _ O
questions -X- _ O
. -X- _ O
For -X- _ O
samples -X- _ O
with -X- _ O
disagreed -X- _ O
labels -X- _ O
, -X- _ O
we -X- _ O
check -X- _ O
whether -X- _ O
agreement -X- _ O
can -X- _ O
be -X- _ O
reached -X- _ O
by -X- _ O
considering -X- _ O
both -X- _ O
labeled -X- _ O
types -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
if -X- _ O
annotator -X- _ O
A -X- _ O
labels -X- _ O
VERIFICATION -X- _ O
and -X- _ O
JUDGMENTAL -X- _ O
, -X- _ O
and -X- _ O
annotator -X- _ O
B -X- _ O
labels -X- _ O
JUDGMENTAL -X- _ O
, -X- _ O
the -X- _ O
agreed -X- _ O
- -X- _ O
upon -X- _ O
type -X- _ O
is -X- _ O
JUDGMENTAL -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
resolve -X- _ O
outstanding -X- _ O
disagreements -X- _ O
by -X- _ O
discussion -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
the -X- _ O
question -X- _ O
type -X- _ O
classifier -X- _ O
γ -X- _ O
q -X- _ O
that -X- _ O
reads -X- _ O
the -X- _ O
question -X- _ O
as -X- _ O
input -X- _ O
, -X- _ O
we -X- _ O
split -X- _ O
the -X- _ O
collected -X- _ O
question -X- _ O
type -X- _ O
dataset -X- _ O
into -X- _ O
training -X- _ O
, -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
. -X- _ O
Sample -X- _ O
counts -X- _ O
and -X- _ O
question -X- _ O
type -X- _ O
distributions -X- _ O
for -X- _ O
different -X- _ O
data -X- _ O
splits -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
use -X- _ O
γ -X- _ O
q -X- _ O
to -X- _ O
identify -X- _ O
types -X- _ O
for -X- _ O
unlabeled -X- _ O
questions -X- _ O
in -X- _ O
Yahoo -X- _ O
and -X- _ O
Reddit -X- _ O
. -X- _ O
The -X- _ O
question -X- _ O
type -X- _ O
distributions -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
datasets -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
. -X- _ O
We -X- _ O
discard -X- _ O
secondary -X- _ O
dependency -X- _ O
relations -X- _ O
for -X- _ O
graph -X- _ O
construction -X- _ O
, -X- _ O
including -X- _ O
case -X- _ O
, -X- _ O
mark -X- _ O
, -X- _ O
cc -X- _ O
, -X- _ O
cc -X- _ O
: -X- _ O
preconj -X- _ O
, -X- _ O
aux -X- _ O
, -X- _ O
aux -X- _ O
: -X- _ O
pass -X- _ O
, -X- _ O
cop -X- _ O
, -X- _ O
det -X- _ O
, -X- _ O
discourse -X- _ O
, -X- _ O
expl -X- _ O
, -X- _ O
det -X- _ O
: -X- _ O
predet -X- _ O
, -X- _ O
punct -X- _ O
, -X- _ O
ref -X- _ O
. -X- _ O
The -X- _ O
definition -X- _ O
for -X- _ O
each -X- _ O
dependency -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Universal -X- _ B-MethodName
Dependency -X- _ I-MethodName
. -X- _ O
10 -X- _ O
Template -X- _ O
Construction -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
replacing -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
representative -X- _ O
of -X- _ O
question -X- _ O
types -X- _ O
during -X- _ O
template -X- _ O
construction -X- _ O
, -X- _ O
we -X- _ O
maintain -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
words -X- _ O
not -X- _ O
to -X- _ O
be -X- _ O
replaced -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
type -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
9 -X- _ O
. -X- _ O
These -X- _ O
words -X- _ O
are -X- _ O
identified -X- _ O
by -X- _ O
frequency -X- _ O
with -X- _ O
additional -X- _ O
manual -X- _ O
inspection -X- _ O
. -X- _ O
Exemplar -X- _ O
Classifiers -X- _ O
. -X- _ O
To -X- _ O
predict -X- _ O
the -X- _ O
exemplars -X- _ O
used -X- _ O
for -X- _ O
question -X- _ O
decoding -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
one -X- _ O
exemplar -X- _ O
classifier -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
type -X- _ O
, -X- _ O
on -X- _ O
each -X- _ O
dataset -X- _ O
. -X- _ O
Accuracy -X- _ O
values -X- _ O
of -X- _ O
these -X- _ O
exemplar -X- _ O
classifiers -X- _ O
on -X- _ O
the -X- _ O
reserved -X- _ O
test -X- _ O
sets -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
11 -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Fairseq -X- _ O
to -X- _ O
build -X- _ O
our -X- _ O
models -X- _ O
and -X- _ O
conduct -X- _ O
training -X- _ O
and -X- _ O
decoding -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
Graph -X- _ B-MethodName
Attention -X- _ I-MethodName
Networks -X- _ I-MethodName
( -X- _ I-MethodName
GATs -X- _ I-MethodName
) -X- _ O
in -X- _ O
our -X- _ O
focus -X- _ O
predictor -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
implementation -X- _ O
by -X- _ O
PyTorch -X- _ O
Geometric -X- _ O
( -X- _ O
Fey -X- _ O
and -X- _ O
Lenssen -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
our -X- _ O
experiments -X- _ O
are -X- _ O
conducted -X- _ O
on -X- _ O
a -X- _ O
Quadro -X- _ O
RTX -X- _ O
8000 -X- _ O
GPU -X- _ O
with -X- _ O
48 -X- _ O
GB -X- _ O
of -X- _ O
memory -X- _ O
. -X- _ O
Training -X- _ O
Settings -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
all -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
Our -X- _ O
question -X- _ O
type -X- _ O
classifiers -X- _ O
and -X- _ O
template -X- _ O
exemplar -X- _ O
classifiers -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
maximum -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
10 -X- _ I-HyperparameterValue
−5 -X- _ I-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O
For -X- _ O
training -X- _ O
generation -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
maximum -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
3 -X- _ B-HyperparameterValue
× -X- _ I-HyperparameterValue
10 -X- _ I-HyperparameterValue
−5 -X- _ I-HyperparameterValue
and -X- _ O
each -X- _ O
batch -X- _ B-HyperparameterName
contains -X- _ O
at -X- _ O
most -X- _ O
32,768 -X- _ B-HyperparameterValue
models -X- _ O
except -X- _ O
for -X- _ O
models -X- _ O
with -X- _ O
GATs -X- _ B-MethodName
. -X- _ O
Decoding -X- _ O
Settings -X- _ O
. -X- _ O
We -X- _ O
use -X- _ B-HyperparameterName
beam -X- _ I-HyperparameterName
search -X- _ I-HyperparameterName
for -X- _ O
decoding -X- _ O
. -X- _ O
A -X- _ O
beam -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
length -X- _ B-HyperparameterName
penalty -X- _ I-HyperparameterName
of -X- _ O
1.5 -X- _ B-HyperparameterValue
are -X- _ O
used -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
. -X- _ O
Repeated -X- _ B-HyperparameterName
trigram -X- _ I-HyperparameterName
blocking -X- _ I-HyperparameterName
is -X- _ O
applied -X- _ O
to -X- _ O
question -X- _ O
generation -X- _ O
. -X- _ O
The -X- _ O
minimum -X- _ B-HyperparameterName
and -X- _ I-HyperparameterName
maximum -X- _ I-HyperparameterName
lengths -X- _ I-HyperparameterName
for -X- _ O
generation -X- _ O
are -X- _ O
set -X- _ O
to -X- _ O
1 -X- _ B-HyperparameterValue
and -X- _ O
100 -X- _ B-HyperparameterValue
, -X- _ O
respectively -X- _ O
. -X- _ O
This -X- _ O
research -X- _ O
is -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
through -X- _ O
Grants -X- _ O
IIS-1813341 -X- _ O
and -X- _ O
a -X- _ O
CAREER -X- _ O
award -X- _ O
IIS-2046016 -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
three -X- _ O
anonymous -X- _ O
reviewers -X- _ O
, -X- _ O
area -X- _ O
chair -X- _ O
, -X- _ O
and -X- _ O
senior -X- _ O
area -X- _ O
chairs -X- _ O
for -X- _ O
their -X- _ O
valuable -X- _ O
suggestions -X- _ O
for -X- _ O
improving -X- _ O
various -X- _ O
aspects -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
study -X- _ O
, -X- _ O
you -X- _ O
are -X- _ O
asked -X- _ O
to -X- _ O
annotate -X- _ O
the -X- _ O
question -X- _ O
types -X- _ O
for -X- _ O
1000 -X- _ O
questions -X- _ O
. -X- _ O
The -X- _ O
question -X- _ O
type -X- _ O
reflects -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
not -X- _ O
determined -X- _ O
by -X- _ O
the -X- _ O
interrogative -X- _ O
word -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
10 -X- _ O
question -X- _ O
types -X- _ O
in -X- _ O
total -X- _ O
. -X- _ O
The -X- _ O
definition -X- _ O
for -X- _ O
each -X- _ O
type -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
Table -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
examples -X- _ O
per -X- _ O
question -X- _ O
type -X- _ O
. -X- _ O
During -X- _ O
annotation -X- _ O
, -X- _ O
you -X- _ O
can -X- _ O
label -X- _ O
two -X- _ O
most -X- _ O
- -X- _ O
confident -X- _ O
types -X- _ O
when -X- _ O
no -X- _ O
clear -X- _ O
decision -X- _ O
can -X- _ O
be -X- _ O
made -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
probable -X- _ O
type -X- _ O
. -X- _ O
VERIFICATION -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
the -X- _ O
truthfulness -X- _ O
of -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept.-"Is -X- _ O
Michael -X- _ O
Jackson -X- _ O
an -X- _ O
African -X- _ O
American -X- _ O
? -X- _ O
" -X- _ O
-"Does -X- _ O
a -X- _ O
Mercedes -X- _ O
dealer -X- _ O
have -X- _ O
to -X- _ O
unlock -X- _ O
a -X- _ O
locked -X- _ O
radio -X- _ O
? -X- _ O
" -X- _ O
-"Could -X- _ O
stress -X- _ O
, -X- _ O
anxiety -X- _ O
, -X- _ O
or -X- _ O
worry -X- _ O
cause -X- _ O
cholesterol -X- _ O
levels -X- _ O
to -X- _ O
rise -X- _ O
? -X- _ O
" -X- _ O
DISJUNCTIVE -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
the -X- _ O
true -X- _ O
one -X- _ O
given -X- _ O
multiple -X- _ O
events -X- _ O
or -X- _ O
concepts -X- _ O
, -X- _ O
where -X- _ O
comparison -X- _ O
among -X- _ O
options -X- _ O
is -X- _ O
not -X- _ O
needed.-"Is -X- _ O
Michael -X- _ O
Jackson -X- _ O
an -X- _ O
African -X- _ O
American -X- _ O
or -X- _ O
Latino -X- _ O
? -X- _ O
" -X- _ O
-"Is -X- _ O
a -X- _ O
DVI -X- _ O
to -X- _ O
HDMI -X- _ O
cable -X- _ O
supposed -X- _ O
to -X- _ O
transmit -X- _ O
audio -X- _ O
and -X- _ O
video -X- _ O
or -X- _ O
just -X- _ O
video -X- _ O
? -X- _ O
" -X- _ O
-"When -X- _ O
you -X- _ O
get -X- _ O
a -X- _ O
spray -X- _ O
- -X- _ O
on -X- _ O
tan -X- _ O
does -X- _ O
someone -X- _ O
put -X- _ O
it -X- _ O
on -X- _ O
you -X- _ O
or -X- _ O
does -X- _ O
a -X- _ O
machine -X- _ O
do -X- _ O
it -X- _ O
? -X- _ O
" -X- _ O
CONCEPT -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
a -X- _ O
definition -X- _ O
of -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept.-"Who -X- _ O
said -X- _ O
the -X- _ O
sun -X- _ O
never -X- _ O
sets -X- _ O
on -X- _ O
the -X- _ O
British -X- _ O
empire -X- _ O
? -X- _ O
" -X- _ O
-"Where -X- _ O
do -X- _ O
dolphins -X- _ O
have -X- _ O
hair -X- _ O
at -X- _ O
? -X- _ O
" -X- _ O
-"What -X- _ O
is -X- _ O
the -X- _ O
origin -X- _ O
of -X- _ O
the -X- _ O
phrase -X- _ O
" -X- _ O
kicking -X- _ O
the -X- _ O
bucket -X- _ O
" -X- _ O
? -X- _ O
" -X- _ O
EXTENT -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
the -X- _ O
extent -X- _ O
or -X- _ O
quantity -X- _ O
of -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept.-"How -X- _ O
long -X- _ O
does -X- _ O
gum -X- _ O
stay -X- _ O
in -X- _ O
your -X- _ O
system -X- _ O
? -X- _ O
" -X- _ O
-"What -X- _ O
is -X- _ O
Barry -X- _ O
Larkin -X- _ O
's -X- _ O
hat -X- _ O
size -X- _ O
? -X- _ O
" -X- _ O
-"To -X- _ O
what -X- _ O
extent -X- _ O
is -X- _ O
the -X- _ O
Renewable -X- _ O
Fuel -X- _ O
Standard -X- _ O
accurate -X- _ O
nationwide -X- _ O
? -X- _ O
" -X- _ O
EXAMPLE -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
example(s -X- _ O
) -X- _ O
or -X- _ O
instance(s -X- _ O
) -X- _ O
of -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept.-"What -X- _ O
are -X- _ O
some -X- _ O
examples -X- _ O
to -X- _ O
support -X- _ O
or -X- _ O
contradict -X- _ O
this -X- _ O
? -X- _ O
" -X- _ O
-"Where -X- _ O
can -X- _ O
I -X- _ O
get -X- _ O
my -X- _ O
teeth -X- _ O
examined -X- _ O
around -X- _ O
Los -X- _ O
Angeles -X- _ O
? -X- _ O
" -X- _ O
-"What -X- _ O
countries -X- _ O
/ -X- _ O
regions -X- _ O
throughout -X- _ O
the -X- _ O
world -X- _ O
do -X- _ O
not -X- _ O
celebrate -X- _ O
the -X- _ O
Christmas -X- _ O
holidays -X- _ O
? -X- _ O
" -X- _ O
-"What -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
goal -X- _ O
or -X- _ O
win -X- _ O
you -X- _ O
have -X- _ O
ever -X- _ O
made -X- _ O
in -X- _ O
a -X- _ O
sport -X- _ O
? -X- _ O
" -X- _ O
COMPARISON -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
comparison -X- _ O
among -X- _ O
multiple -X- _ O
events -X- _ O
or -X- _ O
concepts.-"How -X- _ O
does -X- _ O
an -X- _ O
electric -X- _ O
violin -X- _ O
" -X- _ O
play -X- _ O
" -X- _ O
differently -X- _ O
than -X- _ O
an -X- _ O
acoustic -X- _ O
violin -X- _ O
? -X- _ O
" -X- _ O
-"What -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
tinted -X- _ O
facial -X- _ O
moisturizer -X- _ O
? -X- _ O
" -X- _ O
-"In -X- _ O
what -X- _ O
hilariously -X- _ O
inaccurate -X- _ O
ways -X- _ O
is -X- _ O
your -X- _ O
job -X- _ O
/ -X- _ O
career -X- _ O
portrayed -X- _ O
on -X- _ O
television -X- _ O
or -X- _ O
in -X- _ O
movies -X- _ O
? -X- _ O
" -X- _ O
-"Which -X- _ O
is -X- _ O
better -X- _ O
, -X- _ O
Nike -X- _ O
or -X- _ O
Adidas -X- _ O
? -X- _ O
" -X- _ O
CAUSE -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
the -X- _ O
cause -X- _ O
or -X- _ O
reason -X- _ O
for -X- _ O
an -X- _ O
event -X- _ O
or -X- _ O
a -X- _ O
concept.-"How -X- _ O
does -X- _ O
the -X- _ O
D.M.V. -X- _ O
decide -X- _ O
the -X- _ O
first -X- _ O
letter -X- _ O
of -X- _ O
the -X- _ O
California -X- _ O
driver -X- _ O
's -X- _ O
license -X- _ O
? -X- _ O
" -X- _ O
-"Why -X- _ O
are -X- _ O
parents -X- _ O
strick -X- _ O
on -X- _ O
girls -X- _ O
than -X- _ O
boys -X- _ O
? -X- _ O
" -X- _ O
-"What -X- _ O
makes -X- _ O
nerve -X- _ O
agents -X- _ O
like -X- _ O
" -X- _ O
Novichok -X- _ O
" -X- _ O
so -X- _ O
hard -X- _ O
to -X- _ O
produce -X- _ O
and -X- _ O
why -X- _ O
can -X- _ O
only -X- _ O
a -X- _ O
handful -X- _ O
of -X- _ O
laboratories -X- _ O
create -X- _ O
them -X- _ O
? -X- _ O
" -X- _ O
" -X- _ O
Why -X- _ O
is -X- _ O
the -X- _ O
sky -X- _ O
blue -X- _ O
? -X- _ O
" -X- _ O
CONSEQUENCE -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
the -X- _ O
consequences -X- _ O
or -X- _ O
results -X- _ O
of -X- _ O
an -X- _ O
event.-"What -X- _ O
are -X- _ O
the -X- _ O
negative -X- _ O
consequences -X- _ O
for -X- _ O
the -X- _ O
services -X- _ O
if -X- _ O
they -X- _ O
do -X- _ O
not -X- _ O
evaluate -X- _ O
their -X- _ O
programs -X- _ O
? -X- _ O
" -X- _ O
-"In -X- _ O
the -X- _ O
US -X- _ O
, -X- _ O
what -X- _ O
is -X- _ O
the -X- _ O
benefit -X- _ O
of -X- _ O
having -X- _ O
a -X- _ O
red -X- _ O
left -X- _ O
- -X- _ O
turn -X- _ O
arrow -X- _ O
? -X- _ O
" -X- _ O
-"What -X- _ O
would -X- _ O
happen -X- _ O
if -X- _ O
employers -X- _ O
violate -X- _ O
the -X- _ O
legislation -X- _ O
? -X- _ O
" -X- _ O
-"What -X- _ O
if -X- _ O
the -X- _ O
Hokey -X- _ O
Pokey -X- _ O
is -X- _ O
really -X- _ O
what -X- _ O
it -X- _ O
's -X- _ O
all -X- _ O
about -X- _ O
? -X- _ O
" -X- _ O
PROCEDURAL -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
the -X- _ O
procedures -X- _ O
, -X- _ O
tools -X- _ O
, -X- _ O
or -X- _ O
methods -X- _ O
by -X- _ O
which -X- _ O
a -X- _ O
certain -X- _ O
outcome -X- _ O
is -X- _ O
achieved.-"Why -X- _ O
YM -X- _ O
7.5 -X- _ O
BETA -X- _ O
always -X- _ O
stupidly -X- _ O
shows -X- _ O
me -X- _ O
available -X- _ O
, -X- _ O
although -X- _ O
I -X- _ O
initially -X- _ O
set -X- _ O
it -X- _ O
to -X- _ O
invisible -X- _ O
? -X- _ O
" -X- _ O
-"How -X- _ O
did -X- _ O
the -X- _ O
Amish -X- _ O
resist -X- _ O
assimilation -X- _ O
into -X- _ O
the -X- _ O
current -X- _ O
social -X- _ O
status -X- _ O
in -X- _ O
the -X- _ O
U.S -X- _ O
? -X- _ O
" -X- _ O
-"How -X- _ O
astronomers -X- _ O
detect -X- _ O
a -X- _ O
nebula -X- _ O
when -X- _ O
there -X- _ O
are -X- _ O
no -X- _ O
stars -X- _ O
illuminating -X- _ O
it -X- _ O
? -X- _ O
" -X- _ O
JUDGMENTAL -X- _ O
: -X- _ O
Asking -X- _ O
for -X- _ O
the -X- _ O
opinions -X- _ O
of -X- _ O
the -X- _ O
answerer -X- _ O
's -X- _ O
own.-"Do -X- _ O
you -X- _ O
think -X- _ O
that -X- _ O
it -X- _ O
's -X- _ O
acceptable -X- _ O
to -X- _ O
call -X- _ O
off -X- _ O
work -X- _ O
for -X- _ O
a -X- _ O
dying -X- _ O
- -X- _ O
dead -X- _ O
pet -X- _ O
? -X- _ O
" -X- _ O
-"Should -X- _ O
I -X- _ O
date -X- _ O
a -X- _ O
guy -X- _ O
that -X- _ O
has -X- _ O
an -X- _ O
identical -X- _ O
twin -X- _ O
? -X- _ O
" -X- _ O
-"How -X- _ O
old -X- _ O
is -X- _ O
too -X- _ O
old -X- _ O
for -X- _ O
a -X- _ O
guy -X- _ O
to -X- _ O
still -X- _ O
live -X- _ O
with -X- _ O
his -X- _ O
mother -X- _ O
? -X- _ O
" -X- _ O

While -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
abundance -X- _ O
of -X- _ O
popular -X- _ O
writing -X- _ O
targeted -X- _ O
to -X- _ O
podcast -X- _ O
creators -X- _ O
on -X- _ O
how -X- _ O
to -X- _ O
speak -X- _ O
in -X- _ O
ways -X- _ O
that -X- _ O
engage -X- _ O
their -X- _ O
listeners -X- _ O
, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
little -X- _ O
data -X- _ O
- -X- _ O
driven -X- _ O
analysis -X- _ O
of -X- _ O
podcasts -X- _ O
that -X- _ O
relates -X- _ O
linguistic -X- _ O
style -X- _ O
with -X- _ O
listener -X- _ O
engagement -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
how -X- _ O
various -X- _ O
factors -X- _ O
-vocabulary -X- _ O
diversity -X- _ O
, -X- _ O
distinctiveness -X- _ O
, -X- _ O
emotion -X- _ O
, -X- _ O
and -X- _ O
syntax -X- _ O
, -X- _ O
among -X- _ O
others -X- _ O
-correlate -X- _ O
with -X- _ O
engagement -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
creators -X- _ O
' -X- _ O
written -X- _ O
descriptions -X- _ O
and -X- _ O
transcripts -X- _ O
of -X- _ O
the -X- _ O
audio -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
models -X- _ O
with -X- _ O
different -X- _ O
textual -X- _ O
representations -X- _ O
, -X- _ O
and -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
identified -X- _ O
features -X- _ O
are -X- _ O
highly -X- _ O
predictive -X- _ O
of -X- _ O
engagement -X- _ O
. -X- _ O
Our -X- _ O
analysis -X- _ O
tests -X- _ O
popular -X- _ O
wisdom -X- _ O
about -X- _ O
stylistic -X- _ O
elements -X- _ O
in -X- _ O
highengagement -X- _ O
podcasts -X- _ O
, -X- _ O
corroborating -X- _ O
some -X- _ O
aspects -X- _ O
, -X- _ O
and -X- _ O
adding -X- _ O
new -X- _ O
perspectives -X- _ O
on -X- _ O
others -X- _ O
. -X- _ O
What -X- _ O
makes -X- _ O
a -X- _ O
particular -X- _ O
podcast -X- _ O
broadly -X- _ O
engaging -X- _ O
? -X- _ O
As -X- _ O
a -X- _ O
media -X- _ O
form -X- _ O
, -X- _ O
podcasting -X- _ O
is -X- _ O
new -X- _ O
enough -X- _ O
that -X- _ O
such -X- _ O
questions -X- _ O
are -X- _ O
only -X- _ O
beginning -X- _ O
to -X- _ O
be -X- _ O
understood -X- _ O
. -X- _ O
Websites -X- _ O
exist -X- _ O
with -X- _ O
advice -X- _ O
on -X- _ O
podcast -X- _ O
production -X- _ O
, -X- _ O
including -X- _ O
language -X- _ O
- -X- _ O
related -X- _ O
tips -X- _ O
such -X- _ O
as -X- _ O
reducing -X- _ O
filler -X- _ O
words -X- _ O
and -X- _ O
disfluencies -X- _ O
, -X- _ O
or -X- _ O
incorporating -X- _ O
emotion -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
little -X- _ O
quantitative -X- _ O
research -X- _ O
into -X- _ O
how -X- _ O
aspects -X- _ O
of -X- _ O
language -X- _ O
usage -X- _ O
contribute -X- _ O
to -X- _ O
overall -X- _ O
listener -X- _ O
engagement -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
investigates -X- _ O
the -X- _ O
linguistic -X- _ O
factors -X- _ O
that -X- _ O
correlate -X- _ O
with -X- _ O
engagement -X- _ O
, -X- _ O
leveraging -X- _ O
the -X- _ O
written -X- _ O
descriptions -X- _ O
of -X- _ O
the -X- _ O
parent -X- _ O
show -X- _ O
and -X- _ O
episode -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
transcript -X- _ O
of -X- _ O
the -X- _ O
audio -X- _ O
. -X- _ O
Our -X- _ O
metric -X- _ O
of -X- _ O
engagement -X- _ O
is -X- _ O
stream -X- _ B-DatasetName
rate -X- _ I-DatasetName
, -X- _ O
which -X- _ O
we -X- _ O
define -X- _ O
as -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
first -X- _ O
- -X- _ O
time -X- _ O
listeners -X- _ O
-of -X- _ O
those -X- _ O
who -X- _ O
have -X- _ O
begun -X- _ O
streaming -X- _ O
the -X- _ O
episode -X- _ O
-who -X- _ O
listen -X- _ O
for -X- _ O
at -X- _ O
least -X- _ O
five -X- _ O
minutes -X- _ O
. -X- _ O
Notably -X- _ O
, -X- _ O
stream -X- _ O
rate -X- _ O
is -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
metric -X- _ O
of -X- _ O
popularity -X- _ B-MetricName
as -X- _ O
given -X- _ O
by -X- _ O
the -X- _ O
raw -X- _ O
number -X- _ O
of -X- _ O
streams -X- _ O
; -X- _ O
the -X- _ O
latter -X- _ O
is -X- _ O
inevitably -X- _ O
influenced -X- _ O
by -X- _ O
factors -X- _ O
unrelated -X- _ O
to -X- _ O
the -X- _ O
content -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
host -X- _ O
or -X- _ O
publisher -X- _ O
reputation -X- _ O
, -X- _ O
publicity -X- _ O
, -X- _ O
expo -X- _ O
- -X- _ O
sure -X- _ O
in -X- _ O
recommendations -X- _ O
and -X- _ O
search -X- _ O
engines -X- _ O
, -X- _ O
and -X- _ O
time -X- _ O
of -X- _ O
publication -X- _ O
, -X- _ O
whereas -X- _ O
a -X- _ O
listener -X- _ O
's -X- _ O
decision -X- _ O
to -X- _ O
continue -X- _ O
listening -X- _ O
for -X- _ O
as -X- _ O
long -X- _ O
as -X- _ O
five -X- _ O
minutes -X- _ O
is -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
influenced -X- _ O
by -X- _ O
the -X- _ O
content -X- _ O
. -X- _ O
We -X- _ O
perform -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
descriptive -X- _ O
tests -X- _ O
to -X- _ O
examine -X- _ O
differences -X- _ O
in -X- _ O
language -X- _ O
usage -X- _ O
between -X- _ O
high -X- _ O
and -X- _ O
low -X- _ O
engagement -X- _ O
podcasts -X- _ O
, -X- _ O
and -X- _ O
build -X- _ O
predictive -X- _ O
models -X- _ O
. -X- _ O
Our -X- _ O
tests -X- _ O
show -X- _ O
that -X- _ O
while -X- _ O
much -X- _ O
of -X- _ O
the -X- _ O
conventional -X- _ O
wisdom -X- _ O
on -X- _ O
engaging -X- _ O
podcasting -X- _ O
style -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
to -X- _ O
use -X- _ O
positive -X- _ O
language -X- _ O
) -X- _ O
bears -X- _ O
out -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
other -X- _ O
assumptions -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
to -X- _ O
speak -X- _ O
slowly -X- _ O
) -X- _ O
are -X- _ O
contradicted -X- _ O
and -X- _ O
deserve -X- _ O
a -X- _ O
closer -X- _ O
look -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
stylistic -X- _ O
features -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
correlated -X- _ O
with -X- _ O
engagement -X- _ O
for -X- _ O
podcasts -X- _ O
with -X- _ O
low -X- _ O
absolute -X- _ O
numbers -X- _ O
of -X- _ O
streams -X- _ O
than -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
popular -X- _ O
podcasts -X- _ O
, -X- _ O
suggesting -X- _ O
that -X- _ O
listeners -X- _ O
may -X- _ O
be -X- _ O
less -X- _ O
sensitive -X- _ O
to -X- _ O
style -X- _ O
in -X- _ O
podcasts -X- _ O
made -X- _ O
by -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
creators -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
identify -X- _ O
those -X- _ O
linguistic -X- _ O
factors -X- _ O
that -X- _ O
correlate -X- _ O
with -X- _ O
our -X- _ O
engagement -X- _ O
metric -X- _ O
across -X- _ O
the -X- _ O
popularity -X- _ O
spectrum -X- _ O
, -X- _ O
and -X- _ O
those -X- _ O
that -X- _ O
are -X- _ O
limited -X- _ O
to -X- _ O
podcasts -X- _ O
within -X- _ O
a -X- _ O
certain -X- _ O
popularity -X- _ O
range -X- _ O
. -X- _ O
Our -X- _ O
predictive -X- _ O
models -X- _ O
prove -X- _ O
that -X- _ O
stylistic -X- _ O
factors -X- _ O
alone -X- _ O
play -X- _ O
a -X- _ O
significant -X- _ O
role -X- _ O
in -X- _ O
determining -X- _ O
if -X- _ O
a -X- _ O
podcast -X- _ O
has -X- _ O
high -X- _ O
or -X- _ O
low -X- _ O
engagement -X- _ O
, -X- _ O
achieving -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
of -X- _ O
72 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
distinguishing -X- _ O
between -X- _ O
very -X- _ O
high -X- _ O
engagement -X- _ O
( -X- _ O
top -X- _ O
25 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
podcasts -X- _ O
by -X- _ O
stream -X- _ B-MetricName
rate -X- _ I-MetricName
in -X- _ O
the -X- _ O
corpus -X- _ O
) -X- _ O
and -X- _ O
very -X- _ O
low -X- _ O
engagement -X- _ O
( -X- _ O
bottom -X- _ O
25 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
examples -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
overall -X- _ O
textual -X- _ O
information -X- _ O
in -X- _ O
podcasts -X- _ O
is -X- _ O
highly -X- _ O
predictive -X- _ O
of -X- _ O
engagement -X- _ O
in -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
accuracy -X- _ B-MetricName
as -X- _ O
high -X- _ O
as -X- _ O
81 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
To -X- _ O
understand -X- _ O
how -X- _ O
style -X- _ O
in -X- _ O
podcasts -X- _ O
compares -X- _ O
to -X- _ O
other -X- _ O
spoken -X- _ O
media -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
our -X- _ O
analysis -X- _ O
to -X- _ O
a -X- _ O
corpus -X- _ B-TaskName
of -X- _ I-TaskName
TED -X- _ I-TaskName
talks -X- _ I-TaskName
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
manually -X- _ O
examine -X- _ O
the -X- _ O
highest -X- _ O
engagement -X- _ O
podcasts -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
to -X- _ O
characterize -X- _ O
their -X- _ O
content -X- _ O
. -X- _ B-MethodName
Content -X- _ I-MethodName
- -X- _ I-MethodName
Based -X- _ I-MethodName
Podcast -X- _ I-MethodName
Recommendations -X- _ I-MethodName
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
model -X- _ O
transcripts -X- _ O
with -X- _ O
a -X- _ O
topic -X- _ B-MethodName
model -X- _ I-MethodName
, -X- _ O
and -X- _ O
the -X- _ O
audio -X- _ O
with -X- _ O
a -X- _ O
representation -X- _ O
they -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
textual -X- _ O
attributes -X- _ O
of -X- _ O
seriousness -X- _ O
and -X- _ O
energy -X- _ O
. -X- _ O
They -X- _ O
find -X- _ O
that -X- _ O
combining -X- _ O
these -X- _ O
representations -X- _ O
improves -X- _ O
over -X- _ O
the -X- _ O
purely -X- _ O
topic -X- _ O
based -X- _ O
model -X- _ O
on -X- _ O
popularity -X- _ B-TaskName
prediction -X- _ I-TaskName
. -X- _ O
This -X- _ O
work -X- _ O
indicates -X- _ O
that -X- _ O
stylistic -X- _ O
attributes -X- _ O
are -X- _ O
important -X- _ O
factors -X- _ O
, -X- _ O
and -X- _ O
raises -X- _ O
the -X- _ O
question -X- _ O
of -X- _ O
whether -X- _ O
stylistic -X- _ O
features -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
are -X- _ O
valuable -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
Tsagkias -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2010 -X- _ O
) -X- _ O
develop -X- _ O
a -X- _ O
framework -X- _ O
containing -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
attributes -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
the -X- _ O
proportions -X- _ O
of -X- _ O
these -X- _ O
attributes -X- _ O
relative -X- _ O
to -X- _ O
engagement -X- _ O
on -X- _ O
iTunes -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
follows -X- _ O
a -X- _ O
similar -X- _ O
spirit -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
address -X- _ O
some -X- _ O
limitations -X- _ O
of -X- _ O
their -X- _ O
study -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
they -X- _ O
use -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
podcasts -X- _ O
( -X- _ O
250 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
manually -X- _ O
annotate -X- _ O
the -X- _ O
attributes -X- _ O
for -X- _ O
every -X- _ O
podcast -X- _ O
rather -X- _ O
than -X- _ O
deriving -X- _ O
them -X- _ O
from -X- _ O
the -X- _ O
raw -X- _ O
data -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
derive -X- _ O
all -X- _ O
features -X- _ O
automatically -X- _ O
, -X- _ O
we -X- _ O
limit -X- _ O
ourselves -X- _ O
to -X- _ O
concrete -X- _ O
, -X- _ O
easily -X- _ O
quantifiable -X- _ O
features -X- _ O
, -X- _ O
whereas -X- _ O
the -X- _ O
above -X- _ O
paper -X- _ O
considers -X- _ O
higher -X- _ O
level -X- _ O
attributes -X- _ O
like -X- _ O
' -X- _ O
one -X- _ O
topic -X- _ O
per -X- _ O
episode -X- _ O
' -X- _ O
or -X- _ O
' -X- _ O
fluent' -X- _ O
. -X- _ O
Predicting -X- _ B-TaskName
Performance -X- _ I-TaskName
from -X- _ I-TaskName
Language -X- _ I-TaskName
Previous -X- _ O
research -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
has -X- _ O
explored -X- _ O
the -X- _ O
connections -X- _ O
between -X- _ O
textual -X- _ O
features -X- _ O
and -X- _ O
audience -X- _ O
engagement -X- _ O
in -X- _ O
books -X- _ O
( -X- _ O
Ganjigunte -X- _ O
Ashok -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013;Maharjan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
YouTube -X- _ O
( -X- _ O
Kleinberg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
news -X- _ O
( -X- _ O
Naseri -X- _ O
and -X- _ O
Zamani -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
TED -X- _ O
talks -X- _ O
( -X- _ O
Tanveer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
tweets -X- _ O
( -X- _ O
Tan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Lampos -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Other -X- _ O
works -X- _ O
have -X- _ O
modeled -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
text -X- _ O
and -X- _ O
various -X- _ O
performance -X- _ O
metrics -X- _ O
such -X- _ O
as -X- _ O
movie -X- _ O
quote -X- _ O
memorability -X- _ O
( -X- _ O
Danescu -X- _ O
- -X- _ O
Niculescu -X- _ O
- -X- _ O
Mizil -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
forecasting -X- _ O
ability -X- _ O
( -X- _ O
Zong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
congressional -X- _ O
bill -X- _ O
survival -X- _ O
( -X- _ O
Yano -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
success -X- _ O
of -X- _ O
job -X- _ O
interviews -X- _ O
( -X- _ O
Naim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
impact -X- _ O
of -X- _ O
academic -X- _ O
papers -X- _ O
( -X- _ O
Yogatama -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011;Li -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
entire -X- _ O
field -X- _ O
of -X- _ O
sentiment -X- _ B-TaskName
and -X- _ I-TaskName
opinion -X- _ I-TaskName
mining -X- _ I-TaskName
of -X- _ O
data -X- _ O
such -X- _ O
as -X- _ O
user -X- _ O
reviews -X- _ O
( -X- _ O
Pang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
Spotify -X- _ B-DatasetName
Podcast -X- _ I-DatasetName
Dataset -X- _ O
is -X- _ O
a -X- _ O
recently -X- _ O
released -X- _ O
corpus -X- _ O
of -X- _ O
over -X- _ O
100 -X- _ O
, -X- _ O
000 -X- _ O
podcast -X- _ O
episodes -X- _ O
, -X- _ O
mostly -X- _ O
in -X- _ O
English -X- _ O
, -X- _ O
that -X- _ O
are -X- _ O
transcribed -X- _ O
with -X- _ O
Google -X- _ B-MethodName
's -X- _ I-MethodName
Speech -X- _ I-MethodName
to -X- _ I-MethodName
Text -X- _ I-MethodName
commercial -X- _ I-MethodName
speech -X- _ I-MethodName
recognition -X- _ I-MethodName
, -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
to -X- _ O
have -X- _ O
an -X- _ O
18 -X- _ B-MetricValue
% -X- _ I-MetricValue
word -X- _ B-MetricName
error -X- _ I-MetricName
on -X- _ O
podcasts -X- _ O
. -X- _ O
A -X- _ O
podcast -X- _ O
, -X- _ O
also -X- _ O
known -X- _ O
as -X- _ O
a -X- _ O
' -X- _ O
show -X- _ O
' -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
episodes -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
speech -X- _ O
transcripts -X- _ O
, -X- _ O
the -X- _ O
textual -X- _ O
information -X- _ O
associated -X- _ O
with -X- _ O
each -X- _ O
podcast -X- _ O
episode -X- _ O
includes -X- _ O
the -X- _ O
title -X- _ O
and -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
episode -X- _ O
and -X- _ O
the -X- _ O
parent -X- _ O
show -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
descriptions -X- _ O
and -X- _ O
transcripts -X- _ O
as -X- _ O
the -X- _ O
text -X- _ O
representation -X- _ O
of -X- _ O
an -X- _ O
episode -X- _ O
. -X- _ O
All -X- _ O
textual -X- _ O
data -X- _ O
was -X- _ O
normalized -X- _ O
and -X- _ O
part -X- _ B-TaskName
- -X- _ I-TaskName
of -X- _ I-TaskName
- -X- _ I-TaskName
speech -X- _ I-TaskName
tagged -X- _ I-TaskName
with -X- _ O
spacy -X- _ O
. -X- _ O
1 -X- _ O
Since -X- _ O
many -X- _ O
episode -X- _ O
descriptions -X- _ O
contain -X- _ O
promotions -X- _ O
, -X- _ O
advertisements -X- _ O
, -X- _ O
and -X- _ O
show -X- _ O
notes -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
extraneous -X- _ O
to -X- _ O
the -X- _ O
main -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
podcast -X- _ O
, -X- _ O
we -X- _ O
remove -X- _ O
such -X- _ O
material -X- _ O
before -X- _ O
analysis -X- _ O
( -X- _ O
although -X- _ O
we -X- _ O
also -X- _ O
measure -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
ad -X- _ O
content -X- _ O
as -X- _ O
a -X- _ O
feature -X- _ O
) -X- _ O
. -X- _ O
2 -X- _ O
Promotional -X- _ O
and -X- _ O
extraneous -X- _ O
material -X- _ O
was -X- _ O
detected -X- _ O
by -X- _ O
the -X- _ O
classifier -X- _ O
described -X- _ O
by -X- _ O
, -X- _ O
a -X- _ O
model -X- _ O
using -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
a -X- _ O
classification -X- _ O
head -X- _ O
, -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
manually -X- _ O
annotated -X- _ O
set -X- _ O
of -X- _ O
episode -X- _ O
descriptions -X- _ O
. -X- _ O
This -X- _ O
classifier -X- _ O
is -X- _ O
reported -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
sentence -X- _ B-MetricName
classification -X- _ I-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
95 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
episode -X- _ O
descriptions -X- _ O
. -X- _ O
We -X- _ O
obtained -X- _ O
streaming -X- _ O
numbers -X- _ O
for -X- _ O
the -X- _ O
episodes -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
from -X- _ O
Spotify -X- _ O
, -X- _ O
a -X- _ O
music -X- _ O
and -X- _ O
podcast -X- _ O
streaming -X- _ O
platform -X- _ O
. -X- _ O
The -X- _ O
numbers -X- _ O
were -X- _ O
aggregated -X- _ O
from -X- _ O
the -X- _ O
date -X- _ O
of -X- _ O
the -X- _ O
episode -X- _ O
's -X- _ O
publication -X- _ O
on -X- _ O
the -X- _ O
platform -X- _ O
until -X- _ O
December -X- _ O
2020 -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
most -X- _ O
recently -X- _ O
published -X- _ O
episode -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
is -X- _ O
from -X- _ O
February -X- _ O
2020 -X- _ O
, -X- _ O
all -X- _ O
episodes -X- _ O
had -X- _ O
several -X- _ O
months -X- _ O
of -X- _ O
exposure -X- _ O
by -X- _ O
the -X- _ O
time -X- _ O
of -X- _ O
collection -X- _ O
. -X- _ O
We -X- _ O
specifically -X- _ O
consider -X- _ O
streaming -X- _ O
by -X- _ O
' -X- _ O
first -X- _ O
- -X- _ O
time -X- _ O
listeners -X- _ O
' -X- _ O
who -X- _ O
are -X- _ O
not -X- _ O
already -X- _ O
familiar -X- _ O
with -X- _ O
the -X- _ O
show -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
those -X- _ O
who -X- _ O
have -X- _ O
not -X- _ O
previously -X- _ O
streamed -X- _ O
any -X- _ O
other -X- _ O
episode -X- _ O
of -X- _ O
that -X- _ O
show -X- _ O
for -X- _ O
more -X- _ O
than -X- _ O
five -X- _ O
minutes -X- _ O
. -X- _ O
Listeners -X- _ O
who -X- _ O
are -X- _ O
familiar -X- _ O
with -X- _ O
the -X- _ O
show -X- _ O
through -X- _ O
other -X- _ O
episodes -X- _ O
are -X- _ O
ignored -X- _ O
since -X- _ O
they -X- _ O
may -X- _ O
be -X- _ O
habituated -X- _ O
and -X- _ O
primed -X- _ O
for -X- _ O
the -X- _ O
content -X- _ O
. -X- _ O
As -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
introduction -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
stream -X- _ B-MetricName
rate -X- _ I-MetricName
as -X- _ O
the -X- _ O
engagement -X- _ O
metric -X- _ O
, -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
the -X- _ O
show -X- _ O
's -X- _ O
first -X- _ O
- -X- _ O
time -X- _ O
listeners -X- _ O
who -X- _ O
stream -X- _ O
at -X- _ O
least -X- _ O
five -X- _ O
minutes -X- _ O
of -X- _ O
the -X- _ O
episode -X- _ O
. -X- _ O
Stream -X- _ B-MetricName
rate -X- _ I-MetricName
in -X- _ O
the -X- _ O
dataset -X- _ O
shows -X- _ O
a -X- _ O
weak -X- _ O
but -X- _ O
statistically -X- _ O
significant -X- _ O
inverse -X- _ O
rank -X- _ O
correlation -X- _ O
with -X- _ O
popularity -X- _ B-MetricName
( -X- _ O
Spearman -X- _ B-HyperparameterName
's -X- _ I-HyperparameterName
ρ -X- _ I-HyperparameterName
= -X- _ O
−0.12 -X- _ B-HyperparameterValue
, -X- _ O
p -X- _ B-HyperparameterName
< -X- _ O
0.001 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
because -X- _ O
popular -X- _ O
podcasts -X- _ O
attract -X- _ O
more -X- _ O
listeners -X- _ O
who -X- _ O
may -X- _ O
realize -X- _ O
they -X- _ O
are -X- _ O
not -X- _ O
interested -X- _ O
in -X- _ O
the -X- _ O
content -X- _ O
soon -X- _ O
after -X- _ O
they -X- _ O
begin -X- _ O
streaming -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
listeners -X- _ O
of -X- _ O
less -X- _ O
popular -X- _ O
podcasts -X- _ O
may -X- _ O
have -X- _ O
actively -X- _ O
sought -X- _ O
them -X- _ O
out -X- _ O
. -X- _ O
70 -X- _ B-MetricValue
% -X- _ I-MetricValue
stream -X- _ B-MetricName
rate -X- _ I-MetricName
in -X- _ O
a -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
podcast -X- _ O
which -X- _ O
A -X- _ O
weekly -X- _ O
podcast -X- _ O
covering -X- _ O
all -X- _ O
things -X- _ O
witchcraft -X- _ O
in -X- _ O
the -X- _ O
modern -X- _ O
world -X- _ O
. -X- _ O
Join -X- _ O
us -X- _ O
, -X- _ O
two -X- _ O
best -X- _ O
friends -X- _ O
and -X- _ O
Midwestern -X- _ O
witches -X- _ O
( -X- _ O
one -X- _ O
Wiccan -X- _ O
, -X- _ O
one -X- _ O
not -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
dive -X- _ O
into -X- _ O
all -X- _ O
things -X- _ O
witchy -X- _ O
. -X- _ O
We -X- _ O
're -X- _ O
starting -X- _ O
at -X- _ O
the -X- _ O
beginning -X- _ O
, -X- _ O
making -X- _ O
this -X- _ O
podcast -X- _ O
a -X- _ O
great -X- _ O
resource -X- _ O
for -X- _ O
newbies -X- _ O
... -X- _ O
would -X- _ O
have -X- _ O
attracted -X- _ O
a -X- _ O
broad -X- _ O
array -X- _ O
of -X- _ O
listeners -X- _ O
is -X- _ O
not -X- _ O
comparable -X- _ O
to -X- _ O
70 -X- _ B-MetricValue
% -X- _ I-MetricValue
stream -X- _ B-MetricName
rate -X- _ I-MetricName
in -X- _ O
a -X- _ O
relatively -X- _ O
unknown -X- _ O
podcast -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
bin -X- _ O
the -X- _ O
dataset -X- _ O
into -X- _ O
popularity -X- _ O
quartiles -X- _ O
for -X- _ O
analysis -X- _ O
on -X- _ O
stream -X- _ B-MetricName
rate -X- _ I-MetricName
, -X- _ O
which -X- _ O
is -X- _ O
found -X- _ O
to -X- _ O
be -X- _ O
uncorrelated -X- _ O
with -X- _ O
popularity -X- _ O
within -X- _ O
each -X- _ O
quartile -X- _ O
. -X- _ O
Stream -X- _ B-MetricName
rate -X- _ I-MetricName
is -X- _ O
uncorrelated -X- _ O
with -X- _ O
the -X- _ O
time -X- _ O
of -X- _ O
publication -X- _ O
. -X- _ O
We -X- _ O
filter -X- _ O
out -X- _ O
all -X- _ O
episodes -X- _ O
that -X- _ O
are -X- _ O
shorter -X- _ O
than -X- _ O
ten -X- _ O
minutes -X- _ O
and -X- _ O
fewer -X- _ O
than -X- _ O
a -X- _ O
threshold -X- _ O
number -X- _ O
of -X- _ O
total -X- _ O
streams -X- _ O
. -X- _ O
To -X- _ O
control -X- _ O
for -X- _ O
duration -X- _ O
effects -X- _ O
in -X- _ O
the -X- _ O
analysis -X- _ O
of -X- _ O
transcripts -X- _ O
, -X- _ O
we -X- _ O
truncate -X- _ O
transcripts -X- _ O
at -X- _ O
ten -X- _ B-HyperparameterValue
minutes -X- _ I-HyperparameterValue
. -X- _ O
The -X- _ O
original -X- _ O
podcast -X- _ O
corpus -X- _ O
contains -X- _ O
multiple -X- _ O
episodes -X- _ O
for -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
show -X- _ O
while -X- _ O
other -X- _ O
show -X- _ O
have -X- _ O
only -X- _ O
one -X- _ O
episode -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
the -X- _ O
moststreamed -X- _ O
episode -X- _ O
from -X- _ O
each -X- _ O
show -X- _ O
as -X- _ O
its -X- _ O
representative -X- _ O
, -X- _ O
thereby -X- _ O
ensuring -X- _ O
that -X- _ O
every -X- _ O
show -X- _ O
is -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
single -X- _ O
episode -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
done -X- _ O
so -X- _ O
that -X- _ O
shows -X- _ O
with -X- _ O
several -X- _ O
episodes -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
an -X- _ O
outsize -X- _ O
influence -X- _ O
on -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
original -X- _ O
corpus -X- _ O
is -X- _ O
an -X- _ O
English -X- _ O
- -X- _ O
language -X- _ O
collection -X- _ O
, -X- _ O
all -X- _ O
of -X- _ O
our -X- _ O
analysis -X- _ O
is -X- _ O
constrained -X- _ O
to -X- _ O
English -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
filter -X- _ O
out -X- _ O
any -X- _ O
stray -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
corpus -X- _ O
that -X- _ O
are -X- _ O
detected -X- _ O
as -X- _ O
non -X- _ O
- -X- _ O
English -X- _ O
after -X- _ O
running -X- _ B-TaskName
language -X- _ I-TaskName
identification -X- _ I-TaskName
( -X- _ O
Lui -X- _ O
and -X- _ O
Baldwin -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
descriptions -X- _ O
. -X- _ O
The -X- _ O
resulting -X- _ O
dataset -X- _ O
has -X- _ O
5371 -X- _ B-HyperparameterValue
episodes -X- _ O
. -X- _ O
The -X- _ O
norms -X- _ O
of -X- _ O
language -X- _ O
usage -X- _ O
may -X- _ O
vary -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
genre -X- _ O
and -X- _ O
topics -X- _ O
being -X- _ O
discussed -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
technical -X- _ O
podcasts -X- _ O
are -X- _ O
expected -X- _ O
to -X- _ O
contain -X- _ O
more -X- _ O
complex -X- _ O
language -X- _ O
compared -X- _ O
to -X- _ O
chit -X- _ O
- -X- _ O
chat -X- _ O
, -X- _ O
crime -X- _ O
podcasts -X- _ O
to -X- _ O
contain -X- _ O
words -X- _ O
with -X- _ O
negative -X- _ O
sentiments -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
motivational -X- _ O
podcasts -X- _ O
, -X- _ O
and -X- _ O
so -X- _ O
on -X- _ O
. -X- _ O
The -X- _ O
RSS -X- _ O
feed -X- _ O
of -X- _ O
a -X- _ O
podcast -X- _ O
show -X- _ O
contains -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
categories -X- _ O
selected -X- _ O
by -X- _ O
the -X- _ O
creators -X- _ O
from -X- _ O
the -X- _ O
Apple -X- _ O
iTunes -X- _ O
taxonomy -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
these -X- _ O
are -X- _ O
unreliable -X- _ O
, -X- _ O
since -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
categories -X- _ O
are -X- _ O
ambiguous -X- _ O
or -X- _ O
ill -X- _ O
- -X- _ O
defined -X- _ O
, -X- _ O
( -X- _ O
e.g. -X- _ O
' -X- _ O
Leisure -X- _ O
' -X- _ O
which -X- _ O
mainly -X- _ O
includes -X- _ O
gaming -X- _ O
podcasts -X- _ O
but -X- _ O
also -X- _ O
general -X- _ O
leisure -X- _ O
topics -X- _ O
, -X- _ O
' -X- _ O
Kids -X- _ O
& -X- _ O
Family -X- _ O
' -X- _ O
which -X- _ O
includes -X- _ O
podcasts -X- _ O
for -X- _ O
kids -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
about -X- _ O
parenting -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
podcast -X- _ O
creators -X- _ O
may -X- _ O
not -X- _ O
always -X- _ O
select -X- _ O
the -X- _ O
most -X- _ O
appropriate -X- _ O
categories -X- _ O
( -X- _ O
Sharpe -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
podcasts -X- _ O
span -X- _ O
multiple -X- _ O
themes -X- _ O
and -X- _ O
structures -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
assignment -X- _ O
of -X- _ O
one -X- _ O
or -X- _ O
two -X- _ O
categories -X- _ O
per -X- _ O
podcast -X- _ O
too -X- _ O
restrictive -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
fit -X- _ O
an -X- _ O
LDA -X- _ B-MethodName
topic -X- _ I-MethodName
model -X- _ O
( -X- _ O
Blei -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
with -X- _ O
100 -X- _ B-HyperparameterValue
topics -X- _ B-HyperparameterName
3 -X- _ O
to -X- _ O
transcripts -X- _ O
of -X- _ O
the -X- _ O
entire -X- _ O
100k -X- _ B-HyperparameterValue
podcast -X- _ O
corpus -X- _ O
as -X- _ O
in -X- _ O
previous -X- _ O
works -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
represent -X- _ O
each -X- _ O
episode -X- _ O
by -X- _ O
the -X- _ O
topic -X- _ O
distribution -X- _ O
, -X- _ O
and -X- _ O
measure -X- _ O
topic -X- _ O
proportions -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
metrics -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
contextualize -X- _ O
our -X- _ O
results -X- _ O
on -X- _ O
stylistic -X- _ O
features -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
a -X- _ O
sample -X- _ O
of -X- _ O
the -X- _ O
inferred -X- _ O
topics -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
explainable -X- _ O
linguistic -X- _ O
features -X- _ O
that -X- _ O
are -X- _ O
hypothesized -X- _ O
to -X- _ O
affect -X- _ O
engagement -X- _ O
. -X- _ O
These -X- _ O
features -X- _ O
have -X- _ O
been -X- _ O
drawn -X- _ O
from -X- _ O
different -X- _ O
podcasting -X- _ O
advice -X- _ O
blogs -X- _ O
, -X- _ O
alongside -X- _ O
some -X- _ O
of -X- _ O
our -X- _ O
own -X- _ O
intuitions -X- _ O
. -X- _ O
Length -X- _ B-HyperparameterName
Descriptions -X- _ I-HyperparameterName
are -X- _ O
known -X- _ O
to -X- _ O
be -X- _ O
important -X- _ O
for -X- _ O
listeners -X- _ O
on -X- _ O
their -X- _ O
first -X- _ O
encounter -X- _ O
with -X- _ O
the -X- _ O
pod -X- _ O
- -X- _ O
cast -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
measure -X- _ O
audio -X- _ B-HyperparameterName
duration -X- _ I-HyperparameterName
, -X- _ O
since -X- _ O
surveys -X- _ O
show -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
consideration -X- _ O
( -X- _ O
McLean -X- _ O
, -X- _ O
2020).Proportion -X- _ O
of -X- _ O
ads -X- _ O
and -X- _ O
show -X- _ O
notes -X- _ O
Descriptions -X- _ O
of -X- _ O
well -X- _ O
- -X- _ O
known -X- _ O
podcasts -X- _ O
tend -X- _ O
to -X- _ O
contain -X- _ O
advertisements -X- _ O
of -X- _ O
other -X- _ O
podcasts -X- _ O
made -X- _ O
by -X- _ O
the -X- _ O
same -X- _ O
network -X- _ O
, -X- _ O
links -X- _ O
to -X- _ O
the -X- _ O
hosts -X- _ O
' -X- _ O
or -X- _ O
guests -X- _ O
' -X- _ O
social -X- _ O
media -X- _ O
presence -X- _ O
and -X- _ O
websites -X- _ O
, -X- _ O
or -X- _ O
show -X- _ O
notes -X- _ O
and -X- _ O
transcripts -X- _ O
, -X- _ O
and -X- _ O
podcast -X- _ O
creators -X- _ O
are -X- _ O
often -X- _ O
advised -X- _ O
to -X- _ O
include -X- _ O
such -X- _ O
information -X- _ O
( -X- _ O
Dennis -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
surveys -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
podcast -X- _ O
listeners -X- _ O
do -X- _ O
not -X- _ O
mind -X- _ O
sponsor -X- _ O
ads -X- _ O
in -X- _ O
the -X- _ O
content -X- _ O
( -X- _ O
McLean -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
measure -X- _ O
the -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
text -X- _ O
detected -X- _ O
on -X- _ O
episode -X- _ O
descriptions -X- _ O
by -X- _ O
the -X- _ O
extraneous -X- _ O
content -X- _ O
classifier -X- _ O
described -X- _ O
in -X- _ O
§ -X- _ O
3.1 -X- _ O
. -X- _ O
The -X- _ O
proportion -X- _ O
of -X- _ O
ads -X- _ O
in -X- _ O
transcripts -X- _ O
is -X- _ O
given -X- _ O
by -X- _ O
a -X- _ O
manually -X- _ O
identified -X- _ B-MethodName
LDA -X- _ I-MethodName
topic -X- _ O
that -X- _ O
corresponds -X- _ O
to -X- _ O
words -X- _ O
indicative -X- _ O
of -X- _ O
ads -X- _ O
. -X- _ O
Faithfulness -X- _ O
of -X- _ O
episode -X- _ O
descriptions -X- _ O
to -X- _ O
transcripts -X- _ O
Length -X- _ O
is -X- _ O
a -X- _ O
weak -X- _ O
signal -X- _ O
of -X- _ O
informativeness -X- _ O
. -X- _ O
Do -X- _ O
listeners -X- _ O
seem -X- _ O
to -X- _ O
prefer -X- _ O
descriptions -X- _ O
that -X- _ O
accurately -X- _ O
convey -X- _ O
the -X- _ O
topics -X- _ O
and -X- _ O
synopsis -X- _ O
of -X- _ O
the -X- _ O
episode -X- _ O
? -X- _ O
We -X- _ O
measure -X- _ O
faithfulness -X- _ O
of -X- _ O
the -X- _ O
episode -X- _ O
description -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
ten -X- _ O
minutes -X- _ O
of -X- _ O
the -X- _ O
transcript -X- _ O
as -X- _ O
the -X- _ O
cosine -X- _ B-MethodName
similarity -X- _ I-MethodName
between -X- _ O
the -X- _ O
TF -X- _ B-MethodName
- -X- _ I-MethodName
IDF -X- _ I-MethodName
bag -X- _ I-MethodName
of -X- _ I-MethodName
words -X- _ I-MethodName
representation -X- _ O
of -X- _ O
both -X- _ O
texts -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
ground -X- _ O
- -X- _ O
truth -X- _ O
labels -X- _ O
to -X- _ O
evaluate -X- _ O
this -X- _ O
definition -X- _ O
of -X- _ O
faithfulness -X- _ O
, -X- _ O
we -X- _ O
assessed -X- _ O
it -X- _ O
to -X- _ O
be -X- _ O
a -X- _ O
good -X- _ O
heuristic -X- _ O
by -X- _ O
anecdotally -X- _ O
reviewing -X- _ O
some -X- _ O
examples -X- _ O
. -X- _ O
4 -X- _ O
Distinctiveness -X- _ O
Podcast -X- _ O
creators -X- _ O
are -X- _ O
often -X- _ O
encouraged -X- _ O
to -X- _ O
develop -X- _ O
a -X- _ O
distinctive -X- _ O
style -X- _ O
( -X- _ O
Gray -X- _ O
, -X- _ O
2021a -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
distinctiveness -X- _ O
as -X- _ O
the -X- _ O
perplexity -X- _ B-MetricName
of -X- _ O
the -X- _ O
given -X- _ O
text -X- _ O
under -X- _ O
a -X- _ O
unigram -X- _ B-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
trained -X- _ O
over -X- _ O
all -X- _ O
the -X- _ O
episodes -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
To -X- _ O
control -X- _ O
for -X- _ O
length -X- _ O
, -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
protocol -X- _ O
in -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
of -X- _ O
randomly -X- _ O
sampling -X- _ O
a -X- _ O
constant -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
from -X- _ O
each -X- _ O
text -X- _ O
and -X- _ O
taking -X- _ O
the -X- _ O
mean -X- _ B-MetricName
cross -X- _ I-MetricName
entropy -X- _ I-MetricName
over -X- _ O
a -X- _ O
few -X- _ O
samples -X- _ O
. -X- _ O
5 -X- _ O
Reading -X- _ O
Grade -X- _ O
Level -X- _ O
Similarly -X- _ O
to -X- _ O
Zong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
two -X- _ O
measurements -X- _ O
: -X- _ O
the -X- _ O
Flesch -X- _ B-MetricName
- -X- _ I-MetricName
Kincaid -X- _ I-MetricName
grade -X- _ I-MetricName
level -X- _ I-MetricName
( -X- _ O
Flesch -X- _ O
, -X- _ O
1948 -X- _ O
) -X- _ O
that -X- _ O
measures -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
syllables -X- _ O
per -X- _ O
word -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
words -X- _ O
per -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
Dale -X- _ B-MetricName
- -X- _ I-MetricName
Chall -X- _ I-MetricName
grade -X- _ I-MetricName
level -X- _ I-MetricName
( -X- _ O
Chall -X- _ O
and -X- _ O
Dale -X- _ O
, -X- _ O
1948 -X- _ O
) -X- _ O
which -X- _ O
measures -X- _ O
word -X- _ O
' -X- _ O
difficulty -X- _ O
' -X- _ O
using -X- _ O
a -X- _ O
lookup -X- _ O
table -X- _ O
. -X- _ O
While -X- _ O
caution -X- _ O
must -X- _ O
be -X- _ O
taken -X- _ O
on -X- _ O
interpreting -X- _ O
reading -X- _ O
grade -X- _ B-MetricName
level -X- _ I-MetricName
for -X- _ O
transcribed -X- _ O
speech -X- _ O
, -X- _ O
these -X- _ O
measures -X- _ O
have -X- _ O
been -X- _ O
explored -X- _ O
for -X- _ O
speech -X- _ O
in -X- _ O
prior -X- _ O
work -X- _ O
( -X- _ O
Schumacher -X- _ O
and -X- _ O
Eskenazi -X- _ O
, -X- _ O
2016).Vocabulary -X- _ O
Diversity -X- _ O
We -X- _ O
examine -X- _ O
whether -X- _ O
podcast -X- _ O
creators -X- _ O
of -X- _ O
high -X- _ O
engagement -X- _ O
podcasts -X- _ O
use -X- _ O
more -X- _ O
diverse -X- _ O
vocabularies -X- _ O
, -X- _ O
quantified -X- _ O
by -X- _ O
the -X- _ O
entropy -X- _ B-MetricName
of -X- _ O
the -X- _ O
unigram -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
motivated -X- _ O
by -X- _ O
advice -X- _ O
to -X- _ O
avoid -X- _ O
word -X- _ O
repetition -X- _ O
( -X- _ O
Bellis -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Popular -X- _ O
advice -X- _ O
often -X- _ O
encourages -X- _ O
podcast -X- _ O
creators -X- _ O
to -X- _ O
be -X- _ O
upbeat -X- _ O
and -X- _ O
positive -X- _ O
( -X- _ O
Briggman -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
NRC -X- _ B-DatasetName
Emotion -X- _ I-DatasetName
Lexicon -X- _ I-DatasetName
( -X- _ O
Mohammad -X- _ O
and -X- _ O
Turney -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
contains -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
sentiment -X- _ O
assignments -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
emotions -X- _ O
such -X- _ O
as -X- _ O
anger -X- _ O
, -X- _ O
trust -X- _ O
, -X- _ O
and -X- _ O
fear -X- _ O
, -X- _ O
for -X- _ O
14182 -X- _ O
words -X- _ O
. -X- _ O
6 -X- _ O
We -X- _ O
measure -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
words -X- _ O
associated -X- _ O
to -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
emotions -X- _ O
and -X- _ O
sentiments -X- _ O
. -X- _ O
Since -X- _ O
a -X- _ O
lexicon -X- _ O
lookup -X- _ O
for -X- _ O
sentiment -X- _ O
is -X- _ O
naturally -X- _ O
limited -X- _ O
in -X- _ O
that -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
account -X- _ O
for -X- _ O
compositionality -X- _ O
and -X- _ O
can -X- _ O
not -X- _ O
model -X- _ O
words -X- _ O
and -X- _ O
variants -X- _ O
that -X- _ O
are -X- _ O
missing -X- _ O
in -X- _ O
the -X- _ O
lexicon -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
apply -X- _ O
a -X- _ O
fullsentence -X- _ O
classifier -X- _ O
, -X- _ O
the -X- _ O
sentiment -X- _ O
model -X- _ O
from -X- _ O
the -X- _ O
Google -X- _ B-MethodName
Natural -X- _ I-MethodName
Language -X- _ I-MethodName
API -X- _ I-MethodName
7 -X- _ I-MethodName
. -X- _ O
The -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
classifier -X- _ O
is -X- _ O
a -X- _ O
score -X- _ O
between -X- _ O
+1 -X- _ O
and -X- _ O
−1 -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
polarities -X- _ O
for -X- _ O
each -X- _ O
text -X- _ O
as -X- _ O
as -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
with -X- _ O
highly -X- _ O
positive -X- _ O
( -X- _ O
over -X- _ O
+0.5 -X- _ O
) -X- _ O
or -X- _ O
highly -X- _ O
negative -X- _ O
( -X- _ O
under -X- _ O
−0.5 -X- _ O
) -X- _ O
scores -X- _ O
. -X- _ O
Syntax -X- _ O
Syntactic -X- _ O
features -X- _ O
are -X- _ O
measured -X- _ O
by -X- _ O
the -X- _ O
relative -X- _ O
frequencies -X- _ O
of -X- _ O
each -X- _ O
part -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
tag -X- _ O
. -X- _ O
While -X- _ O
previous -X- _ O
work -X- _ O
of -X- _ O
this -X- _ O
nature -X- _ O
finds -X- _ O
strong -X- _ O
effects -X- _ O
of -X- _ O
syntactic -X- _ O
patterns -X- _ O
from -X- _ O
parses -X- _ O
( -X- _ O
Ganjigunte -X- _ O
Ashok -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
noisy -X- _ O
speech -X- _ O
transcripts -X- _ O
result -X- _ O
in -X- _ O
particularly -X- _ O
noisy -X- _ O
parses -X- _ O
from -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
parsers -X- _ O
. -X- _ O
Swearing -X- _ O
and -X- _ O
fillers -X- _ O
We -X- _ O
conjecture -X- _ O
that -X- _ O
podcasts -X- _ O
with -X- _ O
swearing -X- _ O
and -X- _ O
adult -X- _ O
language -X- _ O
may -X- _ O
not -X- _ O
have -X- _ O
broad -X- _ O
appeal -X- _ O
. -X- _ O
Public -X- _ O
speaking -X- _ O
recommendations -X- _ O
in -X- _ O
podcasting -X- _ O
guides -X- _ O
( -X- _ O
Coips -X- _ O
and -X- _ O
Kramer -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
emphasize -X- _ O
the -X- _ O
reduction -X- _ O
of -X- _ O
filler -X- _ O
words -X- _ O
like -X- _ O
' -X- _ O
yeah -X- _ O
' -X- _ O
or -X- _ O
' -X- _ O
okay -X- _ O
' -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
professional -X- _ O
speech -X- _ O
. -X- _ O
We -X- _ O
attempted -X- _ O
to -X- _ O
manually -X- _ O
define -X- _ O
lexicons -X- _ O
of -X- _ O
these -X- _ O
types -X- _ O
of -X- _ O
categories -X- _ O
, -X- _ O
but -X- _ O
found -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
challenging -X- _ O
and -X- _ O
prone -X- _ O
to -X- _ O
human -X- _ O
biases -X- _ O
, -X- _ O
especially -X- _ O
given -X- _ O
the -X- _ O
novel -X- _ O
domain -X- _ O
and -X- _ O
automatic -X- _ O
transcripts -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
observation -X- _ O
that -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
topics -X- _ O
inferred -X- _ O
by -X- _ O
the -X- _ B-MethodName
LDA -X- _ I-MethodName
model -X- _ O
correspond -X- _ O
to -X- _ O
swear -X- _ O
words -X- _ O
and -X- _ O
filler -X- _ O
terms -X- _ O
, -X- _ O
and -X- _ O
measure -X- _ O
the -X- _ O
proportions -X- _ O
of -X- _ O
these -X- _ O
topics -X- _ O
. -X- _ O
Speech -X- _ O
Rate -X- _ O
and -X- _ O
Non -X- _ O
- -X- _ O
Speech -X- _ O
Time -X- _ O
Podcast -X- _ O
creators -X- _ O
are -X- _ O
often -X- _ O
encouraged -X- _ O
to -X- _ O
speak -X- _ O
slowly -X- _ O
, -X- _ O
since -X- _ O
novice -X- _ O
speakers -X- _ O
tend -X- _ O
to -X- _ O
rush -X- _ O
their -X- _ O
delivery -X- _ O
( -X- _ O
Gray -X- _ O
, -X- _ O
2021b -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
transcripts -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
contain -X- _ O
time -X- _ O
alignments -X- _ O
of -X- _ O
each -X- _ O
word -X- _ O
, -X- _ O
we -X- _ O
measure -X- _ O
the -X- _ O
duration -X- _ O
of -X- _ O
speech -X- _ O
segments -X- _ O
in -X- _ O
the -X- _ O
audio -X- _ O
, -X- _ O
giving -X- _ O
us -X- _ O
the -X- _ O
speech -X- _ O
rate -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
words -X- _ O
per -X- _ O
minute -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
measure -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
time -X- _ O
spent -X- _ O
on -X- _ O
non -X- _ O
- -X- _ O
speech -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
the -X- _ O
different -X- _ O
linguistic -X- _ O
features -X- _ O
by -X- _ O
comparing -X- _ O
group -X- _ O
means -X- _ O
between -X- _ O
the -X- _ O
top -X- _ O
and -X- _ O
bottom -X- _ O
25 -X- _ O
% -X- _ O
of -X- _ O
podcasts -X- _ O
by -X- _ O
engagement -X- _ O
within -X- _ O
each -X- _ O
popularity -X- _ O
quartile -X- _ O
( -X- _ O
approximately -X- _ O
335 -X- _ O
podcasts -X- _ O
per -X- _ O
group -X- _ O
) -X- _ O
with -X- _ O
bootstrapped -X- _ O
Welch -X- _ B-MethodName
's -X- _ I-MethodName
ttests -X- _ I-MethodName
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
group -X- _ O
mean -X- _ O
differences -X- _ O
of -X- _ B-MethodName
LDA -X- _ I-MethodName
topic -X- _ O
proportions -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
contextualize -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
features -X- _ O
. -X- _ O
For -X- _ O
LDA -X- _ B-MethodName
features -X- _ O
, -X- _ O
we -X- _ O
note -X- _ O
significance -X- _ O
after -X- _ O
a -X- _ O
Bonferroni -X- _ B-MetricName
correction -X- _ I-MetricName
of -X- _ I-MetricName
α -X- _ I-MetricName
= -X- _ O
0.05/100 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
linguistic -X- _ O
features -X- _ O
, -X- _ O
a -X- _ O
Bonferroni -X- _ B-HyperparameterName
correction -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
α -X- _ I-HyperparameterName
= -X- _ O
0.05/30.In -X- _ B-HyperparameterValue
the -X- _ O
results -X- _ O
, -X- _ O
' -X- _ O
description -X- _ O
' -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
show -X- _ O
description -X- _ O
and -X- _ O
the -X- _ O
representative -X- _ O
episode -X- _ O
's -X- _ O
description -X- _ O
. -X- _ O
When -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
effect -X- _ O
from -X- _ O
the -X- _ O
show -X- _ O
description -X- _ O
but -X- _ O
not -X- _ O
the -X- _ O
episode -X- _ O
's -X- _ O
or -X- _ O
vice -X- _ O
versa -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
explicitly -X- _ O
identified -X- _ O
as -X- _ O
such -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
podcasts -X- _ O
in -X- _ O
the -X- _ O
top -X- _ O
popularity -X- _ O
quartile -X- _ O
, -X- _ O
high -X- _ O
engagement -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
topics -X- _ O
around -X- _ O
lifestyle -X- _ O
and -X- _ O
culture -X- _ O
, -X- _ O
mental -X- _ O
health -X- _ O
, -X- _ O
spirituality -X- _ O
, -X- _ O
and -X- _ O
crime -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
the -X- _ O
lower -X- _ O
popularity -X- _ O
quartiles -X- _ O
, -X- _ O
high -X- _ O
engagement -X- _ O
podcasts -X- _ O
include -X- _ O
those -X- _ O
about -X- _ O
investing -X- _ O
, -X- _ O
working -X- _ O
out -X- _ O
, -X- _ O
careers -X- _ O
, -X- _ O
business -X- _ O
, -X- _ O
parenting -X- _ O
, -X- _ O
health -X- _ O
, -X- _ O
art -X- _ O
, -X- _ O
and -X- _ O
relationships -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
features -X- _ O
with -X- _ O
significant -X- _ O
differences -X- _ O
across -X- _ O
between -X- _ O
the -X- _ O
high -X- _ O
and -X- _ O
low -X- _ O
engagement -X- _ O
groups -X- _ O
. -X- _ O
We -X- _ O
review -X- _ O
the -X- _ O
main -X- _ O
takeaways -X- _ O
from -X- _ O
these -X- _ O
results -X- _ O
. -X- _ O
High -X- _ O
engagement -X- _ O
podcasts -X- _ O
are -X- _ O
longer -X- _ O
, -X- _ O
and -X- _ O
have -X- _ O
appropriate -X- _ O
descriptions -X- _ O
Across -X- _ O
all -X- _ O
quartiles -X- _ O
, -X- _ O
podcasts -X- _ O
with -X- _ O
high -X- _ O
engagement -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
longer -X- _ O
on -X- _ O
the -X- _ O
whole -X- _ O
( -X- _ O
contrary -X- _ O
to -X- _ O
advice -X- _ O
to -X- _ O
keep -X- _ O
episodes -X- _ O
short -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
contain -X- _ O
less -X- _ O
non -X- _ O
- -X- _ O
speech -X- _ O
in -X- _ O
the -X- _ O
first -X- _ O
ten -X- _ O
minutes -X- _ O
than -X- _ O
the -X- _ O
low -X- _ O
engagement -X- _ O
group -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
have -X- _ O
descriptions -X- _ O
that -X- _ O
are -X- _ O
more -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
ten -X- _ O
minutes -X- _ O
of -X- _ O
the -X- _ O
transcripts -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
because -X- _ O
long -X- _ O
, -X- _ O
faithful -X- _ O
descriptions -X- _ O
better -X- _ O
prepare -X- _ O
listeners -X- _ O
for -X- _ O
the -X- _ O
episode -X- _ O
. -X- _ O
The -X- _ O
correlation -X- _ O
between -X- _ O
ads -X- _ O
and -X- _ O
engagement -X- _ O
is -X- _ O
mixed -X- _ O
Large -X- _ O
amounts -X- _ O
of -X- _ O
ads -X- _ O
in -X- _ O
transcripts -X- _ O
are -X- _ O
associated -X- _ O
with -X- _ O
lower -X- _ O
engagement -X- _ O
in -X- _ O
all -X- _ O
but -X- _ O
the -X- _ O
bottom -X- _ O
popularity -X- _ O
quartile -X- _ O
. -X- _ O
While -X- _ O
this -X- _ O
may -X- _ O
be -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
many -X- _ O
listeners -X- _ O
skip -X- _ O
over -X- _ O
ads -X- _ O
in -X- _ O
the -X- _ O
audio -X- _ O
stream -X- _ O
, -X- _ O
the -X- _ O
effect -X- _ O
is -X- _ O
strong -X- _ O
enough -X- _ O
to -X- _ O
indicate -X- _ O
that -X- _ O
ads -X- _ O
seem -X- _ O
to -X- _ O
hurt -X- _ O
engagement -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
surveys -X- _ O
report -X- _ O
that -X- _ O
most -X- _ O
listeners -X- _ O
do -X- _ O
not -X- _ O
mind -X- _ O
ads -X- _ O
. -X- _ O
The -X- _ O
negative -X- _ O
association -X- _ O
could -X- _ O
be -X- _ O
a -X- _ O
result -X- _ O
of -X- _ O
our -X- _ O
dataset -X- _ O
being -X- _ O
constrained -X- _ O
to -X- _ O
first -X- _ O
- -X- _ O
time -X- _ O
listeners -X- _ O
; -X- _ O
further -X- _ O
analysis -X- _ O
needs -X- _ O
to -X- _ O
be -X- _ O
done -X- _ O
to -X- _ O
understand -X- _ O
if -X- _ O
it -X- _ O
holds -X- _ O
of -X- _ O
returning -X- _ O
listeners -X- _ O
. -X- _ O
Ads -X- _ O
in -X- _ O
episode -X- _ O
descriptions -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
do -X- _ O
not -X- _ O
hurt -X- _ O
engagement -X- _ O
on -X- _ O
the -X- _ O
whole -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
fact -X- _ O
, -X- _ O
are -X- _ O
associated -X- _ O
with -X- _ O
higher -X- _ O
engagement -X- _ O
in -X- _ O
the -X- _ O
top -X- _ O
quartile -X- _ O
, -X- _ O
likely -X- _ O
because -X- _ O
much -X- _ O
of -X- _ O
the -X- _ O
detected -X- _ O
' -X- _ O
ad -X- _ O
' -X- _ O
content -X- _ O
in -X- _ O
popular -X- _ O
podcasts -X- _ O
consists -X- _ O
of -X- _ O
promotional -X- _ O
material -X- _ O
about -X- _ O
the -X- _ O
podcast -X- _ O
itself -X- _ O
, -X- _ O
which -X- _ O
often -X- _ O
includes -X- _ O
useful -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
links -X- _ O
to -X- _ O
the -X- _ O
hosts -X- _ O
' -X- _ O
websites -X- _ O
and -X- _ O
show -X- _ O
notes -X- _ O
. -X- _ O
High -X- _ O
engagement -X- _ O
podcasts -X- _ O
tend -X- _ O
to -X- _ O
use -X- _ O
diverse -X- _ O
and -X- _ O
mainstream -X- _ O
language -X- _ O
Vocabulary -X- _ O
diversity -X- _ O
in -X- _ O
descriptions -X- _ O
and -X- _ O
transcripts -X- _ O
is -X- _ O
consistently -X- _ O
larger -X- _ O
in -X- _ O
the -X- _ O
high -X- _ O
engagement -X- _ O
group -X- _ O
, -X- _ O
as -X- _ O
is -X- _ O
reading -X- _ O
grade -X- _ O
level -X- _ O
. -X- _ O
High -X- _ O
engagement -X- _ O
podcasts -X- _ O
have -X- _ O
more -X- _ O
punctuation -X- _ O
in -X- _ O
their -X- _ O
descriptions -X- _ O
and -X- _ O
more -X- _ O
conjunctions -X- _ O
( -X- _ O
arising -X- _ O
from -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
long -X- _ O
sentences -X- _ O
) -X- _ O
, -X- _ O
adverbs -X- _ O
, -X- _ O
adpositions -X- _ O
, -X- _ O
and -X- _ O
determiners -X- _ O
in -X- _ O
their -X- _ O
transcripts -X- _ O
. -X- _ O
These -X- _ O
syntactic -X- _ O
features -X- _ O
correlate -X- _ O
with -X- _ O
the -X- _ O
topics -X- _ O
such -X- _ O
as -X- _ O
culture -X- _ O
, -X- _ O
mental -X- _ O
health -X- _ O
, -X- _ O
investing -X- _ O
, -X- _ O
and -X- _ O
art -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
surprisingly -X- _ O
, -X- _ O
high -X- _ O
engagement -X- _ O
podcasts -X- _ O
use -X- _ O
less -X- _ O
distinctive -X- _ O
language -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
corpus -X- _ O
than -X- _ O
the -X- _ O
low -X- _ O
engagement -X- _ O
group -X- _ O
. -X- _ O
On -X- _ O
closer -X- _ O
examination -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
podcasts -X- _ O
scoring -X- _ O
low -X- _ O
on -X- _ O
reading -X- _ O
grade -X- _ O
level -X- _ O
also -X- _ O
score -X- _ O
high -X- _ O
on -X- _ O
distinctiveness -X- _ O
. -X- _ O
High -X- _ O
engagement -X- _ O
podcasts -X- _ O
tend -X- _ O
to -X- _ O
contain -X- _ O
positive -X- _ O
sentiments -X- _ O
and -X- _ O
suspense -X- _ O
On -X- _ O
the -X- _ O
whole -X- _ O
, -X- _ O
high -X- _ O
engagement -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
more -X- _ O
positive -X- _ O
and -X- _ O
less -X- _ O
negative -X- _ O
emotions -X- _ O
and -X- _ O
sentiment -X- _ O
. -X- _ O
This -X- _ O
relationship -X- _ O
is -X- _ O
stronger -X- _ O
outside -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
popularity -X- _ O
quartile -X- _ O
. -X- _ O
A -X- _ O
notable -X- _ O
exception -X- _ O
is -X- _ O
' -X- _ O
fear -X- _ O
' -X- _ O
in -X- _ O
the -X- _ O
top -X- _ O
popularity -X- _ O
quartile -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
explained -X- _ O
by -X- _ O
the -X- _ O
high -X- _ O
engagement -X- _ O
of -X- _ O
popular -X- _ O
crime -X- _ O
- -X- _ O
related -X- _ O
podcasts -X- _ O
. -X- _ O
High -X- _ O
engagement -X- _ O
podcasts -X- _ O
are -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
contain -X- _ O
interjections -X- _ O
and -X- _ O
swearing -X- _ O
As -X- _ O
expected -X- _ O
, -X- _ O
words -X- _ O
such -X- _ O
as -X- _ O
' -X- _ O
oh -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
right -X- _ O
' -X- _ O
, -X- _ O
and -X- _ O
' -X- _ O
cool -X- _ O
' -X- _ O
in -X- _ O
contexts -X- _ O
that -X- _ O
the -X- _ O
tagger -X- _ O
infers -X- _ O
as -X- _ O
interjections -X- _ O
are -X- _ O
significantly -X- _ O
less -X- _ O
likely -X- _ O
to -X- _ O
occur -X- _ O
in -X- _ O
high -X- _ O
engagement -X- _ O
podcasts -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
swearing -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
low -X- _ O
engagement -X- _ O
. -X- _ O
Filler -X- _ O
words -X- _ O
are -X- _ O
only -X- _ O
negatively -X- _ O
associated -X- _ O
with -X- _ O
engagement -X- _ O
in -X- _ O
the -X- _ O
lowest -X- _ O
popularity -X- _ O
quartile -X- _ O
, -X- _ O
though -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
correlation -X- _ O
in -X- _ O
other -X- _ O
quartiles -X- _ O
could -X- _ O
be -X- _ O
because -X- _ O
the -X- _ B-MethodName
LDA -X- _ I-MethodName
topics -X- _ O
representing -X- _ O
fillers -X- _ O
do -X- _ O
n't -X- _ O
model -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
do -X- _ O
not -X- _ O
capture -X- _ O
their -X- _ O
discourse -X- _ O
function -X- _ O
in -X- _ O
the -X- _ O
way -X- _ O
the -X- _ O
tagger -X- _ O
does -X- _ O
for -X- _ O
interjections -X- _ O
. -X- _ O
High -X- _ O
engagement -X- _ O
podcast -X- _ O
creators -X- _ O
tend -X- _ O
to -X- _ O
speak -X- _ O
relatively -X- _ O
fast -X- _ O
While -X- _ O
popular -X- _ O
advice -X- _ O
warns -X- _ O
presenters -X- _ O
against -X- _ O
rushing -X- _ O
their -X- _ O
speech -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
indicates -X- _ O
that -X- _ O
on -X- _ O
average -X- _ O
, -X- _ O
high -X- _ O
engagement -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
high -X- _ O
speech -X- _ O
rates -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
also -X- _ O
a -X- _ O
finding -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
( -X- _ O
Tsagkias -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
classifiers -X- _ O
to -X- _ O
automatically -X- _ O
distinguish -X- _ O
high -X- _ O
and -X- _ O
low -X- _ O
engagement -X- _ O
podcasts -X- _ O
. -X- _ O
The -X- _ O
prediction -X- _ O
task -X- _ O
is -X- _ O
treated -X- _ O
as -X- _ O
a -X- _ O
balanced -X- _ O
binary -X- _ O
classification -X- _ O
problem -X- _ O
. -X- _ O
We -X- _ O
make -X- _ O
a -X- _ O
single -X- _ O
dataset -X- _ O
for -X- _ O
podcasts -X- _ O
across -X- _ O
all -X- _ O
quartiles -X- _ O
by -X- _ O
aggregating -X- _ O
the -X- _ O
top -X- _ O
and -X- _ O
bottom -X- _ O
K% -X- _ O
podcasts -X- _ O
by -X- _ O
stream -X- _ B-MetricName
rate -X- _ I-MetricName
within -X- _ O
each -X- _ O
quartile -X- _ O
. -X- _ O
This -X- _ O
aggregation -X- _ O
is -X- _ O
to -X- _ O
ensure -X- _ O
fair -X- _ O
comparisons -X- _ O
of -X- _ O
podcasts -X- _ O
in -X- _ O
different -X- _ O
quartiles -X- _ O
, -X- _ O
since -X- _ O
a -X- _ O
stream -X- _ B-MetricName
rate -X- _ I-MetricName
value -X- _ O
that -X- _ O
is -X- _ O
considered -X- _ O
high -X- _ O
for -X- _ O
a -X- _ O
popular -X- _ O
podcast -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
so -X- _ O
in -X- _ O
the -X- _ O
low -X- _ O
quartiles -X- _ O
. -X- _ O
Models -X- _ O
are -X- _ O
trained -X- _ O
and -X- _ O
evaluated -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
stratified -X- _ O
5 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
validation -X- _ O
splits -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
logistic -X- _ B-MethodName
regression -X- _ I-MethodName
classifiers -X- _ O
using -X- _ O
different -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
content -X- _ O
: -X- _ O
the -X- _ O
linguistic -X- _ O
features -X- _ O
listed -X- _ O
previously -X- _ O
, -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
stylistic -X- _ O
LDA -X- _ B-MethodName
topic -X- _ O
proportions -X- _ O
, -X- _ O
and -X- _ O
bag -X- _ B-MethodName
- -X- _ I-MethodName
of -X- _ I-MethodName
- -X- _ I-MethodName
ngrams -X- _ I-MethodName
( -X- _ O
unigram -X- _ O
and -X- _ O
bigram -X- _ O
words -X- _ O
) -X- _ O
with -X- _ O
TF -X- _ B-MethodName
- -X- _ I-MethodName
IDF -X- _ I-MethodName
scoring -X- _ I-MethodName
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
two -X- _ O
neural -X- _ O
classifiers -X- _ O
-a -X- _ O
feedforward -X- _ B-MethodName
neural -X- _ I-MethodName
network -X- _ I-MethodName
with -X- _ I-MethodName
a -X- _ I-MethodName
single -X- _ I-MethodName
hidden -X- _ I-MethodName
layer -X- _ I-MethodName
, -X- _ O
using -X- _ O
a -X- _ O
paragraph -X- _ O
vector -X- _ O
representation -X- _ O
( -X- _ O
Le -X- _ O
and -X- _ O
Mikolov -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
document -X- _ O
as -X- _ O
input -X- _ O
8 -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
uncased -X- _ O
English -X- _ O
model -X- _ O
9 -X- _ O
with -X- _ O
a -X- _ O
classification -X- _ O
head -X- _ O
, -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
linguistic -X- _ O
features -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
conduct -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
, -X- _ O
removing -X- _ O
one -X- _ O
group -X- _ O
of -X- _ O
features -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
to -X- _ O
estimate -X- _ O
their -X- _ O
contributions -X- _ O
to -X- _ O
predictive -X- _ O
performance -X- _ O
. -X- _ O
Prediction -X- _ O
accuracies -X- _ B-MetricName
( -X- _ O
Table -X- _ O
4 -X- _ O
) -X- _ O
are -X- _ O
over -X- _ O
70 -X- _ B-MetricValue
% -X- _ I-MetricValue
with -X- _ O
linguistic -X- _ O
features -X- _ O
only -X- _ O
, -X- _ O
indicating -X- _ O
that -X- _ O
the -X- _ O
features -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
identified -X- _ O
are -X- _ O
relatively -X- _ O
strong -X- _ O
predictors -X- _ O
of -X- _ O
engagement -X- _ O
. -X- _ O
The -X- _ O
reading -X- _ O
grade -X- _ O
level -X- _ O
of -X- _ O
descriptions -X- _ O
and -X- _ O
transcripts -X- _ O
makes -X- _ O
a -X- _ O
big -X- _ O
contribution -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
ablation -X- _ O
results -X- _ O
, -X- _ O
as -X- _ O
do -X- _ O
the -X- _ O
syntactic -X- _ O
features -X- _ O
on -X- _ O
transcripts -X- _ O
. -X- _ O
Analysis -X- _ O
of -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
bag -X- _ B-MethodName
of -X- _ I-MethodName
n -X- _ I-MethodName
- -X- _ I-MethodName
grams -X- _ I-MethodName
models -X- _ O
surface -X- _ O
patterns -X- _ O
in -X- _ O
language -X- _ O
usage -X- _ O
that -X- _ O
corroborate -X- _ O
our -X- _ O
analysis -X- _ O
on -X- _ O
linguistic -X- _ O
features -X- _ O
-swearing -X- _ O
and -X- _ O
negative -X- _ O
sentiment -X- _ O
is -X- _ O
predictive -X- _ O
of -X- _ O
low -X- _ O
engagement -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
suggest -X- _ O
subtle -X- _ O
dimensions -X- _ O
of -X- _ O
variation -X- _ O
to -X- _ O
complement -X- _ O
our -X- _ O
set -X- _ O
of -X- _ O
linguistic -X- _ O
features -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
collect -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
predictive -X- _ O
terms -X- _ O
and -X- _ O
manually -X- _ O
group -X- _ O
them -X- _ O
into -X- _ O
classes -X- _ O
. -X- _ O
First -X- _ O
or -X- _ O
second -X- _ O
person -X- _ O
pronouns -X- _ O
are -X- _ O
predictive -X- _ O
of -X- _ O
high -X- _ O
engagement -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
third -X- _ O
person -X- _ O
pronouns -X- _ O
. -X- _ O
This -X- _ O
aligns -X- _ O
with -X- _ O
the -X- _ O
finding -X- _ O
by -X- _ O
Tsagkias -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2010 -X- _ O
) -X- _ O
that -X- _ O
personal -X- _ O
experiences -X- _ O
are -X- _ O
favored -X- _ O
in -X- _ O
high -X- _ O
engagement -X- _ O
podcasts -X- _ O
. -X- _ O
While -X- _ O
fillers -X- _ O
exist -X- _ O
in -X- _ O
both -X- _ O
groups -X- _ O
, -X- _ O
the -X- _ O
specific -X- _ O
terms -X- _ O
used -X- _ O
are -X- _ O
different -X- _ O
, -X- _ O
with -X- _ O
' -X- _ O
kind -X- _ O
of -X- _ O
' -X- _ O
and -X- _ O
' -X- _ O
literally -X- _ O
' -X- _ O
being -X- _ O
predictive -X- _ O
of -X- _ O
high -X- _ O
engagement -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
' -X- _ O
um -X- _ O
' -X- _ O
and -X- _ O
' -X- _ O
but -X- _ O
like -X- _ O
' -X- _ O
. -X- _ O
The -X- _ O
conjunction -X- _ O
' -X- _ O
and -X- _ O
' -X- _ O
is -X- _ O
preferred -X- _ O
by -X- _ O
high -X- _ O
engagement -X- _ O
podcasts -X- _ O
over -X- _ O
' -X- _ O
but -X- _ O
' -X- _ O
, -X- _ O
and -X- _ O
' -X- _ O
so -X- _ O
' -X- _ O
over -X- _ O
' -X- _ O
because -X- _ O
' -X- _ O
. -X- _ O
Interrogative -X- _ O
words -X- _ O
are -X- _ O
more -X- _ O
predictive -X- _ O
of -X- _ O
high -X- _ O
engagement -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
' -X- _ O
which -X- _ O
' -X- _ O
, -X- _ O
as -X- _ O
are -X- _ O
open -X- _ O
- -X- _ O
ended -X- _ O
and -X- _ O
future -X- _ O
looking -X- _ O
terms -X- _ O
like -X- _ O
' -X- _ O
asking -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
explore -X- _ O
' -X- _ O
, -X- _ O
and -X- _ O
' -X- _ O
started -X- _ O
' -X- _ O
over -X- _ O
grounded -X- _ O
, -X- _ O
immediate -X- _ O
terms -X- _ O
like -X- _ O
' -X- _ O
make -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
use -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
today -X- _ O
' -X- _ O
, -X- _ O
and -X- _ O
' -X- _ O
quickly -X- _ O
' -X- _ O
. -X- _ O
We -X- _ O
emphasize -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
a -X- _ O
small -X- _ O
qualitative -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
predictive -X- _ O
features -X- _ O
, -X- _ O
and -X- _ O
High -X- _ O
engagement -X- _ O
he -X- _ O
, -X- _ O
she -X- _ O
, -X- _ O
they -X- _ O
, -X- _ O
his -X- _ O
, -X- _ O
her -X- _ O
, -X- _ O
him -X- _ O
, -X- _ O
it -X- _ O
me -X- _ O
, -X- _ O
you -X- _ O
, -X- _ O
us -X- _ O
, -X- _ O
we -X- _ O
, -X- _ O
my -X- _ O
, -X- _ O
our -X- _ O
, -X- _ O
their -X- _ O
, -X- _ O
myself -X- _ O
, -X- _ O
someone -X- _ O
um -X- _ O
, -X- _ O
gon -X- _ O
na -X- _ O
, -X- _ O
oh -X- _ O
, -X- _ O
like -X- _ O
like -X- _ O
, -X- _ O
because -X- _ O
like -X- _ O
, -X- _ O
but -X- _ O
like -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
, -X- _ O
okay -X- _ O
, -X- _ O
all -X- _ O
right -X- _ O
, -X- _ O
you -X- _ O
guys -X- _ O
, -X- _ O
basically -X- _ O
and -X- _ O
and -X- _ O
, -X- _ O
sort -X- _ O
of -X- _ O
, -X- _ O
kind -X- _ O
of -X- _ O
, -X- _ O
was -X- _ O
like -X- _ O
, -X- _ O
you -X- _ O
know -X- _ O
, -X- _ O
quite -X- _ O
, -X- _ O
literally -X- _ O
more -X- _ O
work -X- _ O
needs -X- _ O
to -X- _ O
done -X- _ O
to -X- _ O
establish -X- _ O
which -X- _ O
terms -X- _ O
are -X- _ O
actually -X- _ O
used -X- _ O
in -X- _ O
semantically -X- _ O
similar -X- _ O
contexts -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
explorations -X- _ O
of -X- _ O
computable -X- _ O
features -X- _ O
that -X- _ O
encode -X- _ O
these -X- _ O
aspects -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
whole -X- _ O
, -X- _ O
models -X- _ O
with -X- _ O
lexical -X- _ O
content -X- _ O
features -X- _ O
perform -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
linguistic -X- _ O
signals -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
expected -X- _ O
since -X- _ O
these -X- _ O
models -X- _ O
encode -X- _ O
more -X- _ O
information -X- _ O
than -X- _ O
a -X- _ O
small -X- _ O
set -X- _ O
of -X- _ O
hand -X- _ O
- -X- _ O
designed -X- _ O
features -X- _ O
. -X- _ O
The -X- _ O
BERT -X- _ B-MethodName
classifiers -X- _ O
achieve -X- _ O
nearly -X- _ O
81 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
, -X- _ O
indicating -X- _ O
that -X- _ O
podcast -X- _ O
content -X- _ O
is -X- _ O
highly -X- _ O
predictive -X- _ O
of -X- _ O
engagement -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
shows -X- _ O
how -X- _ O
classification -X- _ O
accuracies -X- _ O
change -X- _ O
when -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
distinguish -X- _ O
the -X- _ O
top -X- _ O
and -X- _ O
bottom -X- _ O
K% -X- _ O
podcasts -X- _ O
, -X- _ O
with -X- _ O
K -X- _ B-HyperparameterName
ranging -X- _ O
from -X- _ O
10 -X- _ B-HyperparameterValue
to -X- _ I-HyperparameterValue
50 -X- _ I-HyperparameterValue
( -X- _ O
all -X- _ O
reports -X- _ O
thus -X- _ O
far -X- _ O
have -X- _ O
been -X- _ O
with -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
25 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
Performance -X- _ O
drops -X- _ O
as -X- _ O
K -X- _ B-HyperparameterName
increases -X- _ O
( -X- _ O
and -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
sets -X- _ O
thereby -X- _ O
decreases -X- _ O
) -X- _ O
although -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
training -X- _ O
data -X- _ O
goes -X- _ O
up -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
language -X- _ O
usage -X- _ O
are -X- _ O
more -X- _ O
predictable -X- _ O
at -X- _ O
the -X- _ O
extremes -X- _ O
of -X- _ O
engagement -X- _ O
. -X- _ O
To -X- _ O
understand -X- _ O
how -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
linguistic -X- _ O
features -X- _ O
and -X- _ O
engagement -X- _ O
in -X- _ O
podcasts -X- _ O
compares -X- _ O
to -X- _ O
other -X- _ O
spoken -X- _ O
media -X- _ O
, -X- _ O
we -X- _ O
carry -X- _ O
out -X- _ O
the -X- _ O
same -X- _ O
analysis -X- _ O
on -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
2480 -X- _ O
talks -X- _ O
from -X- _ O
the -X- _ O
TED -X- _ O
Conferences -X- _ O
( -X- _ O
Tanveer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Acharyya -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
do -X- _ O
n't -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
stream -X- _ B-MetricName
rate -X- _ I-MetricName
of -X- _ O
the -X- _ O
lectures -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
includes -X- _ O
the -X- _ O
total -X- _ O
view -X- _ O
count -X- _ O
and -X- _ O
ratings -X- _ O
. -X- _ O
We -X- _ O
define -X- _ O
engagement -X- _ O
as -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
total -X- _ O
views -X- _ O
that -X- _ O
left -X- _ O
a -X- _ O
rating -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
rationale -X- _ O
that -X- _ O
the -X- _ O
act -X- _ O
of -X- _ O
leaving -X- _ O
a -X- _ O
rating -X- _ O
is -X- _ O
roughly -X- _ O
analogous -X- _ O
to -X- _ O
the -X- _ O
podcast -X- _ O
engagement -X- _ O
metric -X- _ O
of -X- _ O
listening -X- _ O
for -X- _ O
several -X- _ O
minutes -X- _ O
. -X- _ O
Another -X- _ O
point -X- _ O
of -X- _ O
difference -X- _ O
between -X- _ O
this -X- _ O
dataset -X- _ O
and -X- _ O
the -X- _ O
podcasts -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
TED -X- _ O
lectures -X- _ O
are -X- _ O
manually -X- _ O
transcribed -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
the -X- _ O
data -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
comparable -X- _ O
to -X- _ O
the -X- _ O
podcast -X- _ O
dataset -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
carry -X- _ O
out -X- _ O
the -X- _ O
experiment -X- _ O
to -X- _ O
try -X- _ O
to -X- _ O
identify -X- _ O
which -X- _ O
features -X- _ O
of -X- _ O
high -X- _ O
- -X- _ O
engagement -X- _ O
speech -X- _ O
may -X- _ O
be -X- _ O
universal -X- _ O
, -X- _ O
and -X- _ O
which -X- _ O
are -X- _ O
podcast -X- _ O
- -X- _ O
specific -X- _ O
. -X- _ O
We -X- _ O
test -X- _ O
the -X- _ O
same -X- _ O
features -X- _ O
that -X- _ O
we -X- _ O
formulated -X- _ O
for -X- _ O
podcasts -X- _ O
, -X- _ O
except -X- _ O
for -X- _ B-MethodName
LDA -X- _ I-MethodName
topic -X- _ O
distributions -X- _ O
( -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
small -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
TED -X- _ B-DatasetName
corpus -X- _ I-DatasetName
relative -X- _ O
to -X- _ O
the -X- _ O
full -X- _ O
100k+ -X- _ O
podcast -X- _ O
data -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ads -X- _ O
and -X- _ O
swear -X- _ O
words -X- _ O
since -X- _ O
these -X- _ O
occur -X- _ O
rarely -X- _ O
if -X- _ O
at -X- _ O
all -X- _ O
in -X- _ O
TED -X- _ O
talks -X- _ O
. -X- _ O
Table -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
group -X- _ O
means -X- _ O
differences -X- _ O
between -X- _ O
high -X- _ O
and -X- _ O
low -X- _ O
engagement -X- _ O
lectures -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
whole -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
fewer -X- _ O
significant -X- _ O
differences -X- _ O
, -X- _ O
because -X- _ O
either -X- _ O
the -X- _ O
TED -X- _ O
data -X- _ O
is -X- _ O
more -X- _ O
homogenous -X- _ O
than -X- _ O
podcasts -X- _ O
, -X- _ O
the -X- _ O
metric -X- _ O
is -X- _ O
n't -X- _ O
directly -X- _ O
indicative -X- _ O
of -X- _ O
engagement -X- _ O
, -X- _ O
or -X- _ O
the -X- _ O
features -X- _ O
that -X- _ O
we -X- _ O
designed -X- _ O
for -X- _ O
podcasts -X- _ O
do -X- _ O
n't -X- _ O
apply -X- _ O
as -X- _ O
much -X- _ O
for -X- _ O
TED -X- _ O
talks -X- _ O
. -X- _ O
Like -X- _ O
podcasts -X- _ O
, -X- _ O
higher -X- _ O
engagement -X- _ O
lectures -X- _ O
are -X- _ O
longer -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
longer -X- _ O
and -X- _ O
more -X- _ O
faithful -X- _ O
descrip- -X- _ O
tions -X- _ O
are -X- _ O
actually -X- _ O
associated -X- _ O
with -X- _ O
lower -X- _ O
engagement -X- _ O
. -X- _ O
Vocabulary -X- _ O
diversity -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
high -X- _ O
engagement -X- _ O
, -X- _ O
but -X- _ O
unlike -X- _ O
podcasts -X- _ O
, -X- _ O
high -X- _ O
engagement -X- _ O
lectures -X- _ O
have -X- _ O
lower -X- _ O
reading -X- _ O
grade -X- _ O
levels -X- _ O
. -X- _ O
Since -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
lecture -X- _ O
transcripts -X- _ O
measure -X- _ O
over -X- _ O
one -X- _ O
grade -X- _ O
level -X- _ O
higher -X- _ O
than -X- _ O
podcasts -X- _ O
, -X- _ O
it -X- _ O
could -X- _ O
be -X- _ O
that -X- _ O
after -X- _ O
a -X- _ O
point -X- _ O
, -X- _ O
simplicity -X- _ O
is -X- _ O
rewarded -X- _ O
. -X- _ O
Positive -X- _ O
emotions -X- _ O
are -X- _ O
more -X- _ O
significantly -X- _ O
associated -X- _ O
with -X- _ O
engagement -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
podcast -X- _ O
data -X- _ O
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
inspirational -X- _ O
nature -X- _ O
of -X- _ O
the -X- _ O
talks -X- _ O
and -X- _ O
the -X- _ O
relative -X- _ O
paucity -X- _ O
of -X- _ O
crime -X- _ O
- -X- _ O
related -X- _ O
content -X- _ O
( -X- _ O
and -X- _ O
in -X- _ O
fact -X- _ O
, -X- _ O
positive -X- _ O
sentiment -X- _ O
overall -X- _ O
is -X- _ O
more -X- _ O
prevalent -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
podcast -X- _ O
data -X- _ O
) -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
less -X- _ O
variation -X- _ O
in -X- _ O
syntactic -X- _ O
features -X- _ O
, -X- _ O
possibly -X- _ O
because -X- _ O
talks -X- _ O
are -X- _ O
scripted -X- _ O
and -X- _ O
follow -X- _ O
similar -X- _ O
templates -X- _ O
. -X- _ O
The -X- _ O
syntactic -X- _ O
features -X- _ O
with -X- _ O
correlations -X- _ O
tend -X- _ O
to -X- _ O
follow -X- _ O
similar -X- _ O
patterns -X- _ O
as -X- _ O
in -X- _ O
podcasts -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
prediction -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
up -X- _ O
to -X- _ O
71.15 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
Table -X- _ O
8) -X- _ O
accuracy -X- _ B-MetricName
using -X- _ O
only -X- _ O
linguistic -X- _ O
features -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
podcasts -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
bag -X- _ B-MethodName
- -X- _ I-MethodName
of -X- _ I-MethodName
- -X- _ I-MethodName
ngrams -X- _ I-MethodName
features -X- _ O
are -X- _ O
less -X- _ O
predictive -X- _ O
than -X- _ O
linguistic -X- _ O
features -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
only -X- _ O
matches -X- _ O
the -X- _ O
classifier -X- _ O
with -X- _ O
linguistic -X- _ O
features -X- _ O
rather -X- _ O
than -X- _ O
exceeding -X- _ O
it -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
be -X- _ O
because -X- _ O
there -X- _ O
is -X- _ O
n't -X- _ O
as -X- _ O
much -X- _ O
variation -X- _ O
in -X- _ O
topical -X- _ O
content -X- _ O
as -X- _ O
in -X- _ O
podcasts -X- _ O
. -X- _ O
Our -X- _ O
paper -X- _ O
centers -X- _ O
five -X- _ O
minute -X- _ O
stream -X- _ B-MetricName
rate -X- _ I-MetricName
as -X- _ O
the -X- _ O
target -X- _ O
metric -X- _ O
for -X- _ O
analysis -X- _ O
and -X- _ O
prediction -X- _ O
. -X- _ O
Systems -X- _ O
optimized -X- _ O
for -X- _ O
engagement -X- _ O
on -X- _ O
social -X- _ O
media -X- _ O
platforms -X- _ O
have -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
spread -X- _ O
misinformation -X- _ O
and -X- _ O
radical -X- _ O
content -X- _ O
( -X- _ O
Ribeiro -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
be -X- _ O
manipulated -X- _ O
by -X- _ O
bad -X- _ O
actors -X- _ O
( -X- _ O
Sehgal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
side -X- _ O
of -X- _ O
the -X- _ O
coin -X- _ O
, -X- _ O
studies -X- _ O
have -X- _ O
found -X- _ O
that -X- _ O
algorithms -X- _ O
driven -X- _ O
by -X- _ O
engagement -X- _ O
do -X- _ O
not -X- _ O
spread -X- _ O
false -X- _ O
news -X- _ O
at -X- _ O
a -X- _ O
higher -X- _ O
rate -X- _ O
than -X- _ O
true -X- _ O
news -X- _ O
( -X- _ O
Vosoughi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
under -X- _ O
certain -X- _ O
conditions -X- _ O
, -X- _ O
engagement -X- _ O
metrics -X- _ O
may -X- _ O
actually -X- _ O
reward -X- _ O
quality -X- _ O
content -X- _ O
( -X- _ O
Ciampaglia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).Aggregate -X- _ O
stream -X- _ B-MetricName
rate -X- _ I-MetricName
in -X- _ O
podcasts -X- _ O
is -X- _ O
a -X- _ O
specific -X- _ O
engagement -X- _ O
metric -X- _ O
distinct -X- _ O
from -X- _ O
metrics -X- _ O
and -X- _ O
media -X- _ O
in -X- _ O
previous -X- _ O
studies -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
limited -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
engagement -X- _ O
in -X- _ O
podcasts -X- _ O
. -X- _ O
Holtz -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
find -X- _ O
that -X- _ O
algorithms -X- _ O
driven -X- _ O
by -X- _ O
engagement -X- _ O
lead -X- _ O
to -X- _ O
less -X- _ O
diverse -X- _ O
recommendations -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
that -X- _ O
work -X- _ O
does -X- _ O
not -X- _ O
study -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
type -X- _ O
of -X- _ O
content -X- _ O
that -X- _ O
is -X- _ O
favored -X- _ O
by -X- _ O
the -X- _ O
engagement -X- _ O
metric -X- _ O
. -X- _ O
While -X- _ O
a -X- _ O
comprehensive -X- _ O
analysis -X- _ O
of -X- _ O
podcast -X- _ O
engagement -X- _ O
is -X- _ O
beyond -X- _ O
the -X- _ O
scope -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
manually -X- _ O
examine -X- _ O
the -X- _ O
top -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
podcast -X- _ O
episodes -X- _ O
by -X- _ O
engagement -X- _ O
in -X- _ O
our -X- _ O
collection -X- _ O
, -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
537 -X- _ O
episodes -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
noted -X- _ O
in -X- _ O
§ -X- _ O
5.1.1 -X- _ O
, -X- _ O
the -X- _ O
LDA -X- _ B-MethodName
topics -X- _ O
associated -X- _ O
with -X- _ O
high -X- _ O
engagement -X- _ O
are -X- _ O
broad -X- _ O
: -X- _ O
lifestyle -X- _ O
, -X- _ O
mental -X- _ O
health -X- _ O
, -X- _ O
spirituality -X- _ O
, -X- _ O
crime -X- _ O
, -X- _ O
investing -X- _ O
, -X- _ O
working -X- _ O
out -X- _ O
, -X- _ O
careers -X- _ O
, -X- _ O
business -X- _ O
, -X- _ O
parenting -X- _ O
, -X- _ O
health -X- _ O
, -X- _ O
art -X- _ O
, -X- _ O
and -X- _ O
relationships -X- _ O
. -X- _ O
Our -X- _ O
manual -X- _ O
audit -X- _ O
confirms -X- _ O
that -X- _ O
high -X- _ O
engagement -X- _ O
podcast -X- _ O
do -X- _ O
primarily -X- _ O
span -X- _ O
these -X- _ O
topics -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
find -X- _ O
any -X- _ O
episodes -X- _ O
containing -X- _ O
harmful -X- _ O
content -X- _ O
, -X- _ O
incendiary -X- _ O
language -X- _ O
, -X- _ O
or -X- _ O
politically -X- _ O
controversial -X- _ O
topics -X- _ O
in -X- _ O
this -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
that -X- _ O
while -X- _ O
the -X- _ O
connection -X- _ O
between -X- _ O
any -X- _ O
absolute -X- _ O
measure -X- _ O
of -X- _ O
intrinsic -X- _ O
quality -X- _ O
and -X- _ O
engagement -X- _ O
is -X- _ O
unknown -X- _ O
, -X- _ O
high -X- _ O
engagement -X- _ O
in -X- _ O
our -X- _ O
study -X- _ O
does -X- _ O
not -X- _ O
correspond -X- _ O
to -X- _ O
harmful -X- _ O
content -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
presents -X- _ O
the -X- _ O
first -X- _ O
quantitative -X- _ O
analysis -X- _ O
of -X- _ O
how -X- _ O
linguistic -X- _ O
style -X- _ O
and -X- _ O
textual -X- _ O
attributes -X- _ O
in -X- _ O
podcasts -X- _ O
relate -X- _ O
to -X- _ O
listener -X- _ O
engagement -X- _ O
using -X- _ O
automatically -X- _ O
computed -X- _ O
features -X- _ O
. -X- _ O
We -X- _ O
test -X- _ O
several -X- _ O
hypotheses -X- _ O
, -X- _ O
and -X- _ O
identify -X- _ O
factors -X- _ O
that -X- _ O
validate -X- _ O
popular -X- _ O
advice -X- _ O
on -X- _ O
podcast -X- _ O
creation -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
those -X- _ O
with -X- _ O
unexpected -X- _ O
correlations -X- _ O
. -X- _ O
Our -X- _ O
predictive -X- _ O
models -X- _ O
perform -X- _ O
well -X- _ O
at -X- _ O
distinguishing -X- _ O
high -X- _ O
and -X- _ O
low -X- _ O
engagement -X- _ O
podcasts -X- _ O
using -X- _ O
only -X- _ O
textual -X- _ O
information -X- _ O
. -X- _ O
Our -X- _ O
comparison -X- _ O
with -X- _ O
a -X- _ O
similar -X- _ O
task -X- _ O
on -X- _ O
TED -X- _ B-DatasetName
data -X- _ O
shows -X- _ O
similarities -X- _ O
and -X- _ O
differences -X- _ O
between -X- _ O
podcasts -X- _ O
and -X- _ O
public -X- _ O
lectures -X- _ O
vis -X- _ O
a -X- _ O
vis -X- _ O
engagement -X- _ O
. -X- _ O
Opportunities -X- _ O
for -X- _ O
future -X- _ O
research -X- _ O
include -X- _ O
the -X- _ O
investigation -X- _ O
of -X- _ O
other -X- _ O
podcast -X- _ O
creation -X- _ O
advice -X- _ O
based -X- _ O
on -X- _ O
paralinguistic -X- _ O
features -X- _ O
from -X- _ O
the -X- _ O
podcast -X- _ O
audio -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
pitch -X- _ O
and -X- _ O
intonation -X- _ O
) -X- _ O
, -X- _ O
speaker -X- _ O
identities -X- _ O
and -X- _ O
shifts -X- _ O
within -X- _ O
a -X- _ O
conversation -X- _ O
, -X- _ O
trajectories -X- _ O
of -X- _ O
linguistic -X- _ O
features -X- _ O
over -X- _ O
the -X- _ O
course -X- _ O
of -X- _ O
the -X- _ O
episode -X- _ O
, -X- _ O
and -X- _ O
models -X- _ O
using -X- _ O
manual -X- _ O
transcripts -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
dataset -X- _ O
consists -X- _ O
of -X- _ O
a -X- _ O
few -X- _ O
thousand -X- _ O
podcasts -X- _ O
, -X- _ O
uses -X- _ O
automatically -X- _ O
generated -X- _ O
transcripts -X- _ O
, -X- _ O
and -X- _ O
only -X- _ O
contains -X- _ O
podcasts -X- _ O
from -X- _ O
publishers -X- _ O
owned -X- _ O
or -X- _ O
operated -X- _ O
by -X- _ O
Spotify -X- _ O
, -X- _ O
care -X- _ O
must -X- _ O
be -X- _ O
taken -X- _ O
when -X- _ O
generalizing -X- _ O
from -X- _ O
these -X- _ O
results -X- _ O
to -X- _ O
deploying -X- _ O
automatic -X- _ O
recommendation -X- _ O
systems -X- _ O
, -X- _ O
or -X- _ O
advising -X- _ O
podcast -X- _ O
creators -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
aggregated -X- _ O
engagement -X- _ O
data -X- _ O
may -X- _ O
reflect -X- _ O
the -X- _ O
language -X- _ O
preferences -X- _ O
of -X- _ O
the -X- _ O
dominant -X- _ O
community -X- _ O
, -X- _ O
and -X- _ O
may -X- _ O
be -X- _ O
biased -X- _ O
against -X- _ O
minority -X- _ O
cultural -X- _ O
and -X- _ O
linguistic -X- _ O
subcommunities -X- _ O
. -X- _ O
While -X- _ O
this -X- _ O
dataset -X- _ O
lacks -X- _ O
self -X- _ O
- -X- _ O
identified -X- _ O
labels -X- _ O
on -X- _ O
demographics -X- _ O
and -X- _ O
sociolinguistic -X- _ O
identities -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
opportunities -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
( -X- _ O
in -X- _ O
either -X- _ O
podcasts -X- _ O
or -X- _ O
other -X- _ O
media -X- _ O
) -X- _ O
to -X- _ O
collect -X- _ O
these -X- _ O
selfidentifications -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
study -X- _ O
questions -X- _ O
such -X- _ O
as -X- _ O
disparities -X- _ O
in -X- _ O
automatic -X- _ O
speech -X- _ O
recognition -X- _ O
performance -X- _ O
by -X- _ O
race -X- _ O
or -X- _ O
gender -X- _ O
( -X- _ O
Koenecke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Tatman -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
whether -X- _ O
engagement -X- _ O
is -X- _ O
biased -X- _ O
towards -X- _ O
certain -X- _ O
dialects -X- _ O
. -X- _ O
This -X- _ O
paper -X- _ O
defined -X- _ O
a -X- _ O
specific -X- _ O
metric -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
the -X- _ O
rate -X- _ O
of -X- _ O
streaming -X- _ O
for -X- _ O
at -X- _ O
least -X- _ O
five -X- _ O
minutes -X- _ O
; -X- _ O
results -X- _ O
related -X- _ O
to -X- _ O
this -X- _ O
metric -X- _ O
may -X- _ O
or -X- _ O
may -X- _ O
not -X- _ O
apply -X- _ O
to -X- _ O
other -X- _ O
engagement -X- _ O
metrics -X- _ O
. -X- _ O
As -X- _ O
with -X- _ O
all -X- _ O
user -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
engagement -X- _ O
metric -X- _ O
is -X- _ O
influenced -X- _ O
by -X- _ O
the -X- _ O
interface -X- _ O
and -X- _ O
recommendations -X- _ O
of -X- _ O
the -X- _ O
streaming -X- _ O
platform -X- _ O
from -X- _ O
which -X- _ O
the -X- _ O
data -X- _ O
was -X- _ O
collected -X- _ O
, -X- _ O
and -X- _ O
may -X- _ O
not -X- _ O
translate -X- _ O
to -X- _ O
other -X- _ O
platforms -X- _ O
, -X- _ O
nor -X- _ O
reflect -X- _ O
an -X- _ O
objective -X- _ O
notion -X- _ O
of -X- _ O
listener -X- _ O
engagement -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
reiterate -X- _ O
( -X- _ O
from -X- _ O
§ -X- _ O
7 -X- _ O
) -X- _ O
that -X- _ O
listener -X- _ O
engagement -X- _ O
must -X- _ O
not -X- _ O
be -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
proxy -X- _ O
for -X- _ O
intrinsic -X- _ O
quality -X- _ O
or -X- _ O
success -X- _ O
. -X- _ O
It -X- _ O
must -X- _ O
also -X- _ O
be -X- _ O
emphasized -X- _ O
that -X- _ O
the -X- _ O
stylistic -X- _ O
associations -X- _ O
that -X- _ O
were -X- _ O
observed -X- _ O
to -X- _ O
distinguish -X- _ O
high -X- _ O
and -X- _ O
low -X- _ O
engagement -X- _ O
podcasts -X- _ O
in -X- _ O
this -X- _ O
particular -X- _ O
dataset -X- _ O
are -X- _ O
correlations -X- _ O
with -X- _ O
no -X- _ O
causality -X- _ O
established -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
must -X- _ O
be -X- _ O
interpreted -X- _ O
with -X- _ O
caution -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
Ann -X- _ O
Clifton -X- _ O
, -X- _ O
Bernd -X- _ O
Huber -X- _ O
, -X- _ O
Jussi -X- _ O
Karlgren -X- _ O
, -X- _ O
Mi -X- _ O
Tian -X- _ O
, -X- _ O
and -X- _ O
Zahra -X- _ O
Nazari -X- _ O
for -X- _ O
their -X- _ O
input -X- _ O
and -X- _ O
discussions -X- _ O
. -X- _ O

Automatic -X- _ B-TaskName
speech -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
ASR -X- _ B-TaskName
) -X- _ O
in -X- _ O
Sanskrit -X- _ O
is -X- _ O
interesting -X- _ O
, -X- _ O
owing -X- _ O
to -X- _ O
the -X- _ O
various -X- _ O
linguistic -X- _ O
peculiarities -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
. -X- _ O
The -X- _ O
Sanskrit -X- _ O
language -X- _ O
is -X- _ O
lexically -X- _ O
productive -X- _ O
, -X- _ O
undergoes -X- _ O
euphonic -X- _ O
assimilation -X- _ O
of -X- _ O
phones -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
boundaries -X- _ O
and -X- _ O
exhibits -X- _ O
variations -X- _ O
in -X- _ O
spelling -X- _ O
conventions -X- _ O
and -X- _ O
in -X- _ O
pronunciations -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
the -X- _ O
first -X- _ O
large -X- _ O
scale -X- _ O
study -X- _ O
of -X- _ O
automatic -X- _ B-TaskName
speech -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
ASR -X- _ B-TaskName
) -X- _ O
in -X- _ O
Sanskrit -X- _ O
, -X- _ O
with -X- _ O
an -X- _ O
emphasis -X- _ O
on -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
unit -X- _ O
selection -X- _ O
in -X- _ O
Sanskrit -X- _ O
ASR -X- _ B-TaskName
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
release -X- _ O
a -X- _ O
78 -X- _ O
hour -X- _ O
ASR -X- _ B-TaskName
dataset -X- _ O
for -X- _ O
Sanskrit -X- _ O
, -X- _ O
which -X- _ O
faithfully -X- _ O
captures -X- _ O
several -X- _ O
of -X- _ O
the -X- _ O
linguistic -X- _ O
characteristics -X- _ O
expressed -X- _ O
by -X- _ O
the -X- _ O
language -X- _ O
. -X- _ O
We -X- _ O
investigate -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
different -X- _ O
acoustic -X- _ O
model -X- _ O
and -X- _ O
language -X- _ O
model -X- _ O
units -X- _ O
in -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
for -X- _ O
Sanskrit -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
modelling -X- _ O
unit -X- _ O
, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
syllable -X- _ O
level -X- _ O
unit -X- _ O
selection -X- _ O
, -X- _ O
that -X- _ O
captures -X- _ O
character -X- _ O
sequences -X- _ O
from -X- _ O
one -X- _ O
vowel -X- _ O
in -X- _ O
the -X- _ O
word -X- _ O
to -X- _ O
the -X- _ O
next -X- _ O
vowel -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
choosing -X- _ O
graphemic -X- _ O
representations -X- _ O
for -X- _ O
Sanskrit -X- _ O
and -X- _ O
show -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
this -X- _ O
choice -X- _ O
on -X- _ O
word -X- _ B-MetricName
error -X- _ I-MetricName
rates -X- _ I-MetricName
( -X- _ O
WER -X- _ B-MetricName
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
these -X- _ O
insights -X- _ O
from -X- _ O
Sanskrit -X- _ O
ASR -X- _ B-TaskName
for -X- _ O
building -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
in -X- _ O
two -X- _ O
other -X- _ O
Indic -X- _ O
languages -X- _ O
, -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
these -X- _ O
languages -X- _ O
, -X- _ O
our -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
phonetic -X- _ O
based -X- _ O
graphemic -X- _ O
representations -X- _ O
in -X- _ O
ASR -X- _ B-TaskName
results -X- _ O
in -X- _ O
performance -X- _ O
improvements -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
that -X- _ O
use -X- _ O
native -X- _ O
scripts -X- _ O
. -X- _ O
1 -X- _ O
* -X- _ O
Joint -X- _ O
first -X- _ O
author -X- _ O
1 -X- _ O
Dataset -X- _ O
and -X- _ O
code -X- _ O
can -X- _ O
be -X- _ O
accessed -X- _ O
from -X- _ O
www.cse.iitb.ac.in/~asr -X- _ O
and -X- _ O
https://github -X- _ O
. -X- _ O
com -X- _ O
/ -X- _ O
cyfer0618 -X- _ O
/ -X- _ O
Vaksanca.git -X- _ O
. -X- _ O
Sanskrit -X- _ O
is -X- _ O
a -X- _ O
language -X- _ O
with -X- _ O
fairly -X- _ O
advanced -X- _ O
disciplines -X- _ O
of -X- _ O
phonetics -X- _ O
( -X- _ O
Śiks -X- _ O
̣ā -X- _ O
) -X- _ O
, -X- _ O
prosody -X- _ O
( -X- _ O
Chandas -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
grammar -X- _ O
( -X- _ O
Vyākaran -X- _ O
̣a -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
language -X- _ O
has -X- _ O
a -X- _ O
rich -X- _ O
oral -X- _ O
tradition -X- _ O
and -X- _ O
it -X- _ O
tends -X- _ O
to -X- _ O
follow -X- _ O
a -X- _ O
phonemic -X- _ O
- -X- _ O
orthography -X- _ O
resulting -X- _ O
in -X- _ O
systematic -X- _ O
grapheme -X- _ O
- -X- _ O
phoneme -X- _ O
correspondences -X- _ O
. -X- _ O
Connected -X- _ O
speech -X- _ O
leads -X- _ O
to -X- _ O
phonemic -X- _ O
transformations -X- _ O
in -X- _ O
utteracnes -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
Sanskrit -X- _ O
this -X- _ O
is -X- _ O
faithfully -X- _ O
preserved -X- _ O
in -X- _ O
writing -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
called -X- _ O
as -X- _ O
Sandhi -X- _ O
and -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
the -X- _ O
euphonic -X- _ O
assimilation -X- _ O
of -X- _ O
sounds -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
modification -X- _ O
and -X- _ O
fusion -X- _ O
of -X- _ O
sounds -X- _ O
, -X- _ O
at -X- _ O
or -X- _ O
across -X- _ O
the -X- _ O
boundaries -X- _ O
of -X- _ O
grammatical -X- _ O
units -X- _ O
( -X- _ O
Matthews -X- _ O
, -X- _ O
2007 -X- _ O
, -X- _ O
p. -X- _ O
353 -X- _ O
) -X- _ O
. -X- _ O
Phonemic -X- _ O
orthography -X- _ O
is -X- _ O
beneficial -X- _ O
for -X- _ O
a -X- _ O
language -X- _ O
, -X- _ O
when -X- _ O
it -X- _ O
comes -X- _ O
to -X- _ O
designing -X- _ O
automatic -X- _ B-TaskName
speech -X- _ I-TaskName
recognition -X- _ I-TaskName
Systems -X- _ O
( -X- _ O
ASR -X- _ B-TaskName
) -X- _ O
, -X- _ O
specifically -X- _ O
for -X- _ O
unit -X- _ O
selection -X- _ O
at -X- _ O
both -X- _ O
the -X- _ O
Acoustic -X- _ O
Model -X- _ O
( -X- _ O
AM -X- _ O
) -X- _ O
and -X- _ O
Language -X- _ O
Model -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O
levels -X- _ O
. -X- _ O
Regardless -X- _ O
of -X- _ O
the -X- _ O
aforementioned -X- _ O
commonalities -X- _ O
preserved -X- _ O
in -X- _ O
both -X- _ O
the -X- _ O
speech -X- _ O
and -X- _ O
text -X- _ O
in -X- _ O
Sanskrit -X- _ O
, -X- _ O
designing -X- _ O
a -X- _ O
large -X- _ O
scale -X- _ O
ASR -X- _ B-TaskName
system -X- _ O
raises -X- _ O
several -X- _ O
challenges -X- _ O
. -X- _ O
The -X- _ O
Unicode -X- _ O
encoding -X- _ O
for -X- _ O
the -X- _ O
native -X- _ O
scripts -X- _ O
in -X- _ O
Sanskrit -X- _ O
, -X- _ O
both -X- _ O
in -X- _ O
Roman -X- _ O
and -X- _ O
Devanāgari -X- _ O
, -X- _ O
does -X- _ O
not -X- _ O
preserve -X- _ O
the -X- _ O
correspondence -X- _ O
with -X- _ O
the -X- _ O
phonemic -X- _ O
encoding -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
mapping -X- _ O
the -X- _ O
graphemes -X- _ O
in -X- _ O
Unicode -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
phonemes -X- _ O
either -X- _ O
leads -X- _ O
to -X- _ O
ambiguity -X- _ O
and -X- _ O
redundancy -X- _ O
or -X- _ O
often -X- _ O
requires -X- _ O
multi -X- _ O
- -X- _ O
grapheme -X- _ O
combinations -X- _ O
. -X- _ O
The -X- _ O
language -X- _ O
is -X- _ O
lexically -X- _ O
productive -X- _ O
, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
long -X- _ O
compound -X- _ O
words -X- _ O
with -X- _ O
multiple -X- _ O
components -X- _ O
in -X- _ O
usage -X- _ O
. -X- _ O
This -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
speakers -X- _ O
segmenting -X- _ O
the -X- _ O
compounds -X- _ O
at -X- _ O
arbitrary -X- _ O
lexeme -X- _ O
boundaries -X- _ O
of -X- _ O
the -X- _ O
compound -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
need -X- _ O
not -X- _ O
always -X- _ O
be -X- _ O
possible -X- _ O
to -X- _ O
utter -X- _ O
the -X- _ O
compound -X- _ O
in -X- _ O
one -X- _ O
breath -X- _ O
and -X- _ O
also -X- _ O
to -X- _ O
convey -X- _ O
the -X- _ O
meaning -X- _ O
clearly -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
such -X- _ O
arbitrary -X- _ O
segmentations -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
boundaries -X- _ O
are -X- _ O
possible -X- _ O
in -X- _ O
utterance -X- _ O
of -X- _ O
long -X- _ O
text -X- _ O
sequences -X- _ O
where -X- _ O
multiple -X- _ O
lexical -X- _ O
items -X- _ O
are -X- _ O
fused -X- _ O
together -X- _ O
via -X- _ O
Sandhi -X- _ O
. -X- _ O
These -X- _ O
segmentations -X- _ O
are -X- _ O
accompanied -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
Sandhi -X- _ O
based -X- _ O
transformations -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
new -X- _ O
phonetic -X- _ O
sequence -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
sequence -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
Sanskrit -X- _ O
might -X- _ O
be -X- _ O
one -X- _ O
of -X- _ O
those -X- _ O
rare -X- _ O
natural -X- _ O
languages -X- _ O
where -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
native -X- _ O
proficient -X- _ O
speakers -X- _ O
are -X- _ O
manifold -X- _ O
in -X- _ O
comparison -X- _ O
to -X- _ O
the -X- _ O
native -X- _ O
speakers -X- _ O
( -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
makes -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
task -X- _ O
further -X- _ O
challenging -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
speakers -X- _ O
are -X- _ O
prone -X- _ O
to -X- _ O
carry -X- _ O
their -X- _ O
influence -X- _ O
from -X- _ O
their -X- _ O
corresponding -X- _ O
mother -X- _ O
tongues -X- _ O
into -X- _ O
the -X- _ O
Sanskrit -X- _ O
utterances -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
While -X- _ O
there -X- _ O
exist -X- _ O
several -X- _ O
computational -X- _ O
models -X- _ O
for -X- _ O
processing -X- _ O
Sanskrit -X- _ O
texts -X- _ O
( -X- _ O
Kulkarni -X- _ O
, -X- _ O
2013;Kumar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010;Shukla -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010;Kulkarni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010a;Goyal -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012;Kulkarni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010c;Mishra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013;Saluja -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Anoop -X- _ O
and -X- _ O
Ramakrishnan -X- _ O
, -X- _ O
2019;Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
large -X- _ O
scale -X- _ O
systems -X- _ O
for -X- _ O
processing -X- _ O
of -X- _ O
speech -X- _ O
in -X- _ O
Sanskrit -X- _ O
, -X- _ O
are -X- _ O
almost -X- _ O
non -X- _ O
- -X- _ O
existent -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
, -X- _ O
with -X- _ O
78 -X- _ O
hours -X- _ O
of -X- _ O
speech -X- _ O
covering -X- _ O
about -X- _ O
46,000 -X- _ O
sentences -X- _ O
, -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
in -X- _ O
Sanskrit -X- _ O
. -X- _ O
Keeping -X- _ O
the -X- _ O
rich -X- _ O
and -X- _ O
long -X- _ O
cultural -X- _ O
heritage -X- _ O
the -X- _ O
language -X- _ O
carries -X- _ O
, -X- _ O
we -X- _ O
prepare -X- _ O
our -X- _ O
dataset -X- _ O
to -X- _ O
be -X- _ O
diverse -X- _ O
both -X- _ O
chronologically -X- _ O
and -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
the -X- _ O
domain -X- _ O
coverage -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
the -X- _ O
dataset -X- _ O
contains -X- _ O
utterances -X- _ O
from -X- _ O
27 -X- _ O
different -X- _ O
speakers -X- _ O
, -X- _ O
representing -X- _ O
6 -X- _ O
different -X- _ O
native -X- _ O
languages -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
splits -X- _ O
have -X- _ O
disjoint -X- _ O
speakers -X- _ O
, -X- _ O
with -X- _ O
12 -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
5 -X- _ O
each -X- _ O
in -X- _ O
the -X- _ O
validation -X- _ O
, -X- _ O
test -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
test -X- _ O
data -X- _ O
sets -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
explicitly -X- _ O
mark -X- _ O
the -X- _ O
segmentation -X- _ O
decisions -X- _ O
made -X- _ O
by -X- _ O
a -X- _ O
speaker -X- _ O
to -X- _ O
segment -X- _ O
long -X- _ O
compound -X- _ O
words -X- _ O
and -X- _ O
fused -X- _ O
phrases -X- _ O
and -X- _ O
include -X- _ O
the -X- _ O
corresponding -X- _ O
transformations -X- _ O
due -X- _ O
to -X- _ O
sandhi -X- _ O
. -X- _ O
Using -X- _ O
this -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
, -X- _ O
largevocabulary -X- _ O
Sanskrit -X- _ O
ASR -X- _ B-TaskName
system -X- _ O
, -X- _ O
which -X- _ O
, -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
such -X- _ O
system -X- _ O
for -X- _ O
Sanskrit -X- _ O
. -X- _ O
The -X- _ O
phonemic -X- _ O
orthography -X- _ O
followed -X- _ O
in -X- _ O
Sanskrit -X- _ O
has -X- _ O
influenced -X- _ O
our -X- _ O
design -X- _ O
choices -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
unit -X- _ O
selection -X- _ O
at -X- _ O
the -X- _ O
level -X- _ O
of -X- _ O
the -X- _ O
acoustic -X- _ O
and -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
investigate -X- _ O
three -X- _ O
different -X- _ O
encoding -X- _ O
schemes -X- _ O
used -X- _ O
to -X- _ O
model -X- _ O
LM -X- _ O
tokens -X- _ O
, -X- _ O
namely -X- _ O
, -X- _ O
word -X- _ O
- -X- _ O
based -X- _ O
encoding -X- _ O
, -X- _ O
byte -X- _ O
pair -X- _ O
encoding -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
new -X- _ O
vowel -X- _ O
split -X- _ O
encoding -X- _ O
inspired -X- _ O
by -X- _ O
existing -X- _ O
linguistic -X- _ O
theories -X- _ O
of -X- _ O
syllabic -X- _ O
structure -X- _ O
popularly -X- _ O
used -X- _ O
within -X- _ O
text -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
speech -X- _ O
systems -X- _ O
( -X- _ O
Kishore -X- _ O
and -X- _ O
Black -X- _ O
, -X- _ O
2003;Mishra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
to -X- _ O
address -X- _ O
the -X- _ O
redundancy -X- _ O
issues -X- _ O
in -X- _ O
Unicode -X- _ O
representations -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
Sanskrit -X- _ O
Library -X- _ O
Phonetic -X- _ O
( -X- _ O
SLP1 -X- _ O
) -X- _ O
encoding -X- _ O
scheme -X- _ O
proposed -X- _ O
by -X- _ O
Scharf -X- _ O
and -X- _ O
Hyman -X- _ O
( -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
SLP1 -X- _ O
is -X- _ O
designed -X- _ O
such -X- _ O
that -X- _ O
it -X- _ O
preserves -X- _ O
the -X- _ O
phonemic -X- _ O
orthography -X- _ O
. -X- _ O
Building -X- _ O
on -X- _ O
the -X- _ O
study -X- _ O
by -X- _ O
Scharf -X- _ O
and -X- _ O
Hyman -X- _ O
( -X- _ O
2011 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
two -X- _ O
graphemic -X- _ O
representations -X- _ O
only -X- _ O
, -X- _ O
viz -X- _ O
. -X- _ O
, -X- _ O
native -X- _ O
script -X- _ O
( -X- _ O
Devanagari -X- _ O
) -X- _ O
and -X- _ O
SLP1.Finally -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
our -X- _ O
insights -X- _ O
to -X- _ O
model -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
for -X- _ O
two -X- _ O
more -X- _ O
Indian -X- _ O
languages -X- _ O
, -X- _ O
viz -X- _ O
. -X- _ O
, -X- _ O
Telugu -X- _ O
and -X- _ O
Gujarati -X- _ O
. -X- _ O
We -X- _ O
extend -X- _ O
the -X- _ O
SLP1 -X- _ O
to -X- _ O
include -X- _ O
graphemes -X- _ O
relevant -X- _ O
for -X- _ O
these -X- _ O
languages -X- _ O
which -X- _ O
are -X- _ O
missing -X- _ O
from -X- _ O
Sanskrit -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
these -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
on -X- _ O
two -X- _ O
publicly -X- _ O
available -X- _ O
ASR -X- _ B-TaskName
datasets -X- _ O
. -X- _ O
Our -X- _ O
main -X- _ O
contributions -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
are -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
present -X- _ O
( -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
new -X- _ O
, -X- _ O
large -X- _ O
vocabulary -X- _ O
Sanskrit -X- _ O
ASR -X- _ B-TaskName
system -X- _ O
and -X- _ O
the -X- _ O
first -X- _ O
ever -X- _ O
ASRbased -X- _ B-TaskName
study -X- _ O
for -X- _ O
Sanskrit -X- _ O
using -X- _ O
a -X- _ O
new -X- _ O
, -X- _ O
large -X- _ O
and -X- _ O
diverse -X- _ O
, -X- _ O
labeled -X- _ O
speech -X- _ O
corpus -X- _ O
वाक् -X- _ O
सञ्चयः -X- _ O
( -X- _ O
/Vāksañ -X- _ O
cayah -X- _ O
̣/ -X- _ O
) -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
investigate -X- _ O
( -X- _ O
in -X- _ O
Sections -X- _ O
3 -X- _ O
and -X- _ O
4 -X- _ O
) -X- _ O
different -X- _ O
modeling -X- _ O
choices -X- _ O
for -X- _ O
both -X- _ O
acoustic -X- _ O
models -X- _ O
and -X- _ O
language -X- _ O
models -X- _ O
in -X- _ O
Sanskrit -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
, -X- _ O
along -X- _ O
with -X- _ O
different -X- _ O
graphemic -X- _ O
representations -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
word -X- _ O
segmentation -X- _ O
technique -X- _ O
based -X- _ O
on -X- _ O
splitting -X- _ O
at -X- _ O
vowels -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
with -X- _ O
both -X- _ O
the -X- _ O
acoustic -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
3 -X- _ O
) -X- _ O
We -X- _ O
also -X- _ O
contextualize -X- _ O
our -X- _ O
findings -X- _ O
for -X- _ O
Sanskrit -X- _ O
by -X- _ O
providing -X- _ O
comparisons -X- _ O
on -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
built -X- _ O
for -X- _ O
two -X- _ O
other -X- _ O
Indian -X- _ O
languages -X- _ O
, -X- _ O
viz -X- _ O
. -X- _ O
, -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
. -X- _ O
from -X- _ O
one -X- _ O
topical -X- _ O
domain -X- _ O
to -X- _ O
another -X- _ O
, -X- _ O
specifically -X- _ O
one -X- _ O
Śāstra -X- _ O
( -X- _ O
branch -X- _ O
of -X- _ O
learning -X- _ O
) -X- _ O
to -X- _ O
another -X- _ O
( -X- _ O
Adiga -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
corpus -X- _ O
contain -X- _ O
samples -X- _ O
from -X- _ O
diverse -X- _ O
domains -X- _ O
, -X- _ O
including -X- _ O
philosophy -X- _ O
, -X- _ O
literature -X- _ O
, -X- _ O
commentary -X- _ O
on -X- _ O
poetry -X- _ O
and -X- _ O
grammar -X- _ O
. -X- _ O
It -X- _ O
also -X- _ O
includes -X- _ O
contemporary -X- _ O
recordings -X- _ O
such -X- _ O
as -X- _ O
stories -X- _ O
, -X- _ O
live -X- _ O
lectures -X- _ O
, -X- _ O
spiritual -X- _ O
discourse -X- _ O
and -X- _ O
radio -X- _ O
program -X- _ O
/ -X- _ O
podcast -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
collecting -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
Sanskrit -X- _ O
vocabulary -X- _ O
. -X- _ O
The -X- _ O
recordings -X- _ O
were -X- _ O
primarily -X- _ O
collected -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
volunteers -X- _ O
, -X- _ O
recording -X- _ O
their -X- _ O
speech -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
Recorder -X- _ O
app -X- _ O
on -X- _ O
Android -X- _ O
phones -X- _ O
and -X- _ O
the -X- _ O
Audacity -X- _ O
platform -X- _ O
, -X- _ O
and -X- _ O
from -X- _ O
various -X- _ O
sources -X- _ O
available -X- _ O
online -X- _ O
. -X- _ O
3 -X- _ O
oTranscribe -X- _ O
3 -X- _ O
was -X- _ O
used -X- _ O
to -X- _ O
transcribe -X- _ O
the -X- _ O
audio -X- _ O
files -X- _ O
. -X- _ O
We -X- _ O
had -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
9 -X- _ O
volunteers -X- _ O
for -X- _ O
recording -X- _ O
and -X- _ O
18 -X- _ O
unique -X- _ O
speakers -X- _ O
for -X- _ O
the -X- _ O
content -X- _ O
collected -X- _ O
online -X- _ O
. -X- _ O
Each -X- _ O
of -X- _ O
these -X- _ O
speakers -X- _ O
are -X- _ O
proficient -X- _ O
Sanskrit -X- _ O
speakers -X- _ O
, -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
an -X- _ O
undergraduate -X- _ O
or -X- _ O
equivalent -X- _ O
degree -X- _ O
in -X- _ O
Sanskrit -X- _ O
. -X- _ O
These -X- _ O
speakers -X- _ O
are -X- _ O
native -X- _ O
speakers -X- _ O
of -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
6 -X- _ O
following -X- _ O
Indic -X- _ O
languages -X- _ O
, -X- _ O
Hindi -X- _ O
, -X- _ O
Kannada -X- _ O
, -X- _ O
Malayalam -X- _ O
, -X- _ O
Marathi -X- _ O
, -X- _ O
Tamil -X- _ O
and -X- _ O
Telugu -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
provide -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
/ -X- _ O
validation -X- _ O
/ -X- _ O
test -X- _ O
splits -X- _ O
for -X- _ O
our -X- _ O
corpus -X- _ O
, -X- _ O
वाक् -X- _ O
सञ्चयः -X- _ O
( -X- _ O
/Vāksañcayah -X- _ O
̣/ -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
speakers -X- _ O
in -X- _ O
all -X- _ O
these -X- _ O
4 -X- _ O
splits -X- _ O
, -X- _ O
train -X- _ O
, -X- _ O
validation -X- _ O
, -X- _ O
test -X- _ O
, -X- _ O
and -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
test -X- _ O
sets -X- _ O
are -X- _ O
disjoint -X- _ O
. -X- _ O
The -X- _ O
out -X- _ O
- -X- _ O
ofdomain -X- _ O
test -X- _ O
dataset -X- _ O
is -X- _ O
a -X- _ O
stratified -X- _ O
sampled -X- _ O
dataset -X- _ O
, -X- _ O
consisting -X- _ O
of -X- _ O
speech -X- _ O
samples -X- _ O
from -X- _ O
5 -X- _ O
unique -X- _ O
speakers -X- _ O
. -X- _ O
Two -X- _ O
of -X- _ O
these -X- _ O
were -X- _ O
added -X- _ O
to -X- _ O
include -X- _ O
utterances -X- _ O
in -X- _ O
Sanskrit -X- _ O
from -X- _ O
speakers -X- _ O
with -X- _ O
more -X- _ O
pronounced -X- _ O
influence -X- _ O
of -X- _ O
their -X- _ O
native -X- _ O
languages -X- _ O
( -X- _ O
in -X- _ O
Hindi -X- _ O
and -X- _ O
Tamil -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
primarily -X- _ O
is -X- _ O
a -X- _ O
speech -X- _ O
collection -X- _ O
of -X- _ O
readings -X- _ O
from -X- _ O
various -X- _ O
well -X- _ O
known -X- _ O
texts -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
the -X- _ O
speech -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
in -X- _ O
accordance -X- _ O
with -X- _ O
the -X- _ O
traditional -X- _ O
phonetic -X- _ O
prescriptions -X- _ O
of -X- _ O
Sanskrit -X- _ O
( -X- _ O
Śiks -X- _ O
̣ā -X- _ O
) -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
the -X- _ O
remaining -X- _ O
three -X- _ O
in -X- _ O
the -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
test -X- _ O
set -X- _ O
were -X- _ O
added -X- _ O
to -X- _ O
include -X- _ O
utterances -X- _ O
from -X- _ O
different -X- _ O
speech -X- _ O
domains -X- _ O
, -X- _ O
extempore -X- _ O
discourse -X- _ O
, -X- _ O
lecture -X- _ O
and -X- _ O
radio -X- _ O
program -X- _ O
, -X- _ O
differing -X- _ O
from -X- _ O
the -X- _ O
speech -X- _ O
domain -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
radio -X- _ O
program -X- _ O
is -X- _ O
studio -X- _ O
produced -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
are -X- _ O
live -X- _ O
recorded -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
various -X- _ O
linguistic -X- _ O
phenomena -X- _ O
that -X- _ O
are -X- _ O
important -X- _ O
to -X- _ O
consider -X- _ O
when -X- _ O
preparing -X- _ O
datasets -X- _ O
and -X- _ O
building -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
for -X- _ O
Sanskrit -X- _ O
with -X- _ O
the -X- _ O
help -X- _ O
of -X- _ O
illustrative -X- _ O
examples -X- _ O
. -X- _ O
3 -X- _ O
The -X- _ O
URLs -X- _ O
of -X- _ O
the -X- _ O
tools -X- _ O
and -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
the -X- _ O
texts -X- _ O
we -X- _ O
use -X- _ O
are -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
supplementary -X- _ O
material -X- _ O
. -X- _ O
Word -X- _ O
Length -X- _ O
: -X- _ O
The -X- _ O
tokens -X- _ O
in -X- _ O
Sanskrit -X- _ O
texts -X- _ O
can -X- _ O
be -X- _ O
very -X- _ O
long -X- _ O
owing -X- _ O
to -X- _ O
" -X- _ O
Sandhi -X- _ O
" -X- _ O
and -X- _ O
the -X- _ O
lexically -X- _ O
productive -X- _ O
process -X- _ O
of -X- _ O
compounding -X- _ O
( -X- _ O
` -X- _ O
` -X- _ O
Samāsa -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
consider -X- _ O
a -X- _ O
compound -X- _ O
word -X- _ O
, -X- _ O
वागथर् -X- _ O
प्र -X- _ O
तपत्तये -X- _ O
( -X- _ O
/vāgarthapratipattaye/ -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
forms -X- _ O
a -X- _ O
19 -X- _ O
letter -X- _ O
word -X- _ O
in -X- _ O
SLP1 -X- _ O
( -X- _ O
vAgarTapratipattaye -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
formed -X- _ O
by -X- _ O
combining -X- _ O
the -X- _ O
three -X- _ O
Sanskrit -X- _ O
stems -X- _ O
वाक् -X- _ O
, -X- _ O
अथर् -X- _ O
, -X- _ O
प्र -X- _ O
तप -X- _ O
त्त -X- _ O
( -X- _ O
/vāk -X- _ O
, -X- _ O
artha -X- _ O
, -X- _ O
prati -X- _ O
patti/ -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
per -X- _ O
the -X- _ O
rules -X- _ O
of -X- _ O
Sandhi -X- _ O
and -X- _ O
Samāsa -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
characters -X- _ O
( -X- _ O
in -X- _ O
SLP1 -X- _ O
format -X- _ O
) -X- _ O
per -X- _ O
word -X- _ O
across -X- _ O
the -X- _ O
three -X- _ O
languages -X- _ O
that -X- _ O
we -X- _ O
experimentally -X- _ O
analyse -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
viz -X- _ O
. -X- _ O
, -X- _ O
Sanskrit -X- _ O
, -X- _ O
Telugu -X- _ O
and -X- _ O
Gujarati -X- _ O
. -X- _ O
The -X- _ O
plots -X- _ O
are -X- _ O
normalized -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
vocabulary -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
word -X- _ O
length -X- _ O
is -X- _ O
much -X- _ O
higher -X- _ O
in -X- _ O
Sanskrit -X- _ O
( -X- _ O
10.75 -X- _ O
) -X- _ O
compared -X- _ O
to -X- _ O
Gujarati -X- _ O
( -X- _ O
7.79 -X- _ O
) -X- _ O
and -X- _ O
Telugu -X- _ O
( -X- _ O
9.35 -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
same -X- _ O
word -X- _ O
. -X- _ O
While -X- _ O
recognising -X- _ O
longer -X- _ O
sequences -X- _ O
due -X- _ O
to -X- _ O
sandhi -X- _ O
and -X- _ O
compounding -X- _ O
is -X- _ O
a -X- _ O
challenge -X- _ O
in -X- _ O
itself -X- _ O
, -X- _ O
the -X- _ O
external -X- _ O
sandhi -X- _ O
gives -X- _ O
rise -X- _ O
to -X- _ O
the -X- _ O
issue -X- _ O
of -X- _ O
arbitrary -X- _ O
points -X- _ O
of -X- _ O
segmentation -X- _ O
performed -X- _ O
by -X- _ O
speakers -X- _ O
at -X- _ O
the -X- _ O
time -X- _ O
of -X- _ O
utterance -X- _ O
. -X- _ O
Figure -X- _ O
2a -X- _ O
shows -X- _ O
text -X- _ O
- -X- _ O
sequence -X- _ O
where -X- _ O
the -X- _ O
sequence -X- _ O
contains -X- _ O
a -X- _ O
word -X- _ O
nityah -X- _ O
̣ -X- _ O
and -X- _ O
a -X- _ O
compound -X- _ O
śabdārthasambandhah -X- _ O
̣ -X- _ O
fused -X- _ O
together -X- _ O
via -X- _ O
Sandhi -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
śabdārthasam -X- _ O
bandhah -X- _ O
̣ -X- _ O
is -X- _ O
a -X- _ O
compound -X- _ O
with -X- _ O
śabda -X- _ O
, -X- _ O
artha -X- _ O
and -X- _ O
sambandha -X- _ O
as -X- _ O
its -X- _ O
components -X- _ O
. -X- _ O
While -X- _ O
it -X- _ O
is -X- _ O
expected -X- _ O
to -X- _ O
be -X- _ O
uttered -X- _ O
without -X- _ O
any -X- _ O
pause -X- _ O
after -X- _ O
considering -X- _ O
Samhitā -X- _ O
( -X- _ O
As -X- _ O
̣t -X- _ O
̣ādhyāyī-1 -X- _ O
- -X- _ O
4 -X- _ O
- -X- _ O
109 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
speaker -X- _ O
may -X- _ O
choose -X- _ O
to -X- _ O
segment -X- _ O
at -X- _ O
the -X- _ O
lexical -X- _ O
boundaries -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2c -X- _ O
and -X- _ O
Figure -X- _ O
2d -X- _ O
. -X- _ O
However -X- _ O
in -X- _ O
doing -X- _ O
so -X- _ O
, -X- _ O
a -X- _ O
proficient -X- _ O
speaker -X- _ O
would -X- _ O
prefer -X- _ O
a -X- _ O
sequence -X- _ O
similar -X- _ O
to -X- _ O
Figure -X- _ O
2a -X- _ O
or -X- _ O
2b -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
Figure -X- _ O
2c -X- _ O
or -X- _ O
2d -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
because -X- _ O
, -X- _ O
the -X- _ O
former -X- _ O
two -X- _ O
, -X- _ O
though -X- _ O
result -X- _ O
in -X- _ O
phonetic -X- _ O
transformations -X- _ O
, -X- _ O
preserve -X- _ O
the -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
validity -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
latter -X- _ O
do -X- _ O
not -X- _ O
preserve -X- _ O
the -X- _ O
syntactic -X- _ O
and -X- _ O
semantic -X- _ O
validity -X- _ O
of -X- _ O
the -X- _ O
sequence -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
cases -X- _ O
where -X- _ O
there -X- _ O
can -X- _ O
be -X- _ O
phonetic -X- _ O
transformations -X- _ O
between -X- _ O
the -X- _ O
bound -X- _ O
morphemes -X- _ O
and -X- _ O
the -X- _ O
free -X- _ O
morpheme -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
. -X- _ O
These -X- _ O
transformations -X- _ O
do -X- _ O
not -X- _ O
result -X- _ O
in -X- _ O
any -X- _ O
modification -X- _ O
to -X- _ O
the -X- _ O
word -X- _ O
, -X- _ O
other -X- _ O
than -X- _ O
phonetic -X- _ O
variations -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
makes -X- _ O
it -X- _ O
challenging -X- _ O
for -X- _ O
an -X- _ O
ASR -X- _ B-TaskName
system -X- _ O
. -X- _ O
The -X- _ O
case -X- _ O
of -X- _ O
Diphthongs -X- _ O
is -X- _ O
the -X- _ O
quite -X- _ O
prevalent -X- _ O
under -X- _ O
these -X- _ O
cases -X- _ O
. -X- _ O
In -X- _ O
Diphthongs -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
occur -X- _ O
both -X- _ O
at -X- _ O
internal -X- _ O
or -X- _ O
external -X- _ O
sandhi -X- _ O
, -X- _ O
the -X- _ O
independent -X- _ O
vowel -X- _ O
can -X- _ O
only -X- _ O
occur -X- _ O
at -X- _ O
the -X- _ O
start -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
. -X- _ O
Any -X- _ O
vowel -X- _ O
appearing -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
either -X- _ O
gets -X- _ O
converted -X- _ O
to -X- _ O
a -X- _ O
dependent -X- _ O
vowel -X- _ O
or -X- _ O
a -X- _ O
diphthong -X- _ O
. -X- _ O
When -X- _ O
a -X- _ O
word -X- _ O
ending -X- _ O
with -X- _ O
" -X- _ O
ए(/ē/ -X- _ O
) -X- _ O
or -X- _ O
ओ(/ō/ -X- _ O
) -X- _ O
" -X- _ O
and -X- _ O
followed -X- _ O
by -X- _ O
any -X- _ O
vowel -X- _ O
, -X- _ O
then -X- _ O
ending -X- _ O
will -X- _ O
be -X- _ O
changed -X- _ O
to -X- _ O
either -X- _ O
" -X- _ O
अय् -X- _ O
( -X- _ O
/ay/ -X- _ O
) -X- _ O
or -X- _ O
अव् -X- _ O
( -X- _ O
/av/ -X- _ O
) -X- _ O
respectively -X- _ O
" -X- _ O
or -X- _ O
" -X- _ O
अ(/a/ -X- _ O
) -X- _ O
" -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
िवष्णो+इह(/vis -X- _ O
̣n -X- _ O
̣o+iha/ -X- _ O
) -X- _ O
will -X- _ O
get -X- _ O
converted -X- _ O
to -X- _ O
िवष्णइह(/vis -X- _ O
̣n -X- _ O
̣aiha/ -X- _ O
) -X- _ O
or -X- _ O
िवष्णिवह(/vis -X- _ O
̣n -X- _ O
̣aviha/ -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
Unicode -X- _ O
encoding -X- _ O
for -X- _ O
the -X- _ O
native -X- _ O
scripts -X- _ O
in -X- _ O
Sanskrit -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
several -X- _ O
indian -X- _ O
languages -X- _ O
, -X- _ O
does -X- _ O
not -X- _ O
preserve -X- _ O
the -X- _ O
correspondence -X- _ O
with -X- _ O
the -X- _ O
phonemic -X- _ O
encoding -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
mapping -X- _ O
the -X- _ O
graphemes -X- _ O
in -X- _ O
Unicode -X- _ O
to -X- _ O
the -X- _ O
corresponding -X- _ O
phonemes -X- _ O
either -X- _ O
suffers -X- _ O
from -X- _ O
ambiguity -X- _ O
and -X- _ O
redundancy -X- _ O
or -X- _ O
often -X- _ O
requires -X- _ O
multigrapheme -X- _ O
combinations -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
consider -X- _ O
the -X- _ O
word -X- _ O
वागथार् -X- _ O
िवव(/vāgarthāviva/ -X- _ O
) -X- _ O
in -X- _ O
Sanskrit -X- _ O
. -X- _ O
Here -X- _ O
the -X- _ O
graphemes -X- _ O
in -X- _ O
Devanagari -X- _ O
' -X- _ O
व -X- _ O
◌ -X- _ O
ा -X- _ O
ग -X- _ O
र -X- _ O
◌ -X- _ O
् -X- _ O
थ -X- _ O
◌ -X- _ O
ा -X- _ O
व -X- _ O
ि -X- _ O
◌ -X- _ O
व'and -X- _ O
Roman -X- _ O
( -X- _ O
v -X- _ O
ā -X- _ O
g -X- _ O
a -X- _ O
r -X- _ O
t -X- _ O
h -X- _ O
ā -X- _ O
v -X- _ O
i -X- _ O
v -X- _ O
a -X- _ O
) -X- _ O
do -X- _ O
not -X- _ O
exhibit -X- _ O
a -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
mapping -X- _ O
with -X- _ O
the -X- _ O
phonemes -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
grapheme -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
ग -X- _ O
) -X- _ O
may -X- _ O
correspond -X- _ O
to -X- _ O
2 -X- _ O
phonemes -X- _ O
while -X- _ O
two -X- _ O
graphemes -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
र -X- _ O
◌ -X- _ O
् -X- _ O
in -X- _ O
devanagari -X- _ O
, -X- _ O
' -X- _ O
t -X- _ O
h -X- _ O
' -X- _ O
in -X- _ O
roman -X- _ O
) -X- _ O
may -X- _ O
correspond -X- _ O
to -X- _ O
a -X- _ O
single -X- _ O
phoneme -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
different -X- _ O
alternatives -X- _ O
for -X- _ O
identifying -X- _ O
units -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
acoustic -X- _ O
model -X- _ O
that -X- _ O
we -X- _ O
subsequently -X- _ O
employ -X- _ O
in -X- _ O
our -X- _ O
experimental -X- _ O
evaluation -X- _ O
and -X- _ O
analysis -X- _ O
. -X- _ O
The -X- _ O
Unicode -X- _ O
standard -X- _ O
for -X- _ O
native -X- _ O
scripts -X- _ O
of -X- _ O
Sanskrit -X- _ O
: -X- _ O
Devanagari -X- _ O
, -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
faces -X- _ O
challenge -X- _ O
for -X- _ O
computational -X- _ O
language -X- _ O
processing -X- _ O
due -X- _ O
to -X- _ O
redundancy -X- _ O
in -X- _ O
mappings -X- _ O
between -X- _ O
phonemes -X- _ O
and -X- _ O
graphemes -X- _ O
as -X- _ O
previously -X- _ O
discussed -X- _ O
. -X- _ O
So -X- _ O
for -X- _ O
Sanskrit -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Sanskrit -X- _ O
Library -X- _ O
Phonetic -X- _ O
encodings -X- _ O
( -X- _ O
SLP1 -X- _ O
) -X- _ O
designed -X- _ O
by -X- _ O
Scharf -X- _ O
and -X- _ O
Hyman -X- _ O
( -X- _ O
2011).This -X- _ O
encoding -X- _ O
gives -X- _ O
unique -X- _ O
one -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
mapping -X- _ O
to -X- _ O
the -X- _ O
phoneme -X- _ O
. -X- _ O
However -X- _ O
Gujarati -X- _ O
possesses -X- _ O
extra -X- _ O
native -X- _ O
characters -X- _ O
such -X- _ O
as -X- _ O
ઍ(/e/ -X- _ O
) -X- _ O
, -X- _ O
ઑ(/o/ -X- _ O
) -X- _ O
. -X- _ O
Telugu -X- _ O
also -X- _ O
possesses -X- _ O
extra -X- _ O
characters -X- _ O
such -X- _ O
as -X- _ O
ఎ(/e/ -X- _ O
) -X- _ O
, -X- _ O
ఒ(/o/ -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ఱ(/r/ -X- _ O
) -X- _ O
. -X- _ O
So -X- _ O
we -X- _ O
extend -X- _ O
SLP1 -X- _ O
to -X- _ O
fit -X- _ O
to -X- _ O
the -X- _ O
character -X- _ O
set -X- _ O
of -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
One -X- _ O
possibility -X- _ O
for -X- _ O
deriving -X- _ O
subword -X- _ O
units -X- _ O
for -X- _ O
the -X- _ O
language -X- _ O
modeling -X- _ O
is -X- _ O
to -X- _ O
segment -X- _ O
words -X- _ O
in -X- _ O
Sanskrit -X- _ O
based -X- _ O
on -X- _ O
Sandhi -X- _ O
rules -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
Sandhi -X- _ O
splitting -X- _ O
can -X- _ O
change -X- _ O
some -X- _ O
phonemes -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
almost -X- _ O
all -X- _ O
cases -X- _ O
. -X- _ O
Consider -X- _ O
the -X- _ O
word -X- _ O
रामाये -X- _ O
दम् -X- _ O
= -X- _ O
रामाय+इदम् -X- _ O
( -X- _ O
/rāmāyedam/ -X- _ O
= -X- _ O
/rāmāya/+/idam/ -X- _ O
) -X- _ O
, -X- _ O
wherein -X- _ O
the -X- _ O
vowel -X- _ O
ए -X- _ O
( -X- _ O
/e/ -X- _ O
) -X- _ O
is -X- _ O
changed -X- _ O
into -X- _ O
अ+इ -X- _ O
( -X- _ O
/a/+/i/ -X- _ O
) -X- _ O
after -X- _ O
performing -X- _ O
Sandhi -X- _ O
- -X- _ O
based -X- _ O
splitting -X- _ O
. -X- _ O
This -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
mismatch -X- _ O
between -X- _ O
the -X- _ O
speech -X- _ O
transcript -X- _ O
and -X- _ O
the -X- _ O
speech -X- _ O
audio -X- _ O
, -X- _ O
potentially -X- _ O
creating -X- _ O
further -X- _ O
complications -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
. -X- _ O
Byte -X- _ O
pair -X- _ O
encoding -X- _ O
( -X- _ O
BPE -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
data -X- _ O
compression -X- _ O
algorithm -X- _ O
that -X- _ O
iteratively -X- _ O
replaces -X- _ O
the -X- _ O
frequently -X- _ O
occurring -X- _ O
subword -X- _ O
units -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
unused -X- _ O
byte -X- _ O
( -X- _ O
Gage -X- _ O
, -X- _ O
1994 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
technique -X- _ O
was -X- _ O
first -X- _ O
adopted -X- _ O
to -X- _ O
model -X- _ O
rare -X- _ O
words -X- _ O
using -X- _ O
subword -X- _ O
units -X- _ O
in -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Interestingly -X- _ O
, -X- _ O
BPE -X- _ O
has -X- _ O
been -X- _ O
explored -X- _ O
for -X- _ O
learning -X- _ O
new -X- _ O
vocabulary -X- _ O
for -X- _ O
poetry -X- _ O
to -X- _ O
prose -X- _ O
conversion -X- _ O
in -X- _ O
Sanskrit -X- _ O
( -X- _ O
Krishna -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
using -X- _ O
BPE -X- _ O
as -X- _ O
a -X- _ O
subword -X- _ O
unit -X- _ O
for -X- _ O
Sanskrit -X- _ O
ASR.While -X- _ B-TaskName
BPE -X- _ O
is -X- _ O
a -X- _ O
purely -X- _ O
data -X- _ O
- -X- _ O
driven -X- _ O
segmentation -X- _ O
strategy -X- _ O
, -X- _ O
we -X- _ O
next -X- _ O
present -X- _ O
a -X- _ O
linguistically -X- _ O
motivated -X- _ O
segmentation -X- _ O
approach -X- _ O
that -X- _ O
might -X- _ O
be -X- _ O
aligned -X- _ O
with -X- _ O
finding -X- _ O
syllable -X- _ O
units -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
that -X- _ O
are -X- _ O
more -X- _ O
phonetically -X- _ O
compliant -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
technique -X- _ O
as -X- _ O
vowel -X- _ O
segmentation -X- _ O
. -X- _ O
Splitting -X- _ O
the -X- _ O
tokens -X- _ O
based -X- _ O
on -X- _ O
vowels -X- _ O
and -X- _ O
adjacent -X- _ O
consonants -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
identification -X- _ O
of -X- _ O
metres -X- _ O
in -X- _ O
Sanskrit -X- _ O
prosody -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
metre -X- _ O
of -X- _ O
a -X- _ O
verse -X- _ O
is -X- _ O
identified -X- _ O
by -X- _ O
using -X- _ O
syllable -X- _ O
segmentation -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
identification -X- _ O
of -X- _ O
syllable -X- _ O
weights -X- _ O
and -X- _ O
it -X- _ O
's -X- _ O
combinations -X- _ O
( -X- _ O
Melnad -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
syllable -X- _ O
weight -X- _ O
of -X- _ O
a -X- _ O
syllable -X- _ O
can -X- _ O
either -X- _ O
be -X- _ O
laghu -X- _ O
( -X- _ O
light)(represented -X- _ O
by -X- _ O
the -X- _ O
symbol -X- _ O
। -X- _ O
) -X- _ O
or -X- _ O
guru -X- _ O
( -X- _ O
heavy)(represented -X- _ O
by -X- _ O
the -X- _ O
symbol -X- _ O
ऽ -X- _ O
) -X- _ O
. -X- _ O
Syllables -X- _ O
with -X- _ O
short -X- _ O
vowels -X- _ O
generally -X- _ O
form -X- _ O
Laghu -X- _ O
and -X- _ O
those -X- _ O
with -X- _ O
loing -X- _ O
vowels -X- _ O
form -X- _ O
a -X- _ O
Guru -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
when -X- _ O
a -X- _ O
short -X- _ O
vowel -X- _ O
is -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
conjunct -X- _ O
consonant -X- _ O
or -X- _ O
Anusvāra -X- _ O
( -X- _ O
nasal -X- _ O
sound -X- _ O
/ṃ -X- _ O
/ -X- _ O
) -X- _ O
or -X- _ O
Visarga -X- _ O
( -X- _ O
voiceless -X- _ O
glottal -X- _ O
fricative -X- _ O
/h -X- _ O
̣/ -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
short -X- _ O
vowel -X- _ O
now -X- _ O
becomes -X- _ O
Guru -X- _ O
. -X- _ O
E.g. -X- _ O
, -X- _ O
the -X- _ O
Laghu -X- _ O
- -X- _ O
Guru -X- _ O
mapping -X- _ O
of -X- _ O
" -X- _ O
अन्यािन -X- _ O
सं -X- _ O
या -X- _ O
त(/anyāni -X- _ O
saṃ -X- _ O
yāti/ -X- _ O
) -X- _ O
" -X- _ O
is -X- _ O
" -X- _ O
ऽऽ -X- _ O
। -X- _ O
ऽऽ -X- _ O
। -X- _ O
" -X- _ O
. -X- _ O
In -X- _ O
prior -X- _ O
work -X- _ O
involving -X- _ O
Indian -X- _ O
languages -X- _ O
for -X- _ O
TTS -X- _ O
, -X- _ O
Kishore -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2002 -X- _ O
) -X- _ O
proposed -X- _ O
various -X- _ O
syllabification -X- _ O
rules -X- _ O
for -X- _ O
words -X- _ O
. -X- _ O
Herein -X- _ O
( -X- _ O
with -X- _ O
a -X- _ O
few -X- _ O
exceptions -X- _ O
) -X- _ O
, -X- _ O
if -X- _ O
a -X- _ O
vowel -X- _ O
is -X- _ O
followed -X- _ O
by -X- _ O
3 -X- _ O
or -X- _ O
more -X- _ O
consonants -X- _ O
, -X- _ O
only -X- _ O
the -X- _ O
first -X- _ O
following -X- _ O
vowel -X- _ O
is -X- _ O
grouped -X- _ O
with -X- _ O
the -X- _ O
preceding -X- _ O
vowel -X- _ O
to -X- _ O
form -X- _ O
the -X- _ O
subword -X- _ O
unit -X- _ O
. -X- _ O
Our -X- _ O
proposed -X- _ O
algorithm -X- _ O
for -X- _ O
vowel -X- _ O
segmentation -X- _ O
( -X- _ O
VS -X- _ O
) -X- _ O
is -X- _ O
outlined -X- _ O
in -X- _ O
Algorithm -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
segmenting -X- _ O
words -X- _ O
at -X- _ O
vowel -X- _ O
boundaries -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
units -X- _ O
for -X- _ O
which -X- _ O
alignment -X- _ O
with -X- _ O
speech -X- _ O
is -X- _ O
learnt -X- _ O
within -X- _ O
the -X- _ O
ASR -X- _ B-TaskName
system -X- _ O
. -X- _ O
For -X- _ O
acoustic -X- _ O
models -X- _ O
, -X- _ O
an -X- _ O
effective -X- _ O
unit -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
would -X- _ O
arguably -X- _ O
be -X- _ O
the -X- _ O
syllable -X- _ O
( -X- _ O
Lee -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
Representing -X- _ O
a -X- _ O
word -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
syllables -X- _ O
demands -X- _ O
the -X- _ O
mapping -X- _ O
ALGORITHM -X- _ O
1 -X- _ O
: -X- _ O
Vowel -X- _ O
segmentation -X- _ O
algorithm -X- _ O
for -X- _ O
Indian -X- _ O
languages -X- _ O
Input -X- _ O
: -X- _ O
word -X- _ O
in -X- _ O
Indian -X- _ O
language -X- _ O
Output -X- _ O
: -X- _ O
Vowel -X- _ O
segments -X- _ O
in -X- _ O
output -X- _ O
output -X- _ O
= -X- _ O
" -X- _ O
" -X- _ O
; -X- _ O
for -X- _ O
each -X- _ O
graphemic -X- _ O
unit -X- _ O
c -X- _ O
i -X- _ O
in -X- _ O
word -X- _ O
doif -X- _ O
c -X- _ O
i -X- _ O
is -X- _ O
V -X- _ O
then -X- _ O
if -X- _ O
c -X- _ O
i+1 -X- _ O
is -X- _ O
V -X- _ O
then -X- _ O
output -X- _ O
+ -X- _ O
= -X- _ O
c -X- _ O
i -X- _ O
+ -X- _ O
" -X- _ O
" -X- _ O
; -X- _ O
else -X- _ O
if -X- _ O
c -X- _ O
i+1 -X- _ O
is -X- _ O
C -X- _ O
and -X- _ O
c -X- _ O
i+2 -X- _ O
is -X- _ O
C -X- _ O
then -X- _ O
output -X- _ O
+ -X- _ O
= -X- _ O
c -X- _ O
i -X- _ O
; -X- _ O
else -X- _ O
if -X- _ O
c -X- _ O
i+1 -X- _ O
is -X- _ O
C -X- _ O
and -X- _ O
c -X- _ O
i+2 -X- _ O
is -X- _ O
V -X- _ O
then -X- _ O
output -X- _ O
+ -X- _ O
= -X- _ O
c -X- _ O
i -X- _ O
+ -X- _ O
" -X- _ O
" -X- _ O
; -X- _ O
else -X- _ O
if -X- _ O
c -X- _ O
i+1 -X- _ O
is -X- _ O
V -X- _ O
then -X- _ O
output -X- _ O
+ -X- _ O
= -X- _ O
c -X- _ O
i -X- _ O
; -X- _ O
else -X- _ O
if -X- _ O
c -X- _ O
i+1 -X- _ O
is -X- _ O
C -X- _ O
and -X- _ O
c -X- _ O
i+2 -X- _ O
is -X- _ O
C -X- _ O
then -X- _ O
output -X- _ O
+ -X- _ O
= -X- _ O
c -X- _ O
i -X- _ O
; -X- _ O
else -X- _ O
if -X- _ O
c -X- _ O
i+1 -X- _ O
is -X- _ O
C -X- _ O
and -X- _ O
c -X- _ O
i+2 -X- _ O
is -X- _ O
V -X- _ O
and -X- _ O
c -X- _ O
i+2 -X- _ O
is -X- _ O
first -X- _ O
vowel -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
then -X- _ O
output -X- _ O
+ -X- _ O
= -X- _ O
c -X- _ O
i -X- _ O
; -X- _ O
else -X- _ O
if -X- _ O
c -X- _ O
i+1 -X- _ O
is -X- _ O
C -X- _ O
and -X- _ O
c -X- _ O
i+2 -X- _ O
is -X- _ O
V -X- _ O
then -X- _ O
output -X- _ O
+ -X- _ O
= -X- _ O
c -X- _ O
i -X- _ O
+ -X- _ O
" -X- _ O
" -X- _ O
; -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
from -X- _ O
graphemes -X- _ O
to -X- _ O
phonemes -X- _ O
. -X- _ O
To -X- _ O
create -X- _ O
syllable -X- _ O
units -X- _ O
, -X- _ O
phonemes -X- _ O
are -X- _ O
then -X- _ O
combined -X- _ O
together -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
sonority -X- _ O
sequencing -X- _ O
principle -X- _ O
( -X- _ O
Clements -X- _ O
, -X- _ O
1990 -X- _ O
) -X- _ O
. -X- _ O
Absence -X- _ O
of -X- _ O
accurate -X- _ O
syllabifiers -X- _ O
for -X- _ O
Indian -X- _ O
languages -X- _ O
restricts -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
syllables -X- _ O
as -X- _ O
units -X- _ O
for -X- _ O
learning -X- _ O
alignment -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
produces -X- _ O
units -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
a -X- _ O
rough -X- _ O
approximation -X- _ O
to -X- _ O
a -X- _ O
syllable -X- _ O
. -X- _ O
A -X- _ O
syllable -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
three -X- _ O
parts -X- _ O
viz -X- _ O
. -X- _ O
, -X- _ O
onset -X- _ O
, -X- _ O
nucleus -X- _ O
and -X- _ O
coda -X- _ O
, -X- _ O
where -X- _ O
nucleus -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
sonority -X- _ O
and -X- _ O
is -X- _ O
always -X- _ O
a -X- _ O
vowel -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
the -X- _ O
onset -X- _ O
is -X- _ O
always -X- _ O
one -X- _ O
or -X- _ O
zero -X- _ O
consonants -X- _ O
and -X- _ O
the -X- _ O
coda -X- _ O
is -X- _ O
zero -X- _ O
or -X- _ O
n-1 -X- _ O
consonants -X- _ O
if -X- _ O
the -X- _ O
nucleus -X- _ O
is -X- _ O
followed -X- _ O
by -X- _ O
n -X- _ O
consonants -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
observed -X- _ O
in -X- _ O
the -X- _ O
pronunciation -X- _ O
of -X- _ O
conjunct -X- _ O
consonant -X- _ O
by -X- _ O
professional -X- _ O
speakers -X- _ O
that -X- _ O
the -X- _ O
beginning -X- _ O
part -X- _ O
of -X- _ O
conjunct -X- _ O
consonant -X- _ O
gets -X- _ O
associated -X- _ O
more -X- _ O
with -X- _ O
the -X- _ O
preceding -X- _ O
vowel -X- _ O
than -X- _ O
the -X- _ O
following -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
nasal -X- _ O
Anusvāra -X- _ O
( -X- _ O
◌ -X- _ O
ं -X- _ O
) -X- _ O
, -X- _ O
Chandrabindu -X- _ O
( -X- _ O
◌ -X- _ O
ॅ -X- _ O
or -X- _ O
◌ -X- _ O
ँ -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Visarga -X- _ O
( -X- _ O
◌ -X- _ O
ः -X- _ O
) -X- _ O
to -X- _ O
be -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
consonant -X- _ O
set -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
Sanskrit -X- _ O
, -X- _ O
the -X- _ O
units -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
उद्यान -X- _ O
: -X- _ O
( -X- _ O
udyāna -X- _ O
, -X- _ O
park -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
' -X- _ O
उद् -X- _ O
या -X- _ O
न:(/ud -X- _ O
yā -X- _ O
na -X- _ O
/ -X- _ O
) -X- _ O
' -X- _ O
and -X- _ O
subword -X- _ O
units -X- _ O
of -X- _ O
the -X- _ O
Telugu -X- _ O
word -X- _ O
తలిల్ -X- _ O
తండు -X- _ O
ర్ -X- _ O
లు(/tallitaṃ -X- _ O
d -X- _ O
̣rulu/ -X- _ O
) -X- _ O
will -X- _ O
be -X- _ O
' -X- _ O
తల్ -X- _ O
లి -X- _ O
తండ్ -X- _ O
రు -X- _ O
లు(/tal -X- _ O
li -X- _ O
taṃ -X- _ O
d -X- _ O
̣ -X- _ O
ru -X- _ O
lu/ -X- _ O
) -X- _ O
' -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
choice -X- _ O
of -X- _ O
graphemic -X- _ O
unit -X- _ O
( -X- _ O
viz -X- _ O
. -X- _ O
native -X- _ O
script -X- _ O
and -X- _ O
SLP1 -X- _ O
) -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
three -X- _ O
different -X- _ O
units -X- _ O
for -X- _ O
the -X- _ O
acoustic -X- _ O
modeling -X- _ O
( -X- _ O
AM -X- _ O
) -X- _ O
in -X- _ O
ASR -X- _ B-TaskName
, -X- _ O
viz -X- _ O
. -X- _ O
, -X- _ O
graphemic -X- _ O
unit -X- _ O
and -X- _ O
vowel -X- _ O
segmentation -X- _ O
for -X- _ O
Sanskrit -X- _ O
and -X- _ O
also -X- _ O
phonemic -X- _ O
unit -X- _ O
across -X- _ O
the -X- _ O
two -X- _ O
other -X- _ O
representative -X- _ O
Indian -X- _ O
languages -X- _ O
viz -X- _ O
. -X- _ O
, -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
. -X- _ O
Whereas -X- _ O
, -X- _ O
for -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
LM -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
word -X- _ O
, -X- _ O
BPE -X- _ O
and -X- _ O
VS -X- _ O
based -X- _ O
units -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
based -X- _ O
on -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
three -X- _ O
different -X- _ O
unit -X- _ O
selections -X- _ O
and -X- _ O
contrast -X- _ O
the -X- _ O
sizes -X- _ O
with -X- _ O
that -X- _ O
of -X- _ O
two -X- _ O
extreme -X- _ O
hypothetical -X- _ O
systems -X- _ O
-one -X- _ O
that -X- _ O
considers -X- _ O
the -X- _ O
entire -X- _ O
word -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
unit -X- _ O
for -X- _ O
AM -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
that -X- _ O
treats -X- _ O
the -X- _ O
phoneme -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
unit -X- _ O
for -X- _ O
AM -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
while -X- _ O
phonetic -X- _ O
dictionaries -X- _ O
are -X- _ O
available -X- _ O
for -X- _ O
Telugu -X- _ O
and -X- _ O
Gujarati -X- _ O
, -X- _ O
our -X- _ O
dataset -X- _ O
for -X- _ O
Sanskrit -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
an -X- _ O
accompanying -X- _ O
phonetic -X- _ O
dictionary -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
the -X- _ O
variation -X- _ O
in -X- _ O
vocabulary -X- _ O
size -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
the -X- _ O
graphemic -X- _ O
unit -X- _ O
( -X- _ O
native -X- _ O
script -X- _ O
vs. -X- _ O
SLP1 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
both -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
, -X- _ O
we -X- _ O
point -X- _ O
out -X- _ O
that -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
SLP1 -X- _ O
graphemic -X- _ O
units -X- _ O
almost -X- _ O
coincide -X- _ O
with -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
phonemes -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
native -X- _ O
script -X- _ O
- -X- _ O
based -X- _ O
graphemes -X- _ O
are -X- _ O
much -X- _ O
larger -X- _ O
in -X- _ O
number -X- _ O
compared -X- _ O
to -X- _ O
phonemes -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
also -X- _ O
roughly -X- _ O
estimate -X- _ O
the -X- _ O
extent -X- _ O
of -X- _ O
data -X- _ O
sparsity -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
vocabulary -X- _ O
size -X- _ O
in -X- _ O
each -X- _ O
setting -X- _ O
-larger -X- _ O
the -X- _ O
vocabulary -X- _ O
size -X- _ O
, -X- _ O
higher -X- _ O
is -X- _ O
the -X- _ O
chance -X- _ O
of -X- _ O
data -X- _ O
sparsity -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
data -X- _ O
sparsity -X- _ O
is -X- _ O
minimal -X- _ O
for -X- _ O
graphemes -X- _ O
and -X- _ O
highest -X- _ O
for -X- _ O
a -X- _ O
hypothetical -X- _ O
system -X- _ O
where -X- _ O
whole -X- _ O
words -X- _ O
are -X- _ O
the -X- _ O
unit -X- _ O
of -X- _ O
selection -X- _ O
. -X- _ O
Description -X- _ O
of -X- _ O
Datasets -X- _ O
: -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
reporting -X- _ O
ASR -X- _ B-TaskName
results -X- _ O
on -X- _ O
the -X- _ O
carefully -X- _ O
created -X- _ O
वाक् -X- _ O
सञ्चयः -X- _ O
( -X- _ O
/Vāksañcayah -X- _ O
̣/ -X- _ O
) -X- _ O
dataset -X- _ O
( -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
contrast -X- _ O
through -X- _ O
experimental -X- _ O
analysis -X- _ O
on -X- _ O
two -X- _ O
other -X- _ O
Indian -X- _ O
languages -X- _ O
, -X- _ O
viz -X- _ O
. -X- _ O
, -X- _ O
Telugu -X- _ O
and -X- _ O
Gujarati -X- _ O
. -X- _ O
For -X- _ O
Telugu -X- _ O
and -X- _ O
Gujarati -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
publicly -X- _ O
available -X- _ O
speech -X- _ O
corpora -X- _ O
released -X- _ O
by -X- _ O
Microsoft -X- _ O
( -X- _ O
Srivastava -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
that -X- _ O
contains -X- _ O
36.2/8.7 -X- _ O
hours -X- _ O
and -X- _ O
33.2/5.8 -X- _ O
hours -X- _ O
of -X- _ O
training -X- _ O
/ -X- _ O
test -X- _ O
speech -X- _ O
in -X- _ O
Telugu -X- _ O
and -X- _ O
Gujarati -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
new -X- _ O
train -X- _ O
- -X- _ O
test -X- _ O
split -X- _ O
for -X- _ O
the -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
datasets -X- _ O
because -X- _ O
the -X- _ O
original -X- _ O
split -X- _ O
had -X- _ O
overlapping -X- _ O
spekaers -X- _ O
in -X- _ O
their -X- _ O
train -X- _ O
and -X- _ O
test -X- _ O
. -X- _ O
Our -X- _ O
new -X- _ O
split -X- _ O
ensures -X- _ O
that -X- _ O
the -X- _ O
train -X- _ O
- -X- _ O
test -X- _ O
split -X- _ O
have -X- _ O
disjoint -X- _ O
speakers -X- _ O
. -X- _ O
Transcript -X- _ O
of -X- _ O
this -X- _ O
corpora -X- _ O
was -X- _ O
cleaned -X- _ O
for -X- _ O
orthographic -X- _ O
errors -X- _ O
. -X- _ O
Corpora -X- _ O
in -X- _ O
these -X- _ O
two -X- _ O
languages -X- _ O
were -X- _ O
accompanied -X- _ O
by -X- _ O
pronunciation -X- _ O
lexicons -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
used -X- _ O
to -X- _ O
build -X- _ O
phoneme -X- _ O
- -X- _ O
based -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
to -X- _ O
compare -X- _ O
against -X- _ O
our -X- _ O
grapheme -X- _ O
- -X- _ O
based -X- _ O
systems -X- _ O
. -X- _ O
Experimental -X- _ O
Setup -X- _ O
: -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
Kaldi -X- _ O
toolkit -X- _ O
( -X- _ O
Povey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
for -X- _ O
all -X- _ O
our -X- _ O
ASR -X- _ B-TaskName
experiments -X- _ O
. -X- _ O
Our -X- _ O
acoustic -X- _ O
model -X- _ O
is -X- _ O
implemented -X- _ O
using -X- _ O
Time -X- _ B-MethodName
Delay -X- _ I-MethodName
Neural -X- _ I-MethodName
Networks -X- _ I-MethodName
( -X- _ O
TDNNs -X- _ B-MethodName
) -X- _ O
( -X- _ O
Peddinti -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
containing -X- _ O
14 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
. -X- _ O
We -X- _ O
use -X- _ O
40dimensional -X- _ O
MFCCs -X- _ O
as -X- _ O
our -X- _ O
input -X- _ O
features -X- _ O
along -X- _ O
with -X- _ O
100 -X- _ B-HyperparameterValue
- -X- _ I-HyperparameterValue
dimensional -X- _ I-HyperparameterValue
i -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
vector -X- _ I-HyperparameterName
based -X- _ I-HyperparameterName
speaker -X- _ I-HyperparameterName
embeddings -X- _ I-HyperparameterName
( -X- _ O
Saon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
ngram -X- _ O
language -X- _ O
models -X- _ O
with -X- _ O
Kneser -X- _ O
- -X- _ O
Ney -X- _ O
smoothing -X- _ O
implemented -X- _ O
using -X- _ O
the -X- _ O
SRILM -X- _ O
toolkit -X- _ O
( -X- _ O
Stolcke -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
language -X- _ O
models -X- _ O
were -X- _ O
trained -X- _ O
using -X- _ O
both -X- _ O
training -X- _ O
transcripts -X- _ O
from -X- _ O
the -X- _ O
speech -X- _ O
data -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
additional -X- _ O
textual -X- _ O
data -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
Leipzig -X- _ B-DatasetName
Corpora -X- _ I-DatasetName
Collection -X- _ I-DatasetName
for -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
( -X- _ O
Goldhahn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Digital -X- _ B-DatasetName
Corpus -X- _ I-DatasetName
of -X- _ I-DatasetName
Sanskrit -X- _ I-DatasetName
( -X- _ O
Hellwig -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
for -X- _ O
Sanskrit -X- _ O
. -X- _ O
The -X- _ O
word -X- _ O
vocabulary -X- _ O
sizes -X- _ O
in -X- _ O
the -X- _ O
lexicons -X- _ O
for -X- _ O
Sanskrit -X- _ O
, -X- _ O
Telugu -X- _ O
and -X- _ O
Gujarati -X- _ O
are -X- _ O
76 -X- _ O
K -X- _ O
, -X- _ O
43 -X- _ O
K -X- _ O
and -X- _ O
48 -X- _ O
K -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Results -X- _ O
: -X- _ O
Tables -X- _ O
3 -X- _ O
, -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
, -X- _ O
present -X- _ O
the -X- _ O
WERs -X- _ B-MetricName
from -X- _ O
ASR -X- _ B-TaskName
systems -X- _ O
built -X- _ O
using -X- _ O
different -X- _ O
choices -X- _ O
of -X- _ O
AM -X- _ O
and -X- _ O
LM -X- _ O
units -X- _ O
using -X- _ O
both -X- _ O
the -X- _ O
graphemic -X- _ O
representations -X- _ O
( -X- _ O
Native -X- _ O
and -X- _ O
SLP1 -X- _ O
) -X- _ O
for -X- _ O
Sanskrit -X- _ O
, -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
From -X- _ O
Table -X- _ O
3 -X- _ O
see -X- _ O
that -X- _ O
BPE -X- _ O
units -X- _ O
4 -X- _ O
and -X- _ O
vowel -X- _ O
segment -X- _ O
units -X- _ O
are -X- _ O
far -X- _ O
superior -X- _ O
compared -X- _ O
to -X- _ O
words -X- _ O
as -X- _ O
an -X- _ O
LM -X- _ O
unit -X- _ O
for -X- _ O
Sanskrit -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
unsurprising -X- _ O
given -X- _ O
that -X- _ O
Sanskrit -X- _ O
has -X- _ O
a -X- _ O
high -X- _ O
rates -X- _ O
of -X- _ O
OOV -X- _ O
( -X- _ O
44.16 -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Tables -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
the -X- _ O
configurations -X- _ O
with -X- _ O
word -X- _ O
based -X- _ O
LMs -X- _ O
performs -X- _ O
the -X- _ O
best -X- _ O
for -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
respectively -X- _ O
. -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
have -X- _ O
lower -X- _ O
OOV -X- _ O
rates -X- _ O
of -X- _ O
18.63 -X- _ O
% -X- _ O
and -X- _ O
15.26 -X- _ O
% -X- _ O
.Table -X- _ O
6 -X- _ O
shows -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
words -X- _ O
with -X- _ O
1 -X- _ O
- -X- _ O
4 -X- _ O
continuous -X- _ O
consonants -X- _ O
in -X- _ O
all -X- _ O
three -X- _ O
languages -X- _ O
. -X- _ O
For -X- _ O
Telugu -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
conjunct -X- _ O
consonants -X- _ O
with -X- _ O
N -X- _ O
= -X- _ O
2 -X- _ O
is -X- _ O
higher -X- _ O
than -X- _ O
in -X- _ O
Sanskrit -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
on -X- _ O
inspecting -X- _ O
the -X- _ O
audio -X- _ O
data -X- _ O
that -X- _ O
such -X- _ O
conjunct -X- _ O
consonants -X- _ O
are -X- _ O
often -X- _ O
not -X- _ O
enunciated -X- _ O
( -X- _ O
Kulkarni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
inflections -X- _ O
and -X- _ O
compounds -X- _ O
, -X- _ O
Sanskrit -X- _ O
always -X- _ O
has -X- _ O
the -X- _ O
highest -X- _ O
number -X- _ O
of -X- _ O
rare -X- _ O
words -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
training -X- _ O
dataset -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
Sanskrit -X- _ O
ASR -X- _ B-TaskName
experiments -X- _ O
with -X- _ O
the -X- _ O
vocab -X- _ O
size -X- _ O
of -X- _ O
70.5 -X- _ O
K -X- _ O
, -X- _ O
more -X- _ O
than -X- _ O
87.25 -X- _ O
% -X- _ O
words -X- _ O
have -X- _ O
a -X- _ O
frequency -X- _ O
less -X- _ O
than -X- _ O
3 -X- _ O
, -X- _ O
where -X- _ O
as -X- _ O
in -X- _ O
Telugu -X- _ O
and -X- _ O
Gujarati -X- _ O
training -X- _ O
dataset -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
76.76 -X- _ O
% -X- _ O
and -X- _ O
77.26 -X- _ O
% -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Clear -X- _ O
articulation -X- _ O
of -X- _ O
conjunct -X- _ O
consonants -X- _ O
and -X- _ O
higher -X- _ O
rare -X- _ O
word -X- _ O
rates -X- _ O
makes -X- _ O
the -X- _ O
BPE -X- _ O
and -X- _ O
VS -X- _ O
based -X- _ O
models -X- _ O
performs -X- _ O
better -X- _ O
in -X- _ O
Sanskrit -X- _ O
than -X- _ O
other -X- _ O
two -X- _ O
languages -X- _ O
along -X- _ O
with -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
OOVs -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
use -X- _ O
of -X- _ O
SLP1 -X- _ O
as -X- _ O
a -X- _ O
graphemic -X- _ O
representation -X- _ O
schemes -X- _ O
performs -X- _ O
best -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
three -X- _ O
languages -X- _ O
. -X- _ O
SLP1 -X- _ O
is -X- _ O
designed -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
phonemic -X- _ O
- -X- _ O
graphemic -X- _ O
correspondences -X- _ O
present -X- _ O
in -X- _ O
Indic -X- _ O
languages -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
ASR -X- _ B-TaskName
performance -X- _ O
using -X- _ O
phonemes -X- _ O
is -X- _ O
comparable -X- _ O
to -X- _ O
graphemes -X- _ O
for -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
. -X- _ O
In -X- _ O
Sanskrit -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
purely -X- _ O
grapheme -X- _ O
- -X- _ O
based -X- _ O
acous- -X- _ O
tic -X- _ O
models -X- _ O
outperform -X- _ O
grapheme+vowel -X- _ O
segmentbased -X- _ O
acoustic -X- _ O
models -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
consistent -X- _ O
mapping -X- _ O
between -X- _ O
graphemes -X- _ O
and -X- _ O
phonemes -X- _ O
and -X- _ O
the -X- _ O
absence -X- _ O
of -X- _ O
schwa -X- _ O
deletion -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
intuitive -X- _ O
that -X- _ O
grapheme -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
would -X- _ O
be -X- _ O
most -X- _ O
appropriate -X- _ O
for -X- _ O
Sanskrit -X- _ O
. -X- _ O
Even -X- _ O
though -X- _ O
for -X- _ O
Sanskrit -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
Devanagari -X- _ O
as -X- _ O
a -X- _ O
graphemic -X- _ O
representation -X- _ O
outperforms -X- _ O
the -X- _ O
SLP1 -X- _ O
( -X- _ O
Sr -X- _ O
. -X- _ O
1,3,9,11 -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
that -X- _ O
uses -X- _ O
SLP1 -X- _ O
script -X- _ O
always -X- _ O
outperforms -X- _ O
the -X- _ O
other -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
character -X- _ O
error -X- _ O
rate -X- _ O
. -X- _ O
In -X- _ O
Sanskrit -X- _ O
the -X- _ O
pause -X- _ O
given -X- _ O
between -X- _ O
the -X- _ O
subwords -X- _ O
of -X- _ O
a -X- _ O
compound -X- _ O
word -X- _ O
and -X- _ O
in -X- _ O
between -X- _ O
two -X- _ O
words -X- _ O
varies -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
fluency -X- _ O
of -X- _ O
the -X- _ O
speaker -X- _ O
and -X- _ O
the -X- _ O
complexity -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
deteriorate -X- _ O
the -X- _ O
WER -X- _ B-MetricName
. -X- _ O
The -X- _ O
utterance -X- _ O
for -X- _ O
' -X- _ O
महान् -X- _ O
प्राकारः -X- _ O
' -X- _ O
/mahān -X- _ O
prākārah -X- _ O
̣/ -X- _ O
may -X- _ O
get -X- _ O
recognised -X- _ O
as -X- _ O
' -X- _ O
महान्प्राकारः -X- _ O
' -X- _ O
/mahānprākārah -X- _ O
̣/ -X- _ O
, -X- _ O
where -X- _ O
two -X- _ O
correctly -X- _ O
recognised -X- _ O
words -X- _ O
will -X- _ O
be -X- _ O
evaluated -X- _ O
as -X- _ O
one -X- _ O
deletion -X- _ O
and -X- _ O
one -X- _ O
substituion -X- _ O
by -X- _ O
the -X- _ O
evaluation -X- _ O
model -X- _ O
. -X- _ O
Similarly -X- _ O
if -X- _ O
the -X- _ O
audio -X- _ O
of -X- _ O
' -X- _ O
शोभमानमासीत् -X- _ O
' -X- _ O
/śobhamā -X- _ O
namāsīt/ -X- _ O
gets -X- _ O
recognised -X- _ O
as -X- _ O
' -X- _ O
शोभमानम् -X- _ O
आसीत् -X- _ O
' -X- _ O
/śob -X- _ O
hamānam -X- _ O
āsīt/ -X- _ O
, -X- _ O
then -X- _ O
it -X- _ O
will -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
one -X- _ O
insertion -X- _ O
followed -X- _ O
by -X- _ O
one -X- _ O
substituion -X- _ O
. -X- _ O
After -X- _ O
negating -X- _ O
these -X- _ O
two -X- _ O
particular -X- _ O
errors -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
get -X- _ O
17.79 -X- _ B-MetricValue
% -X- _ I-MetricValue
as -X- _ O
the -X- _ O
modulo -X- _ B-MetricName
substitution -X- _ I-MetricName
deletion -X- _ I-MetricName
WER -X- _ I-MetricName
for -X- _ O
our -X- _ O
best -X- _ O
model -X- _ O
of -X- _ O
Sanskrit -X- _ O
( -X- _ O
Sr -X- _ O
. -X- _ O
6 -X- _ O
of -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
character -X- _ B-MetricName
error -X- _ I-MetricName
rate -X- _ I-MetricName
3.10 -X- _ B-MetricValue
% -X- _ I-MetricValue
for -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
in -X- _ O
Sanskrit -X- _ O
also -X- _ O
ensures -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
, -X- _ O
where -X- _ O
as -X- _ O
the -X- _ O
CER -X- _ B-MetricName
for -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
of -X- _ O
Gujarati -X- _ O
and -X- _ O
Telugu -X- _ O
are -X- _ O
5.49 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
5.60 -X- _ B-MetricValue
% -X- _ I-MetricValue
respectively -X- _ O
, -X- _ O
much -X- _ O
higher -X- _ O
than -X- _ O
Sanskrit -X- _ O
. -X- _ O
Out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
Table -X- _ O
7 -X- _ O
presents -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
test -X- _ O
set -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
. -X- _ O
It -X- _ O
shows -X- _ O
the -X- _ O
WERs -X- _ B-MetricName
we -X- _ O
can -X- _ O
expect -X- _ O
from -X- _ O
our -X- _ O
models -X- _ O
when -X- _ O
the -X- _ O
speakers -X- _ O
and -X- _ O
content -X- _ O
largely -X- _ O
vary -X- _ O
in -X- _ O
domain -X- _ O
from -X- _ O
our -X- _ O
dataset -X- _ O
. -X- _ O
This -X- _ O
test -X- _ O
set -X- _ O
was -X- _ O
sampled -X- _ O
for -X- _ O
specific -X- _ O
speakers -X- _ O
and -X- _ O
content -X- _ O
that -X- _ O
qualify -X- _ O
as -X- _ O
being -X- _ O
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
domain -X- _ O
. -X- _ O
These -X- _ O
test -X- _ O
utterances -X- _ O
were -X- _ O
evaluated -X- _ O
using -X- _ O
our -X- _ O
best -X- _ O
performing -X- _ O
Sanskrit -X- _ O
ASR -X- _ B-TaskName
models -X- _ O
. -X- _ O
Speakers -X- _ O
# -X- _ O
1 -X- _ O
and -X- _ O
# -X- _ O
2 -X- _ O
were -X- _ O
included -X- _ O
, -X- _ O
as -X- _ O
their -X- _ O
utterances -X- _ O
show -X- _ O
more -X- _ O
pronounced -X- _ O
influence -X- _ O
of -X- _ O
their -X- _ O
native -X- _ O
languages -X- _ O
, -X- _ O
Tamil -X- _ O
and -X- _ O
Hindi -X- _ O
respectively -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
observed -X- _ O
that -X- _ O
speaker -X- _ O
# -X- _ O
1 -X- _ O
, -X- _ O
does -X- _ O
not -X- _ O
often -X- _ O
attempt -X- _ O
to -X- _ O
distinguish -X- _ O
between -X- _ O
the -X- _ O
pronunciation -X- _ O
of -X- _ O
the -X- _ O
phoneme -X- _ O
pairs -X- _ O
such -X- _ O
as -X- _ O
/ta/ -X- _ O
and -X- _ O
/da/ -X- _ O
, -X- _ O
/ka/ -X- _ O
and -X- _ O
/ga/ -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
in -X- _ O
congruence -X- _ O
with -X- _ O
the -X- _ O
orthography -X- _ O
followed -X- _ O
in -X- _ O
Tamil -X- _ O
, -X- _ O
the -X- _ O
speaker -X- _ O
's -X- _ O
native -X- _ O
language -X- _ O
. -X- _ O
Speaker -X- _ O
# -X- _ O
2 -X- _ O
's -X- _ O
reading -X- _ O
was -X- _ O
influenced -X- _ O
by -X- _ O
schwa -X- _ O
deletion -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
phenomena -X- _ O
of -X- _ O
deleting -X- _ O
vowel -X- _ O
markers -X- _ O
accompanying -X- _ O
consonants -X- _ O
at -X- _ O
certain -X- _ O
contexts -X- _ O
( -X- _ O
elaborated -X- _ O
in -X- _ O
the -X- _ O
supplementary -X- _ O
material -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
dominant -X- _ O
in -X- _ O
Hindi -X- _ O
. -X- _ O
The -X- _ O
inclusion -X- _ O
of -X- _ O
poetry -X- _ O
data -X- _ O
would -X- _ O
require -X- _ O
substantial -X- _ O
changes -X- _ O
to -X- _ O
the -X- _ O
system -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
address -X- _ O
in -X- _ O
the -X- _ O
near -X- _ O
future -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
the -X- _ O
poetry -X- _ O
data -X- _ O
would -X- _ O
greatly -X- _ O
benefit -X- _ O
from -X- _ O
insights -X- _ O
from -X- _ O
Sanskrit -X- _ O
prosody -X- _ O
. -X- _ O
More -X- _ O
importantly -X- _ O
, -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
free -X- _ O
word -X- _ O
orderness -X- _ O
in -X- _ O
prose -X- _ O
and -X- _ O
poetry -X- _ O
greatly -X- _ O
varies -X- _ O
in -X- _ O
Sanskrit -X- _ O
, -X- _ O
so -X- _ O
much -X- _ O
so -X- _ O
that -X- _ O
an -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
LM -X- _ O
will -X- _ O
not -X- _ O
be -X- _ O
effective -X- _ O
. -X- _ O
Sr -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Prof. -X- _ O
K. -X- _ O
Ramasubramanian -X- _ O
, -X- _ O
IIT -X- _ O
Bombay -X- _ O
, -X- _ O
for -X- _ O
supporting -X- _ O
the -X- _ O
creation -X- _ O
of -X- _ O
Sanskrit -X- _ O
speech -X- _ O
corpus -X- _ O
. -X- _ O
We -X- _ O
express -X- _ O
our -X- _ O
gratitude -X- _ O
to -X- _ O
the -X- _ O
volunteers -X- _ O
who -X- _ O
have -X- _ O
participated -X- _ O
in -X- _ O
recording -X- _ O
readings -X- _ O
of -X- _ O
classical -X- _ O
Sanskrit -X- _ O
texts -X- _ O
and -X- _ O
helping -X- _ O
make -X- _ O
this -X- _ O
resource -X- _ O
available -X- _ O
for -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
research -X- _ O
. -X- _ O
A -X- _ O
Differences -X- _ O
between -X- _ O
Sanskrit -X- _ O
and -X- _ O
other -X- _ O
Indic -X- _ O
languages -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
Many -X- _ O
Indian -X- _ O
languages -X- _ O
are -X- _ O
known -X- _ O
to -X- _ O
be -X- _ O
derived -X- _ O
from -X- _ O
Sanskrit -X- _ O
( -X- _ O
Kulkarni -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010b -X- _ O
) -X- _ O
and -X- _ O
their -X- _ O
scripts -X- _ O
derived -X- _ O
from -X- _ O
the -X- _ O
Brahmi -X- _ O
script -X- _ O
( -X- _ O
Salomon -X- _ O
, -X- _ O
1996;Sproat -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
leads -X- _ O
to -X- _ O
graphemebased -X- _ O
similarites -X- _ O
amongst -X- _ O
them -X- _ O
. -X- _ O
In -X- _ O
Figure -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
illustrate -X- _ O
through -X- _ O
an -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
spectrum -X- _ O
of -X- _ O
mapping -X- _ O
the -X- _ O
native -X- _ O
character -X- _ O
/ -X- _ O
grapheme -X- _ O
( -X- _ O
units -X- _ O
) -X- _ O
in -X- _ O
words -X- _ O
across -X- _ O
languages -X- _ O
; -X- _ O
at -X- _ O
one -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
spectrum -X- _ O
is -X- _ O
राम(/rām/ -X- _ O
) -X- _ O
in -X- _ O
Hindi -X- _ O
mapped -X- _ O
to -X- _ O
రామ(/rāma/ -X- _ O
) -X- _ O
in -X- _ O
Telugu -X- _ O
as -X- _ O
an -X- _ O
example -X- _ O
where -X- _ O
direct -X- _ O
correspondence -X- _ O
with -X- _ O
the -X- _ O
native -X- _ O
character -X- _ O
exists -X- _ O
. -X- _ O
Going -X- _ O
further -X- _ O
in -X- _ O
the -X- _ O
spectrum -X- _ O
are -X- _ O
examples -X- _ O
for -X- _ O
which -X- _ O
direct -X- _ O
character -X- _ O
correspondence -X- _ O
does -X- _ O
not -X- _ O
exist -X- _ O
. -X- _ O
सीता(/sītā/ -X- _ O
) -X- _ O
in -X- _ O
Hindi -X- _ O
going -X- _ O
to -X- _ O
ಸೀತೆ(/sīte/ -X- _ O
) -X- _ O
in -X- _ O
Kannada -X- _ O
is -X- _ O
an -X- _ O
instance -X- _ O
where -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
change -X- _ O
in -X- _ O
the -X- _ O
ending -X- _ O
vowel -X- _ O
. -X- _ O
The -X- _ O
schwa -X- _ O
deletion -X- _ O
phenomenon -X- _ O
plays -X- _ O
a -X- _ O
crucial -X- _ O
role -X- _ O
in -X- _ O
the -X- _ O
north -X- _ O
Indian -X- _ O
languages -X- _ O
. -X- _ O
Every -X- _ O
consonant -X- _ O
by -X- _ O
itself -X- _ O
includes -X- _ O
a -X- _ O
short -X- _ O
/a/ -X- _ O
vowel -X- _ O
sound -X- _ O
( -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
" -X- _ O
schwa -X- _ O
" -X- _ O
) -X- _ O
unless -X- _ O
otherwise -X- _ O
specified -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
letter -X- _ O
' -X- _ O
त -X- _ O
' -X- _ O
in -X- _ O
Hindi -X- _ O
is -X- _ O
pronounced -X- _ O
as -X- _ O
/ta/. -X- _ O
This -X- _ O
sound -X- _ O
can -X- _ O
be -X- _ O
associated -X- _ O
with -X- _ O
any -X- _ O
other -X- _ O
vowel -X- _ O
sound -X- _ O
by -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
" -X- _ O
Mātras -X- _ O
" -X- _ O
. -X- _ O
Mātras -X- _ O
are -X- _ O
dependent -X- _ O
forms -X- _ O
of -X- _ O
vowels -X- _ O
. -X- _ O
Schwa -X- _ O
is -X- _ O
the -X- _ O
default -X- _ O
vowel -X- _ O
for -X- _ O
a -X- _ O
consonant -X- _ O
and -X- _ O
hence -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
any -X- _ O
explicit -X- _ O
Mātra -X- _ O
to -X- _ O
represent -X- _ O
it -X- _ O
. -X- _ O
Schwa -X- _ O
deletion -X- _ O
is -X- _ O
a -X- _ O
phenomenon -X- _ O
where -X- _ O
implicit -X- _ O
schwas -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
are -X- _ O
deleted -X- _ O
during -X- _ O
pronunciation -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
Hindi -X- _ O
, -X- _ O
the -X- _ O
proper -X- _ O
noun -X- _ O
, -X- _ O
' -X- _ O
अजु -X- _ O
र् -X- _ O
न -X- _ O
( -X- _ O
/arjun/ -X- _ O
, -X- _ O
the -X- _ O
name -X- _ O
of -X- _ O
a -X- _ O
person -X- _ O
) -X- _ O
has -X- _ O
schwa -X- _ O
deletion -X- _ O
after -X- _ O
the -X- _ O
consonant -X- _ O
' -X- _ O
न -X- _ O
' -X- _ O
and -X- _ O
is -X- _ O
pronounced -X- _ O
as -X- _ O
Arjun -X- _ O
. -X- _ O
This -X- _ O
phenomenon -X- _ O
is -X- _ O
not -X- _ O
observed -X- _ O
in -X- _ O
the -X- _ O
South -X- _ O
Indian -X- _ O
languages -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
in -X- _ O
Kannada -X- _ O
it -X- _ O
is -X- _ O
pronounced -X- _ O
as -X- _ O
' -X- _ O
Arjuna -X- _ O
' -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
no -X- _ O
implicit -X- _ O
schwa -X- _ O
deletion -X- _ O
in -X- _ O
Sanskrit -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
traditional -X- _ O
use -X- _ O
of -X- _ O
South -X- _ O
Indian -X- _ O
languages -X- _ O
such -X- _ O
as -X- _ O
Kannada -X- _ O
. -X- _ O
North -X- _ O
Indian -X- _ O
languages -X- _ O
observe -X- _ O
schwa -X- _ O
deletion -X- _ O
not -X- _ O
only -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
' -X- _ O
गलती -X- _ O
' -X- _ O
( -X- _ O
/galtī/ -X- _ O
meaning -X- _ O
mistake -X- _ O
) -X- _ O
in -X- _ O
Hindi -X- _ O
observes -X- _ O
implicit -X- _ O
schwa -X- _ O
deletion -X- _ O
after -X- _ O
the -X- _ O
consonant -X- _ O
' -X- _ O
ल'(/la/ -X- _ O
) -X- _ O
. -X- _ O
ASR -X- _ B-TaskName
becomes -X- _ O
challenging -X- _ O
because -X- _ O
of -X- _ O
this -X- _ O
phenomenon -X- _ O
since -X- _ O
the -X- _ O
occurrence -X- _ O
of -X- _ O
schwa -X- _ O
deletion -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
explicitly -X- _ O
specified -X- _ O
in -X- _ O
the -X- _ O
orthography -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
name -X- _ O
रामबाबु -X- _ O
( -X- _ O
/rāmbābu/ -X- _ O
) -X- _ O
has -X- _ O
two -X- _ O
basic -X- _ O
words -X- _ O
concatenated -X- _ O
to -X- _ O
form -X- _ O
a -X- _ O
name -X- _ O
. -X- _ O
In -X- _ O
Hindi -X- _ O
, -X- _ O
this -X- _ O
name -X- _ O
has -X- _ O
an -X- _ O
implicit -X- _ O
schwa -X- _ O
deleted -X- _ O
at -X- _ O
म -X- _ O
( -X- _ O
consonant -X- _ O
sounding -X- _ O
' -X- _ O
ma -X- _ O
' -X- _ O
) -X- _ O
of -X- _ O
राम -X- _ O
( -X- _ O
/rām/ -X- _ O
) -X- _ O
. -X- _ O
While -X- _ O
constructing -X- _ O
phonetic -X- _ O
representations -X- _ O
for -X- _ O
ASR -X- _ B-TaskName
, -X- _ O
such -X- _ O
deletions -X- _ O
introduce -X- _ O
ambiguities -X- _ O
in -X- _ O
pronunciation -X- _ O
which -X- _ O
could -X- _ O
be -X- _ O
alleviated -X- _ O
by -X- _ O
enforcing -X- _ O
more -X- _ O
consistency -X- _ O
between -X- _ O
graphemes -X- _ O
and -X- _ O
phonemes -X- _ O
. -X- _ O
This -X- _ O
same -X- _ O
word -X- _ O
रामबाबु -X- _ O
written -X- _ O
in -X- _ O
Telugu -X- _ O
would -X- _ O
be -X- _ O
phonetically -X- _ O
represented -X- _ O
as -X- _ O
రామాబ్బు -X- _ O
( -X- _ O
/rāmbābu/ -X- _ O
) -X- _ O
instead -X- _ O
of -X- _ O
రామబాబు -X- _ O
( -X- _ O
/rāmabābu/ -X- _ O
) -X- _ O
which -X- _ O
is -X- _ O
intuitive -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
former -X- _ O
case -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
addition -X- _ O
of -X- _ O
' -X- _ O
◌ -X- _ O
్ -X- _ O
' -X- _ O
( -X- _ O
halant -X- _ O
: -X- _ O
an -X- _ O
explicit -X- _ O
schwa -X- _ O
deletion -X- _ O
marker -X- _ O
) -X- _ O
at -X- _ O
మ(/ma/ -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
forces -X- _ O
the -X- _ O
consonants -X- _ O
మ(/ma/ -X- _ O
) -X- _ O
and -X- _ O
బ(/ba/ -X- _ O
) -X- _ O
to -X- _ O
combine -X- _ O
and -X- _ O
form -X- _ O
a -X- _ O
conjunct -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
latter -X- _ O
case -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
grapheme -X- _ O
consistency -X- _ O
across -X- _ O
both -X- _ O
Hindi -X- _ O
and -X- _ O
Telugu -X- _ O
languages -X- _ O
but -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
variation -X- _ O
in -X- _ O
their -X- _ O
pronunciation -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
schwa -X- _ O
deletion -X- _ O
phenomenon -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
Sanskrit -X- _ O
, -X- _ O
since -X- _ O
pronunciation -X- _ O
is -X- _ O
strictly -X- _ O
governed -X- _ O
by -X- _ O
the -X- _ O
शक्षा(/śiks -X- _ O
̣ā/ -X- _ O
) -X- _ O
( -X- _ O
Manomohan -X- _ O
and -X- _ O
Pān -X- _ O
̣ini -X- _ O
, -X- _ O
1938 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
treatise -X- _ O
on -X- _ O
phonetics -X- _ O
, -X- _ O
schwa -X- _ O
deletion -X- _ O
is -X- _ O
not -X- _ O
observed -X- _ O
. -X- _ O
In -X- _ O
Sanskrit -X- _ O
a -X- _ O
noun -X- _ O
can -X- _ O
have -X- _ O
24 -X- _ O
to -X- _ O
92 -X- _ O
inflections -X- _ O
( -X- _ O
depending -X- _ O
on -X- _ O
base -X- _ O
word -X- _ O
's -X- _ O
gender -X- _ O
and -X- _ O
alternate -X- _ O
forms -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
verb -X- _ O
can -X- _ O
have -X- _ O
90 -X- _ O
to -X- _ O
180 -X- _ O
inflections -X- _ O
. -X- _ O
Derivative -X- _ O
nouns -X- _ O
( -X- _ O
Taddhitas -X- _ O
) -X- _ O
and -X- _ O
verbs -X- _ O
( -X- _ O
passive -X- _ O
( -X- _ O
Karman -X- _ O
̣i -X- _ O
) -X- _ O
, -X- _ O
san -X- _ O
, -X- _ O
n -X- _ O
̣ic -X- _ O
, -X- _ O
yaṅ -X- _ O
, -X- _ O
etc -X- _ O
) -X- _ O
are -X- _ O
also -X- _ O
used -X- _ O
often -X- _ O
in -X- _ O
Sanskrit -X- _ O
literature -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
this -X- _ O
morphological -X- _ O
richness -X- _ O
and -X- _ O
frequently -X- _ O
occurring -X- _ O
compound -X- _ O
words -X- _ O
, -X- _ O
vocab -X- _ O
size -X- _ O
can -X- _ O
be -X- _ O
reduced -X- _ O
by -X- _ O
properly -X- _ O
selecting -X- _ O
repetitive -X- _ O
stems -X- _ O
and -X- _ O
suffices -X- _ O
using -X- _ O
BPE -X- _ O
by -X- _ O
specifying -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
merge -X- _ O
operations -X- _ O
. -X- _ O
Therefore -X- _ O
we -X- _ O
experimented -X- _ O
varying -X- _ O
number -X- _ O
of -X- _ O
subword -X- _ O
unit -X- _ O
with -X- _ O
vocabulary -X- _ O
sizes -X- _ O
of -X- _ O
2 -X- _ O
K -X- _ O
, -X- _ O
4 -X- _ O
K -X- _ O
, -X- _ O
8 -X- _ O
K -X- _ O
, -X- _ O
16 -X- _ O
K -X- _ O
, -X- _ O
32 -X- _ O
K -X- _ O
and -X- _ O
64 -X- _ O
K -X- _ O
( -X- _ O
K=1000 -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
varying -X- _ O
BPE -X- _ O
configuration -X- _ O
on -X- _ O
our -X- _ O
best -X- _ O
configuration -X- _ O
, -X- _ O
i.e -X- _ O
graphemes -X- _ O
as -X- _ O
AM -X- _ O
unit -X- _ O
and -X- _ O
BPE -X- _ O
as -X- _ O
LM -X- _ O
unit -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
these -X- _ O
configurations -X- _ O
are -X- _ O
comparable -X- _ O
irrespective -X- _ O
of -X- _ O
their -X- _ O
BPE -X- _ O
vocabulary -X- _ O
size -X- _ O
. -X- _ O
BPE -X- _ O
with -X- _ O
vocabulary -X- _ O
size -X- _ O
of -X- _ O
32,000 -X- _ O
stands -X- _ O
closes -X- _ O
to -X- _ O
that -X- _ O
of -X- _ O
VS -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
vocabulary -X- _ O
size -X- _ O
of -X- _ O
29,147 -X- _ O
. -X- _ O
Even -X- _ O
in -X- _ O
this -X- _ O
configuration -X- _ O
, -X- _ O
BPE -X- _ O
outperforms -X- _ O
VS -X- _ O
, -X- _ O
as -X- _ O
BPE -X- _ O
reports -X- _ O
a -X- _ O
WER -X- _ B-MetricName
of -X- _ O
21.94 -X- _ B-MetricValue
as -X- _ O

Pre -X- _ O
- -X- _ O
trained -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
LMs -X- _ O
) -X- _ O
have -X- _ O
achieved -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
in -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
, -X- _ O
but -X- _ O
they -X- _ O
often -X- _ O
lead -X- _ O
to -X- _ O
an -X- _ O
inequitable -X- _ O
representation -X- _ O
of -X- _ O
languages -X- _ O
due -X- _ O
to -X- _ O
limited -X- _ O
capacity -X- _ O
, -X- _ O
skewed -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
vocabularies -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
prompted -X- _ O
the -X- _ O
creation -X- _ O
of -X- _ O
an -X- _ O
ever -X- _ O
- -X- _ O
growing -X- _ O
pretrained -X- _ O
model -X- _ O
universe -X- _ O
, -X- _ O
where -X- _ O
each -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
language -X- _ O
or -X- _ O
domain -X- _ O
specific -X- _ O
data -X- _ O
with -X- _ O
a -X- _ O
carefully -X- _ O
curated -X- _ O
, -X- _ O
linguistically -X- _ O
informed -X- _ O
vocabulary -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
doing -X- _ O
so -X- _ O
brings -X- _ O
us -X- _ O
back -X- _ O
full -X- _ O
circle -X- _ O
and -X- _ O
prevents -X- _ O
one -X- _ O
from -X- _ O
leveraging -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
multilinguality -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
the -X- _ O
gaps -X- _ O
at -X- _ O
both -X- _ O
ends -X- _ O
of -X- _ O
the -X- _ O
spectrum -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
MERGEDISTILL -X- _ B-MethodName
, -X- _ O
a -X- _ O
framework -X- _ O
to -X- _ O
merge -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LMs -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
can -X- _ O
best -X- _ O
leverage -X- _ O
their -X- _ O
assets -X- _ O
with -X- _ O
minimal -X- _ O
dependencies -X- _ O
, -X- _ O
using -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
knowledge -X- _ O
distillation -X- _ O
. -X- _ O
We -X- _ O
demonstrate -X- _ O
the -X- _ O
applicability -X- _ O
of -X- _ O
our -X- _ O
framework -X- _ O
in -X- _ O
a -X- _ O
practical -X- _ O
setting -X- _ O
by -X- _ O
leveraging -X- _ O
pre -X- _ O
- -X- _ O
existing -X- _ O
teacher -X- _ O
LMs -X- _ O
and -X- _ O
training -X- _ O
student -X- _ O
LMs -X- _ O
that -X- _ O
perform -X- _ O
competitively -X- _ O
with -X- _ O
or -X- _ O
even -X- _ O
outperform -X- _ O
teacher -X- _ O
LMs -X- _ O
trained -X- _ O
on -X- _ O
several -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
more -X- _ O
data -X- _ O
and -X- _ O
with -X- _ O
a -X- _ O
fixed -X- _ O
model -X- _ O
capacity -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
teacher -X- _ O
selection -X- _ O
and -X- _ O
its -X- _ O
impact -X- _ O
on -X- _ O
student -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
While -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
( -X- _ O
LMs -X- _ O
) -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
aim -X- _ O
to -X- _ O
represent -X- _ O
100 -X- _ O
+ -X- _ O
languages -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
, -X- _ O
efforts -X- _ O
towards -X- _ O
building -X- _ O
monolingual -X- _ O
( -X- _ O
Martin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Kuratov -X- _ O
and -X- _ O
Arkhipov -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
language -X- _ O
- -X- _ O
family -X- _ O
based -X- _ O
( -X- _ O
Khanuja -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
models -X- _ O
are -X- _ O
only -X- _ O
increasing -X- _ O
with -X- _ O
time -X- _ O
( -X- _ O
Rust -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
single -X- _ O
model -X- _ O
is -X- _ O
often -X- _ O
incapable -X- _ O
of -X- _ O
effectively -X- _ O
representing -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
languages -X- _ O
, -X- _ O
evidence -X- _ O
of -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
provided -X- _ O
by -X- _ O
works -X- _ O
highlighting -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
vocabulary -X- _ O
curation -X- _ O
and -X- _ O
size -X- _ O
( -X- _ O
Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Artetxe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
volume -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a;Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
curse -X- _ O
of -X- _ O
multilinguality -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
Language -X- _ O
specific -X- _ O
models -X- _ O
alleviate -X- _ O
these -X- _ O
issues -X- _ O
with -X- _ O
a -X- _ O
custom -X- _ O
vocabulary -X- _ O
which -X- _ O
captures -X- _ O
language -X- _ O
subtleties -X- _ O
1 -X- _ O
and -X- _ O
large -X- _ O
magnitudes -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
scraped -X- _ O
from -X- _ O
several -X- _ O
domains -X- _ O
( -X- _ O
Virtanen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Antoun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
building -X- _ O
language -X- _ O
specific -X- _ O
LMs -X- _ O
brings -X- _ O
us -X- _ O
back -X- _ O
to -X- _ O
where -X- _ O
we -X- _ O
started -X- _ O
, -X- _ O
preventing -X- _ O
us -X- _ O
from -X- _ O
leveraging -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
multilinguality -X- _ O
like -X- _ O
zeroshot -X- _ O
task -X- _ O
transfer -X- _ O
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
positive -X- _ O
transfer -X- _ O
between -X- _ O
related -X- _ O
languages -X- _ O
( -X- _ O
Pires -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Lauscher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
an -X- _ O
ability -X- _ O
to -X- _ O
handle -X- _ O
codemixed -X- _ O
text -X- _ O
( -X- _ O
Pires -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Tsai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
need -X- _ O
an -X- _ O
approach -X- _ O
that -X- _ O
encompasses -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
both -X- _ O
worlds -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
leverage -X- _ O
the -X- _ O
capabilities -X- _ O
of -X- _ O
the -X- _ O
powerful -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
LMs -X- _ O
while -X- _ O
still -X- _ O
being -X- _ O
multilingual -X- _ O
and -X- _ O
enabling -X- _ O
positive -X- _ O
language -X- _ O
trans-1 -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
Arabic -X- _ O
, -X- _ O
( -X- _ O
Antoun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
argue -X- _ O
that -X- _ O
while -X- _ O
the -X- _ O
definite -X- _ O
article -X- _ O
" -X- _ O
Al -X- _ O
" -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
equivalent -X- _ O
to -X- _ O
" -X- _ O
the -X- _ O
" -X- _ O
in -X- _ O
English -X- _ O
, -X- _ O
is -X- _ O
always -X- _ O
prefixed -X- _ O
to -X- _ O
other -X- _ O
words -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
an -X- _ O
intrinsic -X- _ O
part -X- _ O
of -X- _ O
that -X- _ O
word -X- _ O
. -X- _ O
While -X- _ O
with -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
compatible -X- _ O
tokenization -X- _ O
tokens -X- _ O
will -X- _ O
appear -X- _ O
twice -X- _ O
, -X- _ O
once -X- _ O
with -X- _ O
" -X- _ O
Al- -X- _ O
" -X- _ O
and -X- _ O
once -X- _ O
without -X- _ O
it -X- _ O
, -X- _ O
AraBERT -X- _ B-MethodName
first -X- _ O
segments -X- _ O
the -X- _ O
words -X- _ O
using -X- _ O
Farasa -X- _ O
( -X- _ O
Abdelali -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
then -X- _ O
learns -X- _ O
the -X- _ O
vocabulary -X- _ O
, -X- _ O
thereby -X- _ O
alleviating -X- _ O
the -X- _ O
problem -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
: -X- _ O
Overview -X- _ O
of -X- _ O
MERGEDISTILL -X- _ B-MethodName
: -X- _ O
The -X- _ O
input -X- _ O
to -X- _ O
MERGEDISTILL -X- _ B-MethodName
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
teacher -X- _ O
LMs -X- _ O
and -X- _ O
pretraining -X- _ O
transfer -X- _ O
corpora -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
languages -X- _ O
we -X- _ O
wish -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
student -X- _ O
LM -X- _ O
on -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
four -X- _ O
teacher -X- _ O
LMs -X- _ O
comprising -X- _ O
of -X- _ O
three -X- _ O
monolingual -X- _ O
( -X- _ O
trained -X- _ O
on -X- _ O
English -X- _ O
, -X- _ O
Spanish -X- _ O
and -X- _ O
Korean -X- _ O
respectively -X- _ O
) -X- _ O
and -X- _ O
one -X- _ O
multilingual -X- _ O
LM -X- _ O
( -X- _ O
trained -X- _ O
on -X- _ O
English -X- _ O
and -X- _ O
Hindi -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
student -X- _ O
LM -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
English -X- _ O
, -X- _ O
Spanish -X- _ O
, -X- _ O
Hindi -X- _ O
and -X- _ O
Korean -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
transfer -X- _ O
corpora -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
is -X- _ O
tokenized -X- _ O
and -X- _ O
masked -X- _ O
using -X- _ O
their -X- _ O
respective -X- _ O
teacher -X- _ O
LMs -X- _ O
vocabulary -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
obtain -X- _ O
predictions -X- _ O
for -X- _ O
each -X- _ O
masked -X- _ O
word -X- _ O
in -X- _ O
each -X- _ O
language -X- _ O
, -X- _ O
by -X- _ O
evaluating -X- _ O
all -X- _ O
of -X- _ O
their -X- _ O
respective -X- _ O
teacher -X- _ O
LMs -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
English -X- _ O
masked -X- _ O
examples -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
monolingual -X- _ O
and -X- _ O
multilingual -X- _ O
LM -X- _ O
as -X- _ O
shown -X- _ O
. -X- _ O
The -X- _ O
student -X- _ O
's -X- _ O
vocabulary -X- _ O
is -X- _ O
a -X- _ O
union -X- _ O
of -X- _ O
all -X- _ O
teacher -X- _ O
vocabularies -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
prediction -X- _ O
and -X- _ O
label -X- _ O
indices -X- _ O
obtained -X- _ O
from -X- _ O
teacher -X- _ O
evaluation -X- _ O
are -X- _ O
now -X- _ O
mapped -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
vocabulary -X- _ O
, -X- _ O
and -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
LM -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
Section -X- _ O
3.1 -X- _ O
for -X- _ O
details -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
knowledge -X- _ O
distillation -X- _ O
( -X- _ O
KD -X- _ O
) -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
to -X- _ O
achieve -X- _ O
this -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
KD -X- _ O
methods -X- _ O
can -X- _ O
be -X- _ O
broadly -X- _ O
classified -X- _ O
into -X- _ O
two -X- _ O
categories -X- _ O
: -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
and -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
. -X- _ O
In -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
distillation -X- _ O
, -X- _ O
the -X- _ O
teacher -X- _ O
LM -X- _ O
is -X- _ O
first -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
a -X- _ O
specific -X- _ O
task -X- _ O
and -X- _ O
is -X- _ O
then -X- _ O
distilled -X- _ O
into -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
which -X- _ O
can -X- _ O
solve -X- _ O
that -X- _ O
task -X- _ O
. -X- _ O
Task -X- _ O
- -X- _ O
agnostic -X- _ O
methods -X- _ O
perform -X- _ O
distillation -X- _ O
on -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objective -X- _ O
like -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
Prior -X- _ O
work -X- _ O
has -X- _ O
either -X- _ O
used -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
distillation -X- _ O
to -X- _ O
compress -X- _ O
singlelanguage -X- _ O
teachers -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
or -X- _ O
used -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
distillation -X- _ O
to -X- _ O
combine -X- _ O
multiple -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
teachers -X- _ O
into -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
student -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b;Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
former -X- _ O
prevents -X- _ O
positive -X- _ O
language -X- _ O
transfer -X- _ O
while -X- _ O
the -X- _ O
latter -X- _ O
restricts -X- _ O
the -X- _ O
student -X- _ O
's -X- _ O
capabilities -X- _ O
to -X- _ O
the -X- _ O
tasks -X- _ O
and -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
teacher -X- _ O
LMs -X- _ O
( -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1).We -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
merging -X- _ O
multiple -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LMs -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
multilingual -X- _ O
student -X- _ O
LM -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
setting -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
effort -X- _ O
of -X- _ O
its -X- _ O
kind -X- _ O
, -X- _ O
and -X- _ O
makes -X- _ O
the -X- _ O
following -X- _ O
contributions:• -X- _ O
We -X- _ O
propose -X- _ O
MERGEDISTILL -X- _ B-MethodName
, -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
distillation -X- _ O
approach -X- _ O
to -X- _ O
merge -X- _ O
multiple -X- _ O
teacher -X- _ O
LMs -X- _ O
at -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
stage -X- _ O
, -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
strong -X- _ O
multilingual -X- _ O
student -X- _ O
LM -X- _ O
that -X- _ O
can -X- _ O
then -X- _ O
be -X- _ O
finetuned -X- _ O
for -X- _ O
any -X- _ O
task -X- _ O
on -X- _ O
all -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
student -X- _ O
LM -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
is -X- _ O
more -X- _ O
maintainable -X- _ O
( -X- _ O
fewer -X- _ O
models -X- _ O
) -X- _ O
, -X- _ O
compute -X- _ O
efficient -X- _ O
and -X- _ O
teacherarchitecture -X- _ O
agnostic -X- _ O
( -X- _ O
since -X- _ O
we -X- _ O
obtain -X- _ O
offline -X- _ O
predictions).• -X- _ O
We -X- _ O
use -X- _ O
MERGEDISTILL -X- _ B-MethodName
to -X- _ O
i -X- _ O
) -X- _ O
combine -X- _ O
monolingual -X- _ O
teacher -X- _ O
LMs -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
multilingual -X- _ O
student -X- _ O
LM -X- _ O
that -X- _ O
is -X- _ O
competitive -X- _ O
with -X- _ O
or -X- _ O
outperforms -X- _ O
individual -X- _ O
teachers -X- _ O
, -X- _ O
ii -X- _ O
) -X- _ O
combine -X- _ O
multilingual -X- _ O
teacher -X- _ O
LMs -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
overlapping -X- _ O
languages -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
multiple -X- _ O
teachers.• -X- _ O
Through -X- _ O
extensive -X- _ O
experiments -X- _ O
and -X- _ O
analysis -X- _ O
, -X- _ O
we -X- _ O
study -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
typological -X- _ O
similarity -X- _ O
in -X- _ O
building -X- _ O
multilingual -X- _ O
models -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
strong -X- _ O
teacher -X- _ O
LM -X- _ O
vocabularies -X- _ O
and -X- _ O
predictions -X- _ O
in -X- _ O
our -X- _ O
framework -X- _ O
. -X- _ O
Language -X- _ O
Model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
has -X- _ O
evolved -X- _ O
from -X- _ O
learning -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
to -X- _ O
contextualized -X- _ O
word -X- _ O
representations -X- _ O
( -X- _ O
McCann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Eriguchi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
to -X- _ O
the -X- _ O
most -X- _ O
recent -X- _ O
Transformer -X- _ O
- -X- _ O
based -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
LMs -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
with -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
various -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
. -X- _ O
Most -X- _ O
commonly -X- _ O
, -X- _ O
these -X- _ O
LMs -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
MLM -X- _ O
objective -X- _ O
( -X- _ O
Taylor -X- _ O
, -X- _ O
1953 -X- _ O
) -X- _ O
on -X- _ O
large -X- _ O
unsupervised -X- _ O
corpora -X- _ O
and -X- _ O
then -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
labeled -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
at -X- _ O
hand -X- _ O
. -X- _ O
Concurrently -X- _ O
, -X- _ O
multilingual -X- _ O
LMs -X- _ O
( -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
, -X- _ O
2019;Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Chung -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
, -X- _ O
trained -X- _ O
on -X- _ O
massive -X- _ O
amounts -X- _ O
of -X- _ O
multilingual -X- _ O
data -X- _ O
, -X- _ O
have -X- _ O
surpassed -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
word -X- _ O
embedding -X- _ O
spaces -X- _ O
( -X- _ O
Glavaš -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
to -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
in -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
transfer -X- _ O
. -X- _ O
While -X- _ O
Pires -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
highlight -X- _ O
their -X- _ O
cross -X- _ O
- -X- _ O
lingual -X- _ O
ability -X- _ O
, -X- _ O
several -X- _ O
limitations -X- _ O
have -X- _ O
been -X- _ O
studied -X- _ O
. -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
highlight -X- _ O
the -X- _ O
curse -X- _ O
of -X- _ O
multilinguality -X- _ O
. -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
highlight -X- _ O
that -X- _ O
even -X- _ O
the -X- _ O
best -X- _ O
multilingual -X- _ O
models -X- _ O
do -X- _ O
not -X- _ O
yield -X- _ O
satisfactory -X- _ O
transfer -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
XTREME -X- _ B-DatasetName
bechmark -X- _ O
covering -X- _ O
9 -X- _ O
tasks -X- _ O
and -X- _ O
40 -X- _ O
languages -X- _ O
. -X- _ O
Importantly -X- _ O
, -X- _ O
Wu -X- _ O
and -X- _ O
Dredze -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
and -X- _ O
Lauscher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
observe -X- _ O
that -X- _ O
these -X- _ O
models -X- _ O
significantly -X- _ O
under -X- _ O
- -X- _ O
perform -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
as -X- _ O
representation -X- _ O
of -X- _ O
these -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
vocabulary -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
corpora -X- _ O
are -X- _ O
severely -X- _ O
limited -X- _ O
. -X- _ O
Language -X- _ O
- -X- _ O
specific -X- _ O
LMs -X- _ O
are -X- _ O
becoming -X- _ O
increasingly -X- _ O
popular -X- _ O
as -X- _ O
issues -X- _ O
with -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
persist -X- _ O
. -X- _ O
As -X- _ O
language -X- _ O
identification -X- _ O
systems -X- _ O
are -X- _ O
extended -X- _ O
to -X- _ O
1000 -X- _ O
+ -X- _ O
languages -X- _ O
( -X- _ O
Caswell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
increasing -X- _ O
capacity -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
model -X- _ O
to -X- _ O
uniformly -X- _ O
represent -X- _ O
all -X- _ O
languages -X- _ O
is -X- _ O
prohibitive -X- _ O
. -X- _ O
Often -X- _ O
, -X- _ O
practitioners -X- _ O
prefer -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
model -X- _ O
performing -X- _ O
well -X- _ O
on -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
languages -X- _ O
that -X- _ O
their -X- _ O
application -X- _ O
calls -X- _ O
for -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
this -X- _ O
, -X- _ O
the -X- _ O
community -X- _ O
continues -X- _ O
its -X- _ O
efforts -X- _ O
in -X- _ O
building -X- _ O
strong -X- _ O
multi -X- _ O
- -X- _ O
domain -X- _ O
language -X- _ O
models -X- _ O
using -X- _ O
linguistic -X- _ O
expertise -X- _ O
. -X- _ O
A -X- _ O
few -X- _ O
examples -X- _ O
of -X- _ O
these -X- _ O
are -X- _ O
AraBERT -X- _ B-MethodName
( -X- _ O
Antoun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
CamemBERT -X- _ B-MethodName
( -X- _ O
Martin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
FinBERT -X- _ B-MethodName
( -X- _ O
Virtanen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
2 -X- _ O
Knowledge -X- _ O
Distillation -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
LMs -X- _ O
has -X- _ O
2 -X- _ O
( -X- _ O
Nozza -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
maintain -X- _ O
an -X- _ O
ever -X- _ O
- -X- _ O
growing -X- _ O
list -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
here -X- _ O
most -X- _ O
commonly -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
model -X- _ O
compression -X- _ O
of -X- _ O
a -X- _ O
teacher -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
- -X- _ O
task -X- _ O
student -X- _ O
( -X- _ O
Tang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Kaliamoorthi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
has -X- _ O
been -X- _ O
extended -X- _ O
to -X- _ O
perform -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
distillation -X- _ O
of -X- _ O
multiple -X- _ O
single -X- _ O
- -X- _ O
task -X- _ O
teachers -X- _ O
into -X- _ O
one -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
student -X- _ O
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Turc -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
scenario -X- _ O
, -X- _ O
prior -X- _ O
work -X- _ O
has -X- _ O
focused -X- _ O
on -X- _ O
distilling -X- _ O
a -X- _ O
single -X- _ O
large -X- _ O
teacher -X- _ O
model -X- _ O
into -X- _ O
a -X- _ O
student -X- _ O
model -X- _ O
leveraging -X- _ O
teacher -X- _ O
predictions -X- _ O
( -X- _ O
Sanh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
internal -X- _ O
teacher -X- _ O
representations -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2019 -X- _ O
with -X- _ O
the -X- _ O
goal -X- _ O
of -X- _ O
model -X- _ O
compression -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
attempt -X- _ O
to -X- _ O
perform -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
distillation -X- _ O
from -X- _ O
multiple -X- _ O
teachers -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
student -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
neural -X- _ O
machine -X- _ O
translation -X- _ O
, -X- _ O
Tan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
come -X- _ O
close -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
where -X- _ O
they -X- _ O
attempt -X- _ O
to -X- _ O
combine -X- _ O
multiple -X- _ O
single -X- _ O
language -X- _ O
- -X- _ O
pair -X- _ O
teacher -X- _ O
models -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
multilingual -X- _ O
student -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
work -X- _ O
differs -X- _ O
from -X- _ O
theirs -X- _ O
in -X- _ O
three -X- _ O
key -X- _ O
aspects -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
our -X- _ O
students -X- _ O
are -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
while -X- _ O
theirs -X- _ O
are -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
can -X- _ O
leverage -X- _ O
pre -X- _ O
- -X- _ O
existing -X- _ O
teachers -X- _ O
while -X- _ O
they -X- _ O
can -X- _ O
not -X- _ O
, -X- _ O
and -X- _ O
3 -X- _ O
) -X- _ O
we -X- _ O
support -X- _ O
teachers -X- _ O
with -X- _ O
overlapping -X- _ O
sets -X- _ O
of -X- _ O
languages -X- _ O
while -X- _ O
they -X- _ O
only -X- _ O
consider -X- _ O
single -X- _ O
language -X- _ O
- -X- _ O
pairs -X- _ O
teachers -X- _ O
. -X- _ O
Notations -X- _ O
: -X- _ O
Let -X- _ O
K -X- _ O
denote -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
languages -X- _ O
we -X- _ O
train -X- _ O
our -X- _ O
student -X- _ O
LM -X- _ O
on -X- _ O
and -X- _ O
T -X- _ O
denote -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
teacher -X- _ O
LMs -X- _ O
input -X- _ O
to -X- _ O
MERGEDISTILL -X- _ B-MethodName
3 -X- _ O
. -X- _ O
Consequently -X- _ O
, -X- _ O
T -X- _ O
k -X- _ O
denotes -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
teacher -X- _ O
LMs -X- _ O
trained -X- _ O
on -X- _ O
language -X- _ O
k -X- _ O
, -X- _ O
where|T -X- _ O
k -X- _ O
| -X- _ O
≥ -X- _ O
1 -X- _ O
∀ -X- _ O
k -X- _ O
∈ -X- _ O
K. -X- _ O
An -X- _ O
overview -X- _ O
of -X- _ O
MERGEDISTILL -X- _ B-MethodName
is -X- _ O
presented -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
detail -X- _ O
each -X- _ O
step -X- _ O
involved -X- _ O
in -X- _ O
training -X- _ O
the -X- _ O
student -X- _ O
LM -X- _ O
from -X- _ O
multiple -X- _ O
teacher -X- _ O
LMs -X- _ O
. -X- _ O
Step -X- _ O
1 -X- _ O
: -X- _ O
Input -X- _ O
The -X- _ O
input -X- _ O
to -X- _ O
MERGEDISTILL -X- _ B-MethodName
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
teacher -X- _ O
LMs -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
transfer -X- _ O
corpora -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
languages -X- _ O
we -X- _ O
wish -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
student -X- _ O
LM -X- _ O
on -X- _ O
. -X- _ O
With -X- _ O
reference -X- _ O
to -X- _ O
Figure -X- _ O
2 -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
LM -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
K -X- _ O
= -X- _ O
{ -X- _ O
English -X- _ O
( -X- _ O
en -X- _ O
) -X- _ O
, -X- _ O
Spanish -X- _ O
( -X- _ O
es -X- _ O
) -X- _ O
, -X- _ O
Hindi -X- _ O
( -X- _ O
hi -X- _ O
) -X- _ O
, -X- _ O
Korean -X- _ O
( -X- _ O
ko -X- _ O
) -X- _ O
} -X- _ O
. -X- _ O
We -X- _ O
combine -X- _ O
four -X- _ O
teacher -X- _ O
LMs -X- _ O
comprising -X- _ O
of -X- _ O
three -X- _ O
monolingual -X- _ O
and -X- _ O
one -X- _ O
multilingual -X- _ O
LM -X- _ O
. -X- _ O
The -X- _ O
monolingual -X- _ O
LMs -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
English -X- _ O
( -X- _ O
M -X- _ O
en -X- _ O
) -X- _ O
, -X- _ O
Spanish -X- _ O
( -X- _ O
M -X- _ O
es -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Korean -X- _ O
( -X- _ O
M -X- _ O
ko -X- _ O
) -X- _ O
while -X- _ O
the -X- _ O
multilingual -X- _ O
LM -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
English -X- _ O
and -X- _ O
Hindi -X- _ O
( -X- _ O
M -X- _ O
en -X- _ O
, -X- _ O
hi -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
, -X- _ O
the -X- _ O
corresponding -X- _ O
set -X- _ O
of -X- _ O
teacher -X- _ O
LMs -X- _ O
( -X- _ O
T -X- _ O
k -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O
[ -X- _ O
T -X- _ O
en -X- _ O
= -X- _ O
{ -X- _ O
M -X- _ O
en -X- _ O
, -X- _ O
M -X- _ O
en -X- _ O
, -X- _ O
hi -X- _ O
} -X- _ O
, -X- _ O
T -X- _ O
es -X- _ O
= -X- _ O
{ -X- _ O
M -X- _ O
es -X- _ O
} -X- _ O
, -X- _ O
T -X- _ O
hi -X- _ O
= -X- _ O
{ -X- _ O
M -X- _ O
en -X- _ O
, -X- _ O
hi -X- _ O
} -X- _ O
, -X- _ O
T -X- _ O
ko -X- _ O
= -X- _ O
{ -X- _ O
M -X- _ O
ko -X- _ O
} -X- _ O
] -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
pretraining -X- _ O
transfer -X- _ O
corpora -X- _ O
is -X- _ O
tokenized -X- _ O
and -X- _ O
masked -X- _ O
for -X- _ O
each -X- _ O
language -X- _ O
using -X- _ O
their -X- _ O
respective -X- _ O
teacher -X- _ O
LM -X- _ O
's -X- _ O
tokenizer -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
language -X- _ O
with -X- _ O
two -X- _ O
teachers -X- _ O
, -X- _ O
English -X- _ O
, -X- _ O
we -X- _ O
tokenize -X- _ O
each -X- _ O
example -X- _ O
using -X- _ O
both -X- _ O
the -X- _ O
teacher -X- _ O
LMs -X- _ O
. -X- _ O
Step -X- _ O
2 -X- _ O
: -X- _ O
Offline -X- _ O
Teacher -X- _ O
LM -X- _ O
Evaluation -X- _ O
We -X- _ O
now -X- _ O
obtain -X- _ O
predictions -X- _ O
and -X- _ O
logits -X- _ O
for -X- _ O
each -X- _ O
masked -X- _ O
, -X- _ O
tokenized -X- _ O
example -X- _ O
in -X- _ O
each -X- _ O
language -X- _ O
, -X- _ O
by -X- _ O
evaluating -X- _ O
their -X- _ O
respective -X- _ O
teacher -X- _ O
LMs -X- _ O
. -X- _ O
For -X- _ O
English -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
predictions -X- _ O
from -X- _ O
both -X- _ O
M -X- _ O
en -X- _ O
and -X- _ O
M -X- _ O
en -X- _ O
, -X- _ O
hi -X- _ O
on -X- _ O
their -X- _ O
respective -X- _ O
copies -X- _ O
of -X- _ O
each -X- _ O
training -X- _ O
example -X- _ O
. -X- _ O
In -X- _ O
an -X- _ O
ideal -X- _ O
situation -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
multiple -X- _ O
strong -X- _ O
teachers -X- _ O
can -X- _ O
present -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
view -X- _ O
generalisation -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
as -X- _ O
each -X- _ O
teacher -X- _ O
learns -X- _ O
different -X- _ O
features -X- _ O
in -X- _ O
training -X- _ O
. -X- _ O
Let -X- _ O
x -X- _ O
denote -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
where -X- _ O
x -X- _ O
m -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
x -X- _ O
3 -X- _ O
... -X- _ O
x -X- _ O
n -X- _ O
} -X- _ O
denote -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
x -X- _ O
−m -X- _ O
denote -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O
Let -X- _ O
v -X- _ O
be -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
student -X- _ O
LM -X- _ O
θ -X- _ O
s -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
conventional -X- _ O
case -X- _ O
of -X- _ O
learning -X- _ O
from -X- _ O
gold -X- _ O
labels -X- _ O
, -X- _ O
we -X- _ O
minimize -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
entropy -X- _ O
of -X- _ O
student -X- _ O
logit -X- _ O
distribution -X- _ O
for -X- _ O
a -X- _ O
masked -X- _ O
word -X- _ O
x -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
label -X- _ O
v -X- _ O
j -X- _ O
, -X- _ O
given -X- _ O
by -X- _ O
: -X- _ O
P(x -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
v -X- _ O
j -X- _ O
) -X- _ O
= -X- _ O
1(x -X- _ O
m -X- _ O
i -X- _ O
= -X- _ O
v -X- _ O
j -X- _ O
) -X- _ O
× -X- _ O
log -X- _ O
p(x -X- _ O
m -X- _ O
i -X- _ O
= -X- _ O
v -X- _ O
j -X- _ O
|x -X- _ O
−m -X- _ O
; -X- _ O
θ -X- _ O
s -X- _ O
) -X- _ O
( -X- _ O
1)With -X- _ O
the -X- _ O
teacher -X- _ O
evaluations -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
predictions -X- _ O
( -X- _ O
and -X- _ O
corresponding -X- _ O
logits -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
for -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O
Let -X- _ O
us -X- _ O
denote -X- _ O
the -X- _ O
teacher -X- _ O
output -X- _ O
probability -X- _ O
distribution -X- _ O
( -X- _ O
softmax -X- _ O
over -X- _ O
logits -X- _ O
) -X- _ O
for -X- _ O
token -X- _ O
x -X- _ O
m -X- _ O
i -X- _ O
by -X- _ O
Q(x -X- _ O
m -X- _ O
i -X- _ O
|x -X- _ O
−m -X- _ O
; -X- _ O
θ -X- _ O
t -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
loss -X- _ O
from -X- _ O
gold -X- _ O
labels -X- _ O
, -X- _ O
we -X- _ O
minimize -X- _ O
the -X- _ O
entropy -X- _ O
between -X- _ O
the -X- _ O
student -X- _ O
logits -X- _ O
and -X- _ O
the -X- _ O
teacher -X- _ O
distribution -X- _ O
, -X- _ O
given -X- _ O
by -X- _ O
: -X- _ O
P(x -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
v -X- _ O
j -X- _ O
) -X- _ O
= -X- _ O
Q(x -X- _ O
m -X- _ O
i -X- _ O
= -X- _ O
v -X- _ O
j -X- _ O
|x -X- _ O
−m -X- _ O
; -X- _ O
θ -X- _ O
t -X- _ O
) -X- _ O
× -X- _ O
log -X- _ O
p(x -X- _ O
m -X- _ O
i -X- _ O
= -X- _ O
v -X- _ O
j -X- _ O
|x -X- _ O
−m -X- _ O
; -X- _ O
θ -X- _ O
s -X- _ O
) -X- _ O
( -X- _ O
2)It -X- _ O
is -X- _ O
extremely -X- _ O
burdensome -X- _ O
( -X- _ O
both -X- _ O
memory -X- _ O
and -X- _ O
time -X- _ O
) -X- _ O
to -X- _ O
load -X- _ O
multiple -X- _ O
teacher -X- _ O
LMs -X- _ O
and -X- _ O
obtain -X- _ O
predictions -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
store -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ B-HyperparameterName
logits -X- _ O
for -X- _ O
each -X- _ O
masked -X- _ O
word -X- _ O
offline -X- _ O
, -X- _ O
loading -X- _ O
and -X- _ O
normalizing -X- _ O
them -X- _ O
during -X- _ O
student -X- _ O
LM -X- _ O
training -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
( -X- _ O
Tan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
obtaining -X- _ O
offline -X- _ O
predictions -X- _ O
gives -X- _ O
one -X- _ O
the -X- _ O
freedom -X- _ O
to -X- _ O
use -X- _ O
expensive -X- _ O
teacher -X- _ O
LMs -X- _ O
without -X- _ O
increasing -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
training -X- _ O
costs -X- _ O
and -X- _ O
makes -X- _ O
our -X- _ O
framework -X- _ O
teacher -X- _ O
- -X- _ O
architecture -X- _ O
agnostic -X- _ O
. -X- _ O
Step -X- _ O
3 -X- _ O
: -X- _ O
Vocab -X- _ O
Mapping -X- _ O
A -X- _ O
deterrent -X- _ O
in -X- _ O
attempting -X- _ O
to -X- _ O
distill -X- _ O
from -X- _ O
multiple -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
teacher -X- _ O
LMs -X- _ O
is -X- _ O
that -X- _ O
each -X- _ O
LM -X- _ O
has -X- _ O
its -X- _ O
own -X- _ O
vocabulary -X- _ O
. -X- _ O
This -X- _ O
makes -X- _ O
it -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
to -X- _ O
uniformly -X- _ O
process -X- _ O
an -X- _ O
input -X- _ O
example -X- _ O
for -X- _ O
consumption -X- _ O
by -X- _ O
both -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
LMs -X- _ O
. -X- _ O
Our -X- _ O
student -X- _ O
model -X- _ O
's -X- _ O
vocabulary -X- _ O
is -X- _ O
the -X- _ O
union -X- _ O
of -X- _ O
all -X- _ O
teacher -X- _ O
LM -X- _ O
vocabularies -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
vocab -X- _ O
mapping -X- _ O
step -X- _ O
, -X- _ O
the -X- _ O
input -X- _ O
indices -X- _ O
, -X- _ O
prediction -X- _ O
indices -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
gold -X- _ O
label -X- _ O
indices -X- _ O
, -X- _ O
obtained -X- _ O
after -X- _ O
evaluation -X- _ O
from -X- _ O
each -X- _ O
teacher -X- _ O
LM -X- _ O
are -X- _ O
processed -X- _ O
using -X- _ O
a -X- _ O
teacher→student -X- _ O
vocab -X- _ O
map -X- _ O
. -X- _ O
This -X- _ O
converts -X- _ O
each -X- _ O
teacher -X- _ O
token -X- _ O
index -X- _ O
to -X- _ O
its -X- _ O
corresponding -X- _ O
student -X- _ O
token -X- _ O
index -X- _ O
, -X- _ O
ready -X- _ O
for -X- _ O
consumption -X- _ O
by -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
. -X- _ O
For -X- _ O
simplicity -X- _ O
, -X- _ O
each -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
LM -X- _ O
uses -X- _ O
WordPiece -X- _ O
tokenization -X- _ O
( -X- _ O
Schuster -X- _ O
and -X- _ O
Nakajima -X- _ O
, -X- _ O
2012;Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
in -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
Step -X- _ O
L -X- _ O
MLM -X- _ O
( -X- _ O
x -X- _ O
m -X- _ O
|x -X- _ O
−m -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
1 -X- _ O
n -X- _ O
n -X- _ O
i=1 -X- _ O
|v| -X- _ O
j=1 -X- _ O
P(x -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
v -X- _ O
j -X- _ O
) -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
learning -X- _ O
from -X- _ O
gold -X- _ O
labels -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
teacher -X- _ O
predictions -X- _ O
as -X- _ O
soft -X- _ O
labels -X- _ O
and -X- _ O
minimize -X- _ O
the -X- _ O
cross -X- _ O
entropy -X- _ O
between -X- _ O
student -X- _ O
and -X- _ O
teacher -X- _ O
distributions -X- _ O
. -X- _ O
Let -X- _ O
L -X- _ O
KD -X- _ O
denote -X- _ O
the -X- _ O
KD -X- _ O
loss -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
teacher -X- _ O
LM -X- _ O
. -X- _ O
With -X- _ O
reference -X- _ O
to -X- _ O
Equation -X- _ O
2 -X- _ O
: -X- _ O
L -X- _ O
KD -X- _ O
( -X- _ O
x -X- _ O
m -X- _ O
|x -X- _ O
−m -X- _ O
) -X- _ O
= -X- _ O
− -X- _ O
1 -X- _ O
n -X- _ O
n -X- _ O
i=1 -X- _ O
|v| -X- _ O
j=1P -X- _ O
( -X- _ O
x -X- _ O
m -X- _ O
i -X- _ O
, -X- _ O
v -X- _ O
j -X- _ O
) -X- _ O
; -X- _ O
The -X- _ O
total -X- _ O
loss -X- _ O
across -X- _ O
all -X- _ O
languages -X- _ O
is -X- _ O
minimized -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
below -X- _ O
: -X- _ O
L -X- _ O
ALL -X- _ O
= -X- _ O
K -X- _ O
k=1 -X- _ O
λ(L -X- _ O
T -X- _ O
k -X- _ O
KD -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
λ)L -X- _ O
k -X- _ O
MLMIn -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
multiple -X- _ O
teacher -X- _ O
LMs -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
n -X- _ O
tokenized -X- _ O
instances -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
example -X- _ O
( -X- _ O
where -X- _ O
n -X- _ O
denotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
teachers -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
language -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
each -X- _ O
example -X- _ O
in -X- _ O
English -X- _ O
has -X- _ O
two -X- _ O
copies -X- _ O
-one -X- _ O
tokenized -X- _ O
using -X- _ O
M -X- _ O
en -X- _ O
and -X- _ O
another -X- _ O
using -X- _ O
M -X- _ O
en -X- _ O
, -X- _ O
hi -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
two -X- _ O
possibilities -X- _ O
of -X- _ O
training -X- _ O
in -X- _ O
this -X- _ O
multi -X- _ O
- -X- _ O
teacher -X- _ O
scenario -X- _ O
: -X- _ O
• -X- _ O
Include -X- _ O
all -X- _ O
the -X- _ O
copies -X- _ O
in -X- _ O
training -X- _ O
. -X- _ O
Here -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
exposed -X- _ O
to -X- _ O
n -X- _ O
different -X- _ O
teacher -X- _ O
LM -X- _ O
predictions -X- _ O
, -X- _ O
each -X- _ O
presenting -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
view -X- _ O
generalisation -X- _ O
to -X- _ O
the -X- _ O
student -X- _ O
LM.• -X- _ O
Include -X- _ O
the -X- _ O
best -X- _ O
copy -X- _ O
in -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
best -X- _ O
copy -X- _ O
is -X- _ O
the -X- _ O
one -X- _ O
having -X- _ O
minimum -X- _ O
teacher -X- _ O
LM -X- _ O
loss -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
example -X- _ O
. -X- _ O
Here -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
only -X- _ O
exposed -X- _ O
to -X- _ O
the -X- _ O
best -X- _ O
teacher -X- _ O
LM -X- _ O
predictions -X- _ O
for -X- _ O
each -X- _ O
example -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
following -X- _ O
questions -X- _ O
: -X- _ O
Distillation -X- _ O
Parameters -X- _ O
: -X- _ O
We -X- _ O
have -X- _ O
two -X- _ O
hyperparameter -X- _ O
choices -X- _ O
here -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
k -X- _ B-HyperparameterName
in -X- _ O
top -X- _ O
- -X- _ O
k -X- _ B-HyperparameterName
logits -X- _ O
-as -X- _ O
it -X- _ O
increases -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
while -X- _ O
performances -X- _ O
remain -X- _ O
similar -X- _ O
, -X- _ O
storing -X- _ O
k>8 -X- _ B-HyperparameterName
number -X- _ O
of -X- _ O
predictions -X- _ O
for -X- _ O
each -X- _ O
masked -X- _ O
word -X- _ O
offline -X- _ O
significantly -X- _ O
increases -X- _ O
resource -X- _ O
requirements -X- _ O
4 -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
set -X- _ O
k=8 -X- _ B-HyperparameterName
in -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
λ -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
loss -X- _ O
function -X- _ O
, -X- _ O
which -X- _ O
decides -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
teacher -X- _ O
loss -X- _ O
, -X- _ O
is -X- _ O
annealed -X- _ O
through -X- _ O
training -X- _ O
similar -X- _ O
to -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019).Evaluation -X- _ O
Metrics -X- _ O
: -X- _ O
We -X- _ O
report -X- _ O
F1 -X- _ B-MetricName
scores -X- _ O
for -X- _ O
structured -X- _ O
prediction -X- _ O
tasks -X- _ O
( -X- _ O
NER -X- _ O
, -X- _ O
POS -X- _ O
) -X- _ O
, -X- _ O
accuracy -X- _ B-MetricName
( -X- _ O
Acc -X- _ B-MetricName
. -X- _ O
) -X- _ O
scores -X- _ O
for -X- _ O
sentence -X- _ O
classification -X- _ O
tasks -X- _ O
( -X- _ O
XNLI -X- _ O
, -X- _ O
PAWS -X- _ O
- -X- _ O
X -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
F1 -X- _ B-MetricName
/ -X- _ O
Exact -X- _ B-MetricName
Match -X- _ I-MetricName
( -X- _ O
F1 -X- _ B-MetricName
/ -X- _ O
EM -X- _ B-MetricName
) -X- _ O
scores -X- _ O
for -X- _ O
question -X- _ O
answering -X- _ O
tasks -X- _ O
( -X- _ O
XQuAD -X- _ O
, -X- _ O
MLQA -X- _ O
, -X- _ O
TyDiQA -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
report -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
specific -X- _ O
relative -X- _ B-MetricName
deviation -X- _ I-MetricName
from -X- _ O
teachers -X- _ O
( -X- _ O
RDT -X- _ B-MetricName
) -X- _ O
( -X- _ O
in -X- _ O
% -X- _ O
) -X- _ O
averaged -X- _ O
across -X- _ O
all -X- _ O
languages -X- _ O
( -X- _ O
n -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
RDT -X- _ B-MetricName
is -X- _ O
calculated -X- _ O
as -X- _ O
: -X- _ O
RDT(S -X- _ B-MetricName
, -X- _ O
{ -X- _ O
T -X- _ O
1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
T -X- _ O
n -X- _ O
} -X- _ O
) -X- _ O
= -X- _ O
100 -X- _ O
n -X- _ O
n -X- _ O
i=1 -X- _ O
( -X- _ O
P -X- _ O
T -X- _ O
i -X- _ O
− -X- _ O
P -X- _ O
S -X- _ O
) -X- _ O
P -X- _ O
T -X- _ O
i(3)where -X- _ O
P -X- _ O
T -X- _ O
i -X- _ O
and -X- _ O
P -X- _ O
S -X- _ O
are -X- _ O
performances -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
LMs -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
: -X- _ O
In -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
preexisting -X- _ O
monolingual -X- _ O
teacher -X- _ O
LMs -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
, -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
multilingual -X- _ O
student -X- _ O
LM -X- _ O
on -X- _ O
the -X- _ O
union -X- _ O
of -X- _ O
all -X- _ O
teacher -X- _ O
languages -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
setup,|T -X- _ O
k -X- _ O
| -X- _ O
= -X- _ O
1 -X- _ O
∀ -X- _ O
k -X- _ O
∈ -X- _ O
K -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
each -X- _ O
language -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
its -X- _ O
respective -X- _ O
monolingual -X- _ O
teacher -X- _ O
LM -X- _ O
only -X- _ O
. -X- _ O
Our -X- _ O
teacher -X- _ O
selection -X- _ O
and -X- _ O
setup -X- _ O
follows -X- _ O
a -X- _ O
two -X- _ O
- -X- _ O
step -X- _ O
process -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
select -X- _ O
languages -X- _ O
having -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
monolingual -X- _ O
LMs -X- _ O
available -X- _ O
, -X- _ O
and -X- _ O
evaluation -X- _ O
sets -X- _ O
across -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
This -X- _ O
makes -X- _ O
us -X- _ O
choose -X- _ O
teacher -X- _ O
LMs -X- _ O
for -X- _ O
: -X- _ O
Arabic -X- _ O
( -X- _ O
ar -X- _ O
) -X- _ O
, -X- _ O
Chinese -X- _ O
( -X- _ O
zh -X- _ O
) -X- _ O
, -X- _ O
English -X- _ O
( -X- _ O
en -X- _ O
) -X- _ O
, -X- _ O
Finnish -X- _ O
( -X- _ O
fi -X- _ O
) -X- _ O
, -X- _ O
Table -X- _ O
4 -X- _ O
: -X- _ O
Results -X- _ O
for -X- _ O
multilingual -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
LMs -X- _ O
on -X- _ O
the -X- _ O
XTREME -X- _ B-MetricName
benchmark -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
performances -X- _ O
of -X- _ O
three -X- _ O
student -X- _ O
LM -X- _ O
variants -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.3 -X- _ O
to -X- _ O
the -X- _ O
two -X- _ O
teachers -X- _ O
mBERT -X- _ B-MethodName
and -X- _ O
MuRIL -X- _ B-MethodName
. -X- _ O
Relative -X- _ B-MetricName
deviations -X- _ I-MetricName
of -X- _ O
5 -X- _ B-MetricValue
% -X- _ I-MetricValue
or -X- _ O
less -X- _ O
from -X- _ O
teacher -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
RDT -X- _ B-MetricName
≥ -X- _ O
−5 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
are -X- _ O
marked -X- _ O
in -X- _ O
bold -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
Student -X- _ O
MuRIL -X- _ B-MethodName
performs -X- _ O
the -X- _ O
best -X- _ O
among -X- _ O
all -X- _ O
student -X- _ O
variants -X- _ O
and -X- _ O
report -X- _ O
its -X- _ O
RDT -X- _ B-MetricName
( -X- _ O
in -X- _ O
% -X- _ O
) -X- _ O
( -X- _ O
Equation -X- _ O
3 -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
teachers -X- _ O
. -X- _ O
Please -X- _ O
refer -X- _ O
to -X- _ O
Section -X- _ O
4.3 -X- _ O
for -X- _ O
a -X- _ O
detailed -X- _ O
analysis.we -X- _ O
can -X- _ O
attribute -X- _ O
this -X- _ O
gain -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
English -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
linguistically -X- _ O
and -X- _ O
typologically -X- _ O
similar -X- _ O
languages -X- _ O
in -X- _ O
Student -X- _ O
similar -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
Student -X- _ O
similar -X- _ O
outperforms -X- _ O
its -X- _ O
teacher -X- _ O
LMs -X- _ O
while -X- _ O
Student -X- _ O
dissimilar -X- _ O
is -X- _ O
competitive -X- _ O
for -X- _ O
all -X- _ O
languages -X- _ O
. -X- _ O
These -X- _ O
two -X- _ O
results -X- _ O
across -X- _ O
all -X- _ O
languages -X- _ O
point -X- _ O
towards -X- _ O
Student -X- _ O
similar -X- _ O
benefiting -X- _ O
from -X- _ O
a -X- _ O
positive -X- _ O
transfer -X- _ O
across -X- _ O
similar -X- _ O
languages -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
Student -X- _ O
similar -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
9.9 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
unique -X- _ O
tokens -X- _ O
seen -X- _ O
by -X- _ O
its -X- _ O
respective -X- _ O
teacher -X- _ O
LMs -X- _ O
and -X- _ O
Student -X- _ O
dissimilar -X- _ O
lies -X- _ O
close -X- _ O
with -X- _ O
13.6 -X- _ O
% -X- _ O
. -X- _ O
Despite -X- _ O
this -X- _ O
huge -X- _ O
disparity -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
corpora -X- _ O
, -X- _ O
student -X- _ O
LMs -X- _ O
are -X- _ O
competitive -X- _ O
with -X- _ O
their -X- _ O
teachers -X- _ O
. -X- _ O
This -X- _ O
encouraging -X- _ O
result -X- _ O
proves -X- _ O
that -X- _ O
even -X- _ O
with -X- _ O
very -X- _ O
limited -X- _ O
data -X- _ O
, -X- _ O
MERGEDISTILL -X- _ B-MethodName
enables -X- _ O
one -X- _ O
to -X- _ O
combine -X- _ O
strong -X- _ O
monolingual -X- _ O
teacher -X- _ O
LMs -X- _ O
to -X- _ O
train -X- _ O
competitive -X- _ O
student -X- _ O
LMs -X- _ O
that -X- _ O
can -X- _ O
leverage -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
multilinguality -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
: -X- _ O
In -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
existing -X- _ O
multilingual -X- _ O
models -X- _ O
: -X- _ O
mBERT -X- _ B-MethodName
and -X- _ O
MuRIL -X- _ B-MethodName
. -X- _ O
mBERT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
104 -X- _ O
languages -X- _ O
and -X- _ O
MuRIL -X- _ B-MethodName
covers -X- _ O
12 -X- _ O
of -X- _ O
these -X- _ O
( -X- _ O
11 -X- _ O
Indian -X- _ O
languages -X- _ O
+ -X- _ O
English -X- _ O
): -X- _ O
Bengali -X- _ O
( -X- _ O
bn -X- _ O
) -X- _ O
, -X- _ O
English -X- _ O
( -X- _ O
en -X- _ O
) -X- _ O
, -X- _ O
Gujarati -X- _ O
( -X- _ O
gu -X- _ O
) -X- _ O
, -X- _ O
Hindi -X- _ O
( -X- _ O
hi -X- _ O
) -X- _ O
, -X- _ O
Kannada -X- _ O
( -X- _ O
kn -X- _ O
) -X- _ O
, -X- _ O
Malayalam -X- _ O
( -X- _ O
ml -X- _ O
) -X- _ O
, -X- _ O
Marathi -X- _ O
( -X- _ O
mr -X- _ O
) -X- _ O
, -X- _ O
Nepali -X- _ O
( -X- _ O
ne -X- _ O
) -X- _ O
, -X- _ O
Punjabi -X- _ O
( -X- _ O
pa -X- _ O
) -X- _ O
, -X- _ O
Tamil -X- _ O
( -X- _ O
ta -X- _ O
) -X- _ O
, -X- _ O
Telugu -X- _ O
( -X- _ O
te -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Urdu -X- _ O
( -X- _ O
ur -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
higher -X- _ O
performance -X- _ O
for -X- _ O
these -X- _ O
languages -X- _ O
on -X- _ O
the -X- _ O
XTREME -X- _ B-DatasetName
benchmark -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
on -X- _ O
all -X- _ O
104 -X- _ O
languages -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
MuRIL -X- _ B-MethodName
Languages -X- _ O
( -X- _ O
MuL -X- _ O
) -X- _ O
have -X- _ O
two -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
teachers -X- _ O
( -X- _ O
mBERT -X- _ B-MethodName
and -X- _ O
MuRIL -X- _ B-MethodName
) -X- _ O
and -X- _ O
the -X- _ O
Non -X- _ O
- -X- _ O
MuRIL -X- _ B-MethodName
Languages -X- _ O
( -X- _ O
Non -X- _ O
- -X- _ O
MuL -X- _ O
) -X- _ O
can -X- _ O
learn -X- _ O
from -X- _ O
mBERT -X- _ B-MethodName
only -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
only -X- _ O
use -X- _ O
mBERT -X- _ B-MethodName
as -X- _ O
the -X- _ O
teacher -X- _ O
LM -X- _ O
for -X- _ O
Non -X- _ O
- -X- _ O
MuL -X- _ O
across -X- _ O
all -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
three -X- _ O
possibilities -X- _ O
for -X- _ O
MuL -X- _ O
: -X- _ O
• -X- _ O
Student -X- _ O
Both -X- _ O
all -X- _ O
: -X- _ O
Tokenize -X- _ O
each -X- _ O
input -X- _ O
example -X- _ O
using -X- _ O
mBERT -X- _ B-MethodName
and -X- _ O
MuRIL -X- _ B-MethodName
separately -X- _ O
and -X- _ O
include -X- _ O
both -X- _ O
copies -X- _ O
in -X- _ O
training.• -X- _ O
Student -X- _ O
Both -X- _ O
best -X- _ O
: -X- _ O
Tokenize -X- _ O
each -X- _ O
input -X- _ O
example -X- _ O
using -X- _ O
mBERT -X- _ B-MethodName
and -X- _ O
MuRIL -X- _ B-MethodName
separately -X- _ O
and -X- _ O
include -X- _ O
only -X- _ O
the -X- _ O
best -X- _ O
copy -X- _ O
in -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
best -X- _ O
copy -X- _ O
is -X- _ O
the -X- _ O
one -X- _ O
having -X- _ O
minimum -X- _ O
teacher -X- _ O
LM -X- _ O
loss -X- _ O
for -X- _ O
the -X- _ O
example -X- _ O
. -X- _ O
Note -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
non -X- _ O
- -X- _ O
trivial -X- _ O
to -X- _ O
tokenize -X- _ O
each -X- _ O
example -X- _ O
in -X- _ O
a -X- _ O
way -X- _ O
that -X- _ O
is -X- _ O
compatible -X- _ O
with -X- _ O
all -X- _ O
teacher -X- _ O
LMs -X- _ O
. -X- _ O
One -X- _ O
must -X- _ O
resort -X- _ O
to -X- _ O
tokenization -X- _ O
using -X- _ O
an -X- _ O
intersection -X- _ O
of -X- _ O
vocabularies -X- _ O
which -X- _ O
is -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
. -X- _ O
All -X- _ O
the -X- _ O
student -X- _ O
LMs -X- _ O
use -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
base -X- _ I-MethodName
architecture -X- _ O
and -X- _ O
have -X- _ O
a -X- _ O
vocabulary -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
288,973 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
reduce -X- _ O
our -X- _ O
embedding -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
to -X- _ O
256 -X- _ B-HyperparameterValue
as -X- _ O
opposed -X- _ O
to -X- _ O
768 -X- _ B-HyperparameterValue
to -X- _ O
bring -X- _ O
down -X- _ O
the -X- _ O
model -X- _ O
size -X- _ O
to -X- _ O
be -X- _ O
around -X- _ O
160 -X- _ O
M -X- _ O
, -X- _ O
comparable -X- _ O
to -X- _ O
mBERT -X- _ B-MethodName
( -X- _ O
178 -X- _ O
M -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
keep -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
4096 -X- _ B-HyperparameterValue
and -X- _ O
train -X- _ O
for -X- _ O
500,000 -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512.Finetuning -X- _ B-HyperparameterValue
: -X- _ O
We -X- _ O
report -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
performance -X- _ O
for -X- _ O
all -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
XTREME -X- _ B-DatasetName
( -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
benchmark -X- _ O
8 -X- _ O
.Results -X- _ O
: -X- _ O
We -X- _ O
report -X- _ O
results -X- _ O
of -X- _ O
our -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
LMs -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
Student -X- _ O
MuRIL -X- _ B-MethodName
performs -X- _ O
the -X- _ O
best -X- _ O
among -X- _ O
all -X- _ O
student -X- _ O
variants -X- _ O
. -X- _ O
For -X- _ O
Non -X- _ O
- -X- _ O
MuL -X- _ O
, -X- _ O
Student -X- _ O
MuRIL -X- _ B-MethodName
beats -X- _ O
the -X- _ O
teacher -X- _ O
( -X- _ O
mBERT -X- _ B-MethodName
) -X- _ O
by -X- _ O
an -X- _ O
average -X- _ B-MetricName
relative -X- _ I-MetricName
score -X- _ I-MetricName
of -X- _ O
3.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
For -X- _ O
MuL -X- _ O
, -X- _ O
Student -X- _ O
MuRIL -X- _ B-MethodName
beats -X- _ O
one -X- _ O
teacher -X- _ O
( -X- _ O
mBERT -X- _ B-MethodName
) -X- _ O
by -X- _ O
8.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
but -X- _ O
underperforms -X- _ O
the -X- _ O
other -X- _ O
teacher -X- _ O
( -X- _ O
MuRIL -X- _ B-MethodName
) -X- _ O
by -X- _ O
3.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
There -X- _ O
can -X- _ O
be -X- _ O
two -X- _ O
factors -X- _ O
at -X- _ O
play -X- _ O
here -X- _ O
. -X- _ O
MuRIL -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
monolingual -X- _ O
and -X- _ O
parallel -X- _ O
data -X- _ O
9 -X- _ O
while -X- _ O
the -X- _ O
student -X- _ O
LMs -X- _ O
only -X- _ O
see -X- _ O
∼22 -X- _ O
% -X- _ O
of -X- _ O
unique -X- _ O
tokens -X- _ O
in -X- _ O
comparison -X- _ O
. -X- _ O
MuRIL -X- _ B-MethodName
also -X- _ O
has -X- _ O
different -X- _ O
language -X- _ O
sampling -X- _ O
strategies -X- _ O
( -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
0.3 -X- _ B-HyperparameterValue
as -X- _ O
opposed -X- _ O
to -X- _ O
0.7 -X- _ B-HyperparameterValue
in -X- _ O
our -X- _ O
setting -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
lower -X- _ O
α -X- _ B-HyperparameterName
value -X- _ O
upsamples -X- _ O
more -X- _ O
rigorously -X- _ O
from -X- _ O
the -X- _ O
tail -X- _ O
languages -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
have -X- _ O
a -X- _ O
significant -X- _ O
role -X- _ O
to -X- _ O
play -X- _ O
in -X- _ O
multilingual -X- _ O
model -X- _ O
performances -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
observe -X- _ O
a -X- _ O
significant -X- _ O
drop -X- _ O
in -X- _ O
Student -X- _ O
mBERT -X- _ B-MethodName
's -X- _ O
performance -X- _ O
for -X- _ O
MuL -X- _ O
when -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
other -X- _ O
student -X- _ O
LM -X- _ O
variants -X- _ O
. -X- _ O
This -X- _ O
might -X- _ O
be -X- _ O
because -X- _ O
the -X- _ O
input -X- _ O
is -X- _ O
tokenized -X- _ O
using -X- _ O
the -X- _ O
mBERT -X- _ B-MethodName
tokenizer -X- _ O
which -X- _ O
prevents -X- _ O
learning -X- _ O
from -X- _ O
MuRIL -X- _ B-MethodName
tokens -X- _ O
in -X- _ O
the -X- _ O
student -X- _ O
vocabulary -X- _ O
. -X- _ O
For -X- _ O
Student -X- _ O
Both -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
observe -X- _ O
much -X- _ O
of -X- _ O
a -X- _ O
difference -X- _ O
between -X- _ O
Student -X- _ O
Both -X- _ O
all -X- _ O
and -X- _ O
Student -X- _ O
Both -X- _ O
best -X- _ O
. -X- _ O
This -X- _ O
observation -X- _ O
may -X- _ O
differ -X- _ O
with -X- _ O
one -X- _ O
's -X- _ O
choice -X- _ O
of -X- _ O
teacher -X- _ O
LMs -X- _ O
depending -X- _ O
on -X- _ O
how -X- _ O
well -X- _ O
it -X- _ O
performs -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
language -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
n't -X- _ O
observe -X- _ O
much -X- _ O
of -X- _ O
a -X- _ O
difference -X- _ O
in -X- _ O
incorporating -X- _ O
mBERT -X- _ B-MethodName
predictions -X- _ O
for -X- _ O
MuL.8 -X- _ O
More -X- _ O
details -X- _ O
in -X- _ O
Appendix -X- _ O
A.3 -X- _ O
9 -X- _ O
More -X- _ O
details -X- _ O
in -X- _ O
Appendix -X- _ O
A.2 -X- _ O
The -X- _ O
importance -X- _ O
of -X- _ O
vocabulary -X- _ O
and -X- _ O
teacher -X- _ O
LM -X- _ O
preditions -X- _ O
: -X- _ O
In -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
observe -X- _ O
that -X- _ O
SM2 -X- _ B-MethodName
and -X- _ O
SM3 -X- _ B-MethodName
achieve -X- _ O
competitive -X- _ O
performances -X- _ O
despite -X- _ O
SM3 -X- _ B-MethodName
being -X- _ O
additionally -X- _ O
trained -X- _ O
on -X- _ O
teacher -X- _ O
LM -X- _ O
labels -X- _ O
. -X- _ O
To -X- _ O
motivate -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
teacher -X- _ O
predictions -X- _ O
, -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2015 -X- _ O
) -X- _ O
argue -X- _ O
that -X- _ O
when -X- _ O
soft -X- _ O
targets -X- _ O
have -X- _ O
high -X- _ O
entropy -X- _ O
, -X- _ O
they -X- _ O
provide -X- _ O
much -X- _ O
more -X- _ O
information -X- _ O
per -X- _ O
training -X- _ O
case -X- _ O
than -X- _ O
hard -X- _ O
targets -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
much -X- _ O
less -X- _ O
data -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
cumbersome -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
training -X- _ O
on -X- _ O
500,000 -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
exposes -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
sufficient -X- _ O
data -X- _ O
for -X- _ O
it -X- _ O
to -X- _ O
generalize -X- _ O
well -X- _ O
enough -X- _ O
and -X- _ O
mask -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
teacher -X- _ O
LM -X- _ O
predictions -X- _ O
. -X- _ O
To -X- _ O
validate -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
performances -X- _ O
of -X- _ O
SM2 -X- _ B-MethodName
and -X- _ O
SM3 -X- _ B-MethodName
, -X- _ O
20 -X- _ O
% -X- _ O
into -X- _ O
training -X- _ O
( -X- _ O
i.e. -X- _ O
100,000 -X- _ O
steps -X- _ O
/ -X- _ O
500,000 -X- _ O
total -X- _ O
steps -X- _ O
) -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
a -X- _ O
∼2.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
gain -X- _ B-MetricName
in -X- _ O
average -X- _ O
performance -X- _ O
for -X- _ O
SM3 -X- _ B-MethodName
over -X- _ O
SM2 -X- _ B-MethodName
, -X- _ O
clearly -X- _ O
highlighting -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
teacher -X- _ O
LM -X- _ O
predictions -X- _ O
in -X- _ O
a -X- _ O
limited -X- _ O
data -X- _ O
scenario -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
especially -X- _ O
important -X- _ O
when -X- _ O
one -X- _ O
has -X- _ O
access -X- _ O
to -X- _ O
very -X- _ O
limited -X- _ O
monolingual -X- _ O
data -X- _ O
and -X- _ O
a -X- _ O
strong -X- _ O
teacher -X- _ O
LM -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
language -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
transfer -X- _ O
: -X- _ O
Interestingly -X- _ O
, -X- _ O
Student -X- _ O
MuRIL -X- _ B-MethodName
performs -X- _ O
the -X- _ O
best -X- _ O
on -X- _ O
almost -X- _ O
all -X- _ O
tasks -X- _ O
for -X- _ O
Non -X- _ O
- -X- _ O
MuL. -X- _ O
This -X- _ O
hints -X- _ O
at -X- _ O
positive -X- _ O
transfer -X- _ O
from -X- _ O
strong -X- _ O
teachers -X- _ O
to -X- _ O
languages -X- _ O
that -X- _ O
the -X- _ O
teacher -X- _ O
does -X- _ O
not -X- _ O
cover -X- _ O
at -X- _ O
all -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
shared -X- _ O
multilingual -X- _ O
representations -X- _ O
. -X- _ O
10 -X- _ O
This -X- _ O
would -X- _ O
mean -X- _ O
that -X- _ O
learning -X- _ O
from -X- _ O
strong -X- _ O
teachers -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
student -X- _ O
model -X- _ O
's -X- _ O
performance -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
manner -X- _ O
on -X- _ O
related -X- _ O
languages -X- _ O
not -X- _ O
covered -X- _ O
by -X- _ O
the -X- _ O
teacher -X- _ O
. -X- _ O
This -X- _ O
would -X- _ O
make -X- _ O
MERGEDISTILL -X- _ B-MethodName
highly -X- _ O
beneficial -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
a -X- _ O
strong -X- _ O
teacher -X- _ O
or -X- _ O
limited -X- _ O
gold -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
this -X- _ O
exploration -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
address -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
merging -X- _ O
multiple -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
teacher -X- _ O
LMs -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
multilingual -X- _ O
student -X- _ O
LM -X- _ O
by -X- _ O
proposing -X- _ O
MERGEDIS -X- _ B-MethodName
- -X- _ I-MethodName
TILL -X- _ I-MethodName
, -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
agnostic -X- _ O
distillation -X- _ O
method -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
attempt -X- _ O
of -X- _ O
its -X- _ O
kind -X- _ O
. -X- _ O
The -X- _ O
student -X- _ O
LM -X- _ O
learned -X- _ O
by -X- _ O
MERGEDISTILL -X- _ B-MethodName
may -X- _ O
be -X- _ O
further -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
any -X- _ O
task -X- _ O
across -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
languages -X- _ O
covered -X- _ O
by -X- _ O
the -X- _ O
teacher -X- _ O
LMs -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
results -X- _ O
in -X- _ O
better -X- _ O
maintainability -X- _ O
( -X- _ O
fewer -X- _ O
models -X- _ O
) -X- _ O
and -X- _ O
is -X- _ O
compute -X- _ O
efficient -X- _ O
( -X- _ O
due -X- _ O
to -X- _ O
offline -X- _ O
predictions -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
MERGEDISTILL -X- _ B-MethodName
to -X- _ O
i -X- _ O
) -X- _ O
combine -X- _ O
monolingual -X- _ O
teacher -X- _ O
LMs -X- _ O
into -X- _ O
one -X- _ O
student -X- _ O
multilingual -X- _ O
LM -X- _ O
which -X- _ O
is -X- _ O
competitive -X- _ O
with -X- _ O
the -X- _ O
teachers -X- _ O
, -X- _ O
thereby -X- _ O
demonstrating -X- _ O
positive -X- _ O
crosslingual -X- _ O
transfer -X- _ O
, -X- _ O
and -X- _ O
ii -X- _ O
) -X- _ O
combine -X- _ O
multilingual -X- _ O
LMs -X- _ O
to -X- _ O
train -X- _ O
student -X- _ O
LMs -X- _ O
that -X- _ O
learn -X- _ O
from -X- _ O
multiple -X- _ O
teachers -X- _ O
. -X- _ O
Through -X- _ O
experiments -X- _ O
on -X- _ O
multiple -X- _ O
benchmark -X- _ O
datasets -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
student -X- _ O
LMs -X- _ O
learned -X- _ O
by -X- _ O
MERGEDISTILL -X- _ B-MethodName
perform -X- _ O
competitively -X- _ O
or -X- _ O
even -X- _ O
outperform -X- _ O
teacher -X- _ O
LMs -X- _ O
trained -X- _ O
on -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
more -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
disentangle -X- _ O
the -X- _ O
positive -X- _ O
impact -X- _ O
of -X- _ O
incorporating -X- _ O
strong -X- _ O
teacher -X- _ O
LM -X- _ O
vocabu -X- _ O
- -X- _ O
laries -X- _ O
and -X- _ O
learning -X- _ O
from -X- _ O
teacher -X- _ O
LM -X- _ O
predictions -X- _ O
, -X- _ O
highlighting -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
latter -X- _ O
in -X- _ O
a -X- _ O
limited -X- _ O
data -X- _ O
scenario -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
find -X- _ O
that -X- _ O
MERGEDIS -X- _ B-MethodName
- -X- _ I-MethodName
TILL -X- _ I-MethodName
enables -X- _ O
positive -X- _ O
transfer -X- _ O
from -X- _ O
strong -X- _ O
teachers -X- _ O
to -X- _ O
languages -X- _ O
not -X- _ O
covered -X- _ O
by -X- _ O
them -X- _ O
( -X- _ O
i.e. -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
transfer -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
bridges -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
universe -X- _ O
of -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
models -X- _ O
and -X- _ O
massively -X- _ O
multilingual -X- _ O
LMs -X- _ O
, -X- _ O
incorporating -X- _ O
benefits -X- _ O
of -X- _ O
both -X- _ O
into -X- _ O
one -X- _ O
framework -X- _ O
. -X- _ O
We -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
our -X- _ O
student -X- _ O
models -X- _ O
using -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
base -X- _ I-MethodName
architecture -X- _ O
. -X- _ O
Student -X- _ O
similar -X- _ O
has -X- _ O
a -X- _ O
vocabulary -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
99112 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
model -X- _ O
size -X- _ O
of -X- _ O
162 -X- _ O
M -X- _ O
parameters -X- _ O
. -X- _ O
Student -X- _ O
different -X- _ O
has -X- _ O
a -X- _ O
vocabulary -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
180996 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
model -X- _ O
size -X- _ O
of -X- _ O
225 -X- _ O
M -X- _ O
parameters -X- _ O
. -X- _ O
We -X- _ O
keep -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
4096 -X- _ B-HyperparameterValue
and -X- _ O
train -X- _ O
for -X- _ O
250k -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
TPUs -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
takes -X- _ O
around -X- _ O
1.5 -X- _ O
days -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
each -X- _ O
student -X- _ O
LM -X- _ O
. -X- _ O
We -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
our -X- _ O
student -X- _ O
models -X- _ O
using -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
base -X- _ I-MethodName
architecture -X- _ O
. -X- _ O
All -X- _ O
student -X- _ O
LMs -X- _ O
have -X- _ O
a -X- _ O
vocabulary -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
288973 -X- _ B-HyperparameterName
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
reduce -X- _ O
our -X- _ O
embedding -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
to -X- _ O
256 -X- _ B-HyperparameterValue
as -X- _ O
opposed -X- _ O
to -X- _ O
768 -X- _ B-HyperparameterValue
to -X- _ O
bring -X- _ O
down -X- _ O
the -X- _ O
model -X- _ O
size -X- _ O
to -X- _ O
be -X- _ O
around -X- _ O
160 -X- _ O
M -X- _ O
, -X- _ O
comparable -X- _ O
to -X- _ O
mBERT -X- _ B-MethodName
( -X- _ O
178 -X- _ O
M -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
keep -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
4096 -X- _ B-HyperparameterValue
and -X- _ O
train -X- _ O
for -X- _ O
500k -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
maximum -X- _ B-HyperparameterName
sequence -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
use -X- _ O
TPUs -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
takes -X- _ O
around -X- _ O
3 -X- _ O
days -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
each -X- _ O
student -X- _ O
LM.We -X- _ O
present -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
statistics -X- _ O
for -X- _ O
MuRIL -X- _ B-MethodName
and -X- _ O
the -X- _ O
student -X- _ O
LMs -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
Here -X- _ O
we -X- _ O
only -X- _ O
include -X- _ O
the -X- _ O
monolingual -X- _ O
data -X- _ O
statistics -X- _ O
, -X- _ O
but -X- _ O
MuRIL -X- _ B-MethodName
is -X- _ O
additionally -X- _ O
trained -X- _ O
on -X- _ O
parallel -X- _ O
translated -X- _ O
and -X- _ O
transliterated -X- _ O
data -X- _ O
. -X- _ O
( -X- _ O
Fang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
results -X- _ O
are -X- _ O
computed -X- _ O
in -X- _ O
a -X- _ O
zero -X- _ O
- -X- _ O
shot -X- _ O
setting -X- _ O
. -X- _ O
Hyperparameter -X- _ O
Details -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
for -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
all -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
LMs -X- _ O
, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
11 -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
best -X- _ O
- -X- _ O
performing -X- _ O
checkpoint -X- _ O
for -X- _ O
the -X- _ O
We -X- _ O
present -X- _ O
results -X- _ O
for -X- _ O
Student -X- _ O
MuRIL -X- _ B-MethodName
trained -X- _ O
with -X- _ O
different -X- _ O
top -X- _ O
- -X- _ O
k -X- _ B-HyperparameterName
values -X- _ O
from -X- _ O
teacher -X- _ O
predictions -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
while -X- _ O
performances -X- _ O
remain -X- _ O
similar -X- _ O
for -X- _ O
higher -X- _ O
values -X- _ O
of -X- _ O
k -X- _ O
, -X- _ O
storage -X- _ O
becomes -X- _ O
increasingly -X- _ O
expensive -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
stick -X- _ O
to -X- _ O
a -X- _ O
value -X- _ O
of -X- _ O
k=8 -X- _ B-HyperparameterName
in -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
the -X- _ O
anonymous -X- _ O
reviewers -X- _ O
for -X- _ O
their -X- _ O
insightful -X- _ O
and -X- _ O
constructive -X- _ O
feedback -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
Iulia -X- _ O
Turc -X- _ O
, -X- _ O
Ming -X- _ O
- -X- _ O
Wei -X- _ O
Chang -X- _ O
, -X- _ O
and -X- _ O
Slav -X- _ O
Petrov -X- _ O
for -X- _ O
valuable -X- _ O
comments -X- _ O
on -X- _ O
an -X- _ O
earlier -X- _ O
version -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
our -X- _ O
LMs -X- _ O
with -X- _ O
the -X- _ O
MLM -X- _ O
objective -X- _ O
. -X- _ O
Let -X- _ O
x -X- _ O
denote -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
tokens -X- _ O
where -X- _ O
x -X- _ O
m -X- _ O
= -X- _ O
{ -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
x -X- _ O
3 -X- _ O
... -X- _ O
x -X- _ O
n -X- _ O
} -X- _ O
denote -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
, -X- _ O
and -X- _ O
x -X- _ O
−m -X- _ O
denote -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O
Let -X- _ O
v -X- _ O
be -X- _ O
the -X- _ O
vocabulary -X- _ O
of -X- _ O
LM -X- _ O
θ -X- _ O
. -X- _ O
The -X- _ O
log -X- _ O
- -X- _ O
likelihood -X- _ O
loss -X- _ O
( -X- _ O
crossentropy -X- _ O
with -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
label -X- _ O
) -X- _ O
can -X- _ O
be -X- _ O
formulated -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
In -X- _ O
a -X- _ O
distillation -X- _ O
setup -X- _ O
, -X- _ O
the -X- _ O
student -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
not -X- _ O
only -X- _ O
match -X- _ O
the -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
labels -X- _ O
for -X- _ O
masked -X- _ O
words -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
the -X- _ O
probability -X- _ O
output -X- _ O
distribution -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
t. -X- _ O
Let -X- _ O
us -X- _ O
denote -X- _ O
the -X- _ O
teacher -X- _ O
output -X- _ O
probability -X- _ O
distribution -X- _ O
for -X- _ O
token -X- _ O
x -X- _ O
m -X- _ O
i -X- _ O
by -X- _ O
Q(x -X- _ O
m -X- _ O
i -X- _ O
|x -X- _ O
−m -X- _ O
; -X- _ O
θ -X- _ O
t -X- _ O
) -X- _ O
.The -X- _ O
cross -X- _ O
entropy -X- _ O
between -X- _ O
the -X- _ O
teacher -X- _ O
and -X- _ O
student -X- _ O
distributions -X- _ O
then -X- _ O
serves -X- _ O
as -X- _ O
the -X- _ O
distillation -X- _ O
loss -X- _ O
: -X- _ O
The -X- _ O
total -X- _ O
loss -X- _ O
is -X- _ O
then -X- _ O
defined -X- _ O
as -X- _ O
: -X- _ O
With -X- _ O
the -X- _ O
addition -X- _ O
of -X- _ O
the -X- _ O
teacher -X- _ O
, -X- _ O
the -X- _ O
target -X- _ O
distribution -X- _ O
is -X- _ O
no -X- _ O
longer -X- _ O
a -X- _ O
single -X- _ O
one -X- _ O
- -X- _ O
hot -X- _ O
label -X- _ O
, -X- _ O
but -X- _ O
a -X- _ O
smoother -X- _ O
distribution -X- _ O
with -X- _ O
multiple -X- _ O
words -X- _ O
having -X- _ O
non -X- _ O
- -X- _ O
zero -X- _ O
probabilities -X- _ O
which -X- _ O
yields -X- _ O
in -X- _ O
a -X- _ O
smaller -X- _ O
variance -X- _ O
in -X- _ O
gradients -X- _ O
( -X- _ O
Hinton -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
Intuitively -X- _ O
, -X- _ O
a -X- _ O
single -X- _ O
masked -X- _ O
word -X- _ O
can -X- _ O
have -X- _ O
several -X- _ O
valid -X- _ O
predictions -X- _ O
, -X- _ O
which -X- _ O
appropriately -X- _ O
fit -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O

Warning -X- _ O
: -X- _ O
This -X- _ O
paper -X- _ O
contains -X- _ O
comments -X- _ O
that -X- _ O
may -X- _ O
be -X- _ O
offensive -X- _ O
or -X- _ O
upsetting -X- _ O
. -X- _ O
On -X- _ O
social -X- _ O
media -X- _ O
platforms -X- _ O
, -X- _ O
hateful -X- _ O
and -X- _ O
offensive -X- _ O
language -X- _ O
negatively -X- _ O
impact -X- _ O
the -X- _ O
mental -X- _ O
well -X- _ O
- -X- _ O
being -X- _ O
of -X- _ O
users -X- _ O
and -X- _ O
the -X- _ O
participation -X- _ O
of -X- _ O
people -X- _ O
from -X- _ O
diverse -X- _ O
backgrounds -X- _ O
. -X- _ O
Automatic -X- _ O
methods -X- _ O
to -X- _ O
detect -X- _ O
offensive -X- _ O
language -X- _ O
have -X- _ O
largely -X- _ O
relied -X- _ O
on -X- _ O
datasets -X- _ O
with -X- _ O
categorical -X- _ O
labels -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
comments -X- _ O
can -X- _ O
vary -X- _ O
in -X- _ O
their -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
. -X- _ O
We -X- _ O
create -X- _ O
the -X- _ O
first -X- _ O
dataset -X- _ O
of -X- _ O
English -X- _ O
language -X- _ O
Reddit -X- _ O
comments -X- _ O
that -X- _ O
has -X- _ O
finegrained -X- _ O
, -X- _ O
real -X- _ O
- -X- _ O
valued -X- _ O
scores -X- _ O
between -X- _ O
-1 -X- _ O
( -X- _ O
maximally -X- _ O
supportive -X- _ O
) -X- _ O
and -X- _ O
1 -X- _ O
( -X- _ O
maximally -X- _ O
offensive -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
was -X- _ O
annotated -X- _ O
using -X- _ O
Best -X- _ B-MethodName
- -X- _ I-MethodName
Worst -X- _ I-MethodName
Scaling -X- _ I-MethodName
, -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
comparative -X- _ O
annotation -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
alleviate -X- _ O
known -X- _ O
biases -X- _ O
of -X- _ O
using -X- _ O
rating -X- _ O
scales -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
method -X- _ O
produces -X- _ O
highly -X- _ O
reliable -X- _ O
offensiveness -X- _ O
scores -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
ability -X- _ O
of -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
neural -X- _ O
models -X- _ O
to -X- _ O
predict -X- _ O
offensiveness -X- _ O
scores -X- _ O
on -X- _ O
this -X- _ O
new -X- _ O
dataset -X- _ O
. -X- _ O
Social -X- _ O
media -X- _ O
platforms -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
medium -X- _ O
for -X- _ O
exchange -X- _ O
of -X- _ O
ideas -X- _ O
on -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
topics -X- _ O
, -X- _ O
from -X- _ O
the -X- _ O
personal -X- _ O
to -X- _ O
the -X- _ O
political -X- _ O
. -X- _ O
This -X- _ O
exchange -X- _ O
can -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
be -X- _ O
disrupted -X- _ O
by -X- _ O
offensive -X- _ O
or -X- _ O
hateful -X- _ O
language -X- _ O
. -X- _ O
Such -X- _ O
language -X- _ O
is -X- _ O
pervasive -X- _ O
online -X- _ O
( -X- _ O
Statista -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
exposure -X- _ O
to -X- _ O
it -X- _ O
may -X- _ O
have -X- _ O
numerous -X- _ O
negative -X- _ O
consequences -X- _ O
for -X- _ O
the -X- _ O
victim -X- _ O
's -X- _ O
mental -X- _ O
health -X- _ O
( -X- _ O
Munro -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
Automated -X- _ B-TaskName
offensive -X- _ I-TaskName
language -X- _ I-TaskName
detection -X- _ I-TaskName
has -X- _ O
thus -X- _ O
been -X- _ O
gaining -X- _ O
interest -X- _ O
in -X- _ O
the -X- _ O
NLP -X- _ O
community -X- _ O
, -X- _ O
as -X- _ O
a -X- _ O
promising -X- _ O
direction -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
the -X- _ O
nature -X- _ O
and -X- _ O
spread -X- _ O
of -X- _ O
such -X- _ O
content -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
several -X- _ O
challenges -X- _ O
in -X- _ O
the -X- _ O
automatic -X- _ B-TaskName
detection -X- _ I-TaskName
of -X- _ I-TaskName
offensive -X- _ I-TaskName
language -X- _ I-TaskName
( -X- _ O
Wiedemann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
NLP -X- _ O
community -X- _ O
has -X- _ O
adopted -X- _ O
various -X- _ O
definitions -X- _ O
for -X- _ O
offensive -X- _ O
language -X- _ O
, -X- _ O
classifying -X- _ O
it -X- _ O
into -X- _ O
specific -X- _ O
categories -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Waseem -X- _ O
and -X- _ O
* -X- _ O
Both -X- _ O
authors -X- _ O
contributed -X- _ O
equally -X- _ O
. -X- _ O
Hovy -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
classified -X- _ O
comments -X- _ O
as -X- _ O
racist -X- _ O
, -X- _ O
sexist -X- _ O
, -X- _ O
neither -X- _ O
; -X- _ O
as -X- _ O
hate -X- _ O
- -X- _ O
speech -X- _ O
, -X- _ O
offensive -X- _ O
but -X- _ O
not -X- _ O
hate -X- _ O
- -X- _ O
speech -X- _ O
, -X- _ O
neither -X- _ O
offensive -X- _ O
nor -X- _ O
hate -X- _ O
- -X- _ O
speech -X- _ O
and -X- _ O
Founta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
as -X- _ O
abusive -X- _ O
, -X- _ O
hateful -X- _ O
, -X- _ O
normal -X- _ O
, -X- _ O
spam -X- _ O
. -X- _ O
Schmidt -X- _ O
and -X- _ O
Wiegand -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
; -X- _ O
Fortuna -X- _ O
and -X- _ O
Nunes -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
Mishra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Kiritchenko -X- _ O
and -X- _ O
Nejadgholi -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
summarize -X- _ O
the -X- _ O
different -X- _ O
definitions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
categories -X- _ O
have -X- _ O
significant -X- _ O
overlaps -X- _ O
with -X- _ O
each -X- _ O
other -X- _ O
, -X- _ O
creating -X- _ O
ill -X- _ O
- -X- _ O
defined -X- _ O
boundaries -X- _ O
, -X- _ O
thus -X- _ O
introducing -X- _ O
ambiguity -X- _ O
and -X- _ O
annotation -X- _ O
inconsistency -X- _ O
( -X- _ O
Founta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
further -X- _ O
challenge -X- _ O
is -X- _ O
that -X- _ O
after -X- _ O
encountering -X- _ O
several -X- _ O
highly -X- _ O
offensive -X- _ O
comments -X- _ O
, -X- _ O
an -X- _ O
annotator -X- _ O
might -X- _ O
find -X- _ O
subsequent -X- _ O
moderately -X- _ O
offensive -X- _ O
comments -X- _ O
to -X- _ O
not -X- _ O
be -X- _ O
offensive -X- _ O
( -X- _ O
de -X- _ O
- -X- _ O
sensitization -X- _ O
) -X- _ O
( -X- _ O
Kurrek -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Soral -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).At -X- _ O
the -X- _ O
same -X- _ O
time -X- _ O
, -X- _ O
existing -X- _ O
approaches -X- _ O
do -X- _ O
not -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
that -X- _ O
comments -X- _ O
can -X- _ O
be -X- _ O
offensive -X- _ O
to -X- _ O
a -X- _ O
different -X- _ O
degree -X- _ O
. -X- _ O
Knowing -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
of -X- _ O
a -X- _ O
comment -X- _ O
has -X- _ O
practical -X- _ O
implications -X- _ O
, -X- _ O
when -X- _ O
taking -X- _ O
action -X- _ O
against -X- _ O
inappropriate -X- _ O
behaviour -X- _ O
online -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
allows -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
analysis -X- _ O
and -X- _ O
prioritization -X- _ O
in -X- _ O
moderation -X- _ O
. -X- _ O
The -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
offensive -X- _ O
class -X- _ O
in -X- _ O
a -X- _ O
dataset -X- _ O
is -X- _ O
often -X- _ O
boosted -X- _ O
using -X- _ O
different -X- _ O
strategies -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
common -X- _ O
strategy -X- _ O
used -X- _ O
is -X- _ O
key -X- _ B-MethodName
- -X- _ I-MethodName
word -X- _ I-MethodName
based -X- _ I-MethodName
sampling -X- _ I-MethodName
. -X- _ O
This -X- _ O
results -X- _ O
in -X- _ O
datasets -X- _ O
that -X- _ O
are -X- _ O
rich -X- _ O
in -X- _ O
explicit -X- _ O
offensive -X- _ O
language -X- _ O
( -X- _ O
language -X- _ O
that -X- _ O
is -X- _ O
unambiguous -X- _ O
in -X- _ O
its -X- _ O
potential -X- _ O
to -X- _ O
be -X- _ O
offensive -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
those -X- _ O
using -X- _ O
slurs -X- _ O
or -X- _ O
swear -X- _ O
words -X- _ O
( -X- _ O
Waseem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
) -X- _ O
but -X- _ O
lack -X- _ O
cases -X- _ O
of -X- _ O
implicit -X- _ O
offensive -X- _ O
language -X- _ O
( -X- _ O
language -X- _ O
with -X- _ O
its -X- _ O
true -X- _ O
offensive -X- _ O
nature -X- _ O
obscured -X- _ O
due -X- _ O
to -X- _ O
lack -X- _ O
of -X- _ O
unambiguous -X- _ O
swear -X- _ O
words -X- _ O
, -X- _ O
usage -X- _ O
of -X- _ O
sarcasm -X- _ O
or -X- _ O
offensive -X- _ O
analogies -X- _ O
, -X- _ O
and -X- _ O
others -X- _ O
( -X- _ O
Waseem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
) -X- _ O
( -X- _ O
Waseem -X- _ O
, -X- _ O
2016;Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
key -X- _ B-MethodName
- -X- _ I-MethodName
word -X- _ I-MethodName
based -X- _ I-MethodName
sampling -X- _ I-MethodName
often -X- _ O
results -X- _ O
in -X- _ O
spurious -X- _ O
correlations -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
sports -X- _ O
- -X- _ O
related -X- _ O
expressions -X- _ O
such -X- _ O
as -X- _ O
announcer -X- _ O
and -X- _ O
sport -X- _ O
occur -X- _ O
very -X- _ O
frequently -X- _ O
in -X- _ O
offensive -X- _ O
tweets -X- _ O
) -X- _ O
. -X- _ O
Lastly -X- _ O
, -X- _ O
existing -X- _ O
datasets -X- _ O
consider -X- _ O
of -X- _ O
- -X- _ O
fensive -X- _ O
comments -X- _ O
in -X- _ O
isolation -X- _ O
from -X- _ O
the -X- _ O
wider -X- _ O
conversation -X- _ O
of -X- _ O
which -X- _ O
they -X- _ O
are -X- _ O
a -X- _ O
part -X- _ O
. -X- _ O
Offensive -X- _ O
language -X- _ O
is -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
inherently -X- _ O
a -X- _ O
social -X- _ O
phenomenon -X- _ O
and -X- _ O
its -X- _ O
analysis -X- _ O
has -X- _ O
much -X- _ O
to -X- _ O
gain -X- _ O
from -X- _ O
taking -X- _ O
the -X- _ O
conversational -X- _ O
context -X- _ O
into -X- _ O
account -X- _ O
( -X- _ O
Gao -X- _ O
and -X- _ O
Huang -X- _ O
, -X- _ O
2017).In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
first -X- _ O
dataset -X- _ O
of -X- _ O
6000 -X- _ O
English -X- _ O
language -X- _ O
Reddit -X- _ O
comments -X- _ O
that -X- _ O
has -X- _ O
finegrained -X- _ O
, -X- _ O
real -X- _ O
- -X- _ O
valued -X- _ O
scores -X- _ O
between -X- _ O
-1 -X- _ O
( -X- _ O
maximally -X- _ O
supportive -X- _ O
) -X- _ O
and -X- _ O
1 -X- _ O
( -X- _ O
maximally -X- _ O
offensive -X- _ O
) -X- _ O
-normative -X- _ O
offensiveness -X- _ O
ratings -X- _ O
for -X- _ O
the -X- _ O
comments -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
first -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
comparative -X- _ O
annotations -X- _ O
to -X- _ O
detect -X- _ O
offensive -X- _ O
language -X- _ O
. -X- _ O
In -X- _ O
its -X- _ O
simplest -X- _ O
form -X- _ O
, -X- _ O
comparative -X- _ O
annotations -X- _ O
involve -X- _ O
giving -X- _ O
the -X- _ O
annotators -X- _ O
two -X- _ O
instances -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
asking -X- _ O
which -X- _ O
exhibits -X- _ O
the -X- _ O
property -X- _ O
of -X- _ O
interest -X- _ O
to -X- _ O
a -X- _ O
greater -X- _ O
extent -X- _ O
. -X- _ O
This -X- _ O
alleviates -X- _ O
several -X- _ O
annotation -X- _ O
biases -X- _ O
present -X- _ O
in -X- _ O
standard -X- _ O
rating -X- _ O
scales -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
scale -X- _ O
- -X- _ O
region -X- _ O
bias -X- _ O
( -X- _ O
Presser -X- _ O
and -X- _ O
Schuman -X- _ O
, -X- _ O
1996;Asaadi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
improves -X- _ O
annotation -X- _ O
consistency -X- _ O
( -X- _ O
Kiritchenko -X- _ O
and -X- _ O
Mohammad -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
needing -X- _ O
to -X- _ O
annotate -X- _ O
N -X- _ O
instances -X- _ O
, -X- _ O
one -X- _ O
now -X- _ O
needs -X- _ O
to -X- _ O
annotate -X- _ O
N -X- _ O
2 -X- _ O
instance -X- _ O
pairs -X- _ O
- -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
prohibitive -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
annotate -X- _ O
our -X- _ O
dataset -X- _ O
using -X- _ O
an -X- _ O
efficient -X- _ O
form -X- _ O
of -X- _ O
comparative -X- _ O
annotation -X- _ O
called -X- _ O
Best -X- _ B-MethodName
- -X- _ I-MethodName
Worst -X- _ I-MethodName
Scaling -X- _ I-MethodName
( -X- _ I-MethodName
BWS -X- _ I-MethodName
) -X- _ I-MethodName
( -X- _ O
Louviere -X- _ O
, -X- _ O
1991;Louviere -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015;Mohammad -X- _ O
, -X- _ O
2016 -X- _ O
, -X- _ O
2017).By -X- _ O
eliminating -X- _ O
different -X- _ O
offensiveness -X- _ O
categories -X- _ O
, -X- _ O
treating -X- _ O
offensiveness -X- _ O
as -X- _ O
a -X- _ O
continuous -X- _ O
dimension -X- _ O
, -X- _ O
and -X- _ O
eliciting -X- _ O
comparative -X- _ O
judgments -X- _ O
from -X- _ O
the -X- _ O
annotators -X- _ O
( -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
understanding -X- _ O
of -X- _ O
what -X- _ O
is -X- _ O
offensive -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
alleviate -X- _ O
the -X- _ O
issues -X- _ O
regarding -X- _ O
category -X- _ O
definitions -X- _ O
and -X- _ O
arbitrary -X- _ O
category -X- _ O
boundaries -X- _ O
discussed -X- _ O
earlier -X- _ O
. -X- _ O
By -X- _ O
obtaining -X- _ O
real -X- _ O
- -X- _ O
valued -X- _ O
offensiveness -X- _ O
scores -X- _ O
, -X- _ O
different -X- _ O
thresholds -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
downstream -X- _ O
applications -X- _ O
to -X- _ O
handle -X- _ O
varying -X- _ O
degrees -X- _ O
of -X- _ O
offensiveness -X- _ O
appropriately -X- _ O
. -X- _ O
By -X- _ O
framing -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
comparative -X- _ O
annotation -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
consistent -X- _ O
and -X- _ O
reliable -X- _ O
annotations -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
greatly -X- _ O
mitigate -X- _ O
issues -X- _ O
of -X- _ O
annotator -X- _ O
de -X- _ O
- -X- _ O
sensitization -X- _ O
as -X- _ O
one -X- _ O
will -X- _ O
still -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
recognize -X- _ O
if -X- _ O
one -X- _ O
comment -X- _ O
is -X- _ O
more -X- _ O
offensive -X- _ O
than -X- _ O
another -X- _ O
, -X- _ O
even -X- _ O
if -X- _ O
they -X- _ O
think -X- _ O
both -X- _ O
comments -X- _ O
are -X- _ O
not -X- _ O
that -X- _ O
offensive -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
existing -X- _ O
resources -X- _ O
, -X- _ O
which -X- _ O
provide -X- _ O
annotations -X- _ O
for -X- _ O
individual -X- _ O
comments -X- _ O
, -X- _ O
our -X- _ O
dataset -X- _ O
includes -X- _ O
conversational -X- _ O
context -X- _ O
for -X- _ O
each -X- _ O
comment -X- _ O
( -X- _ O
i.e. -X- _ O
the -X- _ O
Reddit -X- _ O
thread -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
comment -X- _ O
occurred -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
conduct -X- _ O
quantitative -X- _ O
and -X- _ O
qualitative -X- _ O
analyses -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
to -X- _ O
obtain -X- _ O
insights -X- _ O
into -X- _ O
how -X- _ O
emotions -X- _ O
, -X- _ O
identity -X- _ O
terms -X- _ O
, -X- _ O
swear -X- _ O
words -X- _ O
, -X- _ O
are -X- _ O
related -X- _ O
to -X- _ O
offensiveness -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
benchmark -X- _ O
several -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
neural -X- _ O
models -X- _ O
in -X- _ O
their -X- _ O
ability -X- _ O
to -X- _ O
predict -X- _ O
offensiveness -X- _ O
scores -X- _ O
on -X- _ O
this -X- _ O
new -X- _ O
dataset -X- _ O
. -X- _ O
1 -X- _ O
2 -X- _ O
Related -X- _ O
Work -X- _ O
Surveys -X- _ O
by -X- _ O
Schmidt -X- _ O
and -X- _ O
Wiegand -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
; -X- _ O
Fortuna -X- _ O
and -X- _ O
Nunes -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
; -X- _ O
Mishra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Vidgen -X- _ O
and -X- _ O
Derczynski -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
discuss -X- _ O
various -X- _ O
existing -X- _ O
datasets -X- _ O
and -X- _ O
their -X- _ O
compositions -X- _ O
in -X- _ O
detail -X- _ O
. -X- _ O
Waseem -X- _ O
and -X- _ O
Hovy -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
; -X- _ O
Founta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
created -X- _ O
datasets -X- _ O
based -X- _ O
on -X- _ O
Twitter -X- _ O
data -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
prevalence -X- _ O
of -X- _ O
the -X- _ O
non -X- _ O
- -X- _ O
offensive -X- _ O
class -X- _ O
in -X- _ O
naturallyoccurring -X- _ O
data -X- _ O
( -X- _ O
Waseem -X- _ O
, -X- _ O
2016;Founta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
authors -X- _ O
devised -X- _ O
techniques -X- _ O
to -X- _ O
boost -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
the -X- _ O
offensive -X- _ O
class -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
. -X- _ O
Waseem -X- _ O
and -X- _ O
Hovy -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
used -X- _ O
terms -X- _ O
frequently -X- _ O
occurring -X- _ O
in -X- _ O
offensive -X- _ O
tweets -X- _ O
, -X- _ O
while -X- _ O
used -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
hate -X- _ O
- -X- _ O
related -X- _ O
terms -X- _ O
to -X- _ O
extract -X- _ O
offensive -X- _ O
tweets -X- _ O
from -X- _ O
the -X- _ O
Twitter -X- _ O
search -X- _ O
API -X- _ O
. -X- _ O
Park -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Davidson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
Waseem -X- _ O
and -X- _ O
Hovy -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
dataset -X- _ O
exhibits -X- _ O
topic -X- _ O
bias -X- _ O
and -X- _ O
author -X- _ O
bias -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
employed -X- _ O
sampling -X- _ O
strategy -X- _ O
. -X- _ O
Founta -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
boosted -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
offensive -X- _ O
class -X- _ O
in -X- _ O
their -X- _ O
dataset -X- _ O
by -X- _ O
analysing -X- _ O
the -X- _ O
sentiment -X- _ O
of -X- _ O
the -X- _ O
tweets -X- _ O
and -X- _ O
checking -X- _ O
for -X- _ O
the -X- _ O
presence -X- _ O
of -X- _ O
offensive -X- _ O
terms -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
employ -X- _ O
a -X- _ O
hybrid -X- _ O
approach -X- _ O
, -X- _ O
selecting -X- _ O
our -X- _ O
data -X- _ O
in -X- _ O
three -X- _ O
ways -X- _ O
: -X- _ O
specific -X- _ O
topics -X- _ O
, -X- _ O
emotion -X- _ O
- -X- _ O
related -X- _ O
key -X- _ O
- -X- _ O
words -X- _ O
, -X- _ O
and -X- _ O
random -X- _ O
sampling -X- _ O
. -X- _ O
Past -X- _ O
work -X- _ O
has -X- _ O
partitioned -X- _ O
offensive -X- _ O
comments -X- _ O
into -X- _ O
explicitly -X- _ O
offensive -X- _ O
( -X- _ O
those -X- _ O
that -X- _ O
include -X- _ O
profanity -X- _ O
- -X- _ O
swear -X- _ O
words -X- _ O
, -X- _ O
taboo -X- _ O
words -X- _ O
, -X- _ O
or -X- _ O
hate -X- _ O
terms -X- _ O
) -X- _ O
and -X- _ O
implicitly -X- _ O
offensive -X- _ O
( -X- _ O
those -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
include -X- _ O
profanity -X- _ O
) -X- _ O
( -X- _ O
Waseem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017;Caselli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a;Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
. -X- _ O
Some -X- _ O
other -X- _ O
past -X- _ O
work -X- _ O
has -X- _ O
defined -X- _ O
explicitly -X- _ O
and -X- _ O
implicitly -X- _ O
offensive -X- _ O
instances -X- _ O
a -X- _ O
little -X- _ O
differently -X- _ O
: -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
considered -X- _ O
factors -X- _ O
such -X- _ O
as -X- _ O
obviousness -X- _ O
, -X- _ O
intent -X- _ O
to -X- _ O
offend -X- _ O
and -X- _ O
biased -X- _ O
implications -X- _ O
, -X- _ O
Breitfeller -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
considered -X- _ O
factors -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
context -X- _ O
and -X- _ O
the -X- _ O
person -X- _ O
annotating -X- _ O
the -X- _ O
instance -X- _ O
, -X- _ O
and -X- _ O
Razo -X- _ O
and -X- _ O
Kübler -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
considered -X- _ O
the -X- _ O
kind -X- _ O
of -X- _ O
lexicon -X- _ O
used -X- _ O
. -X- _ O
Regardless -X- _ O
of -X- _ O
the -X- _ O
exact -X- _ O
definition -X- _ O
, -X- _ O
implicit -X- _ O
offensive -X- _ O
language -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
a -X- _ O
lack -X- _ O
of -X- _ O
lexical -X- _ O
cues -X- _ O
, -X- _ O
is -X- _ O
harder -X- _ O
to -X- _ O
classify -X- _ O
not -X- _ O
only -X- _ O
for -X- _ O
computational -X- _ O
models -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
for -X- _ O
humans -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
implicitly -X- _ O
offensive -X- _ O
comments -X- _ O
as -X- _ O
those -X- _ O
offensive -X- _ O
comments -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
contain -X- _ O
any -X- _ O
swear -X- _ O
words -X- _ O
. -X- _ O
Wulczyn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016Wulczyn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
, -X- _ O
2017 -X- _ O
created -X- _ O
three -X- _ O
different -X- _ O
datasets -X- _ O
from -X- _ O
Wikipedia -X- _ O
Talk -X- _ O
pages -X- _ O
, -X- _ O
focusing -X- _ O
on -X- _ O
aggression -X- _ O
, -X- _ O
personal -X- _ O
attacks -X- _ O
and -X- _ O
toxicity -X- _ O
. -X- _ O
The -X- _ O
comments -X- _ O
were -X- _ O
sampled -X- _ O
at -X- _ O
random -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
dump -X- _ O
of -X- _ O
English -X- _ O
Wikipedia -X- _ O
, -X- _ O
and -X- _ O
boosted -X- _ O
by -X- _ O
including -X- _ O
comments -X- _ O
from -X- _ O
blocked -X- _ O
users -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
personal -X- _ O
attacks -X- _ O
dataset -X- _ O
, -X- _ O
Wulczyn -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
used -X- _ O
two -X- _ O
different -X- _ O
kinds -X- _ O
of -X- _ O
labels -X- _ O
: -X- _ O
ED -X- _ O
( -X- _ O
empirical -X- _ O
distribution -X- _ O
) -X- _ O
, -X- _ O
OH -X- _ O
( -X- _ O
one -X- _ O
hot -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
case -X- _ O
of -X- _ O
ED -X- _ O
, -X- _ O
the -X- _ O
comments -X- _ O
were -X- _ O
assigned -X- _ O
real -X- _ O
- -X- _ O
valued -X- _ O
scores -X- _ O
between -X- _ O
0 -X- _ O
and -X- _ O
1 -X- _ O
representing -X- _ O
the -X- _ O
fraction -X- _ O
of -X- _ O
annotators -X- _ O
who -X- _ O
considered -X- _ O
the -X- _ O
comment -X- _ O
a -X- _ O
personal -X- _ O
attack -X- _ O
. -X- _ O
While -X- _ O
these -X- _ O
labels -X- _ O
were -X- _ O
introduced -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
separation -X- _ O
between -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
comments -X- _ O
with -X- _ O
a -X- _ O
score -X- _ O
of -X- _ O
1.0 -X- _ O
and -X- _ O
those -X- _ O
with -X- _ O
a -X- _ O
score -X- _ O
of -X- _ O
0.6 -X- _ O
( -X- _ O
which -X- _ O
would -X- _ O
otherwise -X- _ O
be -X- _ O
classified -X- _ O
as -X- _ O
attacks -X- _ O
) -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
discrete -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
work -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
BWS -X- _ B-MethodName
comparative -X- _ O
annotation -X- _ O
setup -X- _ O
, -X- _ O
we -X- _ O
assign -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
continuous -X- _ O
scores -X- _ O
to -X- _ O
comments -X- _ O
to -X- _ O
denote -X- _ O
their -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
. -X- _ O
BWS -X- _ B-MethodName
was -X- _ O
proposed -X- _ O
by -X- _ O
Louviere -X- _ O
( -X- _ O
1991 -X- _ O
) -X- _ O
. -X- _ O
Kiritchenko -X- _ O
and -X- _ O
Mohammad -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
have -X- _ O
experimentally -X- _ O
shown -X- _ O
that -X- _ O
BWS -X- _ B-MethodName
produces -X- _ O
more -X- _ O
reliable -X- _ O
finegrained -X- _ O
scores -X- _ O
than -X- _ O
the -X- _ O
scores -X- _ O
acquired -X- _ O
utilizing -X- _ O
rating -X- _ O
scales -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
BWS -X- _ B-MethodName
annotation -X- _ O
setup -X- _ O
, -X- _ O
the -X- _ O
annotators -X- _ O
are -X- _ O
given -X- _ O
an -X- _ O
n -X- _ O
- -X- _ O
tuple -X- _ O
( -X- _ O
where -X- _ O
n -X- _ O
> -X- _ O
1 -X- _ O
, -X- _ O
and -X- _ O
commonly -X- _ O
n -X- _ O
= -X- _ O
4 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
asked -X- _ O
which -X- _ O
item -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
and -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
worst -X- _ O
( -X- _ O
best -X- _ O
and -X- _ O
worst -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
highest -X- _ O
and -X- _ O
the -X- _ O
lowest -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
a -X- _ O
property -X- _ O
of -X- _ O
interest -X- _ O
) -X- _ O
. -X- _ O
Best -X- _ O
- -X- _ O
worst -X- _ O
annotations -X- _ O
are -X- _ O
particularly -X- _ O
efficient -X- _ O
when -X- _ O
using -X- _ O
4 -X- _ O
- -X- _ O
tuples -X- _ O
, -X- _ O
as -X- _ O
each -X- _ O
annotation -X- _ O
results -X- _ O
in -X- _ O
inequalities -X- _ O
for -X- _ O
5 -X- _ O
of -X- _ O
the -X- _ O
6 -X- _ O
item -X- _ O
pairs -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
a -X- _ O
4 -X- _ O
- -X- _ O
tuple -X- _ O
with -X- _ O
items -X- _ O
A -X- _ O
, -X- _ O
B -X- _ O
, -X- _ O
C -X- _ O
, -X- _ O
and -X- _ O
D -X- _ O
, -X- _ O
where -X- _ O
A -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
, -X- _ O
and -X- _ O
D -X- _ O
is -X- _ O
the -X- _ O
worst -X- _ O
, -X- _ O
results -X- _ O
in -X- _ O
inequalities -X- _ O
: -X- _ O
A -X- _ O
> -X- _ O
B -X- _ O
, -X- _ O
A -X- _ O
> -X- _ O
C -X- _ O
, -X- _ O
A -X- _ O
> -X- _ O
D -X- _ O
, -X- _ O
B -X- _ O
> -X- _ O
D -X- _ O
, -X- _ O
and -X- _ O
C -X- _ O
> -X- _ O
D. -X- _ O
Real -X- _ O
- -X- _ O
valued -X- _ O
scores -X- _ O
of -X- _ O
associations -X- _ O
are -X- _ O
calculated -X- _ O
between -X- _ O
the -X- _ O
items -X- _ O
and -X- _ O
the -X- _ O
property -X- _ O
of -X- _ O
interest -X- _ O
from -X- _ O
the -X- _ O
best -X- _ O
- -X- _ O
worst -X- _ O
annotations -X- _ O
for -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
4 -X- _ O
- -X- _ O
tuples -X- _ O
( -X- _ O
Orme -X- _ O
, -X- _ O
2009;Flynn -X- _ O
and -X- _ O
Marley -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
scores -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
rank -X- _ O
items -X- _ O
by -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
association -X- _ O
with -X- _ O
the -X- _ O
property -X- _ O
of -X- _ O
interest -X- _ O
. -X- _ O
Within -X- _ O
the -X- _ O
NLP -X- _ O
community -X- _ O
, -X- _ O
BWS -X- _ B-MethodName
has -X- _ O
thus -X- _ O
far -X- _ O
been -X- _ O
used -X- _ O
only -X- _ O
for -X- _ O
creating -X- _ O
datasets -X- _ O
for -X- _ O
relational -X- _ O
similarity -X- _ O
( -X- _ O
Jurgens -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
) -X- _ O
, -X- _ O
word -X- _ O
- -X- _ O
sense -X- _ O
disambiguation -X- _ O
( -X- _ O
Jurgens -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
word -X- _ O
- -X- _ O
sentiment -X- _ O
intensity -X- _ O
( -X- _ O
Kiritchenko -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
, -X- _ O
phrase -X- _ O
sentiment -X- _ O
composition -X- _ O
( -X- _ O
Kiritchenko -X- _ O
and -X- _ O
Mohammad -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
tweet -X- _ O
- -X- _ O
emotion -X- _ O
intensity -X- _ O
( -X- _ O
Mohammad -X- _ O
and -X- _ O
Bravo -X- _ O
- -X- _ O
Marquez -X- _ O
, -X- _ O
2017;Mohammad -X- _ O
and -X- _ O
Kiritchenko -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Using -X- _ O
BWS -X- _ B-MethodName
, -X- _ O
we -X- _ O
create -X- _ O
the -X- _ O
first -X- _ O
dataset -X- _ O
with -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
scores -X- _ O
for -X- _ O
social -X- _ O
media -X- _ O
comments -X- _ O
. -X- _ O
We -X- _ O
extracted -X- _ O
Reddit -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
Pushshift -X- _ O
repository -X- _ O
( -X- _ O
Baumgartner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
using -X- _ O
Google -X- _ O
BigQuery -X- _ O
. -X- _ O
Reddit -X- _ O
is -X- _ O
a -X- _ O
social -X- _ O
news -X- _ O
aggregation -X- _ O
, -X- _ O
web -X- _ O
content -X- _ O
rating -X- _ O
, -X- _ O
and -X- _ O
discussion -X- _ O
website -X- _ O
. -X- _ O
It -X- _ O
contains -X- _ O
forums -X- _ O
called -X- _ O
subreddits -X- _ O
dedicated -X- _ O
to -X- _ O
specific -X- _ O
topics -X- _ O
. -X- _ O
Users -X- _ O
can -X- _ O
make -X- _ O
a -X- _ O
post -X- _ O
on -X- _ O
the -X- _ O
subreddit -X- _ O
to -X- _ O
start -X- _ O
a -X- _ O
discussion -X- _ O
. -X- _ O
Users -X- _ O
can -X- _ O
comment -X- _ O
on -X- _ O
existing -X- _ O
posts -X- _ O
or -X- _ O
comments -X- _ O
to -X- _ O
participate -X- _ O
in -X- _ O
the -X- _ O
discussion -X- _ O
. -X- _ O
As -X- _ O
users -X- _ O
can -X- _ O
also -X- _ O
reply -X- _ O
to -X- _ O
a -X- _ O
comment -X- _ O
, -X- _ O
the -X- _ O
entire -X- _ O
discussion -X- _ O
has -X- _ O
a -X- _ O
hierarchical -X- _ O
structure -X- _ O
called -X- _ O
the -X- _ O
comment -X- _ O
thread -X- _ O
. -X- _ O
We -X- _ O
divided -X- _ O
the -X- _ O
extracted -X- _ O
comments -X- _ O
into -X- _ O
3 -X- _ O
categories -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
subreddit -X- _ O
source -X- _ O
: -X- _ O
1 -X- _ O
. -X- _ O
Topics -X- _ O
( -X- _ O
50 -X- _ O
% -X- _ O
): -X- _ O
Contains -X- _ O
comments -X- _ O
from -X- _ O
topic -X- _ O
- -X- _ O
focused -X- _ O
subreddits -X- _ O
: -X- _ O
AskMen -X- _ O
, -X- _ O
AskReddit -X- _ O
, -X- _ O
TwoXChromosomes -X- _ O
, -X- _ O
vaxxhappened -X- _ O
, -X- _ O
worldnews -X- _ O
, -X- _ O
worldpolitics -X- _ O
. -X- _ O
These -X- _ O
subreddits -X- _ O
were -X- _ O
chosen -X- _ O
to -X- _ O
cover -X- _ O
a -X- _ O
diverse -X- _ O
range -X- _ O
of -X- _ O
topics -X- _ O
. -X- _ O
AskReddit -X- _ O
, -X- _ O
vaxxhappened -X- _ O
, -X- _ O
worldnews -X- _ O
, -X- _ O
worldpolitics -X- _ O
discuss -X- _ O
generic -X- _ O
themes -X- _ O
. -X- _ O
TwoXChromosomes -X- _ O
contains -X- _ O
women -X- _ O
's -X- _ O
perspectives -X- _ O
on -X- _ O
various -X- _ O
topics -X- _ O
and -X- _ O
AskMen -X- _ O
contains -X- _ O
men -X- _ O
's -X- _ O
perspectives -X- _ O
. -X- _ O
The -X- _ O
CMV -X- _ O
subreddit -X- _ O
( -X- _ O
with -X- _ O
over -X- _ O
a -X- _ O
million -X- _ O
users -X- _ O
) -X- _ O
has -X- _ O
posts -X- _ O
and -X- _ O
comments -X- _ O
on -X- _ O
controversial -X- _ O
topics.3 -X- _ O
. -X- _ O
Random -X- _ O
( -X- _ O
25 -X- _ O
% -X- _ O
): -X- _ O
Contains -X- _ O
comments -X- _ O
from -X- _ O
random -X- _ O
subreddits -X- _ O
. -X- _ O
We -X- _ O
selected -X- _ O
808 -X- _ O
posts -X- _ O
from -X- _ O
the -X- _ O
subreddits -X- _ O
based -X- _ O
on -X- _ O
criteria -X- _ O
such -X- _ O
as -X- _ O
date -X- _ O
, -X- _ O
thread -X- _ O
length -X- _ O
, -X- _ O
and -X- _ O
post -X- _ O
length -X- _ O
. -X- _ O
( -X- _ O
Further -X- _ O
details -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
A.1 -X- _ O
. -X- _ O
) -X- _ O
We -X- _ O
took -X- _ O
the -X- _ O
first -X- _ O
25 -X- _ O
and -X- _ O
the -X- _ O
last -X- _ O
25 -X- _ O
comments -X- _ O
per -X- _ O
post -X- _ O
( -X- _ O
skipping -X- _ O
comments -X- _ O
that -X- _ O
had -X- _ O
[ -X- _ O
DELETED -X- _ O
] -X- _ O
or -X- _ O
[ -X- _ O
REMOVED -X- _ O
] -X- _ O
as -X- _ O
comment -X- _ O
body -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
responses -X- _ O
are -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
most -X- _ O
relevant -X- _ O
to -X- _ O
the -X- _ O
post -X- _ O
. -X- _ O
The -X- _ O
final -X- _ O
comments -X- _ O
indicate -X- _ O
how -X- _ O
the -X- _ O
discussion -X- _ O
ended -X- _ O
. -X- _ O
We -X- _ O
sampled -X- _ O
6000 -X- _ O
comments -X- _ O
from -X- _ O
this -X- _ O
set -X- _ O
for -X- _ O
annotation -X- _ O
. -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
the -X- _ O
sampling -X- _ O
was -X- _ O
to -X- _ O
increase -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
offensive -X- _ O
and -X- _ O
emotional -X- _ O
comments -X- _ O
. -X- _ O
Emotions -X- _ O
are -X- _ O
highly -X- _ O
representative -X- _ O
of -X- _ O
one -X- _ O
's -X- _ O
mental -X- _ O
state -X- _ O
, -X- _ O
which -X- _ O
in -X- _ O
turn -X- _ O
are -X- _ O
associated -X- _ O
with -X- _ O
their -X- _ O
behaviour -X- _ O
( -X- _ O
Poria -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
Jay -X- _ O
and -X- _ O
Janschewitz -X- _ O
( -X- _ O
2008 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
people -X- _ O
tend -X- _ O
to -X- _ O
swear -X- _ O
when -X- _ O
they -X- _ O
are -X- _ O
angry -X- _ O
, -X- _ O
frustrated -X- _ O
or -X- _ O
anxious -X- _ O
. -X- _ O
Studies -X- _ O
have -X- _ O
shown -X- _ O
that -X- _ O
the -X- _ O
primary -X- _ O
dimensions -X- _ O
of -X- _ O
emotion -X- _ O
are -X- _ O
valence -X- _ O
, -X- _ O
arousal -X- _ O
, -X- _ O
and -X- _ O
dominance -X- _ O
( -X- _ O
VAD -X- _ O
) -X- _ O
( -X- _ O
Osgood -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1957;Russell -X- _ O
, -X- _ O
1980Russell -X- _ O
, -X- _ O
, -X- _ O
2003.Valence -X- _ O
is -X- _ O
the -X- _ O
positive -X- _ O
-negative -X- _ O
or -X- _ O
pleasuredispleasure -X- _ O
dimension -X- _ O
. -X- _ O
Arousal -X- _ O
is -X- _ O
the -X- _ O
excitedcalm -X- _ O
or -X- _ O
active -X- _ O
- -X- _ O
passive -X- _ O
dimension -X- _ O
. -X- _ O
Dominance -X- _ O
is -X- _ O
powerful -X- _ O
- -X- _ O
weak -X- _ O
or -X- _ O
' -X- _ O
have -X- _ O
full -X- _ O
control'-'have -X- _ O
no -X- _ O
control -X- _ O
' -X- _ O
dimension -X- _ O
( -X- _ O
Mohammad -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
boost -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
offensive -X- _ O
and -X- _ O
emotional -X- _ O
comments -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
up -X- _ O
- -X- _ O
sampled -X- _ O
comments -X- _ O
that -X- _ O
included -X- _ O
low -X- _ O
- -X- _ O
valence -X- _ O
( -X- _ O
highly -X- _ O
negative -X- _ O
) -X- _ O
words -X- _ O
and -X- _ O
those -X- _ O
that -X- _ O
included -X- _ O
high -X- _ O
- -X- _ O
arousal -X- _ O
words -X- _ O
( -X- _ O
as -X- _ O
per -X- _ O
the -X- _ O
NRC -X- _ O
VAD -X- _ O
lexicon -X- _ O
( -X- _ O
Mohammad -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
2 -X- _ O
The -X- _ O
manually -X- _ O
constructed -X- _ O
NRC -X- _ O
VAD -X- _ O
lexicon -X- _ O
includes -X- _ O
20,000 -X- _ O
English -X- _ O
words -X- _ O
, -X- _ O
each -X- _ O
with -X- _ O
a -X- _ O
real -X- _ O
- -X- _ O
valued -X- _ O
score -X- _ O
between -X- _ O
0 -X- _ O
and -X- _ O
1 -X- _ O
in -X- _ O
the -X- _ O
V -X- _ O
, -X- _ O
A -X- _ O
, -X- _ O
D -X- _ O
dimensions -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
do -X- _ O
this -X- _ O
upsampling -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
defined -X- _ O
the -X- _ O
valence -X- _ O
score -X- _ O
of -X- _ O
each -X- _ O
comment -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
valence -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
negative -X- _ O
words -X- _ O
within -X- _ O
the -X- _ O
comment -X- _ O
( -X- _ O
A -X- _ O
negative -X- _ O
word -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
a -X- _ O
word -X- _ O
with -X- _ O
a -X- _ O
valence -X- _ O
score -X- _ O
≤ -X- _ O
0.25 -X- _ O
in -X- _ O
the -X- _ O
VAD -X- _ O
lexicon -X- _ O
. -X- _ O
) -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
defined -X- _ O
the -X- _ O
arousal -X- _ O
score -X- _ O
for -X- _ O
a -X- _ O
comment -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
arousal -X- _ O
score -X- _ O
of -X- _ O
high -X- _ O
- -X- _ O
arousal -X- _ O
words -X- _ O
in -X- _ O
each -X- _ O
comment -X- _ O
. -X- _ O
( -X- _ O
A -X- _ O
high -X- _ O
- -X- _ O
arousal -X- _ O
word -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
a -X- _ O
word -X- _ O
with -X- _ O
an -X- _ O
arousal -X- _ O
score -X- _ O
≥ -X- _ O
0.75.)We -X- _ O
selected -X- _ O
comments -X- _ O
from -X- _ O
the -X- _ O
comment -X- _ O
pool -X- _ O
such -X- _ O
that -X- _ O
50 -X- _ O
% -X- _ O
were -X- _ O
from -X- _ O
the -X- _ O
Topics -X- _ O
category -X- _ O
, -X- _ O
25 -X- _ O
% -X- _ O
from -X- _ O
the -X- _ O
CMV -X- _ O
category -X- _ O
, -X- _ O
and -X- _ O
25 -X- _ O
% -X- _ O
from -X- _ O
the -X- _ O
Random -X- _ O
category -X- _ O
. -X- _ O
Within -X- _ O
each -X- _ O
category -X- _ O
, -X- _ O
33 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
comments -X- _ O
were -X- _ O
those -X- _ O
that -X- _ O
had -X- _ O
the -X- _ O
lowest -X- _ O
valence -X- _ O
scores -X- _ O
, -X- _ O
33 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
comments -X- _ O
were -X- _ O
those -X- _ O
that -X- _ O
had -X- _ O
the -X- _ O
highest -X- _ O
arousal -X- _ O
scores -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
remaining -X- _ O
were -X- _ O
chosen -X- _ O
at -X- _ O
random -X- _ O
. -X- _ O
The -X- _ O
perception -X- _ O
of -X- _ O
' -X- _ O
offensiveness -X- _ O
' -X- _ O
of -X- _ O
a -X- _ O
comment -X- _ O
can -X- _ O
vary -X- _ O
from -X- _ O
person -X- _ O
to -X- _ O
person -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
crowdsourcing -X- _ O
to -X- _ O
annotate -X- _ O
our -X- _ O
data -X- _ O
. -X- _ O
Crowdsourcing -X- _ O
helps -X- _ O
us -X- _ O
get -X- _ O
an -X- _ O
aggregation -X- _ O
of -X- _ O
varied -X- _ O
perspectives -X- _ O
rather -X- _ O
than -X- _ O
expert -X- _ O
opinions -X- _ O
which -X- _ O
can -X- _ O
leave -X- _ O
out -X- _ O
offensiveness -X- _ O
in -X- _ O
a -X- _ O
comment -X- _ O
that -X- _ O
lies -X- _ O
outside -X- _ O
the -X- _ O
' -X- _ O
typical -X- _ O
' -X- _ O
offensiveness -X- _ O
norms -X- _ O
( -X- _ O
Blackwell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
carried -X- _ O
out -X- _ O
all -X- _ O
the -X- _ O
annotation -X- _ O
tasks -X- _ O
on -X- _ O
Amazon -X- _ O
Mechanical -X- _ O
Turk -X- _ O
( -X- _ O
AMT -X- _ O
) -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
strong -X- _ O
language -X- _ O
, -X- _ O
an -X- _ O
adult -X- _ O
content -X- _ O
warning -X- _ O
was -X- _ O
issued -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
Reddit -X- _ O
is -X- _ O
most -X- _ O
popular -X- _ O
in -X- _ O
the -X- _ O
US -X- _ O
, -X- _ O
which -X- _ O
accounts -X- _ O
for -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
its -X- _ O
desktop -X- _ O
traffic -X- _ O
( -X- _ O
Statista -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
restricted -X- _ O
annotators -X- _ O
to -X- _ O
those -X- _ O
residing -X- _ O
in -X- _ O
the -X- _ O
US -X- _ O
. -X- _ O
To -X- _ O
maintain -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
annotations -X- _ O
, -X- _ O
only -X- _ O
annotators -X- _ O
with -X- _ O
high -X- _ O
approval -X- _ O
rate -X- _ O
were -X- _ O
allowed -X- _ O
to -X- _ O
participate -X- _ O
. -X- _ O
We -X- _ O
followed -X- _ O
the -X- _ O
procedure -X- _ O
described -X- _ O
in -X- _ O
Kiritchenko -X- _ O
and -X- _ O
Mohammad -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
BWS -X- _ B-MethodName
annotations -X- _ O
. -X- _ O
Annotators -X- _ O
were -X- _ O
presented -X- _ O
with -X- _ O
4 -X- _ O
comments -X- _ O
( -X- _ O
4 -X- _ O
- -X- _ O
tuple -X- _ O
) -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
and -X- _ O
asked -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
comment -X- _ O
that -X- _ O
is -X- _ O
most -X- _ O
offensive -X- _ O
( -X- _ O
least -X- _ O
supportive -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
comment -X- _ O
that -X- _ O
is -X- _ O
least -X- _ O
offensive -X- _ O
( -X- _ O
most -X- _ O
supportive -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
randomly -X- _ O
generated -X- _ O
2N -X- _ O
distinct -X- _ O
4 -X- _ O
- -X- _ O
tuples -X- _ O
( -X- _ O
where -X- _ O
N -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
comments -X- _ O
in -X- _ O
the -X- _ O
dataset -X- _ O
) -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
each -X- _ O
comment -X- _ O
was -X- _ O
seen -X- _ O
in -X- _ O
eight -X- _ O
different -X- _ O
4 -X- _ O
- -X- _ O
tuples -X- _ O
and -X- _ O
no -X- _ O
two -X- _ O
4 -X- _ O
- -X- _ O
tuples -X- _ O
had -X- _ O
more -X- _ O
than -X- _ O
2 -X- _ O
items -X- _ O
in -X- _ O
common -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
script -X- _ O
provided -X- _ O
by -X- _ O
Kiritchenko -X- _ O
and -X- _ O
Mohammad -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
4 -X- _ O
- -X- _ O
tuples -X- _ O
to -X- _ O
be -X- _ O
annotated -X- _ O
. -X- _ O
3 -X- _ O
Kiritchenko -X- _ O
and -X- _ O
Mohammad -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
in -X- _ O
a -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
sentiment -X- _ O
task -X- _ O
, -X- _ O
using -X- _ O
just -X- _ O
three -X- _ O
annotations -X- _ O
per -X- _ O
4 -X- _ O
- -X- _ O
tuple -X- _ O
produces -X- _ O
highly -X- _ O
reliable -X- _ O
results -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
since -X- _ O
we -X- _ O
work -X- _ O
with -X- _ O
long -X- _ O
comments -X- _ O
and -X- _ O
a -X- _ O
relatively -X- _ O
more -X- _ O
difficult -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
got -X- _ O
each -X- _ O
tuple -X- _ O
annotated -X- _ O
by -X- _ O
6 -X- _ O
annotators -X- _ O
. -X- _ O
Since -X- _ O
each -X- _ O
comment -X- _ O
is -X- _ O
seen -X- _ O
in -X- _ O
8 -X- _ O
different -X- _ O
4 -X- _ O
- -X- _ O
tuples -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
8 -X- _ O
X -X- _ O
6 -X- _ O
= -X- _ O
48 -X- _ O
judgements -X- _ O
per -X- _ O
comment -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
instructions -X- _ O
to -X- _ O
the -X- _ O
annotators -X- _ O
, -X- _ O
we -X- _ O
defined -X- _ O
offensive -X- _ O
language -X- _ O
as -X- _ O
comments -X- _ O
that -X- _ O
include -X- _ O
but -X- _ O
are -X- _ O
not -X- _ O
limited -X- _ O
to -X- _ O
[ -X- _ O
being -X- _ O
hurtful -X- _ O
( -X- _ O
with -X- _ O
or -X- _ O
without -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
abusive -X- _ O
words)/ -X- _ O
being -X- _ O
intentionally -X- _ O
harmful/ -X- _ O
treating -X- _ O
someone -X- _ O
improperly/ -X- _ O
harming -X- _ O
the -X- _ O
' -X- _ O
self -X- _ O
- -X- _ O
concept -X- _ O
' -X- _ O
of -X- _ O
another -X- _ O
person/ -X- _ O
aggressive -X- _ O
outbursts/ -X- _ O
name -X- _ O
calling/ -X- _ O
showing -X- _ O
anger -X- _ O
and -X- _ O
hostility/ -X- _ O
bullying/ -X- _ O
hurtful -X- _ O
sarcasm -X- _ O
] -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
encouraged -X- _ O
the -X- _ O
annotators -X- _ O
to -X- _ O
follow -X- _ O
their -X- _ O
instincts -X- _ O
. -X- _ O
By -X- _ O
framing -X- _ O
the -X- _ O
task -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
comparisons -X- _ O
and -X- _ O
providing -X- _ O
a -X- _ O
broad -X- _ O
definition -X- _ O
of -X- _ O
offensiveness -X- _ O
, -X- _ O
we -X- _ O
avoided -X- _ O
introducing -X- _ O
artificial -X- _ O
categories -X- _ O
and -X- _ O
elicit -X- _ O
responses -X- _ O
guided -X- _ O
by -X- _ O
their -X- _ O
intuition -X- _ O
of -X- _ O
the -X- _ O
language -X- _ O
. -X- _ O
Detailed -X- _ O
annotation -X- _ O
instructions -X- _ O
are -X- _ O
made -X- _ O
publicly -X- _ O
available -X- _ O
( -X- _ O
Figure -X- _ O
5 -X- _ O
in -X- _ O
Appendix -X- _ O
A.2 -X- _ O
) -X- _ O
. -X- _ O
4 -X- _ O
A -X- _ O
sample -X- _ O
questionnaire -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
6 -X- _ O
in -X- _ O
Appendix -X- _ O
A.2 -X- _ O
. -X- _ O
For -X- _ O
quality -X- _ O
control -X- _ O
purposes -X- _ O
, -X- _ O
we -X- _ O
manually -X- _ O
annotated -X- _ O
around -X- _ O
5 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
ourselves -X- _ O
beforehand -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
refer -X- _ O
to -X- _ O
these -X- _ O
instances -X- _ O
as -X- _ O
gold -X- _ O
questions -X- _ O
. -X- _ O
The -X- _ O
gold -X- _ O
questions -X- _ O
were -X- _ O
interspersed -X- _ O
with -X- _ O
the -X- _ O
other -X- _ O
questions -X- _ O
. -X- _ O
If -X- _ O
a -X- _ O
worker -X- _ O
's -X- _ O
accuracy -X- _ O
on -X- _ O
the -X- _ O
gold -X- _ O
questions -X- _ O
fell -X- _ O
below -X- _ O
70 -X- _ O
% -X- _ O
, -X- _ O
they -X- _ O
were -X- _ O
refused -X- _ O
further -X- _ O
annotation -X- _ O
and -X- _ O
all -X- _ O
of -X- _ O
their -X- _ O
annotations -X- _ O
were -X- _ O
discarded -X- _ O
. -X- _ O
The -X- _ O
discarded -X- _ O
annotations -X- _ O
were -X- _ O
published -X- _ O
again -X- _ O
for -X- _ O
re -X- _ O
- -X- _ O
annotation -X- _ O
. -X- _ O
We -X- _ O
received -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
95,255 -X- _ O
annotations -X- _ O
by -X- _ O
725 -X- _ O
crowd -X- _ O
workers -X- _ O
. -X- _ O
The -X- _ O
BWS -X- _ B-MethodName
responses -X- _ O
were -X- _ O
converted -X- _ O
to -X- _ O
scores -X- _ O
using -X- _ O
a -X- _ O
simple -X- _ O
counting -X- _ O
procedure -X- _ O
( -X- _ O
Orme -X- _ O
, -X- _ O
2009;Flynn -X- _ O
and -X- _ O
Marley -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
item -X- _ O
, -X- _ O
the -X- _ O
score -X- _ O
is -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
times -X- _ O
the -X- _ O
item -X- _ O
is -X- _ O
chosen -X- _ O
as -X- _ O
the -X- _ O
most -X- _ O
offensive -X- _ O
minus -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
times -X- _ O
the -X- _ O
item -X- _ O
is -X- _ O
chosen -X- _ O
as -X- _ O
the -X- _ O
least -X- _ O
offensive -X- _ O
. -X- _ O
We -X- _ O
release -X- _ O
the -X- _ O
aggregated -X- _ O
annotations -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
individual -X- _ O
annotations -X- _ O
of -X- _ O
Ruddit -X- _ B-DatasetName
, -X- _ O
to -X- _ O
allow -X- _ O
further -X- _ O
work -X- _ O
on -X- _ O
examining -X- _ O
and -X- _ O
understanding -X- _ O
the -X- _ O
variability -X- _ O
. -X- _ O
5 -X- _ O
We -X- _ O
can -X- _ O
not -X- _ O
use -X- _ O
standard -X- _ O
inter -X- _ O
- -X- _ O
annotator -X- _ O
agreement -X- _ O
measures -X- _ O
to -X- _ O
ascertain -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
comparative -X- _ O
annotations -X- _ O
. -X- _ O
The -X- _ O
disagreement -X- _ O
that -X- _ O
arises -X- _ O
in -X- _ O
tuples -X- _ O
having -X- _ O
two -X- _ O
items -X- _ O
that -X- _ O
are -X- _ O
close -X- _ O
together -X- _ O
in -X- _ O
their -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
is -X- _ O
a -X- _ O
useful -X- _ O
signal -X- _ O
for -X- _ O
BWS -X- _ B-MethodName
( -X- _ O
helping -X- _ O
it -X- _ O
give -X- _ O
similar -X- _ O
scores -X- _ O
to -X- _ O
the -X- _ O
two -X- _ O
items -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
quality -X- _ O
of -X- _ O
annotations -X- _ O
can -X- _ O
be -X- _ O
measured -X- _ O
by -X- _ O
measuring -X- _ O
the -X- _ O
reproducibility -X- _ O
of -X- _ O
the -X- _ O
end -X- _ O
resultif -X- _ O
repeated -X- _ O
manual -X- _ O
annotations -X- _ O
from -X- _ O
multiple -X- _ O
annotators -X- _ O
can -X- _ O
produce -X- _ O
similar -X- _ O
rankings -X- _ O
and -X- _ O
scores -X- _ O
, -X- _ O
then -X- _ O
, -X- _ O
one -X- _ O
can -X- _ O
be -X- _ O
confident -X- _ O
about -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
annotations -X- _ O
received -X- _ O
. -X- _ O
To -X- _ O
assess -X- _ O
this -X- _ O
reproducibility -X- _ O
, -X- _ O
we -X- _ O
computed -X- _ O
average -X- _ O
split -X- _ B-MetricName
- -X- _ I-MetricName
half -X- _ I-MetricName
reliability -X- _ I-MetricName
( -X- _ I-MetricName
SHR -X- _ I-MetricName
) -X- _ I-MetricName
values -X- _ O
over -X- _ O
100 -X- _ O
trials -X- _ O
. -X- _ O
SHR -X- _ B-MetricName
is -X- _ O
a -X- _ O
commonly -X- _ O
used -X- _ O
approach -X- _ O
to -X- _ O
determine -X- _ O
consistency -X- _ O
in -X- _ O
psychological -X- _ O
studies -X- _ O
. -X- _ O
For -X- _ O
computing -X- _ O
SHR -X- _ B-MetricName
values -X- _ O
, -X- _ O
the -X- _ O
annotations -X- _ O
for -X- _ O
each -X- _ O
4 -X- _ O
- -X- _ O
tuple -X- _ O
were -X- _ O
randomly -X- _ O
split -X- _ O
in -X- _ O
two -X- _ O
halves -X- _ O
. -X- _ O
Using -X- _ O
these -X- _ O
two -X- _ O
splits -X- _ O
, -X- _ O
two -X- _ O
sets -X- _ O
of -X- _ O
rankings -X- _ O
were -X- _ O
determined -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
calculated -X- _ O
the -X- _ O
correlation -X- _ O
values -X- _ O
between -X- _ O
these -X- _ O
two -X- _ O
sets -X- _ O
. -X- _ O
This -X- _ O
procedure -X- _ O
was -X- _ O
repeated -X- _ O
100 -X- _ O
times -X- _ O
and -X- _ O
the -X- _ O
correlations -X- _ O
were -X- _ O
averaged -X- _ O
. -X- _ O
A -X- _ O
high -X- _ O
correlation -X- _ O
value -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
annotations -X- _ O
are -X- _ O
of -X- _ O
good -X- _ O
quality -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
SHR -X- _ B-MetricName
for -X- _ O
our -X- _ O
annotations -X- _ O
. -X- _ O
SHR -X- _ B-MetricName
scores -X- _ O
of -X- _ O
over -X- _ O
0.8 -X- _ B-MetricValue
indicate -X- _ O
substantial -X- _ O
reliability -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
analyze -X- _ O
various -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
including -X- _ O
: -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
scores -X- _ O
, -X- _ O
the -X- _ O
as- -X- _ O
sociation -X- _ O
with -X- _ O
identity -X- _ O
terms -X- _ O
, -X- _ O
the -X- _ O
relationship -X- _ O
with -X- _ O
emotion -X- _ O
dimensions -X- _ O
, -X- _ O
the -X- _ O
relationship -X- _ O
with -X- _ O
data -X- _ O
source -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
role -X- _ O
of -X- _ O
swear -X- _ O
words -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
a -X- _ O
histogram -X- _ O
of -X- _ O
frequency -X- _ O
of -X- _ O
comments -X- _ O
vs. -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
, -X- _ O
over -X- _ O
40 -X- _ O
equi -X- _ O
- -X- _ O
spaced -X- _ O
score -X- _ O
bins -X- _ O
of -X- _ O
size -X- _ O
0.05 -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
a -X- _ O
normal -X- _ O
distribution -X- _ O
. -X- _ O
To -X- _ O
analyze -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
placed -X- _ O
the -X- _ O
comments -X- _ O
in -X- _ O
5 -X- _ O
equi -X- _ O
- -X- _ O
spaced -X- _ O
score -X- _ O
bins -X- _ O
of -X- _ O
size -X- _ O
0.4 -X- _ O
( -X- _ O
bin -X- _ O
1 -X- _ O
: -X- _ O
−1.0 -X- _ O
to -X- _ O
−0.6 -X- _ O
, -X- _ O
bin -X- _ O
2 -X- _ O
: -X- _ O
−0.6 -X- _ O
to -X- _ O
−0.2 -X- _ O
, -X- _ O
and -X- _ O
so -X- _ O
on -X- _ O
) -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
some -X- _ O
comments -X- _ O
from -X- _ O
the -X- _ O
dataset -X- _ O
( -X- _ O
more -X- _ O
examples -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.3 -X- _ O
Table -X- _ O
6 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
observed -X- _ O
that -X- _ O
bin -X- _ O
1 -X- _ O
primarily -X- _ O
contains -X- _ O
supportive -X- _ O
comments -X- _ O
while -X- _ O
bin -X- _ O
2 -X- _ O
shows -X- _ O
a -X- _ O
transition -X- _ O
from -X- _ O
supportive -X- _ O
to -X- _ O
neutral -X- _ O
comments -X- _ O
. -X- _ O
Bin -X- _ O
3 -X- _ O
is -X- _ O
dominated -X- _ O
by -X- _ O
neutral -X- _ O
comments -X- _ O
but -X- _ O
as -X- _ O
the -X- _ O
score -X- _ O
increases -X- _ O
the -X- _ O
comments -X- _ O
become -X- _ O
potentially -X- _ O
offensive -X- _ O
and -X- _ O
bins -X- _ O
4 -X- _ O
& -X- _ O
5 -X- _ O
predominantly -X- _ O
contain -X- _ O
offensive -X- _ O
comments -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
interesting -X- _ O
to -X- _ O
note -X- _ O
that -X- _ O
bin -X- _ O
4 -X- _ O
contains -X- _ O
some -X- _ O
instances -X- _ O
of -X- _ O
implicit -X- _ O
offensive -X- _ O
language -X- _ O
such -X- _ O
as -X- _ O
' -X- _ O
You -X- _ O
look -X- _ O
like -X- _ O
a -X- _ O
lesbian -X- _ O
mechanic -X- _ O
who -X- _ O
has -X- _ O
a -X- _ O
shell -X- _ O
collection -X- _ O
' -X- _ O
. -X- _ O
In -X- _ O
their -X- _ O
paper -X- _ O
, -X- _ O
Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2021 -X- _ O
) -X- _ O
explore -X- _ O
the -X- _ O
category -X- _ O
of -X- _ O
such -X- _ O
" -X- _ O
implicity -X- _ O
abusive -X- _ O
comparisons -X- _ O
" -X- _ O
, -X- _ O
in -X- _ O
depth -X- _ O
. -X- _ O
More -X- _ O
examples -X- _ O
of -X- _ O
implicitly -X- _ O
offensive -X- _ O
comments -X- _ O
present -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
table -X- _ O
2 -X- _ O
and -X- _ O
table -X- _ O
6 -X- _ O
( -X- _ O
in -X- _ O
Appendix -X- _ O
A.3).To -X- _ O
explore -X- _ O
whether -X- _ O
specific -X- _ O
bins -X- _ O
capture -X- _ O
specific -X- _ O
topics -X- _ O
or -X- _ O
key -X- _ O
- -X- _ O
words -X- _ O
, -X- _ O
we -X- _ O
calculated -X- _ O
Pointwise -X- _ O
Mutual -X- _ O
Information -X- _ O
( -X- _ O
PMI -X- _ O
) -X- _ O
scores -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
unique -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
comments -X- _ O
( -X- _ O
excluding -X- _ O
stop -X- _ O
words -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
five -X- _ O
score -X- _ O
bins -X- _ O
. -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
top -X- _ O
scoring -X- _ O
words -X- _ O
for -X- _ O
each -X- _ O
bin -X- _ O
. -X- _ O
We -X- _ O
observed -X- _ O
that -X- _ O
bins -X- _ O
1 -X- _ O
, -X- _ O
2 -X- _ O
, -X- _ O
and -X- _ O
3 -X- _ O
exhibit -X- _ O
a -X- _ O
strong -X- _ O
association -X- _ O
with -X- _ O
supportive -X- _ O
or -X- _ O
neutral -X- _ O
words -X- _ O
, -X- _ O
while -X- _ O
bins -X- _ O
4 -X- _ O
and -X- _ O
5 -X- _ O
show -X- _ O
a -X- _ O
strong -X- _ O
association -X- _ O
with -X- _ O
swear -X- _ O
words -X- _ O
and -X- _ O
identity -X- _ O
terms -X- _ O
commonly -X- _ O
found -X- _ O
in -X- _ O
offensive -X- _ O
contexts -X- _ O
. -X- _ O
Identity -X- _ O
terms -X- _ O
A -X- _ O
common -X- _ O
criticism -X- _ O
of -X- _ O
the -X- _ O
existing -X- _ O
offensive -X- _ O
language -X- _ O
datasets -X- _ O
is -X- _ O
that -X- _ O
in -X- _ O
those -X- _ O
datasets -X- _ O
, -X- _ O
certain -X- _ O
identity -X- _ O
terms -X- _ O
( -X- _ O
particularly -X- _ O
those -X- _ O
referring -X- _ O
to -X- _ O
minority -X- _ O
groups -X- _ O
) -X- _ O
occur -X- _ O
mainly -X- _ O
in -X- _ O
texts -X- _ O
that -X- _ O
are -X- _ O
offensive -X- _ O
( -X- _ O
Sap -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Davidson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Wiegand -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Park -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Dixon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
leads -X- _ O
to -X- _ O
high -X- _ O
association -X- _ O
of -X- _ O
targeted -X- _ O
minority -X- _ O
groups -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
Muslims -X- _ O
, -X- _ O
females -X- _ O
, -X- _ O
black -X- _ O
people -X- _ O
and -X- _ O
others -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
offensive -X- _ O
class(es -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
bias -X- _ O
, -X- _ O
in -X- _ O
turn -X- _ O
, -X- _ O
is -X- _ O
captured -X- _ O
by -X- _ O
the -X- _ O
computational -X- _ O
models -X- _ O
trained -X- _ O
on -X- _ O
such -X- _ O
datasets -X- _ O
. -X- _ O
As -X- _ O
mentioned -X- _ O
earlier -X- _ O
, -X- _ O
in -X- _ O
Ruddit -X- _ B-DatasetName
, -X- _ O
certain -X- _ O
words -X- _ O
such -X- _ O
as -X- _ O
gay -X- _ O
, -X- _ O
trans -X- _ O
, -X- _ O
male -X- _ O
, -X- _ O
female -X- _ O
, -X- _ O
black -X- _ O
, -X- _ O
white -X- _ O
were -X- _ O
found -X- _ O
to -X- _ O
exhibit -X- _ O
a -X- _ O
relatively -X- _ O
higher -X- _ O
association -X- _ O
with -X- _ O
the -X- _ O
offensive -X- _ O
bins -X- _ O
than -X- _ O
with -X- _ O
the -X- _ O
supportive -X- _ O
bins -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
probe -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
this -X- _ O
on -X- _ O
the -X- _ O
computational -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
created -X- _ O
a -X- _ O
variant -X- _ O
of -X- _ O
Ruddit -X- _ B-DatasetName
by -X- _ O
replacing -X- _ O
all -X- _ O
the -X- _ O
identity -X- _ O
terms -X- _ O
( -X- _ O
from -X- _ O
the -X- _ O
list -X- _ O
given -X- _ O
in -X- _ O
Appendix -X- _ O
A.4 -X- _ O
) -X- _ O
in -X- _ O
the -X- _ O
comments -X- _ O
with -X- _ O
the -X- _ O
[ -X- _ O
group -X- _ O
] -X- _ O
token -X- _ O
and -X- _ O
observed -X- _ O
the -X- _ O
effect -X- _ O
on -X- _ O
the -X- _ O
models -X- _ O
' -X- _ O
per -X- _ O
- -X- _ O
formance -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
variant -X- _ O
of -X- _ O
the -X- _ O
dataset -X- _ O
as -X- _ O
the -X- _ O
identity -X- _ B-DatasetName
- -X- _ I-DatasetName
agnostic -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
We -X- _ O
analyse -X- _ O
the -X- _ O
models -X- _ O
' -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
section -X- _ O
. -X- _ O
Offensiveness -X- _ O
vs. -X- _ O
emotion -X- _ O
As -X- _ O
discussed -X- _ O
earlier -X- _ O
, -X- _ O
our -X- _ O
emotions -X- _ O
impact -X- _ O
the -X- _ O
words -X- _ O
we -X- _ O
use -X- _ O
in -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
examined -X- _ O
this -X- _ O
relationship -X- _ O
quantitatively -X- _ O
using -X- _ O
Ruddit -X- _ B-DatasetName
and -X- _ O
the -X- _ O
NRC -X- _ B-DatasetName
VAD -X- _ I-DatasetName
Lexicon -X- _ I-DatasetName
( -X- _ O
which -X- _ O
has -X- _ O
intensity -X- _ O
scores -X- _ O
along -X- _ O
the -X- _ O
valence -X- _ O
, -X- _ O
arousal -X- _ O
, -X- _ O
and -X- _ O
dominance -X- _ O
dimensions -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
comment -X- _ O
in -X- _ O
Ruddit -X- _ B-DatasetName
, -X- _ O
we -X- _ O
calculated -X- _ O
three -X- _ O
scores -X- _ O
that -X- _ O
captured -X- _ O
the -X- _ O
intensities -X- _ O
of -X- _ O
the -X- _ O
V -X- _ O
, -X- _ O
A -X- _ O
, -X- _ O
D -X- _ O
words -X- _ O
( -X- _ O
the -X- _ O
averages -X- _ O
of -X- _ O
the -X- _ O
intensities -X- _ O
of -X- _ O
the -X- _ O
V -X- _ O
/ -X- _ O
A -X- _ O
/ -X- _ O
D -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
comment -X- _ O
) -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
entire -X- _ O
lexicon -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
determined -X- _ O
the -X- _ O
correlation -X- _ O
between -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
scores -X- _ O
and -X- _ O
the -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
. -X- _ O
Only -X- _ O
comments -X- _ O
containing -X- _ O
at -X- _ O
least -X- _ O
4 -X- _ O
words -X- _ O
from -X- _ O
the -X- _ O
VAD -X- _ O
lexicon -X- _ O
were -X- _ O
considered -X- _ O
for -X- _ O
the -X- _ O
score -X- _ O
and -X- _ O
correlation -X- _ O
calculation -X- _ O
. -X- _ O
A -X- _ O
total -X- _ O
of -X- _ O
4831 -X- _ O
comments -X- _ O
qualified -X- _ O
the -X- _ O
criteria -X- _ O
. -X- _ O
See -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
valence -X- _ O
is -X- _ O
weakly -X- _ O
inversely -X- _ O
correlated -X- _ O
, -X- _ O
arousal -X- _ O
is -X- _ O
weakly -X- _ O
correlated -X- _ O
, -X- _ O
and -X- _ O
dominance -X- _ O
does -X- _ O
not -X- _ O
exhibit -X- _ O
notable -X- _ O
correlation -X- _ O
with -X- _ O
offensiveness -X- _ O
. -X- _ O
This -X- _ O
behaviour -X- _ O
can -X- _ O
also -X- _ O
be -X- _ O
observed -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
that -X- _ O
shows -X- _ O
a -X- _ O
plot -X- _ O
of -X- _ O
the -X- _ O
average -X- _ O
V -X- _ O
, -X- _ O
A -X- _ O
, -X- _ O
and -X- _ O
D -X- _ O
scores -X- _ O
of -X- _ O
comments -X- _ O
in -X- _ O
the -X- _ O
five -X- _ O
equi -X- _ O
- -X- _ O
spaced -X- _ O
offensivenessscore -X- _ O
bins -X- _ O
. -X- _ O
Note -X- _ O
the -X- _ O
clear -X- _ O
trend -X- _ O
that -X- _ O
as -X- _ O
we -X- _ O
look -X- _ O
at -X- _ O
bins -X- _ O
with -X- _ O
more -X- _ O
offensive -X- _ O
comments -X- _ O
, -X- _ O
the -X- _ O
average -X- _ O
valence -X- _ O
of -X- _ O
the -X- _ O
comments -X- _ O
decreases -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
arousal -X- _ O
increases -X- _ O
. -X- _ O
two -X- _ O
sources -X- _ O
, -X- _ O
comments -X- _ O
are -X- _ O
more -X- _ O
prevalent -X- _ O
in -X- _ O
the -X- _ O
supportive -X- _ O
bins -X- _ O
. -X- _ O
The -X- _ O
higher -X- _ O
representation -X- _ O
of -X- _ O
comments -X- _ O
from -X- _ O
Topics -X- _ O
than -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
sources -X- _ O
in -X- _ O
the -X- _ O
offensive -X- _ O
bins -X- _ O
, -X- _ O
is -X- _ O
likely -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
Topics -X- _ O
category -X- _ O
includes -X- _ O
subreddits -X- _ O
such -X- _ O
as -X- _ O
worldnews -X- _ O
and -X- _ O
worldpolitics -X- _ O
. -X- _ O
Discussions -X- _ O
on -X- _ O
these -X- _ O
subreddits -X- _ O
covers -X- _ O
controversial -X- _ O
topics -X- _ O
and -X- _ O
lead -X- _ O
to -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
offensive -X- _ O
language -X- _ O
. -X- _ O
We -X- _ O
observed -X- _ O
that -X- _ O
worldnews -X- _ O
and -X- _ O
worldpolitics -X- _ O
indeed -X- _ O
have -X- _ O
high -X- _ O
representation -X- _ O
in -X- _ O
the -X- _ O
offensive -X- _ O
bins -X- _ O
( -X- _ O
Figure -X- _ O
8 -X- _ O
in -X- _ O
Appendix -X- _ O
A.4 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
identified -X- _ O
868 -X- _ O
comments -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
that -X- _ O
contain -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
swear -X- _ O
word -X- _ O
from -X- _ O
the -X- _ O
cursing -X- _ O
lexicon -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
Comments -X- _ O
containing -X- _ O
swear -X- _ O
words -X- _ O
can -X- _ O
have -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
offensiveness -X- _ O
scores -X- _ O
. -X- _ O
To -X- _ O
visualize -X- _ O
the -X- _ O
distribution -X- _ O
, -X- _ O
we -X- _ O
plot -X- _ O
a -X- _ O
histogram -X- _ O
of -X- _ O
the -X- _ O
comments -X- _ O
containing -X- _ O
swear -X- _ O
words -X- _ O
vs. -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
7 -X- _ O
in -X- _ O
Appendix -X- _ O
A.4 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
distribution -X- _ O
is -X- _ O
skewed -X- _ O
towards -X- _ O
the -X- _ O
offensive -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
scale -X- _ O
. -X- _ O
An -X- _ O
interesting -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O
some -X- _ O
comments -X- _ O
with -X- _ O
low -X- _ O
offensiveness -X- _ O
scores -X- _ O
contain -X- _ O
phrases -X- _ O
using -X- _ O
swear -X- _ O
words -X- _ O
to -X- _ O
express -X- _ O
enthusiasm -X- _ O
or -X- _ O
to -X- _ O
lay -X- _ O
more -X- _ O
emphasis -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
' -X- _ O
Hell -X- _ O
yes -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
sure -X- _ O
as -X- _ O
hell -X- _ O
love -X- _ O
it -X- _ O
' -X- _ O
, -X- _ O
' -X- _ O
uncomfortable -X- _ O
as -X- _ O
shit -X- _ O
' -X- _ O
and -X- _ O
others -X- _ O
. -X- _ O
To -X- _ O
study -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
comments -X- _ O
containing -X- _ O
swear -X- _ O
words -X- _ O
on -X- _ O
computational -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
created -X- _ O
another -X- _ O
variant -X- _ O
of -X- _ O
Ruddit -X- _ B-DatasetName
in -X- _ O
which -X- _ O
we -X- _ O
removed -X- _ O
all -X- _ O
the -X- _ O
comments -X- _ O
containing -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
swear -X- _ O
word -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
variant -X- _ O
as -X- _ O
the -X- _ O
no -X- _ O
- -X- _ O
swearing -X- _ O
dataset -X- _ O
. -X- _ O
This -X- _ O
dataset -X- _ O
contains -X- _ O
5132 -X- _ O
comments -X- _ O
. -X- _ O
We -X- _ O
analyse -X- _ O
the -X- _ O
models -X- _ O
' -X- _ O
performance -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
section -X- _ O
. -X- _ O
Offensiveness -X- _ O
in -X- _ O
different -X- _ O
score -X- _ O
ranges -X- _ O
It -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
comments -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
region -X- _ O
of -X- _ O
the -X- _ O
scale -X- _ O
may -X- _ O
be -X- _ O
more -X- _ O
difficult -X- _ O
for -X- _ O
the -X- _ O
computational -X- _ O
models -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
we -X- _ O
created -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
Ruddit -X- _ B-DatasetName
containing -X- _ O
comments -X- _ O
with -X- _ O
scores -X- _ O
from -X- _ O
−0.5 -X- _ O
to -X- _ O
0.5 -X- _ O
. -X- _ O
We -X- _ O
call -X- _ O
this -X- _ O
subset -X- _ O
( -X- _ O
of -X- _ O
5151 -X- _ O
comments -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
reduced -X- _ O
- -X- _ O
range -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
discuss -X- _ O
the -X- _ O
models -X- _ O
' -X- _ O
performance -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
in -X- _ O
the -X- _ O
next -X- _ O
section -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
benchmark -X- _ O
experiments -X- _ O
on -X- _ O
Ruddit -X- _ B-DatasetName
and -X- _ O
its -X- _ O
variants -X- _ O
by -X- _ O
implementing -X- _ O
some -X- _ O
commonly -X- _ O
used -X- _ O
model -X- _ O
architectures -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
was -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
offensiveness -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
given -X- _ O
comment -X- _ O
. -X- _ O
We -X- _ O
performed -X- _ O
5 -X- _ B-HyperparameterValue
- -X- _ O
fold -X- _ O
crossvalidation -X- _ B-MetricName
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
6 -X- _ O
Bidirectional -X- _ O
LSTM -X- _ O
We -X- _ O
fed -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
300 -X- _ B-HyperparameterValue
dimensional -X- _ O
GloVe -X- _ B-HyperparameterName
word -X- _ I-HyperparameterName
embeddings -X- _ I-HyperparameterName
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
to -X- _ O
a -X- _ O
2 -X- _ B-HyperparameterValue
- -X- _ O
layered -X- _ O
BiLSTM -X- _ B-MethodName
to -X- _ O
obtain -X- _ O
a -X- _ O
sentence -X- _ O
representation -X- _ O
( -X- _ O
using -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
hidden -X- _ O
state -X- _ O
from -X- _ O
the -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
direction -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
sentence -X- _ O
representation -X- _ O
was -X- _ O
then -X- _ O
passed -X- _ O
to -X- _ O
a -X- _ O
linear -X- _ O
layer -X- _ O
with -X- _ O
a -X- _ O
tanh -X- _ O
activation -X- _ O
to -X- _ O
produce -X- _ O
a -X- _ O
score -X- _ O
between -X- _ O
−1 -X- _ O
and -X- _ O
1 -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
Mean -X- _ O
Squared -X- _ O
Error -X- _ O
( -X- _ O
MSE -X- _ O
) -X- _ O
loss -X- _ O
as -X- _ O
the -X- _ O
objective -X- _ O
function -X- _ O
, -X- _ O
Adam -X- _ B-HyperparameterValue
with -X- _ O
0.001 -X- _ B-HyperparameterValue
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
as -X- _ O
the -X- _ O
optimizer -X- _ B-HyperparameterName
, -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
, -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
of -X- _ O
0.5 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
model -X- _ O
was -X- _ O
trained -X- _ O
for -X- _ O
7 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
. -X- _ O
Dataset -X- _ O
HateBERT -X- _ B-MethodName
BERT -X- _ B-MethodName
BiLSTM -X- _ B-MethodName
r -X- _ B-MetricName
MSE -X- _ B-MetricName
r -X- _ B-MetricName
MSE -X- _ B-MetricName
r -X- _ B-MetricName
MSEa -X- _ B-MetricName
. -X- _ O
Ruddit -X- _ B-DatasetName
0.886 -X- _ O
± -X- _ O
0.003 -X- _ O
0.025 -X- _ O
± -X- _ O
0.001 -X- _ O
0.873 -X- _ O
± -X- _ O
0.005 -X- _ O
0.027 -X- _ O
± -X- _ O
0.001 -X- _ O
0.831 -X- _ O
± -X- _ O
0.005 -X- _ O
0.035 -X- _ O
± -X- _ O
0.001 -X- _ O
b. -X- _ O
Identity -X- _ B-DatasetName
- -X- _ I-DatasetName
agnostic -X- _ I-DatasetName
0.883 -X- _ O
± -X- _ O
0.006 -X- _ O
0.025 -X- _ O
± -X- _ O
0.001 -X- _ O
0.869 -X- _ O
± -X- _ O
0.007 -X- _ O
0.027 -X- _ O
± -X- _ O
0.001 -X- _ O
0.824 -X- _ O
± -X- _ O
0.007 -X- _ O
0.036 -X- _ O
± -X- _ O
0.001 -X- _ O
c. -X- _ O
No -X- _ O
- -X- _ O
swearing -X- _ O
0.808 -X- _ O
± -X- _ O
0.013 -X- _ O
0.023 -X- _ O
± -X- _ O
0.001 -X- _ O
0.783 -X- _ O
± -X- _ O
0.012 -X- _ O
0.027 -X- _ O
± -X- _ O
0.001 -X- _ O
0.704 -X- _ O
± -X- _ O
0.014 -X- _ O
0.036 -X- _ O
± -X- _ O
0.002 -X- _ O
d. -X- _ O
Reduced -X- _ O
- -X- _ O
range -X- _ O
0.781 -X- _ O
± -X- _ O
0.014 -X- _ O
0.022 -X- _ O
± -X- _ O
0.001 -X- _ O
0.757 -X- _ O
± -X- _ O
0.011 -X- _ O
0.025 -X- _ O
± -X- _ O
0.001 -X- _ O
0.659 -X- _ O
± -X- _ O
0.008 -X- _ O
0.033 -X- _ O
± -X- _ O
0.001 -X- _ O
BERT -X- _ B-MethodName
We -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
BERT -X- _ B-MethodName
base -X- _ I-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
added -X- _ O
a -X- _ O
regression -X- _ O
head -X- _ O
containing -X- _ O
a -X- _ O
linear -X- _ O
layer -X- _ O
to -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
MSE -X- _ O
loss -X- _ O
as -X- _ O
the -X- _ O
objective -X- _ O
function -X- _ O
, -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
16 -X- _ O
, -X- _ O
and -X- _ O
learning -X- _ O
rate -X- _ O
of -X- _ O
2e -X- _ O
− -X- _ O
5 -X- _ O
( -X- _ O
other -X- _ O
hyperparameters -X- _ O
same -X- _ O
as -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
AdamW -X- _ O
optimizer -X- _ O
with -X- _ O
a -X- _ O
linear -X- _ O
learning -X- _ O
rate -X- _ O
scheduler -X- _ O
with -X- _ O
no -X- _ O
warm -X- _ O
up -X- _ O
steps -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
was -X- _ O
trained -X- _ O
for -X- _ O
3 -X- _ O
epochs -X- _ O
. -X- _ O
( -X- _ O
More -X- _ O
details -X- _ O
in -X- _ O
Appendix -X- _ O
A.5.)HateBERT -X- _ B-MethodName
HateBERT -X- _ B-MethodName
( -X- _ O
Caselli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020b -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
version -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
pretrained -X- _ O
for -X- _ O
abusive -X- _ O
language -X- _ O
detection -X- _ O
in -X- _ O
English -X- _ O
. -X- _ O
HateBERT -X- _ B-MethodName
was -X- _ O
trained -X- _ O
on -X- _ O
RAL -X- _ O
- -X- _ O
E -X- _ O
, -X- _ O
a -X- _ O
large -X- _ O
dataset -X- _ O
of -X- _ O
English -X- _ O
language -X- _ O
Reddit -X- _ O
comments -X- _ O
from -X- _ O
communities -X- _ O
banned -X- _ O
for -X- _ O
being -X- _ O
offensive -X- _ O
or -X- _ O
hateful -X- _ O
. -X- _ O
HateBERT -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
outperform -X- _ O
the -X- _ O
general -X- _ O
purpose -X- _ O
BERT -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
offensive -X- _ O
language -X- _ O
detection -X- _ O
task -X- _ O
when -X- _ O
finetuned -X- _ O
on -X- _ O
popular -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
OffensEval -X- _ O
2019 -X- _ O
( -X- _ O
Zampieri -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
AbusEval -X- _ O
( -X- _ O
Caselli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
HatEval -X- _ O
( -X- _ O
Basile -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019).We -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
HateBERT -X- _ B-MethodName
on -X- _ O
Ruddit -X- _ B-DatasetName
and -X- _ O
its -X- _ O
variants -X- _ O
. -X- _ O
The -X- _ O
experimental -X- _ O
setup -X- _ O
for -X- _ O
this -X- _ O
model -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
that -X- _ O
described -X- _ O
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
( -X- _ I-MetricName
r -X- _ I-MetricName
) -X- _ I-MetricName
and -X- _ O
MSE -X- _ B-MetricName
, -X- _ O
averaged -X- _ O
over -X- _ O
all -X- _ O
folds -X- _ O
. -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
on -X- _ O
Ruddit -X- _ B-DatasetName
and -X- _ O
its -X- _ O
variants -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
values -X- _ O
on -X- _ O
the -X- _ O
noswearing -X- _ O
and -X- _ O
the -X- _ O
reduced -X- _ O
- -X- _ O
range -X- _ O
datasets -X- _ O
are -X- _ O
not -X- _ O
directly -X- _ O
comparable -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
values -X- _ O
on -X- _ O
the -X- _ O
full -X- _ O
Ruddit -X- _ B-DatasetName
as -X- _ O
their -X- _ O
score -X- _ O
range -X- _ O
is -X- _ O
different -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
on -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
HateBERT -X- _ B-MethodName
model -X- _ O
performs -X- _ O
the -X- _ O
best -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O
Interestingly -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
( -X- _ O
for -X- _ O
all -X- _ O
models -X- _ O
) -X- _ O
does -X- _ O
not -X- _ O
change -X- _ O
substantially -X- _ O
when -X- _ O
trained -X- _ O
on -X- _ O
Ruddit -X- _ O
or -X- _ O
the -X- _ O
identity -X- _ B-DatasetName
- -X- _ I-DatasetName
agnostic -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
computational -X- _ O
models -X- _ O
are -X- _ O
not -X- _ O
learning -X- _ O
to -X- _ O
benefit -X- _ O
from -X- _ O
the -X- _ O
association -X- _ O
of -X- _ O
certain -X- _ O
identity -X- _ O
terms -X- _ O
with -X- _ O
a -X- _ O
specific -X- _ O
range -X- _ O
of -X- _ O
scores -X- _ O
on -X- _ O
the -X- _ O
offensiveness -X- _ O
scale -X- _ O
. -X- _ O
7 -X- _ O
The -X- _ O
models -X- _ O
show -X- _ O
a -X- _ O
performance -X- _ O
drop -X- _ O
on -X- _ O
the -X- _ O
no -X- _ O
- -X- _ O
swearing -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
swear -X- _ O
words -X- _ O
are -X- _ O
useful -X- _ O
indicators -X- _ O
of -X- _ O
offensiveness -X- _ O
and -X- _ O
that -X- _ O
the -X- _ O
comments -X- _ O
containing -X- _ O
them -X- _ O
are -X- _ O
easier -X- _ O
to -X- _ O
classify -X- _ O
. -X- _ O
Yet -X- _ O
, -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
still -X- _ O
obtain -X- _ O
performance -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
0.8 -X- _ B-MetricValue
( -X- _ O
r -X- _ B-MetricName
) -X- _ O
demonstrates -X- _ O
that -X- _ O
they -X- _ O
necessitate -X- _ O
and -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
other -X- _ O
types -X- _ O
of -X- _ O
offensiveness -X- _ O
features -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
worth -X- _ O
mentioning -X- _ O
that -X- _ O
even -X- _ O
if -X- _ O
they -X- _ O
encounter -X- _ O
swear -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
comment -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
not -X- _ O
simply -X- _ O
to -X- _ O
label -X- _ O
the -X- _ O
comment -X- _ O
as -X- _ O
offensive -X- _ O
but -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
suitable -X- _ O
score -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
models -X- _ O
obtained -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
up -X- _ O
to -X- _ O
0.78 -X- _ B-MetricValue
( -X- _ O
r -X- _ B-MetricName
) -X- _ O
on -X- _ O
the -X- _ O
reduced -X- _ O
- -X- _ O
range -X- _ O
dataset -X- _ O
, -X- _ O
which -X- _ O
shows -X- _ O
that -X- _ O
even -X- _ O
if -X- _ O
the -X- _ O
comments -X- _ O
from -X- _ O
the -X- _ O
extreme -X- _ O
ends -X- _ O
of -X- _ O
the -X- _ O
offensiveness -X- _ O
scale -X- _ O
are -X- _ O
removed -X- _ O
, -X- _ O
Ruddit -X- _ O
still -X- _ O
presents -X- _ O
an -X- _ O
interesting -X- _ O
and -X- _ O
feasible -X- _ O
offensiveness -X- _ O
scoring -X- _ O
task -X- _ O
. -X- _ O
Error -X- _ O
Analysis -X- _ O
Figure -X- _ O
4 -X- _ O
shows -X- _ O
the -X- _ O
squared -X- _ O
error -X- _ O
values -X- _ O
of -X- _ O
the -X- _ O
3 -X- _ O
models -X- _ O
over -X- _ O
the -X- _ O
offensiveness -X- _ O
score -X- _ O
range -X- _ O
in -X- _ O
Ruddit -X- _ B-DatasetName
. -X- _ O
As -X- _ O
expected -X- _ O
, -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
models -X- _ O
, -X- _ O
the -X- _ O
error -X- _ O
in -X- _ O
predictions -X- _ O
is -X- _ O
lower -X- _ O
on -X- _ O
both -X- _ O
the -X- _ O
extreme -X- _ O
ends -X- _ O
of -X- _ O
the -X- _ O
scale -X- _ O
than -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
region -X- _ O
. -X- _ O
Comments -X- _ O
with -X- _ O
very -X- _ O
high -X- _ O
or -X- _ O
very -X- _ O
low -X- _ O
offensiveness -X- _ O
scores -X- _ O
are -X- _ O
rich -X- _ O
in -X- _ O
obvious -X- _ O
linguistic -X- _ O
cues -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
easier -X- _ O
for -X- _ O
the -X- _ O
computational -X- _ O
models -X- _ O
to -X- _ O
predict -X- _ O
scores -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
the -X- _ O
not -X- _ O
- -X- _ O
obvious -X- _ O
, -X- _ O
indirect -X- _ O
implicitly -X- _ O
offensive -X- _ O
, -X- _ O
and -X- _ O
neutral -X- _ O
comments -X- _ O
should -X- _ O
be -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
region -X- _ O
of -X- _ O
the -X- _ O
offensiveness -X- _ O
scale -X- _ O
, -X- _ O
making -X- _ O
them -X- _ O
more -X- _ O
difficult -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
interesting -X- _ O
to -X- _ O
observe -X- _ O
that -X- _ O
HateBERT -X- _ B-MethodName
, -X- _ O
unlike -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
models -X- _ O
, -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
high -X- _ O
error -X- _ O
values -X- _ O
for -X- _ O
samples -X- _ O
within -X- _ O
the -X- _ O
score -X- _ O
range -X- _ O
0.25 -X- _ O
- -X- _ O
0.75 -X- _ O
. -X- _ O
This -X- _ O
indicates -X- _ O
that -X- _ O
HateBERT -X- _ B-MethodName
is -X- _ O
efficient -X- _ O
in -X- _ O
dealing -X- _ O
with -X- _ O
offensive -X- _ O
language -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
lie -X- _ O
in -X- _ O
the -X- _ O
extreme -X- _ O
offensive -X- _ O
end -X- _ O
. -X- _ O
BiLSTM -X- _ B-MethodName
seems -X- _ O
relatively -X- _ O
less -X- _ O
accurate -X- _ O
for -X- _ O
samples -X- _ O
in -X- _ O
the -X- _ O
supportive -X- _ O
range -X- _ O
( -X- _ O
−0.75 -X- _ O
to -X- _ O
−0.25 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
could -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
the -X- _ O
less -X- _ O
complex -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
the -X- _ O
usage -X- _ O
of -X- _ O
GloVe -X- _ O
word -X- _ O
embeddings -X- _ O
. -X- _ O
We -X- _ O
presented -X- _ O
the -X- _ O
first -X- _ O
dataset -X- _ O
of -X- _ O
online -X- _ O
comments -X- _ O
annotated -X- _ O
for -X- _ O
their -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
comparative -X- _ O
annotation -X- _ O
technique -X- _ O
called -X- _ O
Best -X- _ B-MethodName
- -X- _ I-MethodName
Worst -X- _ I-MethodName
Scaling -X- _ I-MethodName
, -X- _ O
which -X- _ O
addresses -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
traditional -X- _ O
rating -X- _ O
scales -X- _ O
. -X- _ O
We -X- _ O
showed -X- _ O
that -X- _ O
the -X- _ O
ratings -X- _ O
obtained -X- _ O
are -X- _ O
highly -X- _ O
reliable -X- _ O
( -X- _ O
SHR -X- _ O
Pearson -X- _ O
r -X- _ O
≈ -X- _ O
0.88 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
performed -X- _ O
data -X- _ O
analysis -X- _ O
to -X- _ O
gain -X- _ O
insight -X- _ O
into -X- _ O
the -X- _ O
relation -X- _ O
of -X- _ O
emotions -X- _ O
, -X- _ O
data -X- _ O
sources -X- _ O
, -X- _ O
identity -X- _ O
terms -X- _ O
, -X- _ O
and -X- _ O
swear -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
offensiveness -X- _ O
scores -X- _ O
. -X- _ O
We -X- _ O
showed -X- _ O
that -X- _ O
valence -X- _ O
is -X- _ O
inversely -X- _ O
correlated -X- _ O
with -X- _ O
offensiveness -X- _ O
and -X- _ O
arousal -X- _ O
is -X- _ O
directly -X- _ O
correlated -X- _ O
with -X- _ O
offensiveness -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
presented -X- _ O
benchmark -X- _ O
experiments -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
offensiveness -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
comment -X- _ O
, -X- _ O
on -X- _ O
our -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
that -X- _ O
computational -X- _ O
models -X- _ O
are -X- _ O
not -X- _ O
benefiting -X- _ O
from -X- _ O
the -X- _ O
association -X- _ O
of -X- _ O
identity -X- _ O
terms -X- _ O
with -X- _ O
specific -X- _ O
range -X- _ O
of -X- _ O
scores -X- _ O
on -X- _ O
the -X- _ O
offensiveness -X- _ O
scale -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
interesting -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
conversational -X- _ O
context -X- _ O
in -X- _ O
computational -X- _ O
modeling -X- _ O
of -X- _ O
offensiveness -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
studying -X- _ O
the -X- _ O
interaction -X- _ O
between -X- _ O
offensiveness -X- _ O
and -X- _ O
emotions -X- _ O
in -X- _ O
more -X- _ O
depth -X- _ O
. -X- _ O
We -X- _ O
make -X- _ O
our -X- _ O
dataset -X- _ O
freely -X- _ O
available -X- _ O
to -X- _ O
the -X- _ O
research -X- _ O
community -X- _ O
. -X- _ O
We -X- _ O
create -X- _ O
Ruddit -X- _ B-DatasetName
to -X- _ O
study -X- _ O
, -X- _ O
understand -X- _ O
and -X- _ O
explore -X- _ O
the -X- _ O
nature -X- _ O
of -X- _ O
offensive -X- _ O
language -X- _ O
. -X- _ O
Any -X- _ O
such -X- _ O
dataset -X- _ O
might -X- _ O
also -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
create -X- _ O
automatic -X- _ O
offensive -X- _ O
language -X- _ O
detection -X- _ O
systems -X- _ O
. -X- _ O
While -X- _ O
we -X- _ O
realise -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
such -X- _ O
systems -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
accept -X- _ O
that -X- _ O
any -X- _ O
moderation -X- _ O
of -X- _ O
online -X- _ O
content -X- _ O
is -X- _ O
a -X- _ O
threat -X- _ O
to -X- _ O
free -X- _ O
speech -X- _ O
. -X- _ O
Offensive -X- _ O
language -X- _ O
datasets -X- _ O
or -X- _ O
automatic -X- _ O
systems -X- _ O
can -X- _ O
be -X- _ O
misused -X- _ O
to -X- _ O
stifle -X- _ O
disagreeing -X- _ O
voices -X- _ O
. -X- _ O
Our -X- _ O
intent -X- _ O
is -X- _ O
solely -X- _ O
to -X- _ O
learn -X- _ O
more -X- _ O
about -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
offensive -X- _ O
language -X- _ O
, -X- _ O
learn -X- _ O
about -X- _ O
the -X- _ O
various -X- _ O
degrees -X- _ O
of -X- _ O
offensive -X- _ O
language -X- _ O
, -X- _ O
explore -X- _ O
how -X- _ O
computational -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
enabled -X- _ O
to -X- _ O
watch -X- _ O
and -X- _ O
contain -X- _ O
offensive -X- _ O
language -X- _ O
, -X- _ O
and -X- _ O
encourage -X- _ O
others -X- _ O
to -X- _ O
do -X- _ O
so -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
the -X- _ O
format -X- _ O
provided -X- _ O
by -X- _ O
Bender -X- _ O
and -X- _ O
Friedman -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
discuss -X- _ O
the -X- _ O
ethical -X- _ O
considerations -X- _ O
for -X- _ O
our -X- _ O
dataset -X- _ O
. -X- _ O
Institutional -X- _ O
Review -X- _ O
: -X- _ O
This -X- _ O
research -X- _ O
was -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
Facebook -X- _ O
Online -X- _ O
Safety -X- _ O
Benchmark -X- _ O
Research -X- _ O
award -X- _ O
. -X- _ O
The -X- _ O
primary -X- _ O
objective -X- _ O
of -X- _ O
this -X- _ O
research -X- _ O
award -X- _ O
is -X- _ O
the -X- _ O
creation -X- _ O
of -X- _ O
publicly -X- _ O
available -X- _ O
benchmarks -X- _ O
to -X- _ O
improve -X- _ O
online -X- _ O
safety -X- _ O
. -X- _ O
This -X- _ O
award -X- _ O
does -X- _ O
not -X- _ O
directly -X- _ O
benefit -X- _ O
Facebook -X- _ O
in -X- _ O
any -X- _ O
way -X- _ O
. -X- _ O
This -X- _ O
research -X- _ O
was -X- _ O
reviewed -X- _ O
by -X- _ O
Facebook -X- _ O
for -X- _ O
various -X- _ O
aspects -X- _ O
, -X- _ O
in -X- _ O
particular -X- _ O
: -X- _ O
• -X- _ O
Legal -X- _ O
Review -X- _ O
: -X- _ O
Evaluates -X- _ O
whether -X- _ O
the -X- _ O
research -X- _ O
to -X- _ O
be -X- _ O
undertaken -X- _ O
or -X- _ O
the -X- _ O
research -X- _ O
performed -X- _ O
can -X- _ O
violate -X- _ O
intellectual -X- _ O
property -X- _ O
rights.• -X- _ O
Policy -X- _ O
and -X- _ O
Ethics -X- _ O
Review -X- _ O
: -X- _ O
Evaluates -X- _ O
whether -X- _ O
the -X- _ O
research -X- _ O
to -X- _ O
be -X- _ O
undertaken -X- _ O
aligns -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
ethics -X- _ O
practices -X- _ O
. -X- _ O
This -X- _ O
includes -X- _ O
several -X- _ O
aspects -X- _ O
such -X- _ O
as -X- _ O
mitigating -X- _ O
harm -X- _ O
to -X- _ O
people -X- _ O
involved -X- _ O
, -X- _ O
improving -X- _ O
data -X- _ O
privacy -X- _ O
, -X- _ O
and -X- _ O
informed -X- _ O
consent -X- _ O
. -X- _ O
Data -X- _ O
Redistribution -X- _ O
/ -X- _ O
User -X- _ O
Privacy -X- _ O
: -X- _ O
We -X- _ O
extracted -X- _ O
our -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
Pushshift -X- _ O
Reddit -X- _ O
dataset -X- _ O
made -X- _ O
publicly -X- _ O
available -X- _ O
by -X- _ O
Baumgartner -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
for -X- _ O
research -X- _ O
purposes -X- _ O
. -X- _ O
The -X- _ O
creators -X- _ O
of -X- _ O
the -X- _ O
Pushshift -X- _ O
Reddit -X- _ O
dataset -X- _ O
have -X- _ O
provisions -X- _ O
to -X- _ O
delete -X- _ O
comments -X- _ O
from -X- _ O
their -X- _ O
dataset -X- _ O
upon -X- _ O
user -X- _ O
's -X- _ O
request -X- _ O
. -X- _ O
We -X- _ O
release -X- _ O
data -X- _ O
in -X- _ O
a -X- _ O
manner -X- _ O
that -X- _ O
is -X- _ O
GDPR -X- _ O
compliant -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
provide -X- _ O
any -X- _ O
user -X- _ O
- -X- _ O
specific -X- _ O
information -X- _ O
. -X- _ O
We -X- _ O
release -X- _ O
only -X- _ O
the -X- _ O
comment -X- _ O
IDs -X- _ O
and -X- _ O
post -X- _ O
IDs -X- _ O
. -X- _ O
Reddit -X- _ O
's -X- _ O
Terms -X- _ O
of -X- _ O
Service -X- _ O
do -X- _ O
not -X- _ O
prohibit -X- _ O
the -X- _ O
distribution -X- _ O
of -X- _ O
ids -X- _ O
. -X- _ O
8 -X- _ O
The -X- _ O
researchers -X- _ O
using -X- _ O
the -X- _ O
dataset -X- _ O
need -X- _ O
to -X- _ O
retrieve -X- _ O
the -X- _ O
data -X- _ O
using -X- _ O
the -X- _ O
Reddit -X- _ O
API.Speaker -X- _ O
and -X- _ O
Annotator -X- _ O
Demographic -X- _ O
: -X- _ O
No -X- _ O
specific -X- _ O
speaker -X- _ O
demographic -X- _ O
information -X- _ O
is -X- _ O
available -X- _ O
for -X- _ O
the -X- _ O
comments -X- _ O
included -X- _ O
in -X- _ O
Ruddit -X- _ B-DatasetName
. -X- _ O
According -X- _ O
to -X- _ O
the -X- _ O
October -X- _ O
2020 -X- _ O
survey -X- _ O
published -X- _ O
by -X- _ O
Statista -X- _ O
( -X- _ O
Statista -X- _ O
, -X- _ O
2020a -X- _ O
) -X- _ O
, -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
Reddit -X- _ O
's -X- _ O
desktop -X- _ O
traffic -X- _ O
is -X- _ O
from -X- _ O
the -X- _ O
United -X- _ O
States -X- _ O
. -X- _ O
They -X- _ O
also -X- _ O
state -X- _ O
that -X- _ O
from -X- _ O
the -X- _ O
internet -X- _ O
users -X- _ O
in -X- _ O
the -X- _ O
US -X- _ O
, -X- _ O
21 -X- _ O
% -X- _ O
from -X- _ O
ages -X- _ O
18 -X- _ O
- -X- _ O
24 -X- _ O
, -X- _ O
23 -X- _ O
% -X- _ O
from -X- _ O
ages -X- _ O
25 -X- _ O
- -X- _ O
29 -X- _ O
and -X- _ O
14 -X- _ O
% -X- _ O
from -X- _ O
ages -X- _ O
30 -X- _ O
- -X- _ O
49 -X- _ O
use -X- _ O
Reddit -X- _ O
. -X- _ O
We -X- _ O
restricted -X- _ O
annotators -X- _ O
to -X- _ O
those -X- _ O
residing -X- _ O
in -X- _ O
the -X- _ O
US -X- _ O
. -X- _ O
A -X- _ O
total -X- _ O
of -X- _ O
725 -X- _ O
crowd -X- _ O
- -X- _ O
workers -X- _ O
participated -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
Apart -X- _ O
from -X- _ O
the -X- _ O
country -X- _ O
of -X- _ O
residence -X- _ O
, -X- _ O
no -X- _ O
other -X- _ O
information -X- _ O
is -X- _ O
known -X- _ O
about -X- _ O
the -X- _ O
annotators -X- _ O
. -X- _ O
The -X- _ O
annotators -X- _ O
are -X- _ O
governed -X- _ O
by -X- _ O
AMT -X- _ O
's -X- _ O
privacy -X- _ O
policy -X- _ O
. -X- _ O
9 -X- _ O
Pew -X- _ O
Research -X- _ O
Center -X- _ O
conducted -X- _ O
a -X- _ O
demographic -X- _ O
survey -X- _ O
of -X- _ O
AMT -X- _ O
workers -X- _ O
in -X- _ O
2016 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
survey -X- _ O
, -X- _ O
3370 -X- _ O
workers -X- _ O
participated -X- _ O
. -X- _ O
They -X- _ O
found -X- _ O
out -X- _ O
that -X- _ O
80 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
crowd -X- _ O
- -X- _ O
workers -X- _ O
on -X- _ O
AMT -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
US -X- _ O
( -X- _ O
PRC -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
More -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
workers -X- _ O
who -X- _ O
participated -X- _ O
in -X- _ O
their -X- _ O
survey -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
their -X- _ O
article -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
important -X- _ O
to -X- _ O
include -X- _ O
the -X- _ O
opinions -X- _ O
of -X- _ O
targeted -X- _ O
minorities -X- _ O
and -X- _ O
marginalized -X- _ O
groups -X- _ O
when -X- _ O
dealing -X- _ O
with -X- _ O
the -X- _ O
annotation -X- _ O
of -X- _ O
offensive -X- _ O
language -X- _ O
( -X- _ O
Kiritchenko -X- _ O
and -X- _ O
Nejadgholi -X- _ O
, -X- _ O
2020;Blackwell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
have -X- _ O
our -X- _ O
data -X- _ O
annotated -X- _ O
by -X- _ O
the -X- _ O
specific -X- _ O
target -X- _ O
demographic -X- _ O
because -X- _ O
it -X- _ O
poses -X- _ O
certain -X- _ O
challenges -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
: -X- _ O
identification -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
of -X- _ O
offensive -X- _ O
language -X- _ O
; -X- _ O
finding -X- _ O
people -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
demographic -X- _ O
group -X- _ O
who -X- _ O
are -X- _ O
willing -X- _ O
to -X- _ O
annotate -X- _ O
offensive -X- _ O
language -X- _ O
; -X- _ O
and -X- _ O
others -X- _ O
. -X- _ O
Annotating -X- _ O
such -X- _ O
offensive -X- _ O
data -X- _ O
can -X- _ O
be -X- _ O
even -X- _ O
more -X- _ O
traumatizing -X- _ O
for -X- _ O
the -X- _ O
members -X- _ O
of -X- _ O
the -X- _ O
targeted -X- _ O
minorities -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
Ruddit -X- _ B-DatasetName
was -X- _ O
created -X- _ O
with -X- _ O
the -X- _ O
intention -X- _ O
to -X- _ O
look -X- _ O
at -X- _ O
wide -X- _ O
ranging -X- _ O
offensive -X- _ O
language -X- _ O
of -X- _ O
various -X- _ O
degrees -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
detecting -X- _ O
offensive -X- _ O
language -X- _ O
towards -X- _ O
specific -X- _ O
target -X- _ O
groups -X- _ O
. -X- _ O
Annotation -X- _ O
Guidelines -X- _ O
: -X- _ O
We -X- _ O
created -X- _ O
our -X- _ O
annotation -X- _ O
guidelines -X- _ O
drawing -X- _ O
inspiration -X- _ O
from -X- _ O
the -X- _ O
community -X- _ O
standards -X- _ O
set -X- _ O
for -X- _ O
offensive -X- _ O
language -X- _ O
on -X- _ O
several -X- _ O
social -X- _ O
media -X- _ O
platforms -X- _ O
. -X- _ O
These -X- _ O
standards -X- _ O
are -X- _ O
made -X- _ O
after -X- _ O
thorough -X- _ O
research -X- _ O
and -X- _ O
feedback -X- _ O
from -X- _ O
the -X- _ O
community -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
aware -X- _ O
that -X- _ O
the -X- _ O
definitions -X- _ O
in -X- _ O
our -X- _ O
guidelines -X- _ O
are -X- _ O
not -X- _ O
representative -X- _ O
of -X- _ O
all -X- _ O
possible -X- _ O
perspectives -X- _ O
. -X- _ O
The -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
scores -X- _ O
that -X- _ O
we -X- _ O
provide -X- _ O
in -X- _ O
Ruddit -X- _ O
are -X- _ O
a -X- _ O
representation -X- _ O
of -X- _ O
what -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
our -X- _ O
annotators -X- _ O
think -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
emphasize -X- _ O
that -X- _ O
the -X- _ O
scores -X- _ O
provided -X- _ O
are -X- _ O
not -X- _ O
the -X- _ O
" -X- _ O
correct -X- _ O
" -X- _ O
or -X- _ O
the -X- _ O
only -X- _ O
appropriate -X- _ O
value -X- _ O
of -X- _ O
offensiveness -X- _ O
. -X- _ O
Different -X- _ O
individuals -X- _ O
and -X- _ O
demographic -X- _ O
groups -X- _ O
may -X- _ O
find -X- _ O
the -X- _ O
same -X- _ O
comment -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
or -X- _ O
less -X- _ O
offensive -X- _ O
than -X- _ O
the -X- _ O
scores -X- _ O
provided -X- _ O
. -X- _ O
Impact -X- _ O
on -X- _ O
Annotators -X- _ O
: -X- _ O
Annotation -X- _ O
of -X- _ O
harsh -X- _ O
and -X- _ O
offensive -X- _ O
language -X- _ O
might -X- _ O
impact -X- _ O
the -X- _ O
mental -X- _ O
health -X- _ O
of -X- _ O
the -X- _ O
annotators -X- _ O
negatively -X- _ O
( -X- _ O
Vidgen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Roberts -X- _ O
, -X- _ O
2016Roberts -X- _ O
, -X- _ O
, -X- _ O
2019Kiritchenko -X- _ O
and -X- _ O
Nejadgholi -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
minimized -X- _ O
negative -X- _ O
mental -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
annotators -X- _ O
participating -X- _ O
in -X- _ O
our -X- _ O
task -X- _ O
: -X- _ O
• -X- _ O
The -X- _ O
comments -X- _ O
that -X- _ O
we -X- _ O
included -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
are -X- _ O
pre -X- _ O
- -X- _ O
moderated -X- _ O
by -X- _ O
Reddit -X- _ O
's -X- _ O
admins -X- _ O
and -X- _ O
subreddit -X- _ O
specific -X- _ O
moderators -X- _ O
. -X- _ O
Any -X- _ O
comments -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
comply -X- _ O
with -X- _ O
Reddit -X- _ O
's -X- _ O
content -X- _ O
policy -X- _ O
are -X- _ O
not -X- _ O
included -X- _ O
. -X- _ O
10 -X- _ O
• -X- _ O
Our -X- _ O
goal -X- _ O
was -X- _ O
to -X- _ O
annotate -X- _ O
posts -X- _ O
one -X- _ O
sees -X- _ O
on -X- _ O
social -X- _ O
media -X- _ O
( -X- _ O
after -X- _ O
content -X- _ O
moderation -X- _ O
) -X- _ O
. -X- _ O
Unlike -X- _ O
some -X- _ O
past -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
limit -X- _ O
the -X- _ O
data -X- _ O
to -X- _ O
include -X- _ O
only -X- _ O
negative -X- _ O
comments -X- _ O
. -X- _ O
We -X- _ O
included -X- _ O
a -X- _ O
large -X- _ O
sample -X- _ O
of -X- _ O
posts -X- _ O
that -X- _ O
one -X- _ O
normally -X- _ O
sees -X- _ O
on -X- _ O
social -X- _ O
media -X- _ O
, -X- _ O
and -X- _ O
annotated -X- _ O
it -X- _ O
for -X- _ O
degree -X- _ O
of -X- _ O
supportiveness -X- _ O
or -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
. -X- _ O
• -X- _ O
AMT -X- _ O
provides -X- _ O
a -X- _ O
checkbox -X- _ O
where -X- _ O
requesters -X- _ O
can -X- _ O
indicate -X- _ O
that -X- _ O
some -X- _ O
content -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
may -X- _ O
be -X- _ O
offensive -X- _ O
. -X- _ O
These -X- _ O
tasks -X- _ O
are -X- _ O
not -X- _ O
shown -X- _ O
to -X- _ O
annotators -X- _ O
who -X- _ O
have -X- _ O
specified -X- _ O
so -X- _ O
in -X- _ O
their -X- _ O
profile -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
checkbox -X- _ O
to -X- _ O
indicate -X- _ O
that -X- _ O
this -X- _ O
task -X- _ O
has -X- _ O
offensive -X- _ O
content -X- _ O
. -X- _ O
• -X- _ O
We -X- _ O
explicitly -X- _ O
warned -X- _ O
the -X- _ O
annotators -X- _ O
about -X- _ O
the -X- _ O
content -X- _ O
of -X- _ O
annotation -X- _ O
, -X- _ O
and -X- _ O
advised -X- _ O
worker -X- _ O
discretion -X- _ O
. -X- _ O
• -X- _ O
We -X- _ O
provided -X- _ O
detailed -X- _ O
annotation -X- _ O
instructions -X- _ O
and -X- _ O
informed -X- _ O
the -X- _ O
annotators -X- _ O
about -X- _ O
how -X- _ O
the -X- _ O
annotations -X- _ O
for -X- _ O
offensive -X- _ O
language -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
studying -X- _ O
and -X- _ O
understanding -X- _ O
offensive -X- _ O
language -X- _ O
. -X- _ O
• -X- _ O
The -X- _ O
annotation -X- _ O
of -X- _ O
our -X- _ O
data -X- _ O
was -X- _ O
crowdsourced -X- _ O
, -X- _ O
allowing -X- _ O
for -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
raters -X- _ O
( -X- _ O
725 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
reduces -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
comments -X- _ O
seen -X- _ O
per -X- _ O
rater -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
placed -X- _ O
a -X- _ O
limit -X- _ O
on -X- _ O
how -X- _ O
many -X- _ O
posts -X- _ O
one -X- _ O
may -X- _ O
annotate -X- _ O
. -X- _ O
Annotators -X- _ O
were -X- _ O
not -X- _ O
allowed -X- _ O
to -X- _ O
submit -X- _ O
more -X- _ O
than -X- _ O
∼ -X- _ O
5 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
total -X- _ O
assignments -X- _ O
. -X- _ O
• -X- _ O
There -X- _ O
are -X- _ O
just -X- _ O
25 -X- _ O
comments -X- _ O
in -X- _ O
the -X- _ O
top -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
offensiveness -X- _ O
score -X- _ O
range -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
most -X- _ O
annotators -X- _ O
( -X- _ O
> -X- _ O
99.95 -X- _ O
% -X- _ O
) -X- _ O
do -X- _ O
not -X- _ O
see -X- _ O
even -X- _ O
one -X- _ O
such -X- _ O
comment -X- _ O
. -X- _ O
Identity -X- _ O
Terms -X- _ O
: -X- _ O
As -X- _ O
discussed -X- _ O
in -X- _ O
section -X- _ O
5 -X- _ O
, -X- _ O
in -X- _ O
Ruddit -X- _ O
, -X- _ O
certain -X- _ O
identity -X- _ O
terms -X- _ O
show -X- _ O
a -X- _ O
higher -X- _ O
association -X- _ O
with -X- _ O
offensive -X- _ O
comments -X- _ O
than -X- _ O
with -X- _ O
the -X- _ O
supportive -X- _ O
comments -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
address -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
created -X- _ O
a -X- _ O
variant -X- _ O
of -X- _ O
Ruddit -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
replaced -X- _ O
all -X- _ O
the -X- _ O
identity -X- _ O
terms -X- _ O
( -X- _ O
from -X- _ O
the -X- _ O
list -X- _ O
given -X- _ O
in -X- _ O
Appendix -X- _ O
A.4 -X- _ O
) -X- _ O
with -X- _ O
the -X- _ O
[ -X- _ O
group -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O
We -X- _ O
call -X- _ O
this -X- _ O
variant -X- _ O
the -X- _ O
identity -X- _ B-DatasetName
- -X- _ I-DatasetName
agnostic -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
We -X- _ O
release -X- _ O
the -X- _ O
code -X- _ O
for -X- _ O
creating -X- _ O
this -X- _ O
variant -X- _ O
from -X- _ O
the -X- _ O
original -X- _ O
dataset -X- _ O
. -X- _ O
We -X- _ O
evaluated -X- _ O
our -X- _ O
computational -X- _ O
models -X- _ O
on -X- _ O
this -X- _ O
variant -X- _ O
and -X- _ O
observed -X- _ O
that -X- _ O
the -X- _ O
models -X- _ O
did -X- _ O
not -X- _ O
learn -X- _ O
to -X- _ O
benefit -X- _ O
from -X- _ O
the -X- _ O
association -X- _ O
of -X- _ O
the -X- _ O
identity -X- _ O
terms -X- _ O
with -X- _ O
the -X- _ O
offensive -X- _ O
comments -X- _ O
. -X- _ O
Computational -X- _ O
Models -X- _ O
: -X- _ O
The -X- _ O
models -X- _ O
reported -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
not -X- _ O
intended -X- _ O
to -X- _ O
fully -X- _ O
automate -X- _ O
offensive -X- _ O
content -X- _ O
moderation -X- _ O
or -X- _ O
to -X- _ O
make -X- _ O
judgements -X- _ O
about -X- _ O
specific -X- _ O
individuals -X- _ O
. -X- _ O
Owing -X- _ O
to -X- _ O
privacy -X- _ O
concerns -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
model -X- _ O
user -X- _ O
history -X- _ O
to -X- _ O
predict -X- _ O
offensiveness -X- _ O
scores -X- _ O
( -X- _ O
Mitchell -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).Feedback -X- _ O
: -X- _ O
We -X- _ O
are -X- _ O
aware -X- _ O
that -X- _ O
our -X- _ O
dataset -X- _ O
is -X- _ O
subject -X- _ O
to -X- _ O
the -X- _ O
inherent -X- _ O
bias -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
, -X- _ O
the -X- _ O
sampling -X- _ O
procedure -X- _ O
and -X- _ O
the -X- _ O
opinion -X- _ O
of -X- _ O
the -X- _ O
annotators -X- _ O
who -X- _ O
annotated -X- _ O
it -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
acknowledge -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
comprehensive -X- _ O
listing -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
ethical -X- _ O
considerations -X- _ O
and -X- _ O
limitations -X- _ O
. -X- _ O
We -X- _ O
welcome -X- _ O
feedback -X- _ O
from -X- _ O
the -X- _ O
research -X- _ O
community -X- _ O
and -X- _ O
anyone -X- _ O
using -X- _ O
our -X- _ O
dataset -X- _ O
. -X- _ O
A -X- _ O
Supplemental -X- _ O
Material -X- _ O
We -X- _ O
selected -X- _ O
the -X- _ O
posts -X- _ O
from -X- _ O
the -X- _ O
subreddits -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
following -X- _ O
criteria:1 -X- _ O
. -X- _ O
Date -X- _ O
: -X- _ O
To -X- _ O
extract -X- _ O
comments -X- _ O
from -X- _ O
posts -X- _ O
that -X- _ O
discuss -X- _ O
current -X- _ O
matters -X- _ O
, -X- _ O
we -X- _ O
took -X- _ O
comments -X- _ O
from -X- _ O
the -X- _ O
time -X- _ O
period -X- _ O
of -X- _ O
January -X- _ O
, -X- _ O
2015 -X- _ O
to -X- _ O
September -X- _ O
, -X- _ O
2019 -X- _ O
( -X- _ O
last -X- _ O
available -X- _ O
month -X- _ O
at -X- _ O
the -X- _ O
time -X- _ O
of -X- _ O
extraction).2 -X- _ O
. -X- _ O
Thread -X- _ O
length -X- _ O
: -X- _ O
We -X- _ O
chose -X- _ O
posts -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
150 -X- _ O
comments -X- _ O
and -X- _ O
less -X- _ O
than -X- _ O
5000 -X- _ O
comments -X- _ O
. -X- _ O
This -X- _ O
criteria -X- _ O
ensured -X- _ O
that -X- _ O
the -X- _ O
posts -X- _ O
contained -X- _ O
enough -X- _ O
comments -X- _ O
to -X- _ O
capture -X- _ O
meaningful -X- _ O
discussion.3 -X- _ O
. -X- _ O
Post -X- _ O
length -X- _ O
: -X- _ O
We -X- _ O
chose -X- _ O
posts -X- _ O
containing -X- _ O
more -X- _ O
than -X- _ O
5 -X- _ O
words -X- _ O
and -X- _ O
less -X- _ O
than -X- _ O
60 -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
post -X- _ O
body -X- _ O
. -X- _ O
This -X- _ O
was -X- _ O
done -X- _ O
to -X- _ O
avoid -X- _ O
posts -X- _ O
that -X- _ O
are -X- _ O
too -X- _ O
short -X- _ O
to -X- _ O
provide -X- _ O
enough -X- _ O
information -X- _ O
or -X- _ O
are -X- _ O
too -X- _ O
long -X- _ O
and -X- _ O
have -X- _ O
a -X- _ O
possibility -X- _ O
of -X- _ O
being -X- _ O
spam.4 -X- _ O
. -X- _ O
URL -X- _ O
: -X- _ O
Often -X- _ O
, -X- _ O
posts -X- _ O
on -X- _ O
Reddit -X- _ O
contain -X- _ O
URLs -X- _ O
redirecting -X- _ O
to -X- _ O
images -X- _ O
, -X- _ O
videos -X- _ O
, -X- _ O
news -X- _ O
articles -X- _ O
and -X- _ O
others -X- _ O
. -X- _ O
We -X- _ O
limited -X- _ O
our -X- _ O
posts -X- _ O
to -X- _ O
those -X- _ O
containing -X- _ O
at -X- _ O
most -X- _ O
one -X- _ O
URL -X- _ O
to -X- _ O
avoid -X- _ O
issues -X- _ O
arising -X- _ O
due -X- _ O
to -X- _ O
missing -X- _ O
context -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
post -X- _ O
, -X- _ O
the -X- _ O
hierarchical -X- _ O
threads -X- _ O
were -X- _ O
reconstructed -X- _ O
using -X- _ O
the -X- _ O
Anytree -X- _ O
python -X- _ O
library -X- _ O
. -X- _ O
We -X- _ O
filtered -X- _ O
comments -X- _ O
from -X- _ O
these -X- _ O
posts -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
following -X- _ O
criteria:1 -X- _ O
. -X- _ O
Comment -X- _ O
length -X- _ O
: -X- _ O
We -X- _ O
chose -X- _ O
comments -X- _ O
containing -X- _ O
more -X- _ O
than -X- _ O
5 -X- _ O
words -X- _ O
and -X- _ O
less -X- _ O
than -X- _ O
150 -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
comment -X- _ O
body -X- _ O
. -X- _ O
We -X- _ O
did -X- _ O
this -X- _ O
to -X- _ O
include -X- _ O
comments -X- _ O
that -X- _ O
are -X- _ O
neither -X- _ O
too -X- _ O
long -X- _ O
( -X- _ O
can -X- _ O
be -X- _ O
difficult -X- _ O
to -X- _ O
annotate -X- _ O
) -X- _ O
nor -X- _ O
too -X- _ O
short -X- _ O
( -X- _ O
not -X- _ O
very -X- _ O
valuable -X- _ O
) -X- _ O
. -X- _ O
No -X- _ O
. -X- _ O
of -X- _ O
users -X- _ O
: -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
and -X- _ O
last -X- _ O
25 -X- _ O
comments -X- _ O
of -X- _ O
the -X- _ O
thread -X- _ O
, -X- _ O
we -X- _ O
ensured -X- _ O
participation -X- _ O
of -X- _ O
at -X- _ O
least -X- _ O
4 -X- _ O
users -X- _ O
. -X- _ O
This -X- _ O
was -X- _ O
done -X- _ O
to -X- _ O
ensure -X- _ O
that -X- _ O
the -X- _ O
comments -X- _ O
in -X- _ O
our -X- _ O
dataset -X- _ O
are -X- _ O
from -X- _ O
a -X- _ O
diverse -X- _ O
set -X- _ O
of -X- _ O
users -X- _ O
. -X- _ O
We -X- _ O
chose -X- _ O
comments -X- _ O
with -X- _ O
no -X- _ O
URL -X- _ O
in -X- _ O
them -X- _ O
. -X- _ O
Comments -X- _ O
with -X- _ O
URL -X- _ O
can -X- _ O
be -X- _ O
difficult -X- _ O
to -X- _ O
annotate -X- _ O
as -X- _ O
the -X- _ O
URLs -X- _ O
provide -X- _ O
extra -X- _ O
context -X- _ O
for -X- _ O
the -X- _ O
comment -X- _ O
. -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
detailed -X- _ O
annotation -X- _ O
instructions -X- _ O
given -X- _ O
to -X- _ O
the -X- _ O
crowd -X- _ O
- -X- _ O
workers -X- _ O
for -X- _ O
the -X- _ O
task -X- _ O
. -X- _ O
A -X- _ O
sample -X- _ O
questionnaire -X- _ O
for -X- _ O
the -X- _ O
final -X- _ O
annotation -X- _ O
task -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
6.The -X- _ O
hourly -X- _ O
compensation -X- _ O
rate -X- _ O
for -X- _ O
annotators -X- _ O
on -X- _ O
Amazon -X- _ O
Mechanical -X- _ O
Turk -X- _ O
was -X- _ O
US$ -X- _ O
7.50 -X- _ O
/ -X- _ O
hr -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
received -X- _ O
considerable -X- _ O
attention -X- _ O
with -X- _ O
725 -X- _ O
participants -X- _ O
in -X- _ O
total -X- _ O
. -X- _ O
Table -X- _ O
6 -X- _ O
contains -X- _ O
comments -X- _ O
from -X- _ O
Ruddit -X- _ O
grouped -X- _ O
according -X- _ O
to -X- _ O
the -X- _ O
5 -X- _ O
score -X- _ O
bins -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
the -X- _ O
list -X- _ O
of -X- _ O
identity -X- _ O
terms -X- _ O
used -X- _ O
by -X- _ O
Dixon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
few -X- _ O
of -X- _ O
our -X- _ O
own -X- _ O
additions -X- _ O
. -X- _ O
The -X- _ O
terms -X- _ O
used -X- _ O
are -X- _ O
lesbian -X- _ O
, -X- _ O
gay -X- _ O
, -X- _ O
bisexual -X- _ O
, -X- _ O
transgender -X- _ O
, -X- _ O
trans -X- _ O
, -X- _ O
queer -X- _ O
, -X- _ O
lgbt -X- _ O
, -X- _ O
lgbtq -X- _ O
, -X- _ O
homosexual -X- _ O
, -X- _ O
straight -X- _ O
, -X- _ O
heterosexual -X- _ O
, -X- _ O
male -X- _ O
, -X- _ O
female -X- _ O
, -X- _ O
nonbinary -X- _ O
, -X- _ O
african -X- _ O
, -X- _ O
africanamerican -X- _ O
, -X- _ O
black -X- _ O
, -X- _ O
white -X- _ O
, -X- _ O
european -X- _ O
, -X- _ O
hispanic -X- _ O
, -X- _ O
latino -X- _ O
, -X- _ O
latina -X- _ O
, -X- _ O
latinx -X- _ O
, -X- _ O
mexican -X- _ O
, -X- _ O
canadian -X- _ O
, -X- _ O
american -X- _ O
, -X- _ O
asian -X- _ O
, -X- _ O
indian -X- _ O
, -X- _ O
middle -X- _ O
eastern -X- _ O
, -X- _ O
chinese -X- _ O
, -X- _ O
japanese -X- _ O
, -X- _ O
christian -X- _ O
, -X- _ O
muslim -X- _ O
, -X- _ O
jewish -X- _ O
, -X- _ O
buddhist -X- _ O
, -X- _ O
catholic -X- _ O
, -X- _ O
protestant -X- _ O
, -X- _ O
sikh -X- _ O
, -X- _ O
taoist -X- _ O
, -X- _ O
old -X- _ O
, -X- _ O
older -X- _ O
, -X- _ O
young -X- _ O
, -X- _ O
younger -X- _ O
, -X- _ O
teenage -X- _ O
, -X- _ O
millenial -X- _ O
, -X- _ O
middle -X- _ O
aged -X- _ O
, -X- _ O
elderly -X- _ O
, -X- _ O
blind -X- _ O
, -X- _ O
deaf -X- _ O
, -X- _ O
paralyzed -X- _ O
, -X- _ O
atheist -X- _ O
, -X- _ O
feminist -X- _ O
, -X- _ O
islam -X- _ O
, -X- _ O
muslim -X- _ O
, -X- _ O
man -X- _ O
, -X- _ O
woman -X- _ O
, -X- _ O
boy -X- _ O
, -X- _ O
girl -X- _ O
. -X- _ O
Figure -X- _ O
7 -X- _ O
shows -X- _ O
a -X- _ O
histogram -X- _ O
of -X- _ O
the -X- _ O
comments -X- _ O
containing -X- _ O
swear -X- _ O
words -X- _ O
- -X- _ O
degree -X- _ O
of -X- _ O
offensiveness -X- _ O
, -X- _ O
over -X- _ O
40 -X- _ O
equi -X- _ O
- -X- _ O
spaced -X- _ O
score -X- _ O
bins -X- _ O
of -X- _ O
size -X- _ O
0.05.Figure -X- _ O
8 -X- _ O
shows -X- _ O
a -X- _ O
distribution -X- _ O
of -X- _ O
comments -X- _ O
within -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
5 -X- _ O
score -X- _ O
bins -X- _ O
over -X- _ O
the -X- _ O
subreddits -X- _ O
that -X- _ O
were -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
Topics -X- _ O
category -X- _ O
. -X- _ O
Hyperparameter -X- _ O
Tuning -X- _ O
We -X- _ O
tuned -X- _ O
hyperparameters -X- _ O
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
the -X- _ O
BiLSTM -X- _ B-MethodName
models -X- _ O
. -X- _ O
We -X- _ O
performed -X- _ O
grid -X- _ O
search -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
on -X- _ O
Ruddit -X- _ O
and -X- _ O
used -X- _ O
Pearson -X- _ O
's -X- _ O
r -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
hyperparameter -X- _ O
setting -X- _ O
. -X- _ O
All -X- _ O
experiments -X- _ O
were -X- _ O
performed -X- _ O
on -X- _ O
a -X- _ O
fixed -X- _ O
seed -X- _ O
value -X- _ O
of -X- _ O
12.For -X- _ O
the -X- _ O
BiLSTM -X- _ B-MethodName
model -X- _ O
, -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
was -X- _ O
fixed -X- _ O
at -X- _ O
32 -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
epochs -X- _ O
was -X- _ O
set -X- _ O
to -X- _ O
7 -X- _ O
. -X- _ O
The -X- _ O
hyperparameter -X- _ O
search -X- _ O
space -X- _ O
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
For -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
, -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
was -X- _ O
fixed -X- _ O
at -X- _ O
16 -X- _ B-HyperparameterValue
and -X- _ O
BERT -X- _ B-MethodName
tokenizer -X- _ B-HyperparameterName
's -X- _ I-HyperparameterName
maximum -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
was -X- _ O
set -X- _ O
to -X- _ O
200 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
tune -X- _ O
hyperparameters -X- _ O
on -X- _ O
the -X- _ O
settings -X- _ O
that -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
found -X- _ O
to -X- _ O
work -X- _ O
best -X- _ O
on -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
search -X- _ O
space -X- _ O
is -X- _ O
as -X- _ O
follows:2714• -X- _ O
Learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
: -X- _ O
2e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
, -X- _ O
3e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
, -X- _ O
5e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
5 -X- _ I-HyperparameterValue
We -X- _ O
reported -X- _ O
the -X- _ O
best -X- _ O
setting -X- _ O
for -X- _ O
the -X- _ O
models -X- _ O
in -X- _ O
section -X- _ O
6.1 -X- _ O
. -X- _ O
The -X- _ O
average -X- _ B-MetricName
r -X- _ I-MetricName
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
the -X- _ O
BiLSTM -X- _ B-MethodName
models -X- _ O
across -X- _ O
all -X- _ O
hyperparameter -X- _ O
search -X- _ O
This -X- _ O
research -X- _ O
was -X- _ O
funded -X- _ O
by -X- _ O
the -X- _ O
Facebook -X- _ O
Online -X- _ O
Safety -X- _ O
Benchmark -X- _ O
Research -X- _ O
award -X- _ O
for -X- _ O
the -X- _ O
project -X- _ O
" -X- _ O
A -X- _ O
Benchmark -X- _ O
and -X- _ O
Evaluation -X- _ O
Framework -X- _ O
for -X- _ O
Abusive -X- _ O
Language -X- _ O
Detection -X- _ O
. -X- _ O
" -X- _ O
Bin -X- _ O
Comment -X- _ O
Score -X- _ O
1Truly -X- _ O
gave -X- _ O
me -X- _ O
a -X- _ O
smile -X- _ O
−0.812 -X- _ O
Awwwwwe -X- _ O
That -X- _ O
's -X- _ O
was -X- _ O
the -X- _ O
best -X- _ O
reveal -X- _ O
I -X- _ O
've -X- _ O
seen.−0.688 -X- _ O
I -X- _ O
'm -X- _ O
literally -X- _ O
doing -X- _ O
the -X- _ O
same -X- _ O
tonight -X- _ O
! -X- _ O
Have -X- _ O
an -X- _ O
awesome -X- _ O
time -X- _ O
:) -X- _ O
−0.625 -X- _ O
My -X- _ O
apologies -X- _ O
for -X- _ O
missing -X- _ O
that -X- _ O
in -X- _ O
your -X- _ O
post -X- _ O
. -X- _ O
Carry -X- _ O
on -X- _ O
. -X- _ O
−0.583 -X- _ O
I -X- _ O
'm -X- _ O
assuming -X- _ O
this -X- _ O
is -X- _ O
a -X- _ O
great -X- _ O
response -X- _ O
for -X- _ O
i -X- _ O
have -X- _ O
n't -X- _ O
seen -X- _ O
the -X- _ O
video -X- _ O
in -X- _ O
question -X- _ O
, -X- _ O
but -X- _ O
i -X- _ O
do -X- _ O
believe -X- _ O
that -X- _ O
the -X- _ O
woman -X- _ O
in -X- _ O
the -X- _ O
video -X- _ O
carried -X- _ O
herself -X- _ O
very -X- _ O
elegantly -X- _ O
! -X- _ O
−0.375 -X- _ O
Could -X- _ O
you -X- _ O
not -X- _ O
love -X- _ O
a -X- _ O
" -X- _ O
purrfectly -X- _ O
" -X- _ O
healthy -X- _ O
moggy -X- _ O
? -X- _ O
One -X- _ O
whose -X- _ O
life -X- _ O
you -X- _ O
could -X- _ O
save -X- _ O
from -X- _ O
a -X- _ O
shelter -X- _ O
and -X- _ O
wo -X- _ O
n't -X- _ O
break -X- _ O
the -X- _ O
bank -X- _ O
. -X- _ O
−0.25 -X- _ O
Handwritten -X- _ O
letters -X- _ O
are -X- _ O
pure -X- _ O
gold -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
a -X- _ O
simple -X- _ O
but -X- _ O
immensely -X- _ O
pleasant -X- _ O
gift -X- _ O
to -X- _ O
receive -X- _ O
. -X- _ O
Still -X- _ O
have -X- _ O
the -X- _ O
ones -X- _ O
my -X- _ O
ex -X- _ O
gf -X- _ O
would -X- _ O
sent -X- _ O
me -X- _ O
when -X- _ O
we -X- _ O
were -X- _ O
apart.−0.196 -X- _ O
It -X- _ O
would -X- _ O
take -X- _ O
way -X- _ O
more -X- _ O
time -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
screaming -X- _ O
baby -X- _ O
to -X- _ O
stay -X- _ O
still -X- _ O
long -X- _ O
enough -X- _ O
to -X- _ O
inject -X- _ O
them -X- _ O
. -X- _ O
I -X- _ O
remember -X- _ O
my -X- _ O
little -X- _ O
sister -X- _ O
throwing -X- _ O
off -X- _ O
doctors -X- _ O
and -X- _ O
nurses -X- _ O
like -X- _ O
a -X- _ O
tiny -X- _ O
she -X- _ O
- -X- _ O
hulk -X- _ O
when -X- _ O
she -X- _ O
was -X- _ O
a -X- _ O
toddler -X- _ O
. -X- _ O
She -X- _ O
also -X- _ O
punched -X- _ O
my -X- _ O
dad -X- _ O
in -X- _ O
the -X- _ O
face -X- _ O
. -X- _ O

With -X- _ O
the -X- _ O
increasing -X- _ O
interest -X- _ O
in -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
, -X- _ O
unsupervised -X- _ B-TaskName
morphological -X- _ I-TaskName
segmentation -X- _ I-TaskName
has -X- _ O
become -X- _ O
an -X- _ O
active -X- _ O
area -X- _ O
of -X- _ O
research -X- _ O
, -X- _ O
where -X- _ O
approaches -X- _ O
based -X- _ O
on -X- _ O
Adaptor -X- _ B-MethodName
Grammars -X- _ I-MethodName
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
demonstrate -X- _ O
the -X- _ O
power -X- _ O
of -X- _ O
harnessing -X- _ O
linguistic -X- _ O
knowledge -X- _ O
as -X- _ O
priors -X- _ O
within -X- _ O
Adaptor -X- _ B-MethodName
Grammars -X- _ I-MethodName
in -X- _ O
a -X- _ O
minimally -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
fashion -X- _ O
. -X- _ O
We -X- _ O
introduce -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
priors -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
grammar -X- _ B-MethodName
definition -X- _ I-MethodName
, -X- _ O
where -X- _ O
we -X- _ O
design -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
grammars -X- _ O
; -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
linguistprovided -X- _ B-MethodName
affixes -X- _ I-MethodName
, -X- _ O
collected -X- _ O
by -X- _ O
an -X- _ O
expert -X- _ O
in -X- _ O
the -X- _ O
language -X- _ O
and -X- _ O
seeded -X- _ O
into -X- _ O
the -X- _ O
grammars -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Japanese -X- _ O
and -X- _ O
Georgian -X- _ O
as -X- _ O
respective -X- _ O
case -X- _ O
studies -X- _ O
for -X- _ O
the -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
priors -X- _ O
and -X- _ O
introduce -X- _ O
new -X- _ O
datasets -X- _ O
for -X- _ O
these -X- _ O
languages -X- _ O
, -X- _ O
with -X- _ O
gold -X- _ O
morphological -X- _ B-TaskName
segmentation -X- _ I-TaskName
for -X- _ O
evaluation -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
priors -X- _ O
results -X- _ O
in -X- _ O
error -X- _ B-MetricName
reductions -X- _ O
of -X- _ O
8.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
34.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
respectively -X- _ O
, -X- _ O
over -X- _ O
the -X- _ O
equivalent -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
unsupervised -X- _ O
system -X- _ O
. -X- _ O
Morphological -X- _ B-TaskName
segmentation -X- _ I-TaskName
is -X- _ O
an -X- _ O
essential -X- _ O
subtask -X- _ O
in -X- _ O
many -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
applications -X- _ O
, -X- _ O
especially -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
morphologically -X- _ O
complex -X- _ O
languages -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
need -X- _ O
to -X- _ O
develop -X- _ O
NLP -X- _ O
tools -X- _ O
for -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
languages -X- _ O
, -X- _ O
unsupervised -X- _ B-TaskName
morphological -X- _ I-TaskName
segmentation -X- _ I-TaskName
has -X- _ O
been -X- _ O
receiving -X- _ O
increasing -X- _ O
interest -X- _ O
over -X- _ O
the -X- _ O
last -X- _ O
two -X- _ O
decades -X- _ O
( -X- _ O
Goldsmith -X- _ O
, -X- _ O
2001;Creutz -X- _ O
and -X- _ O
Lagus -X- _ O
, -X- _ O
2007a;Poon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009;Sirts -X- _ O
and -X- _ O
Goldwater -X- _ O
, -X- _ O
2013;Botha -X- _ O
and -X- _ O
Blunsom -X- _ O
, -X- _ O
2013;Narasimhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2018Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2019.In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
how -X- _ O
linguistic -X- _ O
priors -X- _ O
effectively -X- _ O
boost -X- _ O
morphological -X- _ O
- -X- _ O
segmentation -X- _ O
performance -X- _ O
in -X- _ O
a -X- _ O
minimally -X- _ O
- -X- _ O
supervised -X- _ O
manner -X- _ O
that -X- _ O
does -X- _ O
not -X- _ O
require -X- _ O
segmented -X- _ O
words -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
integrate -X- _ O
our -X- _ O
priors -X- _ O
within -X- _ O
Adaptor -X- _ B-MethodName
Grammars -X- _ I-MethodName
( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
type -X- _ O
of -X- _ O
nonparametric -X- _ O
Bayesian -X- _ O
models -X- _ O
that -X- _ O
generalize -X- _ B-MethodName
Probabilistic -X- _ I-MethodName
Context -X- _ I-MethodName
- -X- _ I-MethodName
Free -X- _ I-MethodName
Grammars -X- _ I-MethodName
( -X- _ O
PCFGs -X- _ O
) -X- _ O
. -X- _ O
Adaptor -X- _ B-MethodName
Grammars -X- _ I-MethodName
have -X- _ O
proved -X- _ O
successful -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
morphological -X- _ I-TaskName
segmentation -X- _ I-TaskName
, -X- _ O
achieving -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
across -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
typologically -X- _ O
diverse -X- _ O
languages -X- _ O
( -X- _ O
Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020).We -X- _ O
introduce -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
linguistic -X- _ O
priors -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
grammar -X- _ B-MethodName
definition -X- _ I-MethodName
, -X- _ O
where -X- _ O
we -X- _ O
design -X- _ O
a -X- _ O
languagespecific -X- _ O
grammar -X- _ O
that -X- _ O
is -X- _ O
tailored -X- _ O
for -X- _ O
the -X- _ O
language -X- _ O
of -X- _ O
interest -X- _ O
by -X- _ O
modeling -X- _ O
specific -X- _ O
morphological -X- _ O
phenomena -X- _ O
, -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
linguist -X- _ B-MethodName
- -X- _ I-MethodName
provided -X- _ I-MethodName
affixes -X- _ I-MethodName
, -X- _ O
where -X- _ O
an -X- _ O
expert -X- _ O
in -X- _ O
the -X- _ O
underlying -X- _ O
language -X- _ O
compiles -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
carefully -X- _ O
selected -X- _ O
affixes -X- _ O
and -X- _ O
seeds -X- _ O
it -X- _ O
into -X- _ O
the -X- _ O
grammars -X- _ O
prior -X- _ O
to -X- _ O
training -X- _ O
the -X- _ O
segmentation -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Japanese -X- _ O
and -X- _ O
Georgian -X- _ O
as -X- _ O
case -X- _ O
studies -X- _ O
for -X- _ O
priors -X- _ O
1 -X- _ O
and -X- _ O
2 -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
As -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
develop -X- _ O
a -X- _ O
robust -X- _ O
approach -X- _ O
that -X- _ O
benefits -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
and/or -X- _ O
endangered -X- _ O
languages -X- _ O
of -X- _ O
high -X- _ O
morphological -X- _ O
complexity -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Japanese -X- _ O
and -X- _ O
Georgian -X- _ O
in -X- _ O
a -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
setting -X- _ O
where -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
morphologically -X- _ O
segmented -X- _ O
data -X- _ O
for -X- _ O
training -X- _ O
but -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
linguistic -X- _ O
information -X- _ O
such -X- _ O
as -X- _ O
word -X- _ O
structure -X- _ O
and -X- _ O
affixes -X- _ O
. -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
using -X- _ O
linguistic -X- _ O
priors -X- _ O
in -X- _ O
a -X- _ O
minimally -X- _ O
- -X- _ O
supervised -X- _ O
setting -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
significant -X- _ O
improvement -X- _ O
in -X- _ O
performance -X- _ O
over -X- _ O
the -X- _ O
equivalent -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
unsupervised -X- _ O
system -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
present -X- _ O
two -X- _ O
morphologically -X- _ O
segmented -X- _ O
datasets -X- _ O
for -X- _ O
Japanese -X- _ O
and -X- _ O
Georgian -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
as -X- _ O
our -X- _ O
gold -X- _ O
standard -X- _ O
and -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
utilized -X- _ O
in -X- _ O
other -X- _ O
morphology -X- _ O
tasks -X- _ O
. -X- _ O
1 -X- _ O
We -X- _ O
utilize -X- _ O
MorphAGram -X- _ B-MethodName
( -X- _ O
Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
2 -X- _ O
, -X- _ O
an -X- _ O
open -X- _ O
- -X- _ O
source -X- _ O
morphologicalsegmentation -X- _ B-TaskName
framework -X- _ O
that -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
Adaptor -X- _ B-MethodName
Grammars -X- _ I-MethodName
( -X- _ O
AGs -X- _ O
) -X- _ O
( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
. -X- _ O
AGs -X- _ O
have -X- _ O
proved -X- _ O
successful -X- _ O
for -X- _ O
unsupervised -X- _ O
and -X- _ O
1 -X- _ O
The -X- _ O
training -X- _ O
and -X- _ O
evaluation -X- _ O
datasets -X- _ O
, -X- _ O
linguistic -X- _ O
priors -X- _ O
and -X- _ O
models -X- _ O
for -X- _ O
both -X- _ O
Japanese -X- _ O
and -X- _ O
Georgian -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https://github.com/rnd2110/MorphAGram/data -X- _ O
. -X- _ O
minimally -X- _ O
- -X- _ O
supervised -X- _ O
morphological -X- _ O
segmentation -X- _ O
, -X- _ O
outperforming -X- _ O
the -X- _ O
competing -X- _ O
discriminative -X- _ O
models -X- _ O
( -X- _ O
Sirts -X- _ O
and -X- _ O
Goldwater -X- _ O
, -X- _ O
2013;Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2020.Adaptor -X- _ O
Grammars -X- _ O
are -X- _ O
non -X- _ O
- -X- _ O
parametric -X- _ O
Bayesian -X- _ O
models -X- _ O
that -X- _ O
are -X- _ O
composed -X- _ O
of -X- _ O
two -X- _ O
main -X- _ O
components -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ B-MethodName
Probabilistic -X- _ I-MethodName
Context -X- _ I-MethodName
- -X- _ I-MethodName
Free -X- _ I-MethodName
Grammar -X- _ I-MethodName
( -X- _ I-MethodName
PCFG -X- _ I-MethodName
) -X- _ I-MethodName
whose -X- _ O
definition -X- _ O
relies -X- _ O
on -X- _ O
the -X- _ O
underlying -X- _ O
task -X- _ O
( -X- _ O
in -X- _ O
the -X- _ O
case -X- _ O
of -X- _ O
morphological -X- _ O
segmentation -X- _ O
, -X- _ O
a -X- _ O
PCFG -X- _ O
models -X- _ O
word -X- _ O
structure -X- _ O
) -X- _ O
; -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
an -X- _ O
adaptor -X- _ B-MethodName
that -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
Pitman -X- _ B-MethodName
- -X- _ I-MethodName
Yor -X- _ I-MethodName
process -X- _ I-MethodName
( -X- _ O
Pitman -X- _ O
, -X- _ O
1995 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
adaptor -X- _ B-MethodName
keeps -X- _ O
the -X- _ O
posterior -X- _ O
probability -X- _ O
of -X- _ O
a -X- _ O
subtree -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
times -X- _ O
that -X- _ O
subtree -X- _ O
is -X- _ O
utilized -X- _ O
to -X- _ O
parse -X- _ O
the -X- _ O
input -X- _ O
data -X- _ O
and -X- _ O
manages -X- _ O
the -X- _ O
caching -X- _ O
of -X- _ O
the -X- _ O
subtrees -X- _ O
. -X- _ O
The -X- _ O
learning -X- _ O
process -X- _ O
is -X- _ B-MethodName
Markov -X- _ I-MethodName
Chain -X- _ I-MethodName
Monte -X- _ I-MethodName
Carlo -X- _ I-MethodName
sampling -X- _ I-MethodName
( -X- _ I-MethodName
MCMC -X- _ I-MethodName
) -X- _ I-MethodName
( -X- _ O
Andrieu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
that -X- _ O
does -X- _ O
the -X- _ O
inference -X- _ O
of -X- _ O
the -X- _ O
PCFG -X- _ O
probabilities -X- _ O
and -X- _ O
the -X- _ O
hyperparameters -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
define -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
languageindependent -X- _ O
grammars -X- _ O
and -X- _ O
three -X- _ O
learning -X- _ O
settings -X- _ O
for -X- _ B-MethodName
Adaptor -X- _ I-MethodName
Grammars -X- _ I-MethodName
: -X- _ O
1 -X- _ O
) -X- _ O
Standard -X- _ O
, -X- _ O
fully -X- _ O
unsupervised -X- _ O
; -X- _ O
2 -X- _ O
) -X- _ O
Scholar -X- _ O
- -X- _ O
Seeded -X- _ O
, -X- _ O
minimally -X- _ O
- -X- _ O
supervised -X- _ O
by -X- _ O
manually -X- _ O
seeding -X- _ O
affixes -X- _ O
into -X- _ O
the -X- _ O
grammar -X- _ O
prior -X- _ O
to -X- _ O
training -X- _ O
the -X- _ O
segmentation -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
3 -X- _ O
) -X- _ O
Cascaded -X- _ O
, -X- _ O
fully -X- _ O
unsupervised -X- _ O
by -X- _ O
approximating -X- _ O
the -X- _ O
Scholar -X- _ O
- -X- _ O
Seeded -X- _ O
setting -X- _ O
using -X- _ O
automatically -X- _ O
generated -X- _ O
af -X- _ O
- -X- _ O
fixes -X- _ O
from -X- _ O
an -X- _ O
initial -X- _ O
round -X- _ O
of -X- _ O
learning -X- _ O
. -X- _ O
We -X- _ O
next -X- _ O
present -X- _ O
two -X- _ O
ways -X- _ O
of -X- _ O
including -X- _ O
linguistic -X- _ O
priors -X- _ O
in -X- _ O
Adaptor -X- _ O
Grammars -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
defining -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
grammar -X- _ O
; -X- _ O
and -X- _ O
2 -X- _ O
) -X- _ O
using -X- _ O
linguist -X- _ O
- -X- _ O
provided -X- _ O
affixes -X- _ O
in -X- _ O
the -X- _ O
Scholar -X- _ O
- -X- _ O
Seeded -X- _ O
learning -X- _ O
setup -X- _ O
. -X- _ O
Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
define -X- _ O
languageindependent -X- _ O
grammars -X- _ O
that -X- _ O
model -X- _ O
the -X- _ O
word -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
generic -X- _ O
morphemes -X- _ O
or -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
prefixes -X- _ O
, -X- _ O
stem -X- _ O
and -X- _ O
suffixes -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
their -X- _ O
PrStSu+SM -X- _ B-MethodName
grammar -X- _ I-MethodName
in -X- _ O
the -X- _ O
current -X- _ O
study -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
the -X- _ O
grammar -X- _ O
that -X- _ O
performed -X- _ O
best -X- _ O
on -X- _ O
average -X- _ O
across -X- _ O
different -X- _ O
languages -X- _ O
. -X- _ O
This -X- _ O
language -X- _ O
- -X- _ O
independent -X- _ O
definition -X- _ O
of -X- _ O
the -X- _ O
grammar -X- _ O
is -X- _ O
depicted -X- _ O
on -X- _ O
the -X- _ O
left -X- _ O
side -X- _ O
of -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
word -X- _ O
is -X- _ O
modeled -X- _ O
as -X- _ O
a -X- _ O
prefix -X- _ O
Pr -X- _ O
, -X- _ O
a -X- _ O
stem -X- _ O
St -X- _ O
and -X- _ O
a -X- _ O
suffix -X- _ O
Su -X- _ O
, -X- _ O
and -X- _ O
both -X- _ O
the -X- _ O
prefix -X- _ O
and -X- _ O
suffix -X- _ O
are -X- _ O
recursively -X- _ O
defined -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
model -X- _ O
compounding -X- _ O
in -X- _ O
affixes -X- _ O
, -X- _ O
while -X- _ O
a -X- _ O
morpheme -X- _ O
is -X- _ O
composed -X- _ O
of -X- _ O
smaller -X- _ O
units -X- _ O
, -X- _ O
submorphemes -X- _ O
SM -X- _ O
, -X- _ O
representing -X- _ O
sequences -X- _ O
of -X- _ O
characters -X- _ O
. -X- _ O
While -X- _ O
this -X- _ O
grammar -X- _ O
is -X- _ O
intended -X- _ O
to -X- _ O
be -X- _ O
generic -X- _ O
and -X- _ O
to -X- _ O
describe -X- _ O
word -X- _ O
structure -X- _ O
in -X- _ O
any -X- _ O
language -X- _ O
, -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
a -X- _ O
definition -X- _ O
that -X- _ O
imposes -X- _ O
languagespecific -X- _ O
constraints -X- _ O
would -X- _ O
be -X- _ O
more -X- _ O
efficient -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
grammar -X- _ O
for -X- _ O
Japanese -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
use -X- _ O
characteristics -X- _ O
that -X- _ O
are -X- _ O
specific -X- _ O
to -X- _ O
Japane -X- _ O
- -X- _ O
se -X- _ O
word -X- _ O
structure -X- _ O
as -X- _ O
language -X- _ O
priors -X- _ O
. -X- _ O
Our -X- _ O
tailored -X- _ O
grammar -X- _ O
definition -X- _ O
for -X- _ O
Japanese -X- _ O
is -X- _ O
shown -X- _ O
on -X- _ O
the -X- _ O
right -X- _ O
side -X- _ O
of -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
impose -X- _ O
the -X- _ O
following -X- _ O
specifications -X- _ O
: -X- _ O
A -X- _ O
word -X- _ O
has -X- _ O
a -X- _ O
maximum -X- _ O
of -X- _ O
one -X- _ O
one -X- _ O
- -X- _ O
character -X- _ O
or -X- _ O
two -X- _ O
- -X- _ O
character -X- _ O
prefix -X- _ O
morphemes -X- _ O
. -X- _ O
A -X- _ O
stem -X- _ O
is -X- _ O
recursively -X- _ O
defined -X- _ O
as -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
morphemes -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
allow -X- _ O
for -X- _ O
stem -X- _ O
compounding -X- _ O
. -X- _ O
Characters -X- _ O
are -X- _ O
separated -X- _ O
into -X- _ O
two -X- _ O
groups -X- _ O
, -X- _ O
Kana -X- _ O
( -X- _ O
Japanese -X- _ O
syllabaries -X- _ O
) -X- _ O
and -X- _ O
Kanji -X- _ O
( -X- _ O
adapted -X- _ O
Chinese -X- _ O
characters).A -X- _ O
submorpheme -X- _ O
represents -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
characters -X- _ O
that -X- _ O
is -X- _ O
either -X- _ O
in -X- _ O
Kana -X- _ O
or -X- _ O
Kanji -X- _ O
. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
Scholar -X- _ O
- -X- _ O
Seeded -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
compile -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
affixes -X- _ O
and -X- _ O
seed -X- _ O
it -X- _ O
into -X- _ O
the -X- _ O
grammar -X- _ O
trees -X- _ O
before -X- _ O
learning -X- _ O
the -X- _ O
segmentation -X- _ O
model -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
unlike -X- _ O
Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
affixes -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
online -X- _ O
resources -X- _ O
by -X- _ O
someone -X- _ O
who -X- _ O
may -X- _ O
have -X- _ O
never -X- _ O
studied -X- _ O
the -X- _ O
language -X- _ O
of -X- _ O
interest -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
study -X- _ O
we -X- _ O
use -X- _ O
affixes -X- _ O
that -X- _ O
are -X- _ O
carefully -X- _ O
compiled -X- _ O
by -X- _ O
an -X- _ O
expert -X- _ O
linguist -X- _ O
who -X- _ O
specializes -X- _ O
in -X- _ O
Georgian -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
more -X- _ O
accurate -X- _ O
linguistic -X- _ O
priors -X- _ O
. -X- _ O
With -X- _ O
that -X- _ O
goal -X- _ O
in -X- _ O
mind -X- _ O
, -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
119 -X- _ O
affixes -X- _ O
are -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
leading -X- _ O
reference -X- _ O
grammar -X- _ O
book -X- _ O
( -X- _ O
Aronson -X- _ O
, -X- _ O
1990 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
annotate -X- _ O
two -X- _ O
datasets -X- _ O
with -X- _ O
morphological -X- _ B-TaskName
segmentation -X- _ I-TaskName
that -X- _ O
we -X- _ O
use -X- _ O
as -X- _ O
the -X- _ O
gold -X- _ O
standard -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
segmentation -X- _ B-TaskName
models -X- _ O
for -X- _ O
Japanese -X- _ O
and -X- _ O
Georgian -X- _ O
. -X- _ O
Both -X- _ O
datasets -X- _ O
are -X- _ O
composed -X- _ O
of -X- _ O
1,000 -X- _ O
words -X- _ O
that -X- _ O
are -X- _ O
randomly -X- _ O
sampled -X- _ O
from -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
50,000 -X- _ O
words -X- _ O
in -X- _ O
Wikipedia -X- _ O
and -X- _ O
segmented -X- _ O
into -X- _ O
their -X- _ O
basic -X- _ O
morphemes -X- _ O
3 -X- _ O
, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
Morpho -X- _ O
Challenge -X- _ O
shared -X- _ O
task -X- _ O
4 -X- _ O
. -X- _ O
Table -X- _ O
1 -X- _ O
lists -X- _ O
segmentation -X- _ O
examples -X- _ O
for -X- _ O
both -X- _ O
languages -X- _ O
. -X- _ O
The -X- _ O
Japanese -X- _ O
gold -X- _ O
segmentation -X- _ O
was -X- _ O
created -X- _ O
by -X- _ O
a -X- _ O
native -X- _ O
- -X- _ O
speaker -X- _ O
linguist -X- _ O
. -X- _ O
For -X- _ O
Georgian -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
highly -X- _ O
complex -X- _ O
morphology -X- _ O
, -X- _ O
we -X- _ O
started -X- _ O
with -X- _ O
the -X- _ O
gold -X- _ O
- -X- _ O
standard -X- _ O
dataset -X- _ O
of -X- _ O
1000 -X- _ O
words -X- _ O
introduced -X- _ O
by -X- _ O
Eskander -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
morphological -X- _ O
- -X- _ O
segmentation -X- _ O
models -X- _ O
for -X- _ O
Japanese -X- _ O
in -X- _ O
the -X- _ O
Standard -X- _ O
( -X- _ O
STD -X- _ O
) -X- _ O
and -X- _ O
Cascaded -X- _ O
( -X- _ O
CAS -X- _ O
) -X- _ O
5 -X- _ O
settings -X- _ O
, -X- _ O
both -X- _ O
with -X- _ O
generic -X- _ O
and -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
( -X- _ O
LS -X- _ O
) -X- _ O
grammar -X- _ O
definitions -X- _ O
. -X- _ O
For -X- _ O
Georgian -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
morphologicalsegmentation -X- _ O
models -X- _ O
in -X- _ O
the -X- _ O
Standard -X- _ O
( -X- _ O
STD -X- _ O
) -X- _ O
, -X- _ O
Cascaded -X- _ O
( -X- _ O
CAS -X- _ O
) -X- _ O
and -X- _ O
Scholar -X- _ O
- -X- _ O
Seeded -X- _ O
( -X- _ O
SS -X- _ O
) -X- _ O
settings -X- _ O
, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
proposed -X- _ O
Scholar -X- _ O
- -X- _ O
Seeded -X- _ O
setting -X- _ O
with -X- _ O
linguist -X- _ O
- -X- _ O
provided -X- _ O
affixes -X- _ O
( -X- _ O
SS -X- _ O
- -X- _ O
Ling).We -X- _ O
perform -X- _ O
the -X- _ O
evaluation -X- _ O
in -X- _ O
a -X- _ O
transductive -X- _ O
manner -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
unsegmented -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
gold -X- _ O
standard -X- _ O
are -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
sets -X- _ O
; -X- _ O
this -X- _ O
is -X- _ O
common -X- _ O
in -X- _ O
evaluating -X- _ O
unsupervised -X- _ O
and -X- _ O
minimally -X- _ B-TaskName
- -X- _ I-TaskName
supervised -X- _ I-TaskName
morphological -X- _ I-TaskName
segmentation -X- _ I-TaskName
( -X- _ O
Poon -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009;Sirts -X- _ O
and -X- _ O
Goldwater -X- _ O
, -X- _ O
2013;Narasimhan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2019Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2020 -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
metrics -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Boundary -X- _ O
Precision -X- _ O
and -X- _ O
Recall -X- _ O
( -X- _ O
BPR -X- _ O
) -X- _ O
and -X- _ O
EMMA-2 -X- _ O
( -X- _ O
Virpioja -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
BPR -X- _ B-MetricName
is -X- _ O
the -X- _ O
classical -X- _ O
metric -X- _ O
for -X- _ O
evaluating -X- _ O
morphological -X- _ B-TaskName
segmentation -X- _ I-TaskName
; -X- _ O
it -X- _ O
compares -X- _ O
the -X- _ O
boundaries -X- _ O
in -X- _ O
the -X- _ O
proposed -X- _ O
segmentation -X- _ O
to -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
reference -X- _ O
. -X- _ O
EMMA-2 -X- _ O
Table -X- _ O
3 -X- _ O
: -X- _ O
Category -X- _ O
- -X- _ O
wise -X- _ O
morphological -X- _ O
- -X- _ O
segmentation -X- _ O
performance -X- _ O
for -X- _ O
Georgian -X- _ O
using -X- _ O
the -X- _ O
BPR -X- _ O
and -X- _ O
EMMA-2 -X- _ O
metrics -X- _ O
. -X- _ O
AG -X- _ O
= -X- _ O
Adaptor -X- _ O
Grammars -X- _ O
. -X- _ O
SS -X- _ O
= -X- _ O
Scholar -X- _ O
- -X- _ O
Seeded -X- _ O
. -X- _ O
SS -X- _ O
- -X- _ O
Ling -X- _ O
= -X- _ O
Scholar -X- _ O
- -X- _ O
Seeded -X- _ O
with -X- _ O
linguist -X- _ O
- -X- _ O
provided -X- _ O
affixes.is -X- _ O
based -X- _ O
on -X- _ O
matching -X- _ O
the -X- _ O
morphemes -X- _ O
in -X- _ O
the -X- _ O
proposed -X- _ O
segmentation -X- _ O
to -X- _ O
those -X- _ O
in -X- _ O
the -X- _ O
reference -X- _ O
in -X- _ O
a -X- _ O
many -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
one -X- _ O
assignment -X- _ O
setup -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
our -X- _ O
system -X- _ O
versus -X- _ O
two -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
theart -X- _ O
unsupervised -X- _ O
baselines -X- _ O
: -X- _ O
MorphAGram -X- _ B-MethodName
without -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
linguistic -X- _ O
priors -X- _ O
and -X- _ O
Morfessor -X- _ B-MethodName
( -X- _ O
Virpioja -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
6 -X- _ O
. -X- _ O
Morfessor -X- _ B-MethodName
is -X- _ O
a -X- _ O
commonly -X- _ O
- -X- _ O
used -X- _ O
framework -X- _ O
for -X- _ O
unsupervised -X- _ B-TaskName
morphological -X- _ I-TaskName
segmentation -X- _ I-TaskName
. -X- _ O
It -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
an -X- _ O
HMM -X- _ B-MethodName
model -X- _ O
that -X- _ O
relies -X- _ O
on -X- _ O
the -X- _ O
Minimum -X- _ B-MethodName
Description -X- _ I-MethodName
Length -X- _ I-MethodName
( -X- _ O
MDL -X- _ O
) -X- _ O
concept -X- _ O
for -X- _ O
deriving -X- _ O
the -X- _ O
optimal -X- _ O
segmentation -X- _ O
( -X- _ O
Creutz -X- _ O
and -X- _ O
Lagus -X- _ O
, -X- _ O
2007b -X- _ O
) -X- _ O
. -X- _ O
Since -X- _ O
our -X- _ O
approach -X- _ O
does -X- _ O
not -X- _ O
assume -X- _ O
access -X- _ O
to -X- _ O
manually -X- _ O
annotated -X- _ O
segmentation -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
comparable -X- _ O
to -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
approaches -X- _ O
that -X- _ O
rely -X- _ O
on -X- _ O
such -X- _ O
annotations -X- _ O
( -X- _ O
Ruokolainen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Kann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
all -X- _ O
the -X- _ O
Adaptor -X- _ B-MethodName
- -X- _ I-MethodName
Grammar -X- _ I-MethodName
results -X- _ O
as -X- _ O
the -X- _ O
average -X- _ O
over -X- _ O
three -X- _ O
runs -X- _ O
of -X- _ O
different -X- _ O
randomization -X- _ O
parameters -X- _ O
. -X- _ O
Table -X- _ O
2 -X- _ O
reports -X- _ O
the -X- _ O
overall -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
for -X- _ O
both -X- _ O
Japanese -X- _ O
and -X- _ O
Georgian -X- _ O
, -X- _ O
while -X- _ O
Table -X- _ O
3 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
per -X- _ O
part -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
speech -X- _ O
category -X- _ O
for -X- _ O
Georgian -X- _ O
. -X- _ O
For -X- _ O
Japanese -X- _ O
, -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
grammar -X- _ O
definition -X- _ O
improves -X- _ O
both -X- _ O
precision -X- _ B-MetricName
and -X- _ O
recall -X- _ B-MetricName
, -X- _ O
resulting -X- _ O
in -X- _ O
BPR -X- _ B-MetricName
F1 -X- _ I-MetricName
- -X- _ O
score -X- _ O
error -X- _ B-MetricName
reductions -X- _ O
of -X- _ O
8.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
7.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
over -X- _ O
the -X- _ O
generic -X- _ O
Standard -X- _ O
and -X- _ O
Cascaded -X- _ O
settings -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
BPR -X- _ B-MetricName
F1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
error -X- _ I-MetricName
reduction -X- _ O
of -X- _ B-MetricValue
9.8 -X- _ I-MetricValue
% -X- _ I-MetricValue
over -X- _ O
Morfessor -X- _ B-MethodName
. -X- _ O
For -X- _ O
Georgian -X- _ O
, -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
linguist -X- _ O
- -X- _ O
provided -X- _ O
seeded -X- _ O
affixes -X- _ O
improves -X- _ O
both -X- _ O
precision -X- _ B-MetricName
and -X- _ O
recall -X- _ B-MetricName
, -X- _ O
where -X- _ O
the -X- _ O
recall -X- _ B-MetricName
significantly -X- _ O
increases -X- _ O
by -X- _ O
absolute -X- _ O
13.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
over -X- _ O
using -X- _ O
an -X- _ O
affix -X- _ O
list -X- _ O
of -X- _ O
lower -X- _ O
quality -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
the -X- _ O
proposed -X- _ O
linguistic -X- _ O
priors -X- _ O
result -X- _ O
in -X- _ O
BPR -X- _ B-MetricName
F1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
error -X- _ I-MetricName
reductions -X- _ O
of -X- _ O
34.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
30.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
31.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
over -X- _ O
the -X- _ O
Standard -X- _ O
, -X- _ O
Cascaded -X- _ O
and -X- _ O
regular -X- _ O
Scholar -X- _ O
- -X- _ O
Seeded -X- _ O
settings -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
BPR -X- _ B-MetricName
F1 -X- _ I-MetricName
- -X- _ I-MetricName
score -X- _ I-MetricName
error -X- _ I-MetricName
reduction -X- _ O
of -X- _ O
53.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
over -X- _ O
Morfessor -X- _ B-MethodName
. -X- _ O
Analysing -X- _ O
results -X- _ O
per -X- _ O
category -X- _ O
, -X- _ O
verbs -X- _ O
and -X- _ O
nouns -X- _ O
receive -X- _ O
the -X- _ O
biggest -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
score -X- _ O
improvements -X- _ O
of -X- _ O
absolute -X- _ O
14.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
4.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
respectively -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
linguist -X- _ O
- -X- _ O
provided -X- _ O
affixes -X- _ O
. -X- _ O
A -X- _ O
similar -X- _ O
pattern -X- _ O
of -X- _ O
results -X- _ O
is -X- _ O
found -X- _ O
with -X- _ O
EMMA-2 -X- _ B-MethodName
. -X- _ O
Finally -X- _ O
, -X- _ O
all -X- _ O
the -X- _ O
improvements -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
linguistic -X- _ O
priors -X- _ O
are -X- _ O
statistically -X- _ O
significant -X- _ O
( -X- _ O
P -X- _ B-HyperparameterName
< -X- _ O
0.01 -X- _ B-HyperparameterValue
) -X- _ O
on -X- _ O
both -X- _ O
metrics -X- _ O
. -X- _ O
Georgian -X- _ B-MethodName
segmentation -X- _ I-MethodName
models -X- _ I-MethodName
. -X- _ O
We -X- _ O
discuss -X- _ O
the -X- _ O
most -X- _ O
prominent -X- _ O
observations -X- _ O
below -X- _ O
. -X- _ O
Japanese -X- _ O
: -X- _ O
Both -X- _ O
the -X- _ O
STD -X- _ B-MethodName
and -X- _ B-MethodName
STD -X- _ I-MethodName
- -X- _ I-MethodName
LS -X- _ I-MethodName
models -X- _ O
perform -X- _ O
well -X- _ O
on -X- _ B-MethodName
prefix -X- _ I-MethodName
segmentation -X- _ I-MethodName
, -X- _ O
achieving -X- _ B-MetricName
F1 -X- _ I-MetricName
- -X- _ O
scores -X- _ O
of -X- _ O
more -X- _ O
than -X- _ O
90 -X- _ B-MetricValue
% -X- _ I-MetricValue
in -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
several -X- _ O
one -X- _ O
- -X- _ O
character -X- _ O
prefixes -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
お -X- _ O
and -X- _ O
ご -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
STD -X- _ B-MethodName
- -X- _ I-MethodName
LS -X- _ I-MethodName
outperforms -X- _ O
its -X- _ O
languageindependent -X- _ O
counterpart -X- _ O
in -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
stems -X- _ O
, -X- _ O
where -X- _ O
compounding -X- _ O
is -X- _ O
explicitly -X- _ O
modeled -X- _ O
. -X- _ O
For -X- _ O
instance -X- _ O
, -X- _ O
STD -X- _ B-MethodName
and -X- _ O
STD -X- _ B-MethodName
- -X- _ I-MethodName
LS -X- _ I-MethodName
achieve -X- _ O
F1 -X- _ B-MetricName
- -X- _ O
scores -X- _ O
of -X- _ O
15.8 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
98.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
respectively -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
detection -X- _ O
of -X- _ O
the -X- _ O
common -X- _ O
stem -X- _ O
られ -X- _ O
( -X- _ O
be -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
when -X- _ O
either -X- _ O
model -X- _ O
consistently -X- _ O
fails -X- _ O
to -X- _ O
detect -X- _ O
a -X- _ O
specific -X- _ O
morpheme -X- _ O
, -X- _ O
the -X- _ O
other -X- _ O
model -X- _ O
fails -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
neither -X- _ O
model -X- _ O
can -X- _ O
detect -X- _ O
the -X- _ O
morphemes -X- _ O
せん -X- _ O
and -X- _ O
かった -X- _ O
. -X- _ O
Georgian -X- _ O
: -X- _ O
SS -X- _ O
- -X- _ O
Ling -X- _ O
outperforms -X- _ O
both -X- _ O
STD -X- _ B-MethodName
and -X- _ O
SS -X- _ B-MethodName
at -X- _ O
discovering -X- _ O
the -X- _ O
top -X- _ O
most -X- _ O
frequent -X- _ O
one -X- _ O
- -X- _ O
letter -X- _ O
morphemes -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
i -X- _ O
, -X- _ O
a -X- _ O
, -X- _ O
s -X- _ O
, -X- _ O
e -X- _ O
, -X- _ O
m -X- _ O
, -X- _ O
o -X- _ O
and -X- _ O
v -X- _ O
, -X- _ O
achieving -X- _ O
an -X- _ O
average -X- _ B-MetricName
F1 -X- _ I-MetricName
- -X- _ O
score -X- _ O
of -X- _ O
76.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
compared -X- _ O
to -X- _ O
57.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
57.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
by -X- _ O
STD -X- _ B-MethodName
and -X- _ O
SS -X- _ B-MethodName
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
, -X- _ O
SS -X- _ B-MethodName
and -X- _ O
STD -X- _ B-MethodName
suffer -X- _ O
lower -X- _ O
precision -X- _ B-MetricName
as -X- _ O
they -X- _ O
tend -X- _ O
to -X- _ O
oversegment -X- _ O
the -X- _ O
morphemes -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
single -X- _ O
letter -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ B-MethodName
SS -X- _ I-MethodName
- -X- _ I-MethodName
Ling -X- _ I-MethodName
can -X- _ O
recognize -X- _ O
the -X- _ O
most -X- _ O
frequent -X- _ O
two -X- _ O
- -X- _ O
letter -X- _ O
morphemes -X- _ O
, -X- _ O
namely -X- _ O
eb -X- _ O
and -X- _ O
da -X- _ O
, -X- _ O
with -X- _ O
absolute -X- _ O
increases -X- _ O
in -X- _ O
precision -X- _ B-MetricName
of -X- _ B-MetricValue
59.0 -X- _ I-MetricValue
% -X- _ I-MetricValue
and -X- _ O
62.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
over -X- _ O
STD -X- _ B-MethodName
and -X- _ O
SS -X- _ B-MethodName
, -X- _ O
respectively -X- _ O
; -X- _ O
both -X- _ O
morphemes -X- _ O
are -X- _ O
explicitly -X- _ O
seeded -X- _ O
into -X- _ O
the -X- _ O
SS -X- _ O
- -X- _ O
Ling -X- _ O
grammar -X- _ O
prior -X- _ O
to -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
proposed -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
linguistic -X- _ O
priors -X- _ O
for -X- _ O
minimally -X- _ B-TaskName
- -X- _ I-TaskName
supervised -X- _ I-TaskName
morphological -X- _ I-TaskName
segmentation -X- _ I-TaskName
using -X- _ O
Adaptor -X- _ B-MethodName
Grammars -X- _ I-MethodName
. -X- _ O
The -X- _ O
first -X- _ O
prior -X- _ O
is -X- _ O
in -X- _ O
the -X- _ O
form -X- _ O
of -X- _ O
defining -X- _ O
a -X- _ O
language -X- _ O
- -X- _ O
specific -X- _ O
grammar -X- _ O
, -X- _ O
whi -X- _ O
- -X- _ O
le -X- _ O
the -X- _ O
second -X- _ O
relies -X- _ O
on -X- _ O
compiling -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
linguistprovided -X- _ O
affixes -X- _ O
and -X- _ O
seeding -X- _ O
it -X- _ O
into -X- _ O
the -X- _ O
grammars -X- _ O
. -X- _ O
Our -X- _ O
approaches -X- _ O
result -X- _ O
in -X- _ O
error -X- _ B-MetricName
reductions -X- _ O
of -X- _ O
8.9 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
for -X- _ O
Japanese -X- _ O
, -X- _ O
and -X- _ O
34.2 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
for -X- _ O
Georgian -X- _ O
, -X- _ O
as -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
system -X- _ O
. -X- _ O
In -X- _ O
future -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
plan -X- _ O
to -X- _ O
explore -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
linguistic -X- _ O
priors -X- _ O
that -X- _ O
apply -X- _ O
to -X- _ O
a -X- _ O
group -X- _ O
of -X- _ O
morphologically -X- _ O
similar -X- _ O
lowresource -X- _ O
languages -X- _ O
. -X- _ O
This -X- _ O
research -X- _ O
is -X- _ O
based -X- _ O
upon -X- _ O
work -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Intelligence -X- _ O
Advanced -X- _ O
Research -X- _ O
Projects -X- _ O
Activity -X- _ O
( -X- _ O
IARPA -X- _ O
) -X- _ O
, -X- _ O
( -X- _ O
contract -X- _ O
# -X- _ O
FA8650 -X- _ O
- -X- _ O
17 -X- _ O
- -X- _ O
C-9117 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
( -X- _ O
awards -X- _ O
# -X- _ O
1941742 -X- _ O
and -X- _ O
# -X- _ O
1941733 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
views -X- _ O
and -X- _ O
conclusions -X- _ O
herein -X- _ O
are -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
authors -X- _ O
and -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
necessarily -X- _ O
representing -X- _ O
official -X- _ O
policies -X- _ O
, -X- _ O
expressed -X- _ O
or -X- _ O
implied -X- _ O
, -X- _ O
of -X- _ O
ODNI -X- _ O
, -X- _ O
IARPA -X- _ O
, -X- _ O
NSF -X- _ O
or -X- _ O
the -X- _ O
U.S. -X- _ O
Government -X- _ O
. -X- _ O
The -X- _ O
U.S. -X- _ O
Government -X- _ O
is -X- _ O
authorized -X- _ O
to -X- _ O
reproduce -X- _ O
and -X- _ O
distribute -X- _ O
reprints -X- _ O
for -X- _ O
governmental -X- _ O
purposes -X- _ O
notwithstanding -X- _ O
any -X- _ O
copyright -X- _ O
annotation -X- _ O
therein -X- _ O
. -X- _ O
The -X- _ O
Japanese -X- _ O
annotations -X- _ O
were -X- _ O
done -X- _ O
by -X- _ O
a -X- _ O
linguist -X- _ O
with -X- _ O
appropriate -X- _ O
compensation -X- _ O
; -X- _ O
we -X- _ O
thus -X- _ O
have -X- _ O
ownership -X- _ O
of -X- _ O
the -X- _ O
Japanese -X- _ O
dataset -X- _ O
for -X- _ O
open -X- _ O
distribution -X- _ O
. -X- _ O
We -X- _ O
have -X- _ O
been -X- _ O
granted -X- _ O
the -X- _ O
rights -X- _ O
to -X- _ O
modify -X- _ O
and -X- _ O
distribute -X- _ O
the -X- _ O
dataset -X- _ O
for -X- _ O
Georgian -X- _ O
by -X- _ O
Eskander -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
annotations -X- _ O
were -X- _ O
done -X- _ O
in -X- _ O
- -X- _ O
house -X- _ O
by -X- _ O
a -X- _ O
paid -X- _ O
linguist -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
the -X- _ O
annotations -X- _ O
was -X- _ O
examined -X- _ O
, -X- _ O
both -X- _ O
manually -X- _ O
and -X- _ O
empirically -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
article -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
our -X- _ O
methodologies -X- _ O
for -X- _ O
SemEval-2021 -X- _ B-DatasetName
Task-4 -X- _ I-DatasetName
: -X- _ O
Reading -X- _ B-TaskName
Comprehension -X- _ I-TaskName
of -X- _ I-TaskName
Abstract -X- _ I-TaskName
Meaning -X- _ I-TaskName
. -X- _ O
Given -X- _ O
a -X- _ O
fill -X- _ O
- -X- _ O
inthe -X- _ O
- -X- _ O
blank -X- _ O
- -X- _ O
type -X- _ O
question -X- _ O
and -X- _ O
a -X- _ O
corresponding -X- _ O
context -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
most -X- _ O
suitable -X- _ O
word -X- _ O
from -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
5 -X- _ O
options -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
three -X- _ O
sub -X- _ O
- -X- _ O
tasks -X- _ O
within -X- _ O
this -X- _ O
task -X- _ O
: -X- _ O
Imperceptibility -X- _ B-TaskName
( -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
) -X- _ O
, -X- _ O
Non -X- _ B-TaskName
- -X- _ I-TaskName
Specificity -X- _ I-TaskName
( -X- _ O
subtask -X- _ O
- -X- _ O
II -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Intersection -X- _ B-TaskName
( -X- _ O
subtask -X- _ O
- -X- _ O
III -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
encoders -X- _ B-MethodName
of -X- _ I-MethodName
transformers -X- _ I-MethodName
- -X- _ I-MethodName
based -X- _ I-MethodName
models -X- _ I-MethodName
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
modelling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
task -X- _ O
to -X- _ O
build -X- _ O
our -X- _ O
Fill -X- _ B-MethodName
- -X- _ I-MethodName
in -X- _ I-MethodName
- -X- _ I-MethodName
the -X- _ I-MethodName
- -X- _ I-MethodName
blank -X- _ I-MethodName
( -X- _ I-MethodName
FitB -X- _ I-MethodName
) -X- _ I-MethodName
models -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
to -X- _ O
model -X- _ O
imperceptibility -X- _ B-MetricValue
, -X- _ O
we -X- _ O
define -X- _ O
certain -X- _ O
linguistic -X- _ O
features -X- _ O
, -X- _ O
and -X- _ O
to -X- _ O
model -X- _ O
non -X- _ B-MetricValue
- -X- _ I-MetricValue
specificity -X- _ I-MetricValue
, -X- _ O
we -X- _ O
leverage -X- _ O
information -X- _ O
from -X- _ O
hypernyms -X- _ O
and -X- _ O
hyponyms -X- _ O
provided -X- _ O
by -X- _ O
a -X- _ O
lexical -X- _ O
database -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
for -X- _ B-MetricValue
non -X- _ I-MetricValue
- -X- _ I-MetricValue
specificity -X- _ I-MetricValue
, -X- _ O
we -X- _ O
try -X- _ O
out -X- _ O
augmentation -X- _ O
techniques -X- _ O
, -X- _ O
and -X- _ O
other -X- _ O
statistical -X- _ O
techniques -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
propose -X- _ O
variants -X- _ O
, -X- _ O
namely -X- _ O
Chunk -X- _ B-MethodName
Voting -X- _ I-MethodName
and -X- _ O
Max -X- _ B-MethodName
Context -X- _ I-MethodName
, -X- _ O
to -X- _ O
take -X- _ O
care -X- _ O
of -X- _ O
input -X- _ O
length -X- _ O
restrictions -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
etc -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
thorough -X- _ O
ablation -X- _ O
study -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
Integrated -X- _ B-MethodName
Gradients -X- _ I-MethodName
to -X- _ O
explain -X- _ O
our -X- _ O
predictions -X- _ O
on -X- _ O
a -X- _ O
few -X- _ O
samples -X- _ O
. -X- _ O
Our -X- _ O
best -X- _ O
submissions -X- _ O
achieve -X- _ O
accuracies -X- _ B-MetricName
of -X- _ O
75.31 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
77.84 -X- _ B-MetricValue
% -X- _ I-MetricValue
, -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
sets -X- _ O
for -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
and -X- _ O
subtask -X- _ O
- -X- _ O
II -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
For -X- _ O
subtask -X- _ O
- -X- _ O
III -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
accuracies -X- _ B-MetricName
of -X- _ O
65.64 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
62.27 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
The -X- _ O
code -X- _ O
is -X- _ O
available -X- _ O
here -X- _ O
. -X- _ O
A -X- _ O
very -X- _ O
common -X- _ O
assessment -X- _ O
in -X- _ O
schools -X- _ O
is -X- _ O
questionanswering -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
given -X- _ O
" -X- _ O
comprehension -X- _ O
passage -X- _ O
" -X- _ O
. -X- _ O
Students -X- _ O
are -X- _ O
given -X- _ O
a -X- _ O
comprehension -X- _ O
passage -X- _ O
, -X- _ O
from -X- _ O
which -X- _ O
they -X- _ O
are -X- _ O
supposed -X- _ O
to -X- _ O
glean -X- _ O
necessary -X- _ O
information -X- _ O
, -X- _ O
and -X- _ O
answer -X- _ O
short -X- _ O
questions -X- _ O
( -X- _ O
such -X- _ O
as -X- _ O
fill -X- _ O
- -X- _ O
in -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
blanks -X- _ O
- -X- _ O
type -X- _ O
question -X- _ O
) -X- _ O
based -X- _ O
on -X- _ O
what -X- _ O
they -X- _ O
have -X- _ O
garnered -X- _ O
from -X- _ O
the -X- _ O
given -X- _ O
passage -X- _ O
. -X- _ O
While -X- _ O
trying -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
most -X- _ O
appropriate -X- _ O
word -X- _ O
for -X- _ O
the -X- _ O
blank -X- _ O
, -X- _ O
the -X- _ O
children -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
words -X- _ O
surrounding -X- _ O
the -X- _ O
blank -X- _ O
* -X- _ O
Equal -X- _ O
contribution -X- _ O
. -X- _ O
Author -X- _ O
ordering -X- _ O
determined -X- _ O
by -X- _ O
coin -X- _ O
flip -X- _ O
. -X- _ O
( -X- _ O
" -X- _ O
context -X- _ O
" -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
word -X- _ O
should -X- _ O
be -X- _ O
such -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
word -X- _ O
fills -X- _ O
the -X- _ O
blank -X- _ O
, -X- _ O
the -X- _ O
sentence -X- _ O
makes -X- _ O
sense -X- _ O
and -X- _ O
it -X- _ O
is -X- _ O
grammatically -X- _ O
correct -X- _ O
. -X- _ O
Inspired -X- _ O
by -X- _ O
this -X- _ O
, -X- _ O
and -X- _ O
perhaps -X- _ O
, -X- _ O
after -X- _ O
the -X- _ O
enormous -X- _ O
success -X- _ O
of -X- _ O
Transformers -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
researchers -X- _ O
at -X- _ O
Google -X- _ O
came -X- _ O
up -X- _ O
with -X- _ O
a -X- _ O
large -X- _ O
number -X- _ O
of -X- _ O
" -X- _ O
pretraining -X- _ O
tasks -X- _ O
" -X- _ O
and -X- _ O
built -X- _ O
knowledge -X- _ O
- -X- _ O
heavy -X- _ O
language -X- _ O
models -X- _ O
which -X- _ O
could -X- _ O
be -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
various -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
( -X- _ O
NLP -X- _ O
) -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
One -X- _ O
of -X- _ O
the -X- _ O
earlier -X- _ O
pretraining -X- _ O
tasks -X- _ O
was -X- _ O
" -X- _ O
Masked -X- _ O
Language -X- _ O
Modelling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
" -X- _ O
, -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
pretraining -X- _ O
tasks -X- _ O
of -X- _ O
the -X- _ O
breakthrough -X- _ O
model -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
approach -X- _ O
here -X- _ O
was -X- _ O
similar -X- _ O
to -X- _ O
how -X- _ O
kids -X- _ O
are -X- _ O
taught -X- _ O
language -X- _ O
at -X- _ O
school -X- _ O
: -X- _ O
some -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
were -X- _ O
randomly -X- _ O
" -X- _ O
masked -X- _ O
" -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
was -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
these -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O
SemEval-2021 -X- _ B-DatasetName
Task-4 -X- _ I-DatasetName
( -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
focuses -X- _ O
on -X- _ O
a -X- _ O
similar -X- _ O
idea -X- _ O
. -X- _ O
Every -X- _ O
sample -X- _ O
has -X- _ O
an -X- _ O
article -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
corresponding -X- _ O
question -X- _ O
. -X- _ O
The -X- _ O
question -X- _ O
has -X- _ O
a -X- _ O
blank -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
supposed -X- _ O
to -X- _ O
predict -X- _ O
from -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
5 -X- _ O
options -X- _ O
. -X- _ O
The -X- _ O
novelty -X- _ O
in -X- _ O
the -X- _ O
task -X- _ O
lies -X- _ O
in -X- _ O
its -X- _ O
3 -X- _ O
subtasks -X- _ O
: -X- _ O
Imperceptibility -X- _ B-TaskName
( -X- _ I-TaskName
subtask -X- _ I-TaskName
- -X- _ I-TaskName
I -X- _ I-TaskName
) -X- _ I-TaskName
, -X- _ I-TaskName
Non -X- _ I-TaskName
- -X- _ I-TaskName
Specificity -X- _ I-TaskName
( -X- _ I-TaskName
subtask -X- _ I-TaskName
- -X- _ I-TaskName
II -X- _ I-TaskName
) -X- _ I-TaskName
, -X- _ I-TaskName
and -X- _ I-TaskName
Intersection -X- _ I-TaskName
( -X- _ I-TaskName
subtask -X- _ I-TaskName
- -X- _ I-TaskName
III -X- _ I-TaskName
) -X- _ O
. -X- _ O
A -X- _ O
description -X- _ O
of -X- _ O
these -X- _ O
subtasks -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
using -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
its -X- _ O
derivative -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
DistilBERT -X- _ B-MethodName
, -X- _ O
ALBERT -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
2 -X- _ O
BERT -X- _ B-MethodName
variants -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
BERT -X- _ B-MethodName
Voting -X- _ I-MethodName
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
BERT -X- _ B-MethodName
Max -X- _ I-MethodName
. -X- _ O
Context -X- _ O
. -X- _ O
Most -X- _ O
importantly -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
model -X- _ O
the -X- _ O
concepts -X- _ O
of -X- _ O
imperceptibility -X- _ B-TaskName
and -X- _ O
non -X- _ B-TaskName
- -X- _ I-TaskName
specificity -X- _ I-TaskName
. -X- _ O
For -X- _ O
imperceptibility -X- _ B-TaskName
, -X- _ O
we -X- _ O
create -X- _ O
statistical -X- _ O
embeddings -X- _ O
using -X- _ O
features -X- _ O
that -X- _ O
have -X- _ O
a -X- _ O
high -X- _ O
correlation -X- _ O
with -X- _ O
concreteness -X- _ O
. -X- _ O
For -X- _ O
non -X- _ B-TaskName
- -X- _ I-TaskName
specificity -X- _ I-TaskName
, -X- _ O
we -X- _ O
propose -X- _ O
two -X- _ O
approaches -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
we -X- _ O
augment -X- _ O
the -X- _ O
dataset -X- _ O
by -X- _ O
replacing -X- _ O
some -X- _ O
nouns -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
by -X- _ O
their -X- _ O
hypernyms -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
options -X- _ O
' -X- _ O
hyponyms -X- _ O
to -X- _ O
decide -X- _ O
the -X- _ O
most -X- _ O
appropriate -X- _ O
option -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
experiement -X- _ O
with -X- _ O
GA -X- _ O
- -X- _ O
Reader -X- _ O
( -X- _ O
Dhingra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017b -X- _ O
) -X- _ O
and -X- _ O
GSAMNbased -X- _ O
approaches -X- _ O
( -X- _ O
Lai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
by -X- _ O
trying -X- _ O
out -X- _ O
their -X- _ O
various -X- _ O
combinations -X- _ O
with -X- _ O
BERT.In -X- _ B-MethodName
Section -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
a -X- _ O
succinct -X- _ O
literature -X- _ O
survey -X- _ O
. -X- _ O
Section -X- _ O
3 -X- _ O
elucidates -X- _ O
our -X- _ O
approach -X- _ O
, -X- _ O
including -X- _ O
the -X- _ O
modelling -X- _ O
aspect -X- _ O
, -X- _ O
the -X- _ O
various -X- _ O
variants -X- _ O
of -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
different -X- _ O
ways -X- _ O
we -X- _ O
model -X- _ O
imperceptibility -X- _ B-TaskName
and -X- _ O
non -X- _ B-TaskName
- -X- _ I-TaskName
specificity -X- _ I-TaskName
. -X- _ O
In -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
an -X- _ O
extensive -X- _ O
ablation -X- _ O
and -X- _ O
comparative -X- _ O
study -X- _ O
. -X- _ O
The -X- _ O
advent -X- _ O
of -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
question -X- _ O
answering -X- _ O
systems -X- _ O
began -X- _ O
with -X- _ O
straightforward -X- _ O
tasks -X- _ O
, -X- _ O
like -X- _ O
the -X- _ O
one -X- _ O
introduced -X- _ O
by -X- _ O
the -X- _ O
SimpleQuestions -X- _ B-DatasetName
Dataset -X- _ O
( -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
consisted -X- _ O
of -X- _ O
knowledgebase -X- _ O
fact -X- _ O
triples -X- _ O
which -X- _ O
were -X- _ O
later -X- _ O
used -X- _ O
to -X- _ O
answer -X- _ O
questions -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
dataset -X- _ O
would -X- _ O
only -X- _ O
judge -X- _ O
a -X- _ O
model -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
ability -X- _ O
to -X- _ O
relate -X- _ O
the -X- _ O
facts -X- _ O
to -X- _ O
the -X- _ O
question -X- _ O
at -X- _ O
hand -X- _ O
. -X- _ O
The -X- _ O
purpose -X- _ O
of -X- _ O
NLP -X- _ O
research -X- _ O
is -X- _ O
to -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
generalised -X- _ O
model -X- _ O
that -X- _ O
may -X- _ O
answer -X- _ O
questions -X- _ O
based -X- _ O
on -X- _ O
any -X- _ O
context -X- _ O
, -X- _ O
thus -X- _ O
datasets -X- _ O
like -X- _ O
the -X- _ O
CNN -X- _ B-DatasetName
Daily -X- _ I-DatasetName
Mail -X- _ I-DatasetName
( -X- _ O
Hermann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
were -X- _ O
created -X- _ O
. -X- _ O
In -X- _ O
a -X- _ O
typical -X- _ O
question -X- _ O
- -X- _ O
answering -X- _ O
dataset -X- _ O
, -X- _ O
an -X- _ O
original -X- _ O
and -X- _ O
anonymised -X- _ O
context -X- _ O
is -X- _ O
provided -X- _ O
before -X- _ O
each -X- _ O
question -X- _ O
. -X- _ O
Before -X- _ O
transformers -X- _ O
, -X- _ O
methods -X- _ O
consisting -X- _ O
of -X- _ O
LSTM -X- _ B-MethodName
/ -X- _ I-MethodName
GRUs -X- _ I-MethodName
were -X- _ O
used -X- _ O
to -X- _ O
achieve -X- _ O
good -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
aforementioned -X- _ O
tasks -X- _ O
. -X- _ O
These -X- _ O
datasets -X- _ O
however -X- _ O
, -X- _ O
always -X- _ O
had -X- _ O
answers -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
The -X- _ O
CLOTH -X- _ B-DatasetName
( -X- _ O
Xie -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
dataset -X- _ O
focuses -X- _ O
on -X- _ O
passages -X- _ O
from -X- _ O
middle -X- _ O
- -X- _ O
school -X- _ O
and -X- _ O
high -X- _ O
- -X- _ O
school -X- _ O
text -X- _ O
, -X- _ O
with -X- _ O
multiple -X- _ O
fill -X- _ O
- -X- _ O
in -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
blanks -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
The -X- _ O
ReCAM -X- _ B-DatasetName
( -X- _ O
Zheng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2021 -X- _ O
) -X- _ O
dataset -X- _ O
puts -X- _ O
a -X- _ O
twist -X- _ O
to -X- _ O
archetypal -X- _ O
fill -X- _ O
- -X- _ O
in -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
blank -X- _ O
datasets -X- _ O
by -X- _ O
providing -X- _ O
answer -X- _ O
choices -X- _ O
that -X- _ O
are -X- _ O
abstract -X- _ O
in -X- _ O
some -X- _ O
form -X- _ O
and -X- _ O
which -X- _ O
are -X- _ O
not -X- _ O
available -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
itself -X- _ O
. -X- _ O
The -X- _ O
models -X- _ O
created -X- _ O
for -X- _ O
the -X- _ O
QA -X- _ O
task -X- _ O
have -X- _ O
to -X- _ O
take -X- _ O
into -X- _ O
account -X- _ O
semantic -X- _ O
relations -X- _ O
between -X- _ O
the -X- _ O
options -X- _ O
and -X- _ O
the -X- _ O
context -X- _ O
. -X- _ B-MethodName
GA -X- _ I-MethodName
- -X- _ I-MethodName
Reader -X- _ I-MethodName
( -X- _ O
Dhingra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017b -X- _ O
) -X- _ O
, -X- _ O
is -X- _ O
one -X- _ O
such -X- _ O
model -X- _ O
, -X- _ O
which -X- _ O
utilises -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
hop -X- _ O
architecture -X- _ O
with -X- _ O
a -X- _ O
novel -X- _ O
attention -X- _ O
mechanism -X- _ O
, -X- _ O
that -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
baseline -X- _ O
to -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
Cloze -X- _ O
- -X- _ O
Style -X- _ O
QAThe -X- _ O
first -X- _ O
model -X- _ O
we -X- _ O
employ -X- _ O
follows -X- _ O
a -X- _ O
cloze -X- _ B-MethodName
- -X- _ I-MethodName
style -X- _ I-MethodName
question -X- _ I-MethodName
answering -X- _ I-MethodName
approach -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
use -X- _ O
various -X- _ O
pretrained -X- _ O
transformer -X- _ O
models -X- _ O
as -X- _ O
encoders -X- _ O
, -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
decoder -X- _ O
layer -X- _ O
, -X- _ O
which -X- _ O
helps -X- _ O
us -X- _ O
to -X- _ O
select -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
leverage -X- _ O
BERT -X- _ B-MethodName
along -X- _ O
with -X- _ O
some -X- _ O
of -X- _ O
its -X- _ O
popular -X- _ O
and -X- _ O
successful -X- _ O
variants -X- _ O
such -X- _ O
as -X- _ O
: -X- _ B-MethodName
Dis -X- _ I-MethodName
- -X- _ I-MethodName
tilBERT -X- _ I-MethodName
, -X- _ I-MethodName
ALBERT -X- _ I-MethodName
, -X- _ I-MethodName
and -X- _ I-MethodName
RoBERTa -X- _ I-MethodName
. -X- _ O
In -X- _ O
the -X- _ O
MLM -X- _ O
task -X- _ O
, -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
text -X- _ O
are -X- _ O
randomly -X- _ O
masked -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
in -X- _ O
a -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
way -X- _ O
to -X- _ O
predict -X- _ O
these -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O
Conceptually -X- _ O
, -X- _ O
these -X- _ O
transformers -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
are -X- _ O
expected -X- _ O
to -X- _ O
take -X- _ O
care -X- _ O
of -X- _ O
bidirectional -X- _ O
context -X- _ O
while -X- _ O
predicting -X- _ O
the -X- _ O
masked -X- _ O
token -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
method -X- _ O
, -X- _ O
firstly -X- _ O
, -X- _ O
the -X- _ O
transformer -X- _ O
model -X- _ O
learn -X- _ O
the -X- _ O
contextual -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
article -X- _ O
and -X- _ O
the -X- _ O
question -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
next -X- _ O
block -X- _ O
, -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
masked -X- _ O
token -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
blank -X- _ O
) -X- _ O
is -X- _ O
passed -X- _ O
through -X- _ O
a -X- _ O
fully -X- _ O
- -X- _ O
connected -X- _ O
layer -X- _ O
, -X- _ O
of -X- _ O
which -X- _ O
, -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
outputs -X- _ O
corresponds -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
vocabulary -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
pretrained -X- _ O
model -X- _ O
. -X- _ O
Each -X- _ O
candidate -X- _ O
option -X- _ O
is -X- _ O
first -X- _ O
tokenised -X- _ O
using -X- _ O
WordPiece -X- _ B-MethodName
tokeniser -X- _ I-MethodName
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
mapped -X- _ O
to -X- _ O
the -X- _ O
vector -X- _ O
in -X- _ O
the -X- _ O
output -X- _ O
vocabulary -X- _ O
space -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
candidate -X- _ O
option -X- _ O
generates -X- _ O
multiple -X- _ O
tokens -X- _ O
, -X- _ O
we -X- _ O
average -X- _ O
the -X- _ O
mapped -X- _ O
scores -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
chooses -X- _ O
the -X- _ O
option -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
logit -X- _ O
value -X- _ O
. -X- _ O
An -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
given -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O
Nouns -X- _ O
can -X- _ O
be -X- _ O
clearly -X- _ O
demarcated -X- _ O
into -X- _ O
two -X- _ O
broad -X- _ O
categories -X- _ O
: -X- _ O
Concrete -X- _ O
Nouns -X- _ O
, -X- _ O
and -X- _ O
Abstract -X- _ O
Nouns -X- _ O
. -X- _ O
Concrete -X- _ O
Nouns -X- _ O
are -X- _ O
words -X- _ O
that -X- _ O
represent -X- _ O
tangible -X- _ O
concepts -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
any -X- _ O
noun -X- _ O
referring -X- _ O
to -X- _ O
a -X- _ O
name -X- _ O
, -X- _ O
place -X- _ O
, -X- _ O
object -X- _ O
, -X- _ O
material -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
is -X- _ O
considered -X- _ O
a -X- _ O
concrete -X- _ O
word -X- _ O
. -X- _ O
Concrete -X- _ O
words -X- _ O
refer -X- _ O
to -X- _ O
concepts -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
felt -X- _ O
by -X- _ O
5 -X- _ O
human -X- _ O
senses -X- _ O
: -X- _ O
Sight -X- _ O
, -X- _ O
Sound -X- _ O
, -X- _ O
Smell -X- _ O
, -X- _ O
Taste -X- _ O
, -X- _ O
and -X- _ O
Touch -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
any -X- _ O
noun -X- _ O
alluding -X- _ O
to -X- _ O
an -X- _ O
abstract -X- _ O
concept -X- _ O
that -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
experienced -X- _ O
by -X- _ O
our -X- _ O
senses -X- _ O
is -X- _ O
an -X- _ O
abstract -X- _ O
word -X- _ O
( -X- _ O
Spreen -X- _ O
and -X- _ O
Schulz -X- _ O
, -X- _ O
1966 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
most -X- _ O
accurate -X- _ O
and -X- _ O
the -X- _ O
most -X- _ O
imperceptible -X- _ O
word -X- _ O
from -X- _ O
the -X- _ O
given -X- _ O
options -X- _ O
. -X- _ O
Length -X- _ O
and -X- _ O
Frequency -X- _ O
of -X- _ O
the -X- _ O
Word -X- _ O
In -X- _ O
existing -X- _ O
literature -X- _ O
, -X- _ O
authors -X- _ O
have -X- _ O
claimed -X- _ O
that -X- _ O
there -X- _ O
exists -X- _ O
strong -X- _ O
evidence -X- _ O
that -X- _ O
concrete -X- _ O
words -X- _ O
are -X- _ O
, -X- _ O
in -X- _ O
general -X- _ O
, -X- _ O
shorter -X- _ O
than -X- _ O
abstract -X- _ O
words -X- _ O
( -X- _ O
Tanaka -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
A -X- _ O
reasonable -X- _ O
justification -X- _ O
provided -X- _ O
is -X- _ O
that -X- _ O
more -X- _ O
frequently -X- _ O
used -X- _ O
words -X- _ O
tend -X- _ O
to -X- _ O
be -X- _ O
short -X- _ O
( -X- _ O
Feng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
and -X- _ O
since -X- _ O
humans -X- _ O
have -X- _ O
a -X- _ O
penchant -X- _ O
for -X- _ O
describing -X- _ O
objects -X- _ O
, -X- _ O
places -X- _ O
, -X- _ O
or -X- _ O
things -X- _ O
near -X- _ O
them -X- _ O
, -X- _ O
these -X- _ O
frequently -X- _ O
used -X- _ O
words -X- _ O
are -X- _ O
generally -X- _ O
concrete -X- _ O
nouns -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
rather -X- _ O
intuitive -X- _ O
that -X- _ O
humans -X- _ O
would -X- _ O
prefer -X- _ O
ease -X- _ O
in -X- _ O
the -X- _ O
pronunciation -X- _ O
of -X- _ O
oft -X- _ O
- -X- _ O
used -X- _ O
words -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
many -X- _ O
abstract -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
English -X- _ O
language -X- _ O
are -X- _ O
formed -X- _ O
by -X- _ O
adding -X- _ O
suffixes -X- _ O
to -X- _ O
the -X- _ O
root -X- _ O
word -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
coarse -X- _ O
" -X- _ O
becomes -X- _ O
" -X- _ O
coarseness -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
forget -X- _ O
" -X- _ O
becomes -X- _ O
" -X- _ O
forgetfulness -X- _ O
" -X- _ O
and -X- _ O
so -X- _ O
on -X- _ O
( -X- _ O
Tanaka -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
Linguistics -X- _ O
, -X- _ O
polysemy -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
capacity -X- _ O
for -X- _ O
a -X- _ O
word -X- _ O
to -X- _ O
have -X- _ O
multiple -X- _ O
meanings -X- _ O
or -X- _ O
senses -X- _ O
. -X- _ O
Abstract -X- _ O
nouns -X- _ O
are -X- _ O
observed -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
" -X- _ O
polysemous -X- _ O
" -X- _ O
than -X- _ O
concrete -X- _ O
nouns -X- _ O
( -X- _ O
Tanaka -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
Word -X- _ B-DatasetName
- -X- _ I-DatasetName
Net -X- _ I-DatasetName
( -X- _ O
Fellbaum -X- _ O
, -X- _ O
1998 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
" -X- _ O
dog -X- _ O
" -X- _ O
has -X- _ O
8 -X- _ O
senses -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
word -X- _ O
" -X- _ O
love -X- _ O
" -X- _ O
has -X- _ O
10 -X- _ O
senses -X- _ O
. -X- _ O
Tanaka -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
2013 -X- _ O
find -X- _ O
a -X- _ O
direct -X- _ O
correlation -X- _ O
between -X- _ O
the -X- _ O
abstractness -X- _ O
of -X- _ O
a -X- _ O
noun -X- _ O
and -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
hyponyms -X- _ O
the -X- _ O
word -X- _ O
has -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
hyponyms -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
commonly -X- _ O
occurring -X- _ O
sense -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
number -X- _ O
of -X- _ O
hyponyms -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
senses -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
. -X- _ O
Score -X- _ O
- -X- _ O
based -X- _ O
Features -X- _ O
Abstract -X- _ O
nouns -X- _ O
evoke -X- _ O
emotions -X- _ O
in -X- _ O
humans -X- _ O
. -X- _ O
SentiWordNet -X- _ B-MethodName
( -X- _ O
Baccianella -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
another -X- _ O
lexical -X- _ O
database -X- _ O
like -X- _ O
Word -X- _ B-DatasetName
- -X- _ I-DatasetName
Net -X- _ I-DatasetName
, -X- _ O
gives -X- _ O
scores -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
how -X- _ O
positive -X- _ O
, -X- _ O
negative -X- _ O
or -X- _ O
objective -X- _ O
they -X- _ O
are -X- _ O
. -X- _ O
Abstract -X- _ O
words -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
positive -X- _ O
/ -X- _ O
negative -X- _ O
score -X- _ O
, -X- _ O
while -X- _ O
concrete -X- _ O
words -X- _ O
have -X- _ O
a -X- _ O
higher -X- _ O
objective -X- _ O
score -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
here -X- _ O
, -X- _ O
we -X- _ O
consider -X- _ O
these -X- _ O
scores -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
commonly -X- _ O
occurring -X- _ O
sense -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
scores -X- _ O
of -X- _ O
all -X- _ O
the -X- _ O
senses -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
features -X- _ O
above -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
a -X- _ O
13dimensional -X- _ O
vector -X- _ O
for -X- _ O
every -X- _ O
word -X- _ O
in -X- _ O
the -X- _ O
lexicon -X- _ O
. -X- _ O
The -X- _ O
embedding -X- _ O
is -X- _ O
created -X- _ O
so -X- _ O
that -X- _ O
every -X- _ O
dimension -X- _ O
is -X- _ O
directly -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
concreteness -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
a -X- _ O
word -X- _ O
is -X- _ O
in -X- _ O
general -X- _ O
, -X- _ O
indirectly -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
concreteness -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
length -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
vector -X- _ O
as -X- _ O
large -X- _ O
value -X- _ O
− -X- _ O
length -X- _ O
of -X- _ O
word -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
take -X- _ O
10 -X- _ O
, -X- _ O
000 -X- _ O
as -X- _ O
the -X- _ O
large -X- _ O
value -X- _ O
. -X- _ O
The -X- _ O
large -X- _ O
value -X- _ O
chosen -X- _ O
was -X- _ O
the -X- _ O
same -X- _ O
for -X- _ O
all -X- _ O
features -X- _ O
which -X- _ O
are -X- _ O
indirectly -X- _ O
proportional -X- _ O
to -X- _ O
concreteness -X- _ O
. -X- _ O
Towards -X- _ O
improving -X- _ O
the -X- _ O
trained -X- _ O
model -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
method -X- _ O
which -X- _ O
we -X- _ O
term -X- _ O
as -X- _ O
the -X- _ O
Difference -X- _ B-MethodName
Method -X- _ I-MethodName
. -X- _ O
If -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
the -X- _ O
top-2 -X- _ O
probabilities -X- _ O
predicted -X- _ O
by -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
greater -X- _ O
than -X- _ O
a -X- _ O
certain -X- _ O
threshold -X- _ O
, -X- _ O
this -X- _ O
implies -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
sure -X- _ O
of -X- _ O
the -X- _ O
prediction -X- _ O
it -X- _ O
has -X- _ O
made -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
difference -X- _ O
is -X- _ O
less -X- _ O
than -X- _ O
the -X- _ O
tunable -X- _ O
threshold -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
ambivalent -X- _ O
about -X- _ O
whether -X- _ O
the -X- _ O
option -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
probability -X- _ O
or -X- _ O
the -X- _ O
option -X- _ O
with -X- _ O
the -X- _ O
second -X- _ O
highest -X- _ O
probability -X- _ O
is -X- _ O
correct -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
for -X- _ O
how -X- _ O
many -X- _ O
dimensions -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
the -X- _ O
linguistic -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
second -X- _ O
word -X- _ O
is -X- _ O
less -X- _ O
than -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
the -X- _ O
linguistic -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
word -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
values -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
7 -X- _ O
) -X- _ O
are -X- _ O
less -X- _ O
, -X- _ O
we -X- _ O
change -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
the -X- _ O
second -X- _ O
- -X- _ O
most -X- _ O
probable -X- _ O
option -X- _ O
. -X- _ O
The -X- _ O
threshold -X- _ O
is -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
Threshold -X- _ B-MethodName
Method -X- _ I-MethodName
towards -X- _ O
improving -X- _ O
the -X- _ O
model -X- _ O
performance -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
highest -X- _ O
probability -X- _ O
is -X- _ O
less -X- _ O
than -X- _ O
a -X- _ O
tunable -X- _ O
threshold -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
unsure -X- _ O
of -X- _ O
its -X- _ O
predictions -X- _ O
and -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
improvement -X- _ O
approaches -X- _ O
on -X- _ O
the -X- _ O
option -X- _ O
with -X- _ O
the -X- _ O
second -X- _ O
- -X- _ O
highest -X- _ O
probability -X- _ O
. -X- _ O
According -X- _ O
to -X- _ O
Spreen -X- _ O
and -X- _ O
Schulz -X- _ O
, -X- _ O
1966 -X- _ O
, -X- _ O
a -X- _ O
highly -X- _ O
specific -X- _ O
word -X- _ O
refers -X- _ O
to -X- _ O
a -X- _ O
very -X- _ O
particular -X- _ O
instance -X- _ O
, -X- _ O
while -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
specific -X- _ O
word -X- _ O
refers -X- _ O
to -X- _ O
a -X- _ O
generic -X- _ O
concept -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
it -X- _ O
encompasses -X- _ O
many -X- _ O
classes -X- _ O
/ -X- _ O
instances -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
consider -X- _ O
the -X- _ O
words -X- _ O
" -X- _ O
animal -X- _ O
" -X- _ O
, -X- _ O
" -X- _ O
bird -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
eagle -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
words -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
increasing -X- _ O
order -X- _ O
of -X- _ O
specificity -X- _ O
. -X- _ O
We -X- _ O
find -X- _ O
parallels -X- _ O
between -X- _ O
the -X- _ O
definition -X- _ O
of -X- _ O
specificity -X- _ O
/ -X- _ O
non -X- _ O
- -X- _ O
specificity -X- _ O
and -X- _ O
the -X- _ O
linguistic -X- _ O
phenomenon -X- _ O
of -X- _ O
hypernymy -X- _ O
. -X- _ O
Schreuder -X- _ O
and -X- _ O
Baayen -X- _ O
, -X- _ O
1995 -X- _ O
define -X- _ O
a -X- _ O
hypernym -X- _ O
as -X- _ O
" -X- _ O
a -X- _ O
word -X- _ O
with -X- _ O
a -X- _ O
general -X- _ O
meaning -X- _ O
that -X- _ O
has -X- _ O
basically -X- _ O
the -X- _ O
same -X- _ O
meaning -X- _ O
of -X- _ O
a -X- _ O
more -X- _ O
specific -X- _ O
word -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
more -X- _ O
specific -X- _ O
word -X- _ O
is -X- _ O
the -X- _ O
corresponding -X- _ O
hyponym -X- _ O
. -X- _ O
In -X- _ O
simpler -X- _ O
terms -X- _ O
, -X- _ O
each -X- _ O
word -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
some -X- _ O
super -X- _ O
- -X- _ O
types -X- _ O
and -X- _ O
sub -X- _ O
- -X- _ O
types -X- _ O
, -X- _ O
called -X- _ O
as -X- _ O
hypernyms -X- _ O
and -X- _ O
hyponyms -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
In -X- _ O
linguistics -X- _ O
, -X- _ O
hyponymy -X- _ O
is -X- _ O
a -X- _ O
semantic -X- _ O
relation -X- _ O
be -X- _ O
- -X- _ O
tween -X- _ O
a -X- _ O
hyponym -X- _ O
denoting -X- _ O
a -X- _ O
subtype -X- _ O
and -X- _ O
a -X- _ O
hypernym -X- _ O
denoting -X- _ O
a -X- _ O
supertype -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
figure -X- _ O
1 -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
traverse -X- _ O
up -X- _ O
the -X- _ O
hypernymy -X- _ O
tree -X- _ O
, -X- _ O
assuming -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
word -X- _ O
" -X- _ O
dog -X- _ O
" -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
its -X- _ O
hypernym -X- _ O
is -X- _ O
" -X- _ O
animal -X- _ O
" -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
much -X- _ O
broader -X- _ O
than -X- _ O
" -X- _ O
dog -X- _ O
" -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
go -X- _ O
down -X- _ O
the -X- _ O
hypernymy -X- _ O
tree -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
more -X- _ O
specific -X- _ O
terms -X- _ O
for -X- _ O
the -X- _ O
word -X- _ O
" -X- _ O
dog -X- _ O
" -X- _ O
such -X- _ O
as -X- _ O
" -X- _ O
terrier -X- _ O
" -X- _ O
. -X- _ O
Essentially -X- _ O
, -X- _ O
hyponyms -X- _ O
represent -X- _ O
" -X- _ O
IS -X- _ O
- -X- _ O
A -X- _ O
" -X- _ O
relationships -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
" -X- _ O
terrier -X- _ O
" -X- _ O
is -X- _ O
a -X- _ O
" -X- _ O
dog -X- _ O
" -X- _ O
. -X- _ O
We -X- _ O
leverage -X- _ O
the -X- _ O
hypernymy -X- _ O
property -X- _ O
of -X- _ O
words -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
model -X- _ O
in -X- _ O
deciding -X- _ O
the -X- _ O
most -X- _ O
non -X- _ O
- -X- _ O
specific -X- _ O
option -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
methods -X- _ O
which -X- _ O
we -X- _ O
implement -X- _ O
are -X- _ O
: -X- _ O
Hypernym -X- _ O
Augmentation -X- _ O
Method -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
infuse -X- _ O
a -X- _ O
sense -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
specificity -X- _ O
( -X- _ O
other -X- _ O
than -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
given -X- _ O
dataset -X- _ O
for -X- _ O
non -X- _ O
- -X- _ O
specificity -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
augment -X- _ O
the -X- _ O
dataset -X- _ O
for -X- _ O
subtask -X- _ O
- -X- _ O
I. -X- _ O
We -X- _ O
randomly -X- _ O
select -X- _ O
n -X- _ O
nouns -X- _ O
from -X- _ O
the -X- _ O
article -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
basic -X- _ O
POS -X- _ O
Tagging -X- _ O
pipeline -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
noun -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Lesk -X- _ B-MethodName
algorithm -X- _ I-MethodName
( -X- _ O
Lesk -X- _ O
, -X- _ O
1986 -X- _ O
) -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
most -X- _ O
appropriate -X- _ O
sense -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
based -X- _ O
on -X- _ O
its -X- _ O
context -X- _ O
. -X- _ O
For -X- _ O
this -X- _ O
sense -X- _ O
of -X- _ O
the -X- _ O
word -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
its -X- _ O
hypernyms -X- _ O
, -X- _ O
pick -X- _ O
a -X- _ O
hypernym -X- _ O
uniformly -X- _ O
at -X- _ O
random -X- _ O
from -X- _ O
this -X- _ O
list -X- _ O
of -X- _ O
hypernyms -X- _ O
and -X- _ O
replace -X- _ O
the -X- _ O
noun -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
with -X- _ O
the -X- _ O
hypernym -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
this -X- _ O
for -X- _ O
all -X- _ O
2 -X- _ O
n -X- _ O
combinations -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
corresponding -X- _ O
to -X- _ O
every -X- _ O
sample -X- _ O
, -X- _ O
we -X- _ O
have -X- _ O
2 -X- _ O
n -X- _ O
augmented -X- _ O
samples -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
randomly -X- _ O
mask -X- _ O
tokens -X- _ O
in -X- _ O
this -X- _ O
dataset -X- _ O
and -X- _ O
train -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
MLM -X- _ O
task -X- _ O
, -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O
This -X- _ O
serves -X- _ O
a -X- _ O
dual -X- _ O
purpose -X- _ O
. -X- _ O
Firstly -X- _ O
, -X- _ O
it -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
sort -X- _ O
of -X- _ O
domain -X- _ B-MethodName
adaptation -X- _ I-MethodName
, -X- _ O
and -X- _ O
secondly -X- _ O
, -X- _ O
it -X- _ O
infuses -X- _ O
a -X- _ O
sense -X- _ O
of -X- _ O
non -X- _ B-TaskName
- -X- _ I-TaskName
specificity -X- _ I-TaskName
in -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
While -X- _ O
finetuning -X- _ O
BERT -X- _ B-MethodName
MLM -X- _ O
on -X- _ O
the -X- _ O
augmented -X- _ O
dataset -X- _ O
, -X- _ O
we -X- _ O
freeze -X- _ O
two -X- _ O
layers -X- _ O
, -X- _ O
due -X- _ O
to -X- _ O
time -X- _ O
and -X- _ O
computational -X- _ O
constraints -X- _ O
. -X- _ O
We -X- _ O
replace -X- _ O
the -X- _ O
normal -X- _ O
BERT -X- _ B-MethodName
Encoder -X- _ O
in -X- _ O
our -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
model -X- _ O
with -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
Encoder -X- _ I-MethodName
fine -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
the -X- _ O
augmented -X- _ O
dataset -X- _ O
. -X- _ O
Hyponyms -X- _ B-MethodName
Options -X- _ I-MethodName
Method -X- _ I-MethodName
Here -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Difference -X- _ B-MethodName
Method -X- _ I-MethodName
/ -X- _ I-MethodName
Threshold -X- _ I-MethodName
Method -X- _ I-MethodName
. -X- _ O
If -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
sure -X- _ O
of -X- _ O
its -X- _ O
prediction -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Otherwise -X- _ O
, -X- _ O
we -X- _ O
generate -X- _ O
hyponyms -X- _ O
for -X- _ O
each -X- _ O
option -X- _ O
using -X- _ O
WordNet -X- _ O
. -X- _ O
After -X- _ O
the -X- _ O
hyponyms -X- _ O
are -X- _ O
tokenised -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
trained -X- _ O
model -X- _ O
's -X- _ O
output -X- _ O
and -X- _ O
map -X- _ O
each -X- _ O
hyponym -X- _ O
token -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
vocabulary -X- _ O
space -X- _ O
and -X- _ O
get -X- _ O
the -X- _ O
corresponding -X- _ O
scores -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
take -X- _ O
the -X- _ O
maximum -X- _ O
score -X- _ O
amongst -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
hyponyms -X- _ O
as -X- _ O
the -X- _ O
predicted -X- _ O
probability -X- _ O
for -X- _ O
that -X- _ O
option -X- _ O
. -X- _ O
The -X- _ O
reason -X- _ O
for -X- _ O
incorporating -X- _ O
this -X- _ O
approach -X- _ O
pertains -X- _ O
to -X- _ O
how -X- _ O
the -X- _ O
transformer -X- _ O
models -X- _ O
were -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
. -X- _ O
Consider -X- _ O
the -X- _ O
following -X- _ O
sentence -X- _ O
: -X- _ O
" -X- _ O
He -X- _ O
had -X- _ O
a -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
and -X- _ O
it -X- _ O
was -X- _ O
bitter -X- _ O
" -X- _ O
. -X- _ O
Now -X- _ O
, -X- _ O
suppose -X- _ O
that -X- _ O
we -X- _ O
have -X- _ O
two -X- _ O
options -X- _ O
: -X- _ O
" -X- _ O
beer -X- _ O
" -X- _ O
and -X- _ O
" -X- _ O
drink -X- _ O
" -X- _ O
. -X- _ O
Generally -X- _ O
, -X- _ O
our -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
model -X- _ O
would -X- _ O
look -X- _ O
at -X- _ O
the -X- _ O
word -X- _ O
" -X- _ O
bitter -X- _ O
" -X- _ O
and -X- _ O
predict -X- _ O
" -X- _ O
beer -X- _ O
" -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
" -X- _ O
drink -X- _ O
" -X- _ O
is -X- _ O
more -X- _ O
non -X- _ O
- -X- _ O
specific -X- _ O
than -X- _ O
" -X- _ O
beer -X- _ O
" -X- _ O
. -X- _ O
To -X- _ O
address -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
the -X- _ O
vanilla -X- _ O
transformer -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
attempt -X- _ O
multiple -X- _ O
modifications -X- _ O
to -X- _ O
the -X- _ O
proposed -X- _ O
baseline -X- _ O
transformer -X- _ O
models -X- _ O
, -X- _ O
specifically -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
The -X- _ O
major -X- _ O
limitation -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
that -X- _ O
we -X- _ O
've -X- _ O
used -X- _ O
, -X- _ O
is -X- _ O
the -X- _ O
restriction -X- _ O
on -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
tokenised -X- _ O
inputs -X- _ O
. -X- _ O
Only -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ B-HyperparameterName
from -X- _ O
a -X- _ O
sample -X- _ O
can -X- _ O
be -X- _ O
processed -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
one -X- _ O
parse -X- _ O
and -X- _ O
hence -X- _ O
, -X- _ O
some -X- _ O
articles -X- _ O
end -X- _ O
up -X- _ O
getting -X- _ O
truncated -X- _ O
and -X- _ O
context -X- _ O
is -X- _ O
lost -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
are -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
modifications -X- _ O
we -X- _ O
've -X- _ O
made -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
models -X- _ O
: -X- _ O
Voting -X- _ O
We -X- _ O
tokenise -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
article -X- _ O
. -X- _ O
We -X- _ O
split -X- _ O
the -X- _ O
article -X- _ O
into -X- _ O
chunks -X- _ O
and -X- _ O
pair -X- _ O
each -X- _ O
chunk -X- _ O
with -X- _ O
the -X- _ O
question -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
tokenised -X- _ O
( -X- _ O
chunk -X- _ O
, -X- _ O
question -X- _ O
) -X- _ O
pair -X- _ O
is -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
While -X- _ O
splitting -X- _ O
the -X- _ O
article -X- _ O
into -X- _ O
chunks -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
a -X- _ O
maxoverlap -X- _ B-HyperparameterName
stride -X- _ I-HyperparameterName
of -X- _ O
128 -X- _ B-HyperparameterValue
so -X- _ O
that -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
chunk -X- _ O
is -X- _ O
not -X- _ O
lost -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
these -X- _ O
newly -X- _ O
formed -X- _ O
( -X- _ O
chunk -X- _ O
, -X- _ O
question -X- _ O
) -X- _ O
pairs -X- _ O
. -X- _ O
During -X- _ O
inference -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
the -X- _ O
weighted -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
logits -X- _ O
. -X- _ O
For -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
Voting -X- _ I-MethodName
( -X- _ I-MethodName
Similarity -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
the -X- _ O
weights -X- _ O
are -X- _ O
calculated -X- _ O
as -X- _ O
: -X- _ O
weight -X- _ O
ij -X- _ O
= -X- _ O
u -X- _ O
i -X- _ O
.v -X- _ O
j -X- _ O
||u -X- _ O
i -X- _ O
||||v -X- _ O
j -X- _ O
|| -X- _ O
( -X- _ O
1)where -X- _ O
u -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
question -X- _ O
in -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
sample -X- _ O
, -X- _ O
and -X- _ O
v -X- _ O
j -X- _ O
is -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
th -X- _ O
chunk -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
's -X- _ O
article -X- _ O
. -X- _ O
To -X- _ O
find -X- _ O
the -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
embedding -X- _ O
from -X- _ O
a -X- _ O
pretrained -X- _ O
BERT -X- _ B-MethodName
encoder -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
try -X- _ O
out -X- _ O
an -X- _ O
alternate -X- _ O
way -X- _ O
of -X- _ O
defining -X- _ O
the -X- _ O
weights -X- _ O
: -X- _ O
weight -X- _ O
ij -X- _ O
= -X- _ O
|{q -X- _ O
i -X- _ O
toks -X- _ O
. -X- _ O
} -X- _ O
∩ -X- _ O
{ -X- _ O
chunk -X- _ O
j -X- _ O
toks.}| -X- _ O
|{chunk -X- _ O
j -X- _ O
toks.}|(2 -X- _ O
) -X- _ O
where -X- _ O
{ -X- _ O
q -X- _ O
i -X- _ O
toks -X- _ O
. -X- _ O
} -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
sample -X- _ O
's -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
{ -X- _ O
chunk -X- _ O
j -X- _ O
toks -X- _ O
. -X- _ O
} -X- _ O
is -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
j -X- _ O
th -X- _ O
chunk -X- _ O
of -X- _ O
the -X- _ O
sample -X- _ O
. -X- _ O
|.| -X- _ O
represents -X- _ O
the -X- _ O
cardinality -X- _ O
of -X- _ O
a -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
call -X- _ O
the -X- _ O
method -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
Voting -X- _ I-MethodName
( -X- _ I-MethodName
Exact -X- _ I-MethodName
Matching).We -X- _ I-MethodName
normalise -X- _ O
the -X- _ O
computed -X- _ O
weights -X- _ O
: -X- _ O
norm -X- _ O
weight -X- _ O
ij -X- _ O
= -X- _ O
weight -X- _ O
ij -X- _ O
n -X- _ O
i -X- _ O
j=1 -X- _ O
weight -X- _ O
ij -X- _ O
( -X- _ O
3)where -X- _ O
n -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
chunks -X- _ O
in -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
sample -X- _ O
. -X- _ O
The -X- _ O
idea -X- _ O
behind -X- _ O
this -X- _ O
is -X- _ O
that -X- _ O
higher -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
article -X- _ O
's -X- _ O
chunk -X- _ O
, -X- _ O
higher -X- _ O
is -X- _ O
the -X- _ O
weight -X- _ O
assigned -X- _ O
to -X- _ O
the -X- _ O
logits -X- _ O
returned -X- _ O
by -X- _ O
the -X- _ O
trained -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
question -X- _ O
- -X- _ O
chunk -X- _ O
pair -X- _ O
as -X- _ O
input -X- _ O
. -X- _ O
In -X- _ O
Equation -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
the -X- _ O
fraction -X- _ O
of -X- _ O
tokens -X- _ O
common -X- _ O
between -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
chunk -X- _ O
. -X- _ O
Max -X- _ B-MethodName
Context -X- _ I-MethodName
This -X- _ O
method -X- _ O
is -X- _ O
a -X- _ O
slight -X- _ O
modification -X- _ O
of -X- _ O
the -X- _ O
Voting -X- _ B-MethodName
Method -X- _ I-MethodName
. -X- _ O
Instead -X- _ O
of -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
all -X- _ O
( -X- _ O
chunk -X- _ O
, -X- _ O
question -X- _ O
) -X- _ O
pairs -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
sample -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
pair -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
weight -X- _ O
. -X- _ O
The -X- _ O
weights -X- _ O
are -X- _ O
calculated -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Equation -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
a -X- _ O
few -X- _ O
modifications -X- _ O
to -X- _ O
the -X- _ O
baseline -X- _ O
, -X- _ O
namely -X- _ O
GA -X- _ B-MethodName
- -X- _ I-MethodName
Reader -X- _ I-MethodName
( -X- _ O
Dhingra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017a -X- _ O
) -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
organisers -X- _ O
. -X- _ O
GA -X- _ B-MethodName
- -X- _ I-MethodName
Reader -X- _ I-MethodName
BERT -X- _ I-MethodName
We -X- _ O
use -X- _ O
GA -X- _ B-MethodName
- -X- _ I-MethodName
Reader -X- _ I-MethodName
on -X- _ O
top -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
embeddings -X- _ O
. -X- _ O
This -X- _ O
could -X- _ O
lead -X- _ O
to -X- _ O
potential -X- _ O
improvement -X- _ O
in -X- _ O
performance -X- _ O
for -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
embeddings -X- _ O
are -X- _ O
more -X- _ O
feature -X- _ O
- -X- _ O
rich -X- _ O
than -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ O
. -X- _ O
Reader -X- _ O
, -X- _ O
we -X- _ O
came -X- _ O
up -X- _ O
with -X- _ O
an -X- _ O
approach -X- _ O
that -X- _ O
uses -X- _ O
Gated -X- _ B-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
across -X- _ O
two -X- _ O
- -X- _ O
BERT -X- _ B-MethodName
streams -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
stream -X- _ O
takes -X- _ O
in -X- _ O
the -X- _ O
question -X- _ O
input -X- _ O
, -X- _ O
and -X- _ O
works -X- _ O
like -X- _ O
the -X- _ O
regular -X- _ O
BERT -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
stream -X- _ O
takes -X- _ O
the -X- _ O
article -X- _ O
input -X- _ O
. -X- _ O
Assume -X- _ O
the -X- _ O
layer -X- _ O
outputs -X- _ O
for -X- _ O
layer -X- _ O
L -X- _ O
are -X- _ O
Q -X- _ O
L -X- _ O
and -X- _ O
A -X- _ O
L -X- _ O
, -X- _ O
respectively -X- _ O
, -X- _ O
for -X- _ O
question -X- _ O
and -X- _ O
article -X- _ O
streams -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
to -X- _ O
the -X- _ O
layer -X- _ O
L -X- _ O
+ -X- _ O
1 -X- _ O
for -X- _ O
question -X- _ O
stream -X- _ O
, -X- _ O
Q -X- _ O
L -X- _ O
is -X- _ O
passed -X- _ O
as -X- _ O
input -X- _ O
, -X- _ O
while -X- _ O
to -X- _ O
layer -X- _ O
L -X- _ O
+ -X- _ O
1 -X- _ O
for -X- _ O
article -X- _ O
stream -X- _ O
, -X- _ O
GA(Q -X- _ O
L -X- _ O
, -X- _ O
A -X- _ O
L -X- _ O
) -X- _ O
is -X- _ O
passed -X- _ O
, -X- _ O
where -X- _ O
GA -X- _ O
is -X- _ O
the -X- _ O
Gated -X- _ B-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
function -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
done -X- _ O
for -X- _ O
all -X- _ O
12 -X- _ O
layers -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
BASE -X- _ I-MethodName
. -X- _ O
Finally -X- _ O
, -X- _ O
on -X- _ O
this -X- _ O
model -X- _ O
, -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
heads -X- _ O
are -X- _ O
attached -X- _ O
-Selection -X- _ B-MethodName
and -X- _ I-MethodName
Pooling -X- _ I-MethodName
( -X- _ I-MethodName
similar -X- _ I-MethodName
to -X- _ I-MethodName
BERT -X- _ I-MethodName
FitB -X- _ I-MethodName
) -X- _ I-MethodName
, -X- _ O
and -X- _ O
Attention -X- _ B-MethodName
Classification -X- _ I-MethodName
( -X- _ I-MethodName
similar -X- _ I-MethodName
to -X- _ I-MethodName
GA -X- _ I-MethodName
- -X- _ I-MethodName
Reader -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O
The -X- _ O
logits -X- _ O
for -X- _ O
each -X- _ O
head -X- _ O
are -X- _ O
concatenated -X- _ O
and -X- _ O
a -X- _ O
fully -X- _ O
- -X- _ O
connected -X- _ O
layer -X- _ O
is -X- _ O
added -X- _ O
on -X- _ O
top -X- _ O
. -X- _ O
Since -X- _ O
this -X- _ O
is -X- _ O
a -X- _ O
major -X- _ O
change -X- _ O
in -X- _ O
the -X- _ O
architecture -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
this -X- _ O
model -X- _ O
needs -X- _ O
a -X- _ O
significant -X- _ O
amount -X- _ O
of -X- _ O
pretraining -X- _ O
. -X- _ O
Answer -X- _ O
- -X- _ O
Attention -X- _ O
Since -X- _ O
GA -X- _ B-MethodName
- -X- _ I-MethodName
Reader -X- _ I-MethodName
also -X- _ O
attends -X- _ O
to -X- _ O
the -X- _ O
candidate -X- _ O
answer -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
attempt -X- _ O
an -X- _ O
approach -X- _ O
where -X- _ O
we -X- _ O
pass -X- _ O
the -X- _ O
options -X- _ O
to -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
option -X- _ O
embeddings -X- _ O
and -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
multiplicative -X- _ O
attention -X- _ O
( -X- _ O
dot -X- _ O
product -X- _ O
) -X- _ O
to -X- _ O
get -X- _ O
attention -X- _ O
scores -X- _ O
. -X- _ O
These -X- _ O
scores -X- _ O
are -X- _ O
directly -X- _ O
used -X- _ O
as -X- _ O
logits -X- _ O
for -X- _ O
the -X- _ O
prediction -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
GSAMN -X- _ I-MethodName
- -X- _ I-MethodName
Cloze -X- _ I-MethodName
Lai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
propose -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
Gated -X- _ B-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
and -X- _ I-MethodName
Self -X- _ I-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
-Gated -X- _ I-MethodName
Self -X- _ I-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
( -X- _ I-MethodName
GSA -X- _ I-MethodName
) -X- _ I-MethodName
. -X- _ O
They -X- _ O
show -X- _ O
improvements -X- _ O
on -X- _ O
smaller -X- _ O
datasets -X- _ O
compared -X- _ O
to -X- _ O
Compare -X- _ B-MethodName
- -X- _ I-MethodName
Aggregate -X- _ I-MethodName
Approaches -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
two -X- _ O
GSA -X- _ B-MethodName
layers -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
Embeddings -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
decoder -X- _ O
and -X- _ O
selection -X- _ O
method -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
FitB. -X- _ I-MethodName
In -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
PyTorch -X- _ O
implementations -X- _ O
of -X- _ O
the -X- _ O
transformers -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
HuggingFace -X- _ O
.The -X- _ O
metric -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
3 -X- _ O
subtasks -X- _ O
is -X- _ O
accuracy -X- _ B-MetricName
. -X- _ O
For -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
, -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
linguistic -X- _ O
features -X- _ O
mentioned -X- _ O
in -X- _ O
3.2 -X- _ O
, -X- _ O
and -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
hypernyms -X- _ O
and -X- _ O
hyponyms -X- _ O
for -X- _ O
subtask -X- _ O
- -X- _ O
II -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
lexical -X- _ O
database -X- _ O
, -X- _ O
WordNet -X- _ B-DatasetName
provided -X- _ O
by -X- _ O
NLTK -X- _ O
( -X- _ O
Bird -X- _ O
and -X- _ O
Loper -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
library -X- _ O
in -X- _ O
Python -X- _ O
. -X- _ O
For -X- _ O
both -X- _ O
subtasks -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
train -X- _ O
+ -X- _ O
trial -X- _ O
dataset -X- _ O
, -X- _ O
and -X- _ O
evaluate -X- _ O
them -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
and -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
systems -X- _ O
was -X- _ O
on -X- _ O
Google -X- _ O
Colaboratory -X- _ O
's -X- _ O
free -X- _ O
GPU -X- _ O
( -X- _ O
NVIDIA -X- _ O
K80 -X- _ O
/ -X- _ O
P100 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
time -X- _ O
varies -X- _ O
with -X- _ O
the -X- _ O
models -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
around -X- _ O
1 -X- _ O
- -X- _ O
2 -X- _ O
hours -X- _ O
for -X- _ O
the -X- _ O
base -X- _ O
variants -X- _ O
and -X- _ O
2 -X- _ O
- -X- _ O
4 -X- _ O
hours -X- _ O
for -X- _ O
the -X- _ O
large -X- _ O
models -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
well -X- _ O
within -X- _ O
the -X- _ O
12 -X- _ O
hour -X- _ O
limit -X- _ O
of -X- _ O
Colab -X- _ O
. -X- _ O
DistilBERT -X- _ B-MethodName
took -X- _ O
about -X- _ O
half -X- _ O
an -X- _ O
hour -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
For -X- _ O
finetuning -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
Hypr -X- _ I-MethodName
Aug -X- _ I-MethodName
Model -X- _ O
on -X- _ O
the -X- _ O
augmented -X- _ O
dataset -X- _ O
on -X- _ O
the -X- _ O
MLM -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Nvidia -X- _ O
- -X- _ O
DGX -X- _ O
Station -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
specifications -X- _ O
: -X- _ O
four -X- _ O
32 -X- _ O
GB -X- _ O
Tesla -X- _ O
V100 -X- _ O
GPUs -X- _ O
, -X- _ O
256 -X- _ O
GB -X- _ O
RAM -X- _ O
and -X- _ O
forty -X- _ O
Intel -X- _ O
Xeon -X- _ O
2.20GHz -X- _ O
processors -X- _ O
since -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
computationally -X- _ O
intensive -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
all -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterName
Optimiser -X- _ I-HyperparameterName
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
Cross -X- _ B-HyperparameterName
Entropy -X- _ I-HyperparameterName
Loss -X- _ I-HyperparameterName
. -X- _ O
For -X- _ O
choosing -X- _ O
the -X- _ O
optimal -X- _ O
set -X- _ O
of -X- _ O
hyperparameters -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
a -X- _ O
Grid -X- _ B-MethodName
Search -X- _ I-MethodName
on -X- _ O
our -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
zero -X- _ O
in -X- _ O
on -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-5 -X- _ B-MetricValue
. -X- _ O
Schedulers -X- _ O
such -X- _ O
as -X- _ O
Linear -X- _ B-MetricName
Scheduler -X- _ I-MetricName
, -X- _ O
Cosine -X- _ B-MetricName
Annealing -X- _ I-MetricName
Scheduler -X- _ I-MetricName
, -X- _ O
etc -X- _ O
. -X- _ O
seem -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
negative -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
FitB -X- _ B-HyperparameterName
models -X- _ O
, -X- _ O
we -X- _ O
keep -X- _ O
all -X- _ O
the -X- _ O
layers -X- _ O
unfrozen -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
the -X- _ O
maximum -X- _ B-HyperparameterName
input -X- _ I-HyperparameterName
length -X- _ I-HyperparameterName
is -X- _ O
kept -X- _ O
as -X- _ O
512 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
train -X- _ O
our -X- _ O
models -X- _ O
for -X- _ O
4 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
, -X- _ O
keeping -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
2 -X- _ B-HyperparameterValue
. -X- _ O
Among -X- _ O
the -X- _ O
vanilla -X- _ O
models -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
Large -X- _ I-MethodName
performs -X- _ O
the -X- _ O
best -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
understandable -X- _ O
when -X- _ O
it -X- _ O
comes -X- _ O
to -X- _ O
DistilBERT -X- _ B-MethodName
and -X- _ O
ALBERT -X- _ B-MethodName
, -X- _ O
since -X- _ O
these -X- _ O
models -X- _ O
are -X- _ O
pruned -X- _ O
and -X- _ O
distilled -X- _ O
for -X- _ O
faster -X- _ O
computation -X- _ O
. -X- _ O
Notably -X- _ O
, -X- _ O
DistilBERT -X- _ B-MethodName
gives -X- _ O
comparable -X- _ O
performance -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
Base -X- _ I-MethodName
. -X- _ O
A -X- _ O
slightly -X- _ O
surprising -X- _ O
observation -X- _ O
was -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
degradation -X- _ O
in -X- _ O
accuracy -X- _ O
on -X- _ O
using -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
This -X- _ O
could -X- _ O
be -X- _ O
because -X- _ O
even -X- _ O
though -X- _ O
it -X- _ O
was -X- _ O
pretrained -X- _ O
more -X- _ O
robustly -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
MLM -X- _ O
task -X- _ O
, -X- _ O
it -X- _ O
was -X- _ O
not -X- _ O
pretrained -X- _ O
on -X- _ O
the -X- _ O
Next -X- _ B-TaskName
Sentence -X- _ I-TaskName
Prediction -X- _ I-TaskName
Task -X- _ I-TaskName
, -X- _ O
and -X- _ O
hence -X- _ O
, -X- _ O
might -X- _ O
perform -X- _ O
worse -X- _ O
on -X- _ O
Textual -X- _ B-TaskName
Entailment -X- _ I-TaskName
tasks -X- _ I-TaskName
. -X- _ O
A -X- _ O
peculiar -X- _ O
observation -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
large -X- _ O
variants -X- _ O
of -X- _ O
ALBERT -X- _ B-MethodName
FitB -X- _ I-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
FitB -X- _ I-MethodName
models -X- _ O
perform -X- _ O
worse -X- _ O
than -X- _ O
their -X- _ O
base -X- _ O
variants -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
imply -X- _ O
that -X- _ O
more -X- _ O
training -X- _ O
data -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
large -X- _ O
variants -X- _ O
. -X- _ O
For -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
, -X- _ O
in -X- _ O
table -X- _ O
2 -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
demonstrate -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
Ensemble -X- _ I-MethodName
, -X- _ O
in -X- _ O
which -X- _ O
we -X- _ O
ensemble -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
averaging -X- _ O
over -X- _ O
the -X- _ O
predictions -X- _ O
) -X- _ O
two -X- _ O
checkpoints -X- _ O
saved -X- _ O
during -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
When -X- _ O
it -X- _ O
comes -X- _ O
to -X- _ O
the -X- _ O
Difference -X- _ B-MethodName
Method -X- _ I-MethodName
using -X- _ I-MethodName
Linguistic -X- _ I-MethodName
Features -X- _ I-MethodName
for -X- _ O
imperceptibility -X- _ B-TaskName
, -X- _ O
we -X- _ O
observe -X- _ O
an -X- _ O
improvement -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
, -X- _ O
but -X- _ O
a -X- _ O
slight -X- _ O
fall -X- _ O
is -X- _ O
observed -X- _ O
while -X- _ O
evaluating -X- _ O
it -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
This -X- _ O
might -X- _ O
be -X- _ O
solved -X- _ O
by -X- _ O
careful -X- _ O
tuning -X- _ O
of -X- _ O
the -X- _ O
threshold -X- _ O
. -X- _ O
The -X- _ O
polls -X- _ O
are -X- _ O
already -X- _ O
years -X- _ O
overdue -X- _ O
and -X- _ O
were -X- _ O
scheduled -X- _ O
for -X- _ O
Sunday -X- _ O
. -X- _ O
They -X- _ O
were -X- _ O
postponed -X- _ O
because -X- _ O
of -X- _ O
an -X- _ O
ongoing -X- _ O
stalemate -X- _ O
between -X- _ O
the -X- _ O
government -X- _ O
and -X- _ O
a -X- _ O
group -X- _ O
of -X- _ O
opposition -X- _ O
senators -X- _ O
over -X- _ O
an -X- _ O
electoral -X- _ O
law -X- _ O
. -X- _ O
Haiti -X- _ O
is -X- _ O
the -X- _ O
poorest -X- _ O
country -X- _ O
in -X- _ O
the -X- _ O
region -X- _ O
and -X- _ O
is -X- _ O
still -X- _ O
struggling -X- _ O
to -X- _ O
recover -X- _ O
from -X- _ O
a -X- _ O
2010 -X- _ O
earthquake -X- _ O
. -X- _ O
Protesters -X- _ O
lit -X- _ O
piles -X- _ O
of -X- _ O
wood -X- _ O
in -X- _ O
the -X- _ O
central -X- _ O
neighbourhood -X- _ O
of -X- _ O
Bel -X- _ O
Aire -X- _ O
before -X- _ O
marching -X- _ O
to -X- _ O
a -X- _ O
wealthy -X- _ O
hillside -X- _ O
neighbourhood -X- _ O
, -X- _ O
where -X- _ O
riot -X- _ O
police -X- _ O
guarded -X- _ O
hotels -X- _ O
, -X- _ O
shops -X- _ O
and -X- _ O
Haiti -X- _ O
' -X- _ O
s -X- _ O
elections -X- _ O
office -X- _ O
. -X- _ O
Some -X- _ O
demanded -X- _ O
President -X- _ O
Michel -X- _ O
Martelly -X- _ O
' -X- _ O
s -X- _ O
resignation -X- _ O
for -X- _ O
his -X- _ O
" -X- _ O
inability -X- _ O
to -X- _ O
organise -X- _ O
elections -X- _ O
in -X- _ O
the -X- _ O
country -X- _ O
" -X- _ O
. -X- _ O
Two -X- _ O
opposition -X- _ O
activists -X- _ O
who -X- _ O
had -X- _ O
organised -X- _ O
the -X- _ O
protest -X- _ O
were -X- _ O
arrested -X- _ O
by -X- _ O
police -X- _ O
for -X- _ O
" -X- _ O
public -X- _ O
unrest -X- _ O
and -X- _ O
inciting -X- _ O
violence -X- _ O
" -X- _ O
. -X- _ O
Mid -X- _ O
-term -X- _ O
senate -X- _ O
elections -X- _ O
in -X- _ O
Haiti -X- _ O
had -X- _ O
been -X- _ O
due -X- _ O
in -X- _ O
May -X- _ O
2012 -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
municipal -X- _ O
poll -X- _ O
is -X- _ O
three -X- _ O
years -X- _ O
behind -X- _ O
schedule -X- _ O
as -X- _ O
Haiti -X- _ O
slowly -X- _ O
emerges -X- _ O
from -X- _ O
the -X- _ O
earthquake -X- _ O
which -X- _ O
left -X- _ O
much -X- _ O
of -X- _ O
the -X- _ O
country -X- _ O
devastated -X- _ O
in -X- _ O
2010 -X- _ O
. -X- _ O
In -X- _ O
June -X- _ O
, -X- _ O
President -X- _ O
Michel -X- _ O
Martelly -X- _ O
decreed -X- _ O
that -X- _ O
the -X- _ O
elections -X- _ O
be -X- _ O
held -X- _ O
on -X- _ O
26 -X- _ O
October -X- _ O
. -X- _ O
The -X- _ O
date -X- _ O
was -X- _ O
set -X- _ O
after -X- _ O
lengthy -X- _ O
talks -X- _ O
mediated -X- _ O
by -X- _ O
the -X- _ O
president -X- _ O
of -X- _ O
Haiti -X- _ O
' -X- _ O
s -X- _ O
Bishops -X- _ O
' -X- _ O
Conference -X- _ O
, -X- _ O
Cardinal -X- _ O
Chibly -X- _ O
Langlois -X- _ O
, -X- _ O
intended -X- _ O
to -X- _ O
overcome -X- _ O
the -X- _ O
political -X- _ O
deadlock -X- _ O
between -X- _ O
the -X- _ O
opposition -X- _ O
and -X- _ O
the -X- _ O
government -X- _ O
. -X- _ O
But -X- _ O
after -X- _ O
the -X- _ O
National -X- _ O
Assembly -X- _ O
failed -X- _ O
to -X- _ O
pass -X- _ O
an -X- _ O
electoral -X- _ O
law -X- _ O
in -X- _ O
time -X- _ O
, -X- _ O
the -X- _ O
office -X- _ O
of -X- _ O
Mr -X- _ O
Martelly -X- _ O
announced -X- _ O
another -X- _ O
postponement -X- _ O
on -X- _ O
Sunday -X- _ O
. -X- _ O
No -X- _ O
new -X- _ O
date -X- _ O
has -X- _ O
been -X- _ O
set -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
statement -X- _ O
said -X- _ O
that -X- _ O
" -X- _ O
President -X- _ O
Michel -X- _ O
Martelly -X- _ O
, -X- _ O
in -X- _ O
his -X- _ O
constant -X- _ O
concern -X- _ O
to -X- _ O
guarantee -X- _ O
political -X- _ O
stability -X- _ O
, -X- _ O
promises -X- _ O
to -X- _ O
pursue -X- _ O
consultations -X- _ O
with -X- _ O
the -X- _ O
different -X- _ O
sectors -X- _ O
of -X- _ O
national -X- _ O
life -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
hold -X- _ O
the -X- _ O
elections -X- _ O
as -X- _ O
soon -X- _ O
as -X- _ O
possible -X- _ O
" -X- _ O
. -X- _ O
Opposition -X- _ O
politicians -X- _ O
accuse -X- _ O
President -X- _ O
Martelly -X- _ O
of -X- _ O
wanting -X- _ O
to -X- _ O
rule -X- _ O
by -X- _ O
decree -X- _ O
-a -X- _ O
likely -X- _ O
scenario -X- _ O
if -X- _ O
no -X- _ O
elections -X- _ O
are -X- _ O
held -X- _ O
before -X- _ O
the -X- _ O
lower -X- _ O
chamber -X- _ O
' -X- _ O
s -X- _ O
term -X- _ O
runs -X- _ O
out -X- _ O
in -X- _ O
January -X- _ O
. -X- _ O
The -X- _ O
government -X- _ O
argues -X- _ O
that -X- _ O
opposition -X- _ O
politicians -X- _ O
are -X- _ O
also -X- _ O
dragging -X- _ O
their -X- _ O
feet -X- _ O
in -X- _ O
the -X- _ O
hope -X- _ O
of -X- _ O
extending -X- _ O
their -X- _ O
time -X- _ O
in -X- _ O
office -X- _ O
without -X- _ O
elections -X- _ O
. -X- _ O
Thousands -X- _ O
of -X- _ O
Haitians -X- _ O
marched -X- _ O
in -X- _ O
the -X- _ O
capital -X- _ O
Port -X- _ O
-au -X- _ O
-Prince -X- _ O
on -X- _ O
Sunday -X- _ O
in -X- _ O
protest -X- _ O
at -X- _ O
a -X- _ O
delay -X- _ O
in -X- _ O
the -X- _ O
country -X- _ O
' -X- _ O
s -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
and -X- _ O
municipal -X- _ O
elections -X- _ O
.Options -X- _ O
: -X- _ O
Local -X- _ O
, -X- _ O
Annual -X- _ O
, -X- _ O
Legislative -X- _ O
, -X- _ O
Municipal -X- _ O
, -X- _ O
Devastating -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
aspire -X- _ O
to -X- _ O
learn -X- _ O
embeddings -X- _ O
using -X- _ O
these -X- _ O
Linguistic -X- _ O
Features -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
common -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
Word2Vec -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013).For -X- _ O
non -X- _ O
- -X- _ O
specificity -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
hypernym -X- _ B-MethodName
augmentation -X- _ I-MethodName
method -X- _ I-MethodName
, -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
achieves -X- _ O
lower -X- _ O
accuracy -X- _ O
. -X- _ O
A -X- _ O
possible -X- _ O
reason -X- _ O
for -X- _ O
this -X- _ O
could -X- _ O
be -X- _ O
that -X- _ O
replacing -X- _ O
the -X- _ O
nouns -X- _ O
with -X- _ O
their -X- _ O
hypernyms -X- _ O
in -X- _ O
some -X- _ O
contexts -X- _ O
changes -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
( -X- _ O
even -X- _ O
though -X- _ O
we -X- _ O
use -X- _ B-MethodName
Lesk -X- _ I-MethodName
Algorithm -X- _ I-MethodName
for -X- _ O
WSD -X- _ O
, -X- _ O
not -X- _ O
all -X- _ O
hypernyms -X- _ O
make -X- _ O
sense -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
word -X- _ O
" -X- _ O
drink -X- _ O
" -X- _ O
is -X- _ O
replaced -X- _ O
with -X- _ O
" -X- _ O
food -X- _ O
" -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
hyponyms -X- _ B-MethodName
method -X- _ I-MethodName
, -X- _ O
we -X- _ O
can -X- _ O
improve -X- _ O
our -X- _ O
results -X- _ O
by -X- _ O
recursively -X- _ O
generating -X- _ O
hyponyms -X- _ O
for -X- _ O
a -X- _ O
particular -X- _ O
option -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
taking -X- _ O
the -X- _ O
immediate -X- _ O
hyponyms -X- _ O
. -X- _ O
Again -X- _ O
, -X- _ O
threshold -X- _ O
tuning -X- _ O
may -X- _ O
help -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
a -X- _ O
positive -X- _ O
sign -X- _ O
for -X- _ O
the -X- _ O
Difference -X- _ B-MethodName
Method -X- _ I-MethodName
or -X- _ O
the -X- _ O
Threshold -X- _ B-MethodName
Method -X- _ I-MethodName
is -X- _ O
the -X- _ O
improvement -X- _ O
in -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
Voting -X- _ I-MethodName
( -X- _ I-MethodName
Exact -X- _ I-MethodName
Matching -X- _ I-MethodName
) -X- _ I-MethodName
when -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
hyponyms -X- _ O
. -X- _ O
The -X- _ O
accuracy -X- _ B-MetricName
jumps -X- _ O
from -X- _ O
72.86 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ I-MetricValue
75.79 -X- _ I-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
and -X- _ O
from -X- _ O
77.83 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ I-MetricValue
78.98 -X- _ I-MetricValue
% -X- _ I-MetricValue
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
This -X- _ O
reinforces -X- _ O
our -X- _ O
claim -X- _ O
that -X- _ O
with -X- _ O
more -X- _ O
careful -X- _ O
tuning -X- _ O
of -X- _ O
the -X- _ O
threshold -X- _ O
, -X- _ O
we -X- _ O
might -X- _ O
get -X- _ O
improvements -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
in -X- _ O
other -X- _ O
methods -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
Voting -X- _ I-MethodName
performs -X- _ O
better -X- _ O
than -X- _ O
vanilla -X- _ B-MethodName
BERT -X- _ I-MethodName
FitB -X- _ I-MethodName
on -X- _ O
both -X- _ O
subtasks -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
intuitive -X- _ O
since -X- _ O
in -X- _ O
the -X- _ O
latter -X- _ O
, -X- _ O
we -X- _ O
truncate -X- _ O
the -X- _ O
article -X- _ O
to -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ I-HyperparameterValue
without -X- _ O
any -X- _ O
consideration -X- _ O
of -X- _ O
how -X- _ O
much -X- _ O
context -X- _ O
is -X- _ O
lost -X- _ O
. -X- _ O
Voting -X- _ O
, -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
considers -X- _ O
all -X- _ O
contexts -X- _ O
and -X- _ O
hence -X- _ O
, -X- _ O
gives -X- _ O
a -X- _ O
superior -X- _ O
performance -X- _ O
. -X- _ O
For -X- _ O
GA -X- _ B-MethodName
- -X- _ I-MethodName
Reader -X- _ I-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
, -X- _ O
when -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
GA -X- _ B-MethodName
- -X- _ I-MethodName
Reader -X- _ I-MethodName
baseline -X- _ O
, -X- _ O
the -X- _ B-MetricName
accuracy -X- _ I-MetricName
improves -X- _ O
from -X- _ O
21 -X- _ B-MetricValue
% -X- _ I-MetricValue
to -X- _ O
39 -X- _ B-MetricValue
% -X- _ I-MetricValue
on -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
dev -X- _ O
set -X- _ O
. -X- _ O
Due -X- _ O
to -X- _ O
computational -X- _ O
restrictions -X- _ O
, -X- _ O
we -X- _ O
could -X- _ O
n't -X- _ O
pretrain -X- _ O
GA -X- _ O
- -X- _ O
BERT -X- _ O
, -X- _ O
and -X- _ O
only -X- _ O
fine -X- _ O
- -X- _ O
tuned -X- _ O
it -X- _ O
for -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
to -X- _ O
get -X- _ O
an -X- _ O
idea -X- _ O
about -X- _ O
its -X- _ O
performance -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
( -X- _ B-MetricValue
19 -X- _ I-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
The -X- _ O
Answer -X- _ B-MethodName
- -X- _ I-MethodName
Attention -X- _ I-MethodName
system -X- _ I-MethodName
gave -X- _ O
us -X- _ O
a -X- _ O
dev -X- _ O
score -X- _ O
of -X- _ O
≈61 -X- _ B-MetricName
% -X- _ I-MetricName
on -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
much -X- _ O
higher -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
GSAMN -X- _ I-MethodName
- -X- _ I-MethodName
Cloze -X- _ I-MethodName
achieves -X- _ O
≈31 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
on -X- _ O
subtask -X- _ O
- -X- _ O
I -X- _ O
dev -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
reasons -X- _ O
for -X- _ O
this -X- _ O
could -X- _ O
be -X- _ O
lack -X- _ O
of -X- _ O
pretraining -X- _ O
, -X- _ O
unlike -X- _ O
the -X- _ O
original -X- _ O
paper -X- _ O
, -X- _ O
or -X- _ O
different -X- _ O
way -X- _ O
to -X- _ O
getting -X- _ O
the -X- _ O
output -X- _ O
logits -X- _ O
. -X- _ O
We -X- _ O
see -X- _ O
improvement -X- _ O
as -X- _ O
we -X- _ O
reduced -X- _ O
number -X- _ O
of -X- _ O
layers -X- _ O
to -X- _ O
1(≈38 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
and -X- _ O
to -X- _ O
0(≈73 -X- _ B-MetricValue
% -X- _ I-MetricValue
) -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
we -X- _ O
discarded -X- _ O
this -X- _ O
approach -X- _ O
. -X- _ O
The -X- _ O
Royal -X- _ O
College -X- _ O
of -X- _ O
Physicians -X- _ O
of -X- _ O
Edinburgh -X- _ O
warned -X- _ O
that -X- _ O
being -X- _ O
overweight -X- _ O
may -X- _ O
now -X- _ O
be -X- _ O
considered -X- _ O
" -X- _ O
the -X- _ O
norm -X- _ O
" -X- _ O
. -X- _ O
It -X- _ O
claimed -X- _ O
a -X- _ O
tax -X- _ O
would -X- _ O
help -X- _ O
fund -X- _ O
the -X- _ O
" -X- _ O
spiralling -X- _ O
" -X- _ O
healthcare -X- _ O
costs -X- _ O
associated -X- _ O
with -X- _ O
the -X- _ O
problem -X- _ O
. -X- _ O
The -X- _ O
British -X- _ O
Soft -X- _ O
Drinks -X- _ O
Association -X- _ O
( -X- _ O
BSDA -X- _ O
) -X- _ O
insisted -X- _ O
that -X- _ O
the -X- _ O
case -X- _ O
is -X- _ O
" -X- _ O
not -X- _ O
compelling -X- _ O
" -X- _ O
. -X- _ O
It -X- _ O
cited -X- _ O
research -X- _ O
which -X- _ O
suggested -X- _ O
a -X- _ O
20 -X- _ O
% -X- _ O
tax -X- _ O
would -X- _ O
save -X- _ O
just -X- _ O
four -X- _ O
calories -X- _ O
per -X- _ O
day -X- _ O
. -X- _ O
Liverpool -X- _ O
University -X- _ O
chair -X- _ O
of -X- _ O
clinical -X- _ O
epidemiology -X- _ O
, -X- _ O
Simon -X- _ O
Capewell -X- _ O
, -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
speak -X- _ O
at -X- _ O
a -X- _ O
conference -X- _ O
on -X- _ O
the -X- _ O
issue -X- _ O
in -X- _ O
Edinburgh -X- _ O
later -X- _ O
, -X- _ O
entitled -X- _ O
: -X- _ O
" -X- _ O
Obesity -X- _ O
: -X- _ O
A -X- _ O
21st -X- _ O
Century -X- _ O
Epidemic -X- _ O
" -X- _ O
. -X- _ O
Professor -X- _ O
Capewell -X- _ O
will -X- _ O
cite -X- _ O
Mexico -X- _ O
as -X- _ O
one -X- _ O
example -X- _ O
where -X- _ O
a -X- _ O
10 -X- _ O
% -X- _ O
sugary -X- _ O
drinks -X- _ O
tax -X- _ O
is -X- _ O
believed -X- _ O
to -X- _ O
have -X- _ O
contributed -X- _ O
to -X- _ O
a -X- _ O
10 -X- _ O
% -X- _ O
reduction -X- _ O
in -X- _ O
the -X- _ O
consumption -X- _ O
of -X- _ O
such -X- _ O
beverages -X- _ O
while -X- _ O
Finland -X- _ O
, -X- _ O
France -X- _ O
, -X- _ O
Hungary -X- _ O
, -X- _ O
Latvia -X- _ O
and -X- _ O
the -X- _ O
USA -X- _ O
have -X- _ O
also -X- _ O
introduced -X- _ O
sugar -X- _ O
taxes -X- _ O
. -X- _ O
He -X- _ O
said -X- _ O
: -X- _ O
" -X- _ O
The -X- _ O
revenues -X- _ O
raised -X- _ O
can -X- _ O
then -X- _ O
be -X- _ O
invested -X- _ O
back -X- _ O
into -X- _ O
initiatives -X- _ O
to -X- _ O
increase -X- _ O
children -X- _ O
' -X- _ O
s -X- _ O
health -X- _ O
in -X- _ O
these -X- _ O
countries -X- _ O
, -X- _ O
as -X- _ O
is -X- _ O
happening -X- _ O
in -X- _ O
Mexico -X- _ O
. -X- _ O
" -X- _ O
Scotland -X- _ O
has -X- _ O
an -X- _ O
excellent -X- _ O
track -X- _ O
record -X- _ O
in -X- _ O
addressing -X- _ O
public -X- _ O
health -X- _ O
issues -X- _ O
. -X- _ O
Notable -X- _ O
achievements -X- _ O
include -X- _ O
smoke -X- _ O
-free -X- _ O
public -X- _ O
places -X- _ O
and -X- _ O
proposals -X- _ O
for -X- _ O
minimum -X- _ O
unit -X- _ O
pricing -X- _ O
for -X- _ O
alcohol -X- _ O
. -X- _ O
We -X- _ O
need -X- _ O
to -X- _ O
explore -X- _ O
how -X- _ O
these -X- _ O
developments -X- _ O
could -X- _ O
be -X- _ O
repeated -X- _ O
with -X- _ O
sugary -X- _ O
drinks -X- _ O
. -X- _ O
" -X- _ O
Gavin -X- _ O
Partington -X- _ O
, -X- _ O
BSDA -X- _ O
director -X- _ O
general -X- _ O
, -X- _ O
said -X- _ O
: -X- _ O
" -X- _ O
The -X- _ O
efforts -X- _ O
by -X- _ O
soft -X- _ O
drinks -X- _ O
companies -X- _ O
including -X- _ O
product -X- _ O
reformulation -X- _ O
, -X- _ O
smaller -X- _ O
pack -X- _ O
sizes -X- _ O
and -X- _ O
increased -X- _ O
promotion -X- _ O
of -X- _ O
low -X- _ O
and -X- _ O
no -X- _ O
-calorie -X- _ O
drinks -X- _ O
have -X- _ O
led -X- _ O
to -X- _ O
a -X- _ O
7 -X- _ O
% -X- _ O
reduction -X- _ O
in -X- _ O
calories -X- _ O
from -X- _ O
soft -X- _ O
drinks -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
three -X- _ O
years -X- _ O
. -X- _ O
" -X- _ O
It -X- _ O
' -X- _ O
s -X- _ O
also -X- _ O
worth -X- _ O
noting -X- _ O
that -X- _ O
politicians -X- _ O
in -X- _ O
Belgium -X- _ O
and -X- _ O
Denmark -X- _ O
rejected -X- _ O
the -X- _ O
notion -X- _ O
of -X- _ O
a -X- _ O
tax -X- _ O
in -X- _ O
2013 -X- _ O
and -X- _ O
the -X- _ O
experience -X- _ O
in -X- _ O
France -X- _ O
shows -X- _ O
that -X- _ O
while -X- _ O
sales -X- _ O
of -X- _ O
soft -X- _ O
drinks -X- _ O
initially -X- _ O
fell -X- _ O
after -X- _ O
a -X- _ O
tax -X- _ O
was -X- _ O
introduced -X- _ O
in -X- _ O
2012 -X- _ O
, -X- _ O
they -X- _ O
have -X- _ O
increased -X- _ O
since -X- _ O
. -X- _ O
" -X- _ O
Doctors -X- _ O
have -X- _ O
called -X- _ O
for -X- _ O
the -X- _ O
introduction -X- _ O
of -X- _ O
a -X- _ O
tax -X- _ O
on -X- _ O
sugary -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
and -X- _ O
drinks -X- _ O
to -X- _ O
tackle -X- _ O
what -X- _ O
they -X- _ O
describe -X- _ O
as -X- _ O
an -X- _ O
" -X- _ O
obesity -X- _ O
epidemic -X- _ O
" -X- _ O
.Options -X- _ O
: -X- _ O
Food -X- _ O
, -X- _ O
Terms -X- _ O
, -X- _ O
Head -X- _ O
, -X- _ O
Unit -X- _ O
, -X- _ O
Snacks -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
method -X- _ O
of -X- _ O
Integrated -X- _ O
Gradients -X- _ O
( -X- _ O
Sundararajan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
follow -X- _ O
Ramnath -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2020 -X- _ O
) -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
wise -X- _ O
attribution -X- _ O
scores -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
for -X- _ O
both -X- _ O
subtasks -X- _ O
. -X- _ O
We -X- _ O
compute -X- _ O
the -X- _ O
Integrated -X- _ B-MethodName
Gradients -X- _ I-MethodName
of -X- _ O
the -X- _ O
target -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
embedding -X- _ O
outputs -X- _ O
. -X- _ O
The -X- _ O
Riemann -X- _ B-MethodName
Right -X- _ I-MethodName
Approximation -X- _ I-MethodName
Method -X- _ I-MethodName
with -X- _ O
n -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
= -X- _ O
25 -X- _ B-HyperparameterValue
is -X- _ O
used -X- _ O
. -X- _ O
After -X- _ O
obtaining -X- _ O
the -X- _ O
token -X- _ O
- -X- _ O
wise -X- _ O
attribution -X- _ O
scores -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
the -X- _ O
word -X- _ O
- -X- _ O
wise -X- _ O
attribution -X- _ O
scores -X- _ O
by -X- _ O
using -X- _ O
token -X- _ B-MethodName
- -X- _ I-MethodName
to -X- _ I-MethodName
- -X- _ I-MethodName
word -X- _ I-MethodName
offset -X- _ I-MethodName
mapping -X- _ I-MethodName
. -X- _ O
We -X- _ O
pick -X- _ O
the -X- _ O
top-10 -X- _ O
word -X- _ O
- -X- _ O
wise -X- _ O
attribution -X- _ O
scores -X- _ O
and -X- _ O
normalise -X- _ O
them -X- _ O
. -X- _ O
To -X- _ O
implement -X- _ O
IG -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Captum -X- _ O
( -X- _ O
Kokhlikyan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
library -X- _ O
. -X- _ O
In -X- _ O
favour -X- _ O
of -X- _ O
brevity -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
one -X- _ O
example -X- _ O
for -X- _ O
each -X- _ O
subtask -X- _ O
. -X- _ O
In -X- _ O
Fig -X- _ O
. -X- _ O
3 -X- _ O
, -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
is -X- _ O
" -X- _ O
legislative -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
attribution -X- _ O
scores -X- _ O
of -X- _ O
words -X- _ O
like -X- _ O
senate -X- _ O
, -X- _ O
senators -X- _ O
, -X- _ O
municipal -X- _ O
and -X- _ O
President -X- _ O
are -X- _ O
high -X- _ O
, -X- _ O
as -X- _ O
is -X- _ O
demonstrated -X- _ O
by -X- _ O
the -X- _ O
intensity -X- _ O
of -X- _ O
the -X- _ O
colour -X- _ O
. -X- _ O
The -X- _ O
word -X- _ O
" -X- _ O
legislative -X- _ O
" -X- _ O
is -X- _ O
, -X- _ O
in -X- _ O
a -X- _ O
sense -X- _ O
, -X- _ O
more -X- _ O
imperceptible -X- _ O
than -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
mentioned -X- _ O
above -X- _ O
. -X- _ O
The -X- _ O
senate -X- _ O
is -X- _ O
the -X- _ O
legislative -X- _ O
branch -X- _ O
of -X- _ O
the -X- _ O
government -X- _ O
, -X- _ O
and -X- _ O
senators -X- _ O
are -X- _ O
its -X- _ O
members -X- _ O
; -X- _ O
municipal -X- _ O
refers -X- _ O
to -X- _ O
municipal -X- _ O
corporations -X- _ O
which -X- _ O
are -X- _ O
the -X- _ O
grassroots -X- _ O
governing -X- _ O
bodies -X- _ O
, -X- _ O
etc -X- _ O
. -X- _ O
Moreover -X- _ O
, -X- _ O
other -X- _ O
words -X- _ O
such -X- _ O
as -X- _ O
elections -X- _ O
, -X- _ O
political -X- _ O
, -X- _ O
country -X- _ O
also -X- _ O
have -X- _ O
high -X- _ O
attribution -X- _ O
scores -X- _ O
. -X- _ O
These -X- _ O
words -X- _ O
are -X- _ O
related -X- _ O
to -X- _ O
" -X- _ O
legislative -X- _ O
" -X- _ O
which -X- _ O
exhibits -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
FitB -X- _ I-MethodName
is -X- _ O
not -X- _ O
only -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
imperceptibility -X- _ B-TaskName
, -X- _ O
but -X- _ O
is -X- _ O
also -X- _ O
able -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
suitable -X- _ O
word -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
in -X- _ O
Fig -X- _ O
. -X- _ O
4 -X- _ O
, -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
is -X- _ O
" -X- _ O
food -X- _ O
" -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
" -X- _ O
snacks -X- _ O
" -X- _ O
is -X- _ O
also -X- _ O
an -X- _ O
option -X- _ O
; -X- _ O
however -X- _ O
, -X- _ O
food -X- _ O
is -X- _ O
more -X- _ O
non -X- _ B-TaskName
- -X- _ I-TaskName
specific -X- _ I-TaskName
than -X- _ O
" -X- _ O
snacks -X- _ O
" -X- _ O
and -X- _ O
hence -X- _ O
, -X- _ O
food -X- _ O
is -X- _ O
the -X- _ O
correct -X- _ O
option -X- _ O
. -X- _ O
Another -X- _ O
interesting -X- _ O
thing -X- _ O
to -X- _ O
note -X- _ O
is -X- _ O
the -X- _ O
high -X- _ O
attribution -X- _ O
scores -X- _ O
for -X- _ O
words -X- _ O
/ -X- _ O
phrases -X- _ O
like -X- _ O
calories -X- _ O
, -X- _ O
beverages -X- _ O
, -X- _ O
sugar -X- _ O
and -X- _ O
sugary -X- _ O
drinks -X- _ O
. -X- _ O
This -X- _ O
backs -X- _ O
the -X- _ O
fact -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
concept -X- _ O
of -X- _ O
non -X- _ O
- -X- _ O
specificity -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
above -X- _ O
mentioned -X- _ O
words -X- _ O
are -X- _ O
essentially -X- _ O
hyponyms -X- _ O
of -X- _ O
" -X- _ O
food -X- _ O
" -X- _ O
. -X- _ O
We -X- _ O
tried -X- _ O
out -X- _ O
myriad -X- _ O
approaches -X- _ O
, -X- _ O
taking -X- _ O
care -X- _ O
to -X- _ O
not -X- _ O
only -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
architecture -X- _ O
aspect -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
how -X- _ O
we -X- _ O
can -X- _ O
quantify -X- _ O
imperceptibility -X- _ O
and -X- _ O
nonspecificity -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
achieve -X- _ O
favourable -X- _ O
improvements -X- _ O
in -X- _ O
all -X- _ O
approaches -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
observe -X- _ O
gains -X- _ O
in -X- _ O
accuracy -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
reckon -X- _ O
that -X- _ O
with -X- _ O
more -X- _ O
careful -X- _ O
tuning -X- _ O
of -X- _ O
parameters -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
threshold -X- _ O
in -X- _ O
the -X- _ O
Difference -X- _ B-MethodName
Method -X- _ I-MethodName
, -X- _ O
we -X- _ O
will -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
these -X- _ O
gains -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
We -X- _ O
further -X- _ O
interpreted -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
transformers -X- _ O
- -X- _ O
based -X- _ O
models -X- _ O
using -X- _ O
Integrated -X- _ B-MethodName
Gradients -X- _ I-MethodName
, -X- _ O
and -X- _ O
demonstrated -X- _ O
that -X- _ O
transformer -X- _ O
models -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
concepts -X- _ O
of -X- _ O
imperceptibility -X- _ B-TaskName
and -X- _ O
non -X- _ B-TaskName
- -X- _ I-TaskName
specificity -X- _ I-TaskName
. -X- _ O
In -X- _ O
the -X- _ O
future -X- _ O
, -X- _ O
we -X- _ O
intend -X- _ O
to -X- _ O
solidify -X- _ O
our -X- _ O
proposed -X- _ O
approaches -X- _ O
and -X- _ O
carry -X- _ O
out -X- _ O
further -X- _ O
research -X- _ O
in -X- _ O
this -X- _ O
interesting -X- _ O
field -X- _ O
. -X- _ O
We -X- _ O
thank -X- _ O
Rajaswa -X- _ O
Patil -X- _ O
1 -X- _ O
and -X- _ O
Somesh -X- _ O
Singh -X- _ O
2 -X- _ O
for -X- _ O
their -X- _ O
support -X- _ O
. -X- _ O
We -X- _ O
would -X- _ O
also -X- _ O
like -X- _ O
to -X- _ O
express -X- _ O
our -X- _ O
gratitude -X- _ O
to -X- _ O
our -X- _ O
colleagues -X- _ O
at -X- _ O
the -X- _ O
Language -X- _ O
Research -X- _ O
Group -X- _ O
( -X- _ O
LRG -X- _ O
) -X- _ O
3 -X- _ O
, -X- _ O
who -X- _ O
have -X- _ O
been -X- _ O
with -X- _ O
us -X- _ O
at -X- _ O
every -X- _ O
stepping -X- _ O
stone -X- _ O
. -X- _ O

When -X- _ O
evaluating -X- _ O
an -X- _ O
article -X- _ O
and -X- _ O
the -X- _ O
claims -X- _ O
it -X- _ O
makes -X- _ O
, -X- _ O
a -X- _ O
critical -X- _ O
reader -X- _ O
must -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
assess -X- _ O
where -X- _ O
the -X- _ O
information -X- _ O
presented -X- _ O
comes -X- _ O
from -X- _ O
, -X- _ O
and -X- _ O
whether -X- _ O
the -X- _ O
various -X- _ O
claims -X- _ O
are -X- _ O
mutually -X- _ O
consistent -X- _ O
and -X- _ O
support -X- _ O
the -X- _ O
conclusion -X- _ O
. -X- _ O
This -X- _ O
motivates -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
claim -X- _ B-TaskName
provenance -X- _ I-TaskName
, -X- _ O
which -X- _ O
seeks -X- _ O
to -X- _ O
trace -X- _ O
and -X- _ O
explain -X- _ O
the -X- _ O
origins -X- _ O
of -X- _ O
claims -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
new -X- _ O
techniques -X- _ O
to -X- _ O
model -X- _ O
and -X- _ O
reason -X- _ O
about -X- _ O
the -X- _ O
provenance -X- _ O
of -X- _ O
multiple -X- _ O
interacting -X- _ O
claims -X- _ O
, -X- _ O
including -X- _ O
how -X- _ O
to -X- _ O
capture -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
information -X- _ O
about -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
Our -X- _ O
solution -X- _ O
hinges -X- _ O
on -X- _ O
first -X- _ O
identifying -X- _ O
the -X- _ O
sentences -X- _ O
that -X- _ O
potentially -X- _ O
contain -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
develop -X- _ O
a -X- _ O
query -X- _ O
generator -X- _ O
with -X- _ O
our -X- _ O
novel -X- _ O
rank -X- _ O
- -X- _ O
aware -X- _ O
cross -X- _ O
attention -X- _ O
mechanism -X- _ O
, -X- _ O
which -X- _ O
aims -X- _ O
at -X- _ O
generating -X- _ O
metadata -X- _ O
for -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
context -X- _ O
and -X- _ O
signals -X- _ O
collected -X- _ O
from -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
. -X- _ O
This -X- _ O
establishes -X- _ O
relevant -X- _ O
search -X- _ O
queries -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
obtain -X- _ O
source -X- _ O
article -X- _ O
candidates -X- _ O
for -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
and -X- _ O
propose -X- _ O
an -X- _ O
ILP -X- _ B-MethodName
based -X- _ I-MethodName
algorithm -X- _ I-MethodName
to -X- _ O
infer -X- _ O
the -X- _ O
best -X- _ O
sources -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
a -X- _ O
newly -X- _ O
created -X- _ O
evaluation -X- _ O
dataset -X- _ O
1 -X- _ O
, -X- _ O
Politi -X- _ B-DatasetName
- -X- _ I-DatasetName
Prov -X- _ I-DatasetName
, -X- _ O
based -X- _ O
on -X- _ O
fact -X- _ O
- -X- _ O
checking -X- _ O
articles -X- _ O
from -X- _ O
www.politifa -X- _ O
ct.com -X- _ O
; -X- _ O
our -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
our -X- _ O
solution -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
significant -X- _ O
improvement -X- _ O
over -X- _ O
baselines -X- _ O
. -X- _ O
Misinformation -X- _ O
is -X- _ O
on -X- _ O
the -X- _ O
rise -X- _ O
, -X- _ O
and -X- _ O
people -X- _ O
are -X- _ O
fighting -X- _ O
it -X- _ O
with -X- _ O
fact -X- _ O
checking -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
work -X- _ O
in -X- _ O
the -X- _ O
current -X- _ O
literature -X- _ O
( -X- _ O
Thorne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019;Barrón -X- _ O
- -X- _ O
Cedeno -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020;Hidey -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
focuses -X- _ O
on -X- _ O
automating -X- _ O
factchecking -X- _ O
for -X- _ O
a -X- _ O
single -X- _ O
claim -X- _ O
. -X- _ O
In -X- _ O
reality -X- _ O
, -X- _ O
a -X- _ O
claim -X- _ O
can -X- _ O
be -X- _ O
complex -X- _ O
, -X- _ O
and -X- _ O
proposed -X- _ O
as -X- _ O
a -X- _ O
conclusion -X- _ O
of -X- _ O
an -X- _ O
article -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
understanding -X- _ O
what -X- _ O
information -X- _ O
supports -X- _ O
the -X- _ O
article -X- _ O
, -X- _ O
especially -X- _ O
information -X- _ O
that -X- _ O
was -X- _ O
not -X- _ O
originated -X- _ O
within -X- _ O
the -X- _ O
same -X- _ O
article -X- _ O
, -X- _ O
and -X- _ O
where -X- _ O
it -X- _ O
originates -X- _ O
from -X- _ O
, -X- _ O
are -X- _ O
very -X- _ O
important -X- _ O
for -X- _ O
readers -X- _ O
who -X- _ O
want -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
they -X- _ O
can -X- _ O
believe -X- _ O
the -X- _ O
claim -X- _ O
. -X- _ O
Figure -X- _ O
1 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
such -X- _ O
a -X- _ O
claim -X- _ O
, -X- _ O
" -X- _ O
Marco -X- _ O
Rubio -X- _ O
says -X- _ O
Anthony -X- _ O
Fauci -X- _ O
lies -X- _ O
about -X- _ O
masks -X- _ O
. -X- _ O
Fauci -X- _ O
did -X- _ O
n't -X- _ O
. -X- _ O
" -X- _ O
2 -X- _ O
with -X- _ O
its -X- _ O
article -X- _ O
from -X- _ O
politifact.com -X- _ O
. -X- _ O
A -X- _ O
critical -X- _ O
reader -X- _ O
of -X- _ O
the -X- _ O
content -X- _ O
will -X- _ O
find -X- _ O
that -X- _ O
several -X- _ O
major -X- _ O
sources -X- _ O
support -X- _ O
the -X- _ O
author -X- _ O
's -X- _ O
claim -X- _ O
: -X- _ O
Source -X- _ O
article -X- _ O
1 -X- _ O
in -X- _ O
the -X- _ O
figure -X- _ O
is -X- _ O
CBS -X- _ O
News,"60 -X- _ O
Minutes -X- _ O
" -X- _ O
interview -X- _ O
with -X- _ O
Anthony -X- _ O
Fauci -X- _ O
, -X- _ O
on -X- _ O
March -X- _ O
8 -X- _ O
, -X- _ O
2020 -X- _ O
, -X- _ O
which -X- _ O
reveals -X- _ O
that -X- _ O
Dr. -X- _ O
Fauci -X- _ O
's -X- _ O
main -X- _ O
point -X- _ O
was -X- _ O
to -X- _ O
preserve -X- _ O
masks -X- _ O
for -X- _ O
those -X- _ O
who -X- _ O
were -X- _ O
already -X- _ O
ill -X- _ O
and -X- _ O
people -X- _ O
providing -X- _ O
care -X- _ O
. -X- _ O
If -X- _ O
readers -X- _ O
can -X- _ O
validate -X- _ O
all -X- _ O
sources -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
, -X- _ O
they -X- _ O
will -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
the -X- _ O
article -X- _ O
is -X- _ O
trustworthy -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
our -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
automatically -X- _ O
find -X- _ O
these -X- _ O
sources -X- _ O
for -X- _ O
a -X- _ O
given -X- _ O
article -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
different -X- _ O
problem -X- _ O
from -X- _ O
fact -X- _ O
- -X- _ O
checking -X- _ O
: -X- _ O
Factchecking -X- _ O
seeks -X- _ O
evidence -X- _ O
for -X- _ O
a -X- _ O
claim -X- _ O
, -X- _ O
while -X- _ O
here -X- _ O
we -X- _ O
only -X- _ O
care -X- _ O
about -X- _ O
the -X- _ O
information -X- _ O
sources -X- _ O
the -X- _ O
authors -X- _ O
used -X- _ O
when -X- _ O
they -X- _ O
were -X- _ O
writing -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
problem -X- _ O
we -X- _ O
address -X- _ O
is -X- _ O
critical -X- _ O
also -X- _ O
to -X- _ O
authors -X- _ O
who -X- _ O
want -X- _ O
to -X- _ O
give -X- _ O
credit -X- _ O
to -X- _ O
those -X- _ O
who -X- _ O
have -X- _ O
contributed -X- _ O
to -X- _ O
their -X- _ O
article -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
enables -X- _ O
a -X- _ O
recursive -X- _ O
analysis -X- _ O
that -X- _ O
can -X- _ O
trace -X- _ O
back -X- _ O
to -X- _ O
the -X- _ O
starting -X- _ O
points -X- _ O
of -X- _ O
an -X- _ O
article -X- _ O
. -X- _ O
This -X- _ O
motivates -X- _ O
the -X- _ O
study -X- _ O
of -X- _ O
provenance -X- _ B-TaskName
for -X- _ I-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
claims -X- _ I-TaskName
, -X- _ O
which -X- _ O
describes -X- _ O
where -X- _ O
a -X- _ O
specific -X- _ O
claim -X- _ O
may -X- _ O
have -X- _ O
come -X- _ O
from -X- _ O
and -X- _ O
how -X- _ O
it -X- _ O
has -X- _ O
spread -X- _ O
. -X- _ O
Early -X- _ O
work -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
proposed -X- _ O
a -X- _ O
formulation -X- _ O
to -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
solution -X- _ O
to -X- _ O
infer -X- _ O
, -X- _ O
the -X- _ O
provenance -X- _ O
graph -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
claim -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
that -X- _ O
model -X- _ O
is -X- _ O
insufficient -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
provenance -X- _ O
of -X- _ O
an -X- _ O
article -X- _ O
, -X- _ O
because -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
an -X- _ O
article -X- _ O
consists -X- _ O
of -X- _ O
multiple -X- _ O
claims -X- _ O
, -X- _ O
and -X- _ O
it -X- _ O
leverages -X- _ O
information -X- _ O
from -X- _ O
other -X- _ O
sources -X- _ O
, -X- _ O
therefore -X- _ O
the -X- _ O
provenance -X- _ O
of -X- _ O
all -X- _ O
claims -X- _ O
should -X- _ O
be -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
's -X- _ O
provenance -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
inference -X- _ O
solution -X- _ O
they -X- _ O
proposed -X- _ O
can -X- _ O
only -X- _ O
extract -X- _ O
domain -X- _ O
- -X- _ O
level -X- _ O
provenance -X- _ O
information -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
cbsnews.com -X- _ O
, -X- _ O
while -X- _ O
it -X- _ O
can -X- _ O
not -X- _ O
directly -X- _ O
link -X- _ O
the -X- _ O
claim -X- _ O
to -X- _ O
its -X- _ O
source -X- _ O
article -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
https://www.cbsnews.com/news/preventingcoronavirus-facemask-60-minutes-2020-03-08/. -X- _ O
Such -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
provenance -X- _ O
information -X- _ O
is -X- _ O
important -X- _ O
because -X- _ O
it -X- _ O
can -X- _ O
help -X- _ O
people -X- _ O
understand -X- _ O
the -X- _ O
original -X- _ O
context -X- _ O
that -X- _ O
influenced -X- _ O
the -X- _ O
information -X- _ O
they -X- _ O
read -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
notion -X- _ O
of -X- _ O
a -X- _ O
provenance -X- _ O
graph -X- _ O
should -X- _ O
be -X- _ O
extended -X- _ O
to -X- _ O
incorporate -X- _ O
provenance -X- _ O
for -X- _ O
articles -X- _ O
, -X- _ O
and -X- _ O
that -X- _ O
we -X- _ O
need -X- _ O
a -X- _ O
more -X- _ O
comprehensive -X- _ O
solution -X- _ O
that -X- _ O
can -X- _ O
identify -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
used -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
and -X- _ O
infer -X- _ O
its -X- _ O
corresponding -X- _ O
source -X- _ O
article -X- _ O
: -X- _ O
namely -X- _ O
, -X- _ O
its -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
provenance -X- _ O
information -X- _ O
. -X- _ O
Technically -X- _ O
, -X- _ O
capturing -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
provenance -X- _ O
for -X- _ O
an -X- _ O
article -X- _ O
is -X- _ O
challenging -X- _ O
because -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
there -X- _ O
may -X- _ O
be -X- _ O
large -X- _ O
numbers -X- _ O
of -X- _ O
sentences -X- _ O
in -X- _ O
an -X- _ O
article -X- _ O
, -X- _ O
and -X- _ O
not -X- _ O
all -X- _ O
are -X- _ O
from -X- _ O
external -X- _ O
sources -X- _ O
nor -X- _ O
important -X- _ O
( -X- _ O
thus -X- _ O
, -X- _ O
their -X- _ O
provenance -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
worth -X- _ O
considering);(2 -X- _ O
) -X- _ O
a -X- _ O
sentence -X- _ O
in -X- _ O
an -X- _ O
article -X- _ O
is -X- _ O
usually -X- _ O
just -X- _ O
a -X- _ O
textual -X- _ O
fragment -X- _ O
of -X- _ O
its -X- _ O
source -X- _ O
article -X- _ O
, -X- _ O
and -X- _ O
simply -X- _ O
looking -X- _ O
for -X- _ O
other -X- _ O
articles -X- _ O
with -X- _ O
related -X- _ O
content -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
low -X- _ O
precision -X- _ B-MetricName
with -X- _ O
regards -X- _ O
to -X- _ O
finding -X- _ O
the -X- _ O
correct -X- _ O
original -X- _ O
article -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
running -X- _ O
example -X- _ O
, -X- _ O
sentence2 -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
is -X- _ O
" -X- _ O
On -X- _ O
March -X- _ O
29 -X- _ O
, -X- _ O
President -X- _ O
Donald -X- _ O
Trump -X- _ O
and -X- _ O
the -X- _ O
coronavirus -X- _ O
task -X- _ O
force -X- _ O
briefed -X- _ O
the -X- _ O
press -X- _ O
on -X- _ O
steps -X- _ O
underway -X- _ O
to -X- _ O
increase -X- _ O
... -X- _ O
" -X- _ O
, -X- _ O
whose -X- _ O
source -X- _ O
is -X- _ O
White -X- _ O
House -X- _ O
's -X- _ O
coronavirus -X- _ O
task -X- _ O
force -X- _ O
press -X- _ O
briefing -X- _ O
on -X- _ O
March -X- _ O
29 -X- _ O
, -X- _ O
2020 -X- _ O
. -X- _ O
If -X- _ O
we -X- _ O
directly -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
sentence -X- _ O
on -X- _ O
the -X- _ O
web -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
find -X- _ O
this -X- _ O
among -X- _ O
popular -X- _ O
articles -X- _ O
from -X- _ O
the -X- _ O
news -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
generate -X- _ O
better -X- _ O
keywords -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
focused -X- _ O
search -X- _ O
. -X- _ O
The -X- _ O
key -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
we -X- _ O
introduce -X- _ O
and -X- _ O
formalize -X- _ O
the -X- _ O
problem -X- _ O
of -X- _ O
inferring -X- _ B-TaskName
finegrained -X- _ I-TaskName
provenance -X- _ I-TaskName
for -X- _ O
an -X- _ O
article -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
general -X- _ O
framework -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
that -X- _ O
have -X- _ O
provided -X- _ O
important -X- _ O
information -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
article -X- _ O
, -X- _ O
including -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
a -X- _ O
ranking -X- _ O
module -X- _ O
that -X- _ O
can -X- _ O
identify -X- _ O
sentences -X- _ O
that -X- _ O
contain -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
main -X- _ O
topic -X- _ O
and -X- _ O
the -X- _ O
main -X- _ O
entities -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
; -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
a -X- _ O
query -X- _ O
generator -X- _ O
that -X- _ O
can -X- _ O
generate -X- _ O
possible -X- _ O
metadata -X- _ O
for -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
title -X- _ O
, -X- _ O
the -X- _ O
published -X- _ O
date -X- _ O
, -X- _ O
the -X- _ O
source -X- _ O
website -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
the -X- _ O
selected -X- _ O
sentences -X- _ O
; -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
an -X- _ O
integer -X- _ O
linear -X- _ O
program -X- _ O
( -X- _ O
ILP -X- _ O
) -X- _ O
based -X- _ O
algorithm -X- _ O
to -X- _ O
jointly -X- _ O
identify -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
from -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
candidates -X- _ O
. -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
solutions -X- _ O
, -X- _ O
we -X- _ O
collect -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
Politi -X- _ B-DatasetName
- -X- _ I-DatasetName
Prov -X- _ I-DatasetName
from -X- _ O
politifact.com -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
solution -X- _ O
we -X- _ O
proposed -X- _ O
can -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
significant -X- _ O
improvement -X- _ O
compared -X- _ O
with -X- _ O
baselines -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
article -X- _ O
d -X- _ O
, -X- _ O
we -X- _ O
are -X- _ O
to -X- _ O
capture -X- _ O
its -X- _ O
finegrained -X- _ B-TaskName
provenance -X- _ I-TaskName
, -X- _ O
by -X- _ O
inferring -X- _ O
k -X- _ O
source -X- _ O
articles -X- _ O
SA -X- _ O
k -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
that -X- _ O
provide -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
information -X- _ O
for -X- _ O
d. -X- _ O
We -X- _ O
adopt -X- _ O
the -X- _ O
notion -X- _ O
of -X- _ O
provenance -X- _ O
from -X- _ O
( -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
inferring -X- _ O
provenance -X- _ O
for -X- _ O
a -X- _ O
claim -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
information -X- _ O
from -X- _ O
the -X- _ O
given -X- _ O
article -X- _ O
. -X- _ O
To -X- _ O
find -X- _ O
SA -X- _ O
k -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
three -X- _ O
subproblems -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
solve -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
locate -X- _ O
the -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
in -X- _ O
d -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
we -X- _ O
need -X- _ O
a -X- _ O
sentence -X- _ O
ranking -X- _ O
module -X- _ O
that -X- _ O
can -X- _ O
estimate -X- _ O
a -X- _ O
score -X- _ O
σ -X- _ O
i -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
in -X- _ O
d -X- _ O
= -X- _ O
{ -X- _ O
s -X- _ O
i -X- _ O
} -X- _ O
n -X- _ O
i=1 -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
how -X- _ O
likely -X- _ O
s -X- _ O
i -X- _ O
contains -X- _ O
external -X- _ O
information -X- _ O
. -X- _ O
Then -X- _ O
we -X- _ O
will -X- _ O
choose -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
sentences -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
score -X- _ O
, -X- _ O
and -X- _ O
try -X- _ O
to -X- _ O
find -X- _ O
source -X- _ O
articles -X- _ O
for -X- _ O
those -X- _ O
sentences -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
selected -X- _ O
sentence -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
candidate -X- _ O
links -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
be -X- _ O
its -X- _ O
source -X- _ O
articles -X- _ O
. -X- _ O
To -X- _ O
achieve -X- _ O
this -X- _ O
goal -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
, -X- _ O
based -X- _ O
on -X- _ O
which -X- _ O
we -X- _ O
can -X- _ O
access -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
articles -X- _ O
on -X- _ O
the -X- _ O
web -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
have -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
1 -X- _ O
, -X- _ O
directly -X- _ O
searching -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
on -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
may -X- _ O
result -X- _ O
in -X- _ O
a -X- _ O
low -X- _ O
precision -X- _ B-MetricName
of -X- _ O
finding -X- _ O
the -X- _ O
correct -X- _ O
source -X- _ O
article -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
develop -X- _ O
a -X- _ O
query -X- _ O
generator -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
possible -X- _ O
metadata -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
source -X- _ O
article -X- _ O
as -X- _ O
new -X- _ O
search -X- _ O
keywords -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
search -X- _ O
engine -X- _ O
is -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
recall -X- _ O
source -X- _ O
articles -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
collect -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
search -X- _ O
results -X- _ O
as -X- _ O
the -X- _ O
candidates -X- _ O
for -X- _ O
a -X- _ O
selected -X- _ O
sentence -X- _ O
. -X- _ O
Finally -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
correct -X- _ O
source -X- _ O
article -X- _ O
from -X- _ O
the -X- _ O
candidates -X- _ O
, -X- _ O
for -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
. -X- _ O
Figure -X- _ O
2 -X- _ O
depicts -X- _ O
the -X- _ O
three -X- _ O
steps -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
conduct -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
fine -X- _ B-TaskName
- -X- _ I-TaskName
grained -X- _ I-TaskName
provenance -X- _ I-TaskName
, -X- _ O
which -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
three -X- _ O
subproblems -X- _ O
listed -X- _ O
above -X- _ O
. -X- _ O
We -X- _ O
will -X- _ O
elaborate -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
each -X- _ O
step -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
. -X- _ O
To -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
our -X- _ O
knowledge -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
existing -X- _ O
dataset -X- _ O
that -X- _ O
can -X- _ O
support -X- _ O
inferring -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
provenance -X- _ O
for -X- _ O
an -X- _ O
article -X- _ O
, -X- _ O
therefore -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
fact -X- _ O
- -X- _ O
checks -X- _ O
from -X- _ O
politifact -X- _ O
.com -X- _ O
to -X- _ O
support -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
the -X- _ O
evaluation -X- _ O
of -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
crawled -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
fact -X- _ O
- -X- _ O
check -X- _ O
questions -X- _ O
from -X- _ O
politifact.com -X- _ O
on -X- _ O
4 -X- _ O
different -X- _ O
issues -X- _ O
: -X- _ O
Coronavirus -X- _ O
, -X- _ O
Health -X- _ O
Care -X- _ O
, -X- _ O
Immigration -X- _ O
, -X- _ O
Taxes -X- _ O
in -X- _ O
September -X- _ O
, -X- _ O
2020 -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
question -X- _ O
, -X- _ O
we -X- _ O
further -X- _ O
crawled -X- _ O
its -X- _ O
webpage -X- _ O
to -X- _ O
obtain -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
title -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
actually -X- _ O
the -X- _ O
fact -X- _ O
- -X- _ O
check -X- _ O
question -X- _ O
itself -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
sections -X- _ O
of -X- _ O
the -X- _ O
main -X- _ O
text -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
the -X- _ O
" -X- _ O
Our -X- _ O
Sources -X- _ O
" -X- _ O
section -X- _ O
listing -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
articles -X- _ O
( -X- _ O
including -X- _ O
urls -X- _ O
) -X- _ O
that -X- _ O
provide -X- _ O
important -X- _ O
information -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
fact -X- _ O
- -X- _ O
check -X- _ O
article -X- _ O
. -X- _ O
Figure -X- _ O
3 -X- _ O
shows -X- _ O
an -X- _ O
example -X- _ O
of -X- _ O
such -X- _ O
a -X- _ O
section -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
extract -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
hyperlinks -X- _ O
in -X- _ O
the -X- _ O
webpage -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
tell -X- _ O
us -X- _ O
where -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
are -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
main -X- _ O
text -X- _ O
. -X- _ O
To -X- _ O
sum -X- _ O
up -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
main -X- _ O
text -X- _ O
of -X- _ O
each -X- _ O
webpage -X- _ O
as -X- _ O
the -X- _ O
given -X- _ O
article -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
listed -X- _ O
in -X- _ O
the -X- _ O
section -X- _ O
of -X- _ O
" -X- _ O
Our -X- _ O
Sources -X- _ O
" -X- _ O
as -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
our -X- _ O
system -X- _ O
wants -X- _ O
to -X- _ O
return -X- _ O
. -X- _ O
We -X- _ O
want -X- _ O
to -X- _ O
note -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
there -X- _ O
may -X- _ O
be -X- _ O
some -X- _ O
sources -X- _ O
missing -X- _ O
in -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
we -X- _ O
can -X- _ O
obtain -X- _ O
, -X- _ O
therefore -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
more -X- _ O
on -X- _ O
the -X- _ O
recall -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
we -X- _ O
collected -X- _ O
data -X- _ O
from -X- _ O
1765 -X- _ O
articles -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
use -X- _ O
883 -X- _ O
of -X- _ O
them -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
and -X- _ O
441 -X- _ O
and -X- _ O
441 -X- _ O
for -X- _ O
validation -X- _ O
and -X- _ O
testing -X- _ O
respectively -X- _ O
. -X- _ O
On -X- _ O
average -X- _ O
, -X- _ O
each -X- _ O
article -X- _ O
has -X- _ O
9.8 -X- _ O
source -X- _ O
articles -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
elaborate -X- _ O
how -X- _ O
we -X- _ O
solve -X- _ O
the -X- _ O
problems -X- _ O
proposed -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
article -X- _ O
, -X- _ O
the -X- _ O
first -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
identify -X- _ O
the -X- _ O
sentences -X- _ O
that -X- _ O
are -X- _ O
most -X- _ O
likely -X- _ O
to -X- _ O
contain -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
. -X- _ O
To -X- _ O
develop -X- _ O
a -X- _ O
general -X- _ O
data -X- _ O
- -X- _ O
driven -X- _ O
solution -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
design -X- _ O
a -X- _ O
ranking -X- _ O
function -X- _ O
by -X- _ O
domain -X- _ O
- -X- _ O
specific -X- _ O
feature -X- _ O
engineering -X- _ O
, -X- _ O
we -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
the -X- _ O
hyperlinks -X- _ O
inserted -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
find -X- _ O
where -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
are -X- _ O
mentioned -X- _ O
. -X- _ O
The -X- _ O
hyperlink -X- _ O
is -X- _ O
helpful -X- _ O
here -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
standard -X- _ O
for -X- _ O
the -X- _ O
author -X- _ O
to -X- _ O
provide -X- _ O
external -X- _ O
information -X- _ O
on -X- _ O
related -X- _ O
topics -X- _ O
to -X- _ O
the -X- _ O
reader -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
hyperlink -X- _ O
refers -X- _ O
one -X- _ O
at -X- _ O
the -X- _ O
listed -X- _ O
source -X- _ O
articles -X- _ O
, -X- _ O
it -X- _ O
means -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
the -X- _ O
one -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
looking -X- _ O
for -X- _ O
. -X- _ O
Then -X- _ O
our -X- _ O
problem -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
distinguish -X- _ O
those -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
regular -X- _ O
ones -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
. -X- _ O
Specifically -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
extract -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
hyperlinks -X- _ O
with -X- _ O
their -X- _ O
corresponding -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
article -X- _ O
d -X- _ O
, -X- _ O
and -X- _ O
denote -X- _ O
the -X- _ O
output -X- _ O
as -X- _ O
Hp(d -X- _ O
) -X- _ O
= -X- _ O
{ -X- _ O
( -X- _ O
l -X- _ O
, -X- _ O
s)|s -X- _ O
∈ -X- _ O
d -X- _ O
} -X- _ O
, -X- _ O
where -X- _ O
l -X- _ O
represents -X- _ O
the -X- _ O
link -X- _ O
of -X- _ O
the -X- _ O
article -X- _ O
and -X- _ O
s -X- _ O
represents -X- _ O
the -X- _ O
sentence -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
positive -X- _ O
sentences -X- _ O
for -X- _ O
d -X- _ O
denoted -X- _ O
as -X- _ O
P -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
by -X- _ O
finding -X- _ O
the -X- _ O
intersection -X- _ O
between -X- _ O
the -X- _ O
articles -X- _ O
in -X- _ O
Hp(d -X- _ O
) -X- _ O
and -X- _ O
those -X- _ O
inSA -X- _ O
k -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
P -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
= -X- _ O
{ -X- _ O
s|s -X- _ O
∈ -X- _ O
d -X- _ O
, -X- _ O
∃(l -X- _ O
, -X- _ O
s -X- _ O
) -X- _ O
∈ -X- _ O
Hp(d -X- _ O
) -X- _ O
, -X- _ O
s.t -X- _ O
. -X- _ O
, -X- _ O
l -X- _ O
∈ -X- _ O
SA -X- _ O
k -X- _ O
( -X- _ O
d)}.Meanwhile -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
negative -X- _ O
sentences -X- _ O
for -X- _ O
d -X- _ O
by -X- _ O
randomly -X- _ O
sampling -X- _ O
from -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
its -X- _ O
sentences -X- _ O
, -X- _ O
denoted -X- _ O
as -X- _ O
N -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
. -X- _ O
When -X- _ O
a -X- _ O
new -X- _ O
article -X- _ O
is -X- _ O
given -X- _ O
, -X- _ O
the -X- _ O
job -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
turns -X- _ O
out -X- _ O
to -X- _ O
estimate -X- _ O
a -X- _ O
score -X- _ O
σ -X- _ O
i -X- _ O
of -X- _ O
how -X- _ O
likely -X- _ O
each -X- _ O
sentence -X- _ O
s -X- _ O
i -X- _ O
in -X- _ O
d -X- _ O
refers -X- _ O
to -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
. -X- _ O
Since -X- _ O
the -X- _ O
sentences -X- _ O
referring -X- _ O
to -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
are -X- _ O
always -X- _ O
either -X- _ O
directly -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
main -X- _ O
topic -X- _ O
or -X- _ O
about -X- _ O
the -X- _ O
main -X- _ O
entities -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
leverage -X- _ O
them -X- _ O
to -X- _ O
build -X- _ O
our -X- _ O
model -X- _ O
. -X- _ O
Denote -X- _ O
the -X- _ O
title -X- _ O
of -X- _ O
d -X- _ O
as -X- _ O
t -X- _ O
d -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
entities -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
as -X- _ O
E -X- _ O
d -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
use -X- _ O
tf -X- _ O
- -X- _ O
idf -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
an -X- _ O
entity -X- _ O
to -X- _ O
an -X- _ O
article -X- _ O
. -X- _ O
We -X- _ O
build -X- _ O
our -X- _ O
model -X- _ O
by -X- _ O
leveraging -X- _ O
Roberta -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Using -X- _ O
the -X- _ O
same -X- _ O
notation -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
t -X- _ O
d -X- _ O
and -X- _ O
each -X- _ O
e -X- _ O
∈ -X- _ O
E -X- _ O
d -X- _ O
, -X- _ O
feeding -X- _ O
it -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
as -X- _ O
sentence -X- _ O
A -X- _ O
, -X- _ O
and -X- _ O
s -X- _ O
∈ -X- _ O
P -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
or -X- _ O
N -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
as -X- _ O
sentence -X- _ O
B -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
of -X- _ O
Roberta -X- _ B-MethodName
. -X- _ O
We -X- _ O
then -X- _ O
use -X- _ O
Roberta -X- _ B-MethodName
as -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
model -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
its -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
vector -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
a -X- _ O
two -X- _ B-HyperparameterValue
layer -X- _ B-HyperparameterName
neural -X- _ O
network -X- _ O
to -X- _ O
obtain -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
s -X- _ O
referring -X- _ O
to -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
learning -X- _ O
the -X- _ O
features -X- _ O
independently -X- _ O
for -X- _ O
each -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
model -X- _ O
better -X- _ O
capture -X- _ O
the -X- _ O
discriminative -X- _ O
feature -X- _ O
between -X- _ O
the -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
examples -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
margin -X- _ O
ranking -X- _ O
loss -X- _ O
to -X- _ O
the -X- _ O
learning -X- _ O
objective -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
enforce -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
distinguish -X- _ O
the -X- _ O
representations -X- _ O
between -X- _ O
positive -X- _ O
and -X- _ O
negative -X- _ O
examples -X- _ O
. -X- _ O
We -X- _ O
start -X- _ O
training -X- _ O
from -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Roberta -X- _ B-MethodName
model -X- _ O
and -X- _ O
fine -X- _ O
- -X- _ O
tune -X- _ O
it -X- _ O
to -X- _ O
our -X- _ O
ranking -X- _ O
task -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
loss -X- _ O
, -X- _ O
given -X- _ O
s -X- _ O
i -X- _ O
∈ -X- _ O
P -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
and -X- _ O
s -X- _ O
j -X- _ O
∈ -X- _ O
N -X- _ O
( -X- _ O
d):Li -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
− -X- _ O
log -X- _ O
σi -X- _ O
− -X- _ O
log -X- _ O
( -X- _ O
1 -X- _ O
− -X- _ O
σj -X- _ O
) -X- _ O
+ -X- _ O
max -X- _ O
0 -X- _ O
, -X- _ O
τ -X- _ O
( -X- _ O
sj -X- _ O
) -X- _ O
− -X- _ O
τ -X- _ O
( -X- _ O
si -X- _ O
) -X- _ O
+ -X- _ O
( -X- _ O
1)where -X- _ O
τ -X- _ O
( -X- _ O
s -X- _ O
i -X- _ O
) -X- _ O
and -X- _ O
τ -X- _ O
( -X- _ O
s -X- _ O
j -X- _ O
) -X- _ O
are -X- _ O
the -X- _ O
representations -X- _ O
, -X- _ O
obtained -X- _ O
by -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
a -X- _ O
single -X- _ B-HyperparameterValue
layer -X- _ B-HyperparameterName
neural -X- _ O
network -X- _ O
τ -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
vector -X- _ O
of -X- _ O
Roberta -X- _ B-MethodName
. -X- _ O
Identifying -X- _ O
the -X- _ O
sentences -X- _ O
that -X- _ O
are -X- _ O
describing -X- _ O
external -X- _ O
information -X- _ O
provides -X- _ O
us -X- _ O
with -X- _ O
a -X- _ O
clue -X- _ O
to -X- _ O
finding -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
. -X- _ O
The -X- _ O
next -X- _ O
step -X- _ O
is -X- _ O
to -X- _ O
find -X- _ O
candidate -X- _ O
articles -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
identified -X- _ O
sentences -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
have -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
1 -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
by -X- _ O
directly -X- _ O
searching -X- _ O
the -X- _ O
sentence -X- _ O
on -X- _ O
the -X- _ O
web -X- _ O
, -X- _ O
since -X- _ O
so -X- _ O
many -X- _ O
articles -X- _ O
may -X- _ O
be -X- _ O
talking -X- _ O
about -X- _ O
the -X- _ O
related -X- _ O
information -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
besides -X- _ O
using -X- _ O
the -X- _ O
sentence -X- _ O
as -X- _ O
the -X- _ O
query -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
a -X- _ O
query -X- _ O
generator -X- _ O
that -X- _ O
can -X- _ O
generate -X- _ O
a -X- _ O
better -X- _ O
query -X- _ O
for -X- _ O
searching -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
can -X- _ O
increase -X- _ O
the -X- _ O
possibility -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
recall -X- _ O
the -X- _ O
correct -X- _ O
source -X- _ O
article -X- _ O
. -X- _ O
To -X- _ O
generate -X- _ O
a -X- _ O
query -X- _ O
that -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
recall -X- _ B-MetricName
, -X- _ O
the -X- _ O
question -X- _ O
here -X- _ O
is -X- _ O
what -X- _ O
search -X- _ O
keywords -X- _ O
are -X- _ O
good -X- _ O
for -X- _ O
finding -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
besides -X- _ O
the -X- _ O
identified -X- _ O
sentences -X- _ O
themselves -X- _ O
? -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
that -X- _ O
the -X- _ O
metadata -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
article -X- _ O
, -X- _ O
including -X- _ O
its -X- _ O
source -X- _ O
domain -X- _ O
, -X- _ O
title -X- _ O
and -X- _ O
published -X- _ O
date -X- _ O
is -X- _ O
a -X- _ O
good -X- _ O
choice -X- _ O
. -X- _ O
Since -X- _ O
most -X- _ O
of -X- _ O
those -X- _ O
information -X- _ O
may -X- _ O
be -X- _ O
revealed -X- _ O
in -X- _ O
the -X- _ O
sentence -X- _ O
or -X- _ O
its -X- _ O
context -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
where -X- _ O
we -X- _ O
can -X- _ O
feed -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
generate -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
possible -X- _ O
source -X- _ O
domain -X- _ O
, -X- _ O
title -X- _ O
and -X- _ O
published -X- _ O
date -X- _ O
of -X- _ O
the -X- _ O
article -X- _ O
it -X- _ O
refers -X- _ O
to -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
running -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
sentence -X- _ O
identified -X- _ O
( -X- _ O
sentence -X- _ O
2 -X- _ O
in -X- _ O
the -X- _ O
figure -X- _ O
) -X- _ O
is -X- _ O
" -X- _ O
... -X- _ O
On -X- _ O
March -X- _ O
29 -X- _ O
, -X- _ O
President -X- _ O
... -X- _ O
" -X- _ O
. -X- _ O
The -X- _ O
source -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
article -X- _ O
it -X- _ O
refers -X- _ O
to -X- _ O
( -X- _ O
source -X- _ O
article -X- _ O
2 -X- _ O
in -X- _ O
the -X- _ O
figure -X- _ O
) -X- _ O
is -X- _ O
white -X- _ O
house -X- _ O
, -X- _ O
the -X- _ O
title -X- _ O
of -X- _ O
the -X- _ O
article -X- _ O
is -X- _ O
coronavirus -X- _ O
task -X- _ O
force -X- _ O
press -X- _ O
briefing -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
published -X- _ O
date -X- _ O
is -X- _ O
March -X- _ O
29 -X- _ O
, -X- _ O
2020 -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
obvious -X- _ O
that -X- _ O
most -X- _ O
of -X- _ O
those -X- _ O
information -X- _ O
has -X- _ O
been -X- _ O
somehow -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
or -X- _ O
at -X- _ O
least -X- _ O
can -X- _ O
be -X- _ O
very -X- _ O
easily -X- _ O
associated -X- _ O
with -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
treat -X- _ O
this -X- _ O
problem -X- _ O
as -X- _ O
a -X- _ O
text -X- _ O
generation -X- _ O
problem -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
feed -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
with -X- _ O
its -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
try -X- _ O
to -X- _ O
generate -X- _ O
its -X- _ O
metadata -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
this -X- _ O
model -X- _ O
via -X- _ O
fine -X- _ O
- -X- _ O
tuning -X- _ O
BART -X- _ B-MethodName
( -X- _ O
Lewis -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2020 -X- _ O
) -X- _ O
, -X- _ O
a -X- _ O
pretrained -X- _ O
text -X- _ O
generation -X- _ O
model -X- _ O
. -X- _ O
Besides -X- _ O
the -X- _ O
metadata -X- _ O
to -X- _ O
generate -X- _ O
, -X- _ O
the -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
itself -X- _ O
should -X- _ O
be -X- _ O
useful -X- _ O
for -X- _ O
searching -X- _ O
, -X- _ O
when -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
overlap -X- _ O
between -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
content -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
article -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
search -X- _ O
for -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
on -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
, -X- _ O
the -X- _ O
results -X- _ O
returned -X- _ O
can -X- _ O
be -X- _ O
related -X- _ O
articles -X- _ O
, -X- _ O
and -X- _ O
their -X- _ O
metadata -X- _ O
may -X- _ O
provide -X- _ O
additional -X- _ O
useful -X- _ O
information -X- _ O
that -X- _ O
can -X- _ O
tell -X- _ O
the -X- _ O
model -X- _ O
what -X- _ O
should -X- _ O
be -X- _ O
included -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
output -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
running -X- _ O
example -X- _ O
mentioned -X- _ O
in -X- _ O
the -X- _ O
last -X- _ O
section -X- _ O
, -X- _ O
if -X- _ O
we -X- _ O
search -X- _ O
that -X- _ O
sentence -X- _ O
on -X- _ O
Google -X- _ O
, -X- _ O
one -X- _ O
result -X- _ O
it -X- _ O
returned -X- _ O
is -X- _ O
cspan -X- _ O
's -X- _ O
article -X- _ O
" -X- _ O
President -X- _ O
Trump -X- _ O
with -X- _ O
Coronavirus -X- _ O
Task -X- _ O
Press -X- _ O
Briefing -X- _ O
" -X- _ O
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
very -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
title -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
article -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
our -X- _ O
generation -X- _ O
model -X- _ O
should -X- _ O
leverage -X- _ O
those -X- _ O
signals -X- _ O
, -X- _ O
which -X- _ O
consist -X- _ O
of -X- _ O
metadata -X- _ O
of -X- _ O
related -X- _ O
articles -X- _ O
to -X- _ O
the -X- _ O
target -X- _ O
article -X- _ O
. -X- _ O
To -X- _ O
incorporate -X- _ O
the -X- _ O
signals -X- _ O
, -X- _ O
we -X- _ O
first -X- _ O
issue -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
as -X- _ O
a -X- _ O
query -X- _ O
to -X- _ O
the -X- _ O
search -X- _ O
engine -X- _ O
and -X- _ O
collect -X- _ O
its -X- _ O
top-5 -X- _ O
returned -X- _ O
urls -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
as -X- _ O
what -X- _ O
we -X- _ O
do -X- _ O
to -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
, -X- _ O
we -X- _ O
crawl -X- _ O
its -X- _ O
metadata -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
, -X- _ O
title -X- _ O
, -X- _ O
and -X- _ O
published -X- _ O
date -X- _ O
, -X- _ O
and -X- _ O
put -X- _ O
them -X- _ O
together -X- _ O
as -X- _ O
one -X- _ O
document -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
our -X- _ O
problem -X- _ O
becomes -X- _ O
to -X- _ O
generating -X- _ O
the -X- _ O
metadata -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
, -X- _ O
when -X- _ O
we -X- _ O
are -X- _ O
given -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
, -X- _ O
its -X- _ O
context -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
possible -X- _ O
metadata -X- _ O
outputs -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
we -X- _ O
actually -X- _ O
have -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
inputs -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
One -X- _ O
is -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
with -X- _ O
its -X- _ O
context -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
are -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
metadata -X- _ O
from -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
one -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
possible -X- _ O
outputs -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
correct -X- _ O
metadata -X- _ O
components -X- _ O
directly -X- _ O
from -X- _ O
. -X- _ O
To -X- _ O
solve -X- _ O
this -X- _ O
problem -X- _ O
, -X- _ O
we -X- _ O
extend -X- _ O
the -X- _ O
BART -X- _ B-MethodName
baseline -X- _ O
to -X- _ O
incorporate -X- _ O
two -X- _ O
sources -X- _ O
of -X- _ O
inputs -X- _ O
, -X- _ O
by -X- _ O
first -X- _ O
feeding -X- _ O
the -X- _ O
text -X- _ O
inputs -X- _ O
independently -X- _ O
to -X- _ O
the -X- _ O
BART -X- _ B-MethodName
's -X- _ O
encoders -X- _ O
, -X- _ O
then -X- _ O
concatenating -X- _ O
the -X- _ O
outputs -X- _ O
of -X- _ O
the -X- _ O
encoders -X- _ O
together -X- _ O
, -X- _ O
and -X- _ O
finally -X- _ O
feeding -X- _ O
the -X- _ O
unified -X- _ O
representations -X- _ O
to -X- _ O
the -X- _ O
BART -X- _ B-MethodName
's -X- _ O
decoder -X- _ O
. -X- _ O
We -X- _ O
collect -X- _ O
multiple -X- _ O
possible -X- _ O
metadata -X- _ O
for -X- _ O
each -X- _ O
source -X- _ O
article -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
integration -X- _ O
can -X- _ O
help -X- _ O
us -X- _ O
generate -X- _ O
better -X- _ O
keywords -X- _ O
for -X- _ O
the -X- _ O
search -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
treating -X- _ O
the -X- _ O
multiple -X- _ O
possible -X- _ O
metadata -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
document -X- _ O
neglects -X- _ O
the -X- _ O
rank -X- _ O
of -X- _ O
the -X- _ O
urls -X- _ O
returned -X- _ O
, -X- _ O
which -X- _ O
reflects -X- _ O
the -X- _ O
different -X- _ O
possibility -X- _ O
for -X- _ O
each -X- _ O
candidate -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
right -X- _ O
metadata -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
rank -X- _ O
- -X- _ O
aware -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
to -X- _ O
relieve -X- _ O
this -X- _ O
problem -X- _ O
. -X- _ O
The -X- _ O
basic -X- _ O
idea -X- _ O
is -X- _ O
when -X- _ O
BART -X- _ B-MethodName
's -X- _ O
decoders -X- _ O
are -X- _ O
performing -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
over -X- _ O
the -X- _ O
text -X- _ O
input -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
and -X- _ O
the -X- _ O
possible -X- _ O
metadata -X- _ O
, -X- _ O
we -X- _ O
require -X- _ O
that -X- _ O
each -X- _ O
set -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
derives -X- _ O
different -X- _ O
attention -X- _ O
scores -X- _ O
based -X- _ O
on -X- _ O
different -X- _ O
metadata -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
each -X- _ O
set -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
will -X- _ O
explicitly -X- _ O
pay -X- _ O
attention -X- _ O
to -X- _ O
different -X- _ O
parts -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
corresponding -X- _ O
to -X- _ O
different -X- _ O
pieces -X- _ O
of -X- _ O
metadata -X- _ O
, -X- _ O
and -X- _ O
neglect -X- _ O
the -X- _ O
others -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
after -X- _ O
training -X- _ O
, -X- _ O
each -X- _ O
set -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
project -X- _ O
the -X- _ O
input -X- _ O
embeddings -X- _ O
into -X- _ O
different -X- _ O
representation -X- _ O
subspaces -X- _ O
but -X- _ O
focusing -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
set -X- _ O
of -X- _ O
candidate -X- _ O
metadata -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
have -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
attention -X- _ O
heads -X- _ O
do -X- _ O
cross -X- _ O
- -X- _ O
attention -X- _ O
only -X- _ O
over -X- _ O
the -X- _ O
positions -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
and -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
first -X- _ O
url -X- _ O
, -X- _ O
another -X- _ O
set -X- _ O
do -X- _ O
it -X- _ O
only -X- _ O
over -X- _ O
the -X- _ O
positions -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
and -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
first -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
urls -X- _ O
, -X- _ O
and -X- _ O
so -X- _ O
on -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
candidate -X- _ O
metadata -X- _ O
from -X- _ O
the -X- _ O
urls -X- _ O
ranked -X- _ O
higher -X- _ O
will -X- _ O
always -X- _ O
receive -X- _ O
more -X- _ O
attention -X- _ O
than -X- _ O
the -X- _ O
others -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
. -X- _ O
Figure -X- _ O
4 -X- _ O
summarizes -X- _ O
our -X- _ O
final -X- _ O
design -X- _ O
of -X- _ O
the -X- _ O
generation -X- _ O
model -X- _ O
. -X- _ O
Given -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
query -X- _ O
keywords -X- _ O
generated -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
search -X- _ O
for -X- _ O
them -X- _ O
on -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
and -X- _ O
collect -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
links -X- _ O
that -X- _ O
are -X- _ O
the -X- _ O
candidates -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
. -X- _ O
The -X- _ O
next -X- _ O
problem -X- _ O
is -X- _ O
to -X- _ O
infer -X- _ O
the -X- _ O
correct -X- _ O
ones -X- _ O
from -X- _ O
them -X- _ O
. -X- _ O
Figure -X- _ O
4 -X- _ O
: -X- _ O
The -X- _ O
architecture -X- _ O
of -X- _ O
the -X- _ O
query -X- _ O
generator -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
extends -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
BART -X- _ B-MethodName
's -X- _ O
encoders -X- _ O
to -X- _ O
incorporate -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
input -X- _ O
, -X- _ O
one -X- _ O
is -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
the -X- _ O
selected -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
other -X- _ O
one -X- _ O
is -X- _ O
possible -X- _ O
metadata -X- _ O
collected -X- _ O
from -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
BART -X- _ B-MethodName
's -X- _ O
decoders -X- _ O
with -X- _ O
a -X- _ O
rankaware -X- _ B-HyperparameterValue
multi -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
head -X- _ I-HyperparameterName
cross -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
to -X- _ O
generate -X- _ O
the -X- _ O
gold -X- _ O
metadata -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
our -X- _ O
observations -X- _ O
, -X- _ O
the -X- _ O
author -X- _ O
is -X- _ O
very -X- _ O
likely -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
external -X- _ O
information -X- _ O
coming -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
source -X- _ O
websites -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
running -X- _ O
example -X- _ O
introduced -X- _ O
in -X- _ O
Section -X- _ O
1 -X- _ O
, -X- _ O
the -X- _ O
author -X- _ O
cited -X- _ O
8 -X- _ O
articles -X- _ O
in -X- _ O
total -X- _ O
, -X- _ O
and -X- _ O
among -X- _ O
those -X- _ O
articles -X- _ O
, -X- _ O
two -X- _ O
of -X- _ O
them -X- _ O
come -X- _ O
from -X- _ O
whitehouse.gov -X- _ O
and -X- _ O
another -X- _ O
two -X- _ O
come -X- _ O
from -X- _ O
politicfact.com -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
actually -X- _ O
two -X- _ O
claims -X- _ O
they -X- _ O
have -X- _ O
done -X- _ O
fact -X- _ O
- -X- _ O
check -X- _ O
before -X- _ O
. -X- _ O
Besides -X- _ O
the -X- _ O
sources -X- _ O
, -X- _ O
the -X- _ O
titles -X- _ O
of -X- _ O
the -X- _ O
articles -X- _ O
are -X- _ O
also -X- _ O
very -X- _ O
likely -X- _ O
to -X- _ O
be -X- _ O
related -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
same -X- _ O
example -X- _ O
, -X- _ O
some -X- _ O
of -X- _ O
them -X- _ O
are -X- _ O
all -X- _ O
talking -X- _ O
about -X- _ O
the -X- _ O
interviews -X- _ O
done -X- _ O
by -X- _ O
Anthony -X- _ O
Fauci -X- _ O
at -X- _ O
different -X- _ O
time -X- _ O
, -X- _ O
and -X- _ O
some -X- _ O
of -X- _ O
them -X- _ O
are -X- _ O
talking -X- _ O
about -X- _ O
the -X- _ O
white -X- _ O
house -X- _ O
's -X- _ O
Coronavirus -X- _ O
Task -X- _ O
Force -X- _ O
in -X- _ O
Press -X- _ O
Briefing -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
an -X- _ O
algorithmic -X- _ O
inference -X- _ O
framework -X- _ O
that -X- _ O
can -X- _ O
take -X- _ O
advantage -X- _ O
of -X- _ O
those -X- _ O
relations -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
correct -X- _ O
source -X- _ O
articles -X- _ O
of -X- _ O
identified -X- _ O
sentences -X- _ O
jointly -X- _ O
. -X- _ O
We -X- _ O
formulate -X- _ O
the -X- _ O
inference -X- _ O
as -X- _ O
an -X- _ O
Integer -X- _ O
Linear -X- _ O
Program -X- _ O
( -X- _ O
ILP -X- _ O
) -X- _ O
( -X- _ O
Roth -X- _ O
and -X- _ O
tau -X- _ O
Yih -X- _ O
, -X- _ O
2004;Cheng -X- _ O
and -X- _ O
Roth -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
that -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
jointly -X- _ O
determine -X- _ O
the -X- _ O
best -X- _ O
candidate -X- _ O
for -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
. -X- _ O
Formally -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
Boolean -X- _ O
variables -X- _ O
: -X- _ O
x -X- _ O
k -X- _ O
i -X- _ O
, -X- _ O
which -X- _ O
represents -X- _ O
if -X- _ O
the -X- _ O
k -X- _ O
th -X- _ O
candidate -X- _ O
is -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
z -X- _ O
kl -X- _ O
ij -X- _ O
, -X- _ O
which -X- _ O
represents -X- _ O
if -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
th -X- _ O
sentence -X- _ O
are -X- _ O
related -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
either -X- _ O
they -X- _ O
come -X- _ O
from -X- _ O
related -X- _ O
source -X- _ O
websites -X- _ O
or -X- _ O
provide -X- _ O
related -X- _ O
content -X- _ O
. -X- _ O
To -X- _ O
infer -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
the -X- _ O
Boolean -X- _ O
variables -X- _ O
, -X- _ O
our -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
assign -X- _ O
the -X- _ O
best -X- _ O
candidate -X- _ O
to -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
that -X- _ O
can -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
maximize -X- _ O
the -X- _ O
overall -X- _ O
relatedness -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
to -X- _ O
the -X- _ O
query -X- _ O
document -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
maximize -X- _ O
the -X- _ O
relatedness -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
. -X- _ O
To -X- _ O
compute -X- _ O
the -X- _ O
relatedness -X- _ O
, -X- _ O
we -X- _ O
introduce -X- _ O
w -X- _ O
k -X- _ O
i -X- _ O
, -X- _ O
which -X- _ O
represents -X- _ O
the -X- _ O
relatedness -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
candidate -X- _ O
article -X- _ O
to -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
, -X- _ O
γ -X- _ O
kl -X- _ O
ij -X- _ O
, -X- _ O
which -X- _ O
represents -X- _ O
the -X- _ O
similarity -X- _ O
score -X- _ O
between -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
article -X- _ O
's -X- _ O
k -X- _ O
th -X- _ O
candidate -X- _ O
and -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
th -X- _ O
article -X- _ O
's -X- _ O
l -X- _ O
th -X- _ O
candidate -X- _ O
, -X- _ O
and -X- _ O
τ -X- _ O
kl -X- _ O
ij -X- _ O
, -X- _ O
which -X- _ O
represents -X- _ O
the -X- _ O
similarity -X- _ O
score -X- _ O
between -X- _ O
the -X- _ O
representations -X- _ O
of -X- _ O
the -X- _ O
title -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
article -X- _ O
's -X- _ O
k -X- _ O
th -X- _ O
candidate -X- _ O
and -X- _ O
the -X- _ O
source -X- _ O
domain -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
th -X- _ O
article -X- _ O
's -X- _ O
l -X- _ O
th -X- _ O
candidate -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
the -X- _ O
optimization -X- _ O
goal -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
best -X- _ O
assignments -X- _ O
Γ -X- _ O
d -X- _ O
of -X- _ O
candidates -X- _ O
for -X- _ O
the -X- _ O
identified -X- _ O
sentences -X- _ O
is -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O
Γ -X- _ O
d -X- _ O
= -X- _ O
argmax -X- _ O
Γ -X- _ O
i -X- _ O
k -X- _ O
ω -X- _ O
k -X- _ O
i -X- _ O
x -X- _ O
k -X- _ O
i -X- _ O
+ -X- _ O
i -X- _ O
, -X- _ O
j -X- _ O
k -X- _ O
, -X- _ O
l -X- _ O
τ -X- _ O
kl -X- _ O
ij -X- _ O
+ -X- _ O
γ -X- _ O
kl -X- _ O
ij -X- _ O
z -X- _ O
kl -X- _ O
ij -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
s.t -X- _ O
. -X- _ O
x -X- _ O
k -X- _ O
i -X- _ O
∈ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
} -X- _ O
, -X- _ O
z -X- _ O
kl -X- _ O
ij -X- _ O
∈ -X- _ O
{ -X- _ O
0 -X- _ O
, -X- _ O
1 -X- _ O
} -X- _ O
∀i -X- _ O
, -X- _ O
k -X- _ O
x -X- _ O
k -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
2z -X- _ O
kl -X- _ O
ij -X- _ O
≤ -X- _ O
x -X- _ O
k -X- _ O
i -X- _ O
+ -X- _ O
x -X- _ O
l -X- _ O
j -X- _ O
( -X- _ O
3)Here -X- _ O
, -X- _ O
k -X- _ O
x -X- _ O
k -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
means -X- _ O
only -X- _ O
one -X- _ O
candidate -X- _ O
will -X- _ O
finally -X- _ O
be -X- _ O
chosen -X- _ O
as -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
2z -X- _ O
kl -X- _ O
ij -X- _ O
≤ -X- _ O
x -X- _ O
k -X- _ O
i -X- _ O
+ -X- _ O
x -X- _ O
l -X- _ O
j -X- _ O
means -X- _ O
only -X- _ O
if -X- _ O
the -X- _ O
k -X- _ O
th -X- _ O
candidate -X- _ O
of -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
l -X- _ O
th -X- _ O
candidate -X- _ O
of -X- _ O
the -X- _ O
j -X- _ O
th -X- _ O
sentence -X- _ O
have -X- _ O
been -X- _ O
chosen -X- _ O
, -X- _ O
we -X- _ O
need -X- _ O
to -X- _ O
consider -X- _ O
the -X- _ O
relations -X- _ O
between -X- _ O
them -X- _ O
. -X- _ O
In -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
last -X- _ O
hidden -X- _ O
layer -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
large -X- _ I-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
representation -X- _ O
for -X- _ O
titles -X- _ O
and -X- _ O
source -X- _ O
domains -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
cosine -X- _ O
similarity -X- _ O
to -X- _ O
compute -X- _ O
the -X- _ O
similarity -X- _ O
score -X- _ O
. -X- _ O
The -X- _ O
ILP -X- _ O
problem -X- _ O
is -X- _ O
solved -X- _ O
using -X- _ O
an -X- _ O
off -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
shelf -X- _ O
high -X- _ O
- -X- _ O
performance -X- _ O
package -X- _ O
3 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
aim -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
following -X- _ O
research -X- _ O
questions -X- _ O
: -X- _ O
RQ1 -X- _ O
Can -X- _ O
we -X- _ O
correctly -X- _ O
identify -X- _ O
the -X- _ O
sentences -X- _ O
that -X- _ O
refer -X- _ O
to -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
article -X- _ O
? -X- _ O
RQ2 -X- _ O
Given -X- _ O
the -X- _ O
identified -X- _ O
sentences -X- _ O
, -X- _ O
can -X- _ O
we -X- _ O
generate -X- _ O
the -X- _ O
metadata -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
articles -X- _ O
from -X- _ O
the -X- _ O
context -X- _ O
? -X- _ O
RQ3 -X- _ O
Given -X- _ O
a -X- _ O
list -X- _ O
of -X- _ O
candidates -X- _ O
for -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
, -X- _ O
can -X- _ O
we -X- _ O
assign -X- _ O
the -X- _ O
correct -X- _ O
candidate -X- _ O
to -X- _ O
each -X- _ O
identified -X- _ O
sentence?3 -X- _ O
https://www.python-mip.com/ -X- _ O
RQ4 -X- _ O
Given -X- _ O
the -X- _ O
identified -X- _ O
sentences -X- _ O
, -X- _ O
can -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
query -X- _ O
we -X- _ O
generated -X- _ O
to -X- _ O
find -X- _ O
candidates -X- _ O
, -X- _ O
and -X- _ O
successfully -X- _ O
use -X- _ O
them -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
inference -X- _ O
of -X- _ O
source -X- _ O
articles -X- _ O
? -X- _ O
Among -X- _ O
those -X- _ O
questions -X- _ O
, -X- _ O
RQ1 -X- _ O
- -X- _ O
RQ3 -X- _ O
are -X- _ O
to -X- _ O
evaluate -X- _ O
a -X- _ O
specific -X- _ O
component -X- _ O
of -X- _ O
our -X- _ O
solution -X- _ O
, -X- _ O
and -X- _ O
RQ4 -X- _ O
is -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
joint -X- _ O
performance -X- _ O
of -X- _ O
candidate -X- _ O
generation -X- _ O
and -X- _ O
source -X- _ O
article -X- _ O
inference -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
following -X- _ O
part -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
elaborate -X- _ O
the -X- _ O
answers -X- _ O
to -X- _ O
those -X- _ O
questions -X- _ O
, -X- _ O
and -X- _ O
for -X- _ O
each -X- _ O
question -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
start -X- _ O
with -X- _ O
describing -X- _ O
its -X- _ O
experimental -X- _ O
setting -X- _ O
, -X- _ O
baselines -X- _ O
and -X- _ O
the -X- _ O
metrics -X- _ O
. -X- _ O
Setup -X- _ O
We -X- _ O
use -X- _ O
Politi -X- _ B-DatasetName
- -X- _ I-DatasetName
Prov -X- _ I-DatasetName
dataset -X- _ O
introduced -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
and -X- _ O
validate -X- _ O
our -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
articles -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
and -X- _ O
validation -X- _ O
set -X- _ O
, -X- _ O
and -X- _ O
try -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
sentence -X- _ O
referring -X- _ O
to -X- _ O
a -X- _ O
source -X- _ O
article -X- _ O
from -X- _ O
the -X- _ O
article -X- _ O
belonging -X- _ O
to -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
. -X- _ O
To -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
implement -X- _ O
our -X- _ O
solution -X- _ O
( -X- _ O
SR -X- _ B-MethodName
- -X- _ I-MethodName
TE -X- _ I-MethodName
) -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
4.1 -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
it -X- _ O
with -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
a -X- _ O
retrieval -X- _ O
baseline -X- _ O
that -X- _ O
simply -X- _ O
computes -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
embedding -X- _ O
vectors -X- _ O
( -X- _ O
using -X- _ O
Roberta -X- _ B-MethodName
) -X- _ O
of -X- _ O
the -X- _ O
title -X- _ O
and -X- _ O
the -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
( -X- _ O
SR -X- _ B-MethodName
) -X- _ O
. -X- _ O
This -X- _ O
retrieval -X- _ O
baseline -X- _ O
only -X- _ O
captures -X- _ O
the -X- _ O
relatedness -X- _ O
between -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
main -X- _ O
topic -X- _ O
of -X- _ O
the -X- _ O
article;(2 -X- _ O
) -X- _ O
a -X- _ O
retrieval -X- _ O
baseline -X- _ O
similar -X- _ O
to -X- _ O
SR -X- _ B-MethodName
, -X- _ O
but -X- _ O
computing -X- _ O
the -X- _ O
cosine -X- _ O
similarity -X- _ O
between -X- _ O
the -X- _ O
embedding -X- _ O
vectors -X- _ O
of -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
title -X- _ O
and -X- _ O
the -X- _ O
most -X- _ O
important -X- _ O
entities -X- _ O
( -X- _ O
top-50 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
sentence -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
( -X- _ O
SR -X- _ B-MethodName
- -X- _ I-MethodName
E -X- _ I-MethodName
) -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
show -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
considering -X- _ O
important -X- _ O
entities -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
our -X- _ O
learning -X- _ O
solution -X- _ O
without -X- _ O
considering -X- _ O
entities -X- _ O
( -X- _ O
SR -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
) -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ B-MetricName
precision -X- _ I-MetricName
and -X- _ O
recall -X- _ B-MetricName
of -X- _ I-MetricName
the -X- _ I-MetricName
top -X- _ I-MetricName
- -X- _ I-MetricName
k -X- _ I-MetricName
results -X- _ I-MetricName
respectively -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
. -X- _ O
The -X- _ O
gaps -X- _ O
between -X- _ O
SR -X- _ B-MethodName
, -X- _ O
SR -X- _ B-MethodName
- -X- _ I-MethodName
E -X- _ I-MethodName
, -X- _ O
and -X- _ O
SR -X- _ B-MethodName
- -X- _ I-MethodName
T -X- _ I-MethodName
, -X- _ O
SR -X- _ B-MethodName
- -X- _ I-MethodName
TE -X- _ I-MethodName
show -X- _ O
that -X- _ O
considering -X- _ O
important -X- _ O
entities -X- _ O
always -X- _ O
results -X- _ O
in -X- _ O
an -X- _ O
improvement -X- _ O
on -X- _ O
both -X- _ O
precision -X- _ B-MetricName
and -X- _ O
recall -X- _ B-MetricName
, -X- _ O
which -X- _ O
reveals -X- _ O
that -X- _ O
the -X- _ O
sentences -X- _ O
can -X- _ O
not -X- _ O
be -X- _ O
identified -X- _ O
based -X- _ O
on -X- _ O
their -X- _ O
relatedness -X- _ O
to -X- _ O
the -X- _ O
title -X- _ O
( -X- _ O
the -X- _ O
main -X- _ O
topic -X- _ O
) -X- _ O
only -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
requires -X- _ O
other -X- _ O
important -X- _ O
information -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
figure -X- _ O
also -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
learning -X- _ O
method -X- _ O
is -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
retrieval -X- _ O
baseline -X- _ O
without -X- _ O
a -X- _ O
learning -X- _ O
objective -X- _ O
. -X- _ O
Setup -X- _ O
We -X- _ O
collect -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
sentences -X- _ O
that -X- _ O
correspond -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
in -X- _ O
training -X- _ O
, -X- _ O
validation -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
of -X- _ O
Politi -X- _ B-DatasetName
- -X- _ I-DatasetName
Prov -X- _ I-DatasetName
serving -X- _ O
as -X- _ O
training -X- _ O
, -X- _ O
validation -X- _ O
and -X- _ O
testing -X- _ O
respectively -X- _ O
. -X- _ O
Overall -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
5279 -X- _ O
cases -X- _ O
for -X- _ O
training -X- _ O
, -X- _ O
1847 -X- _ O
for -X- _ O
validation -X- _ O
, -X- _ O
and -X- _ O
1538 -X- _ O
for -X- _ O
testing -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
source -X- _ O
input -X- _ O
is -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
with -X- _ O
its -X- _ O
context -X- _ O
( -X- _ O
two -X- _ O
sentences -X- _ O
which -X- _ O
are -X- _ O
before -X- _ O
and -X- _ O
after -X- _ O
the -X- _ O
sentence -X- _ O
respectively -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
output -X- _ O
to -X- _ O
generate -X- _ O
is -X- _ O
the -X- _ O
metadata -X- _ O
of -X- _ O
the -X- _ O
corresponding -X- _ O
source -X- _ O
article -X- _ O
in -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
its -X- _ O
source -X- _ O
domain -X- _ O
, -X- _ O
title -X- _ O
and -X- _ O
published -X- _ O
date -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
Rouge -X- _ B-MetricName
1 -X- _ I-MetricName
, -X- _ O
Rouge -X- _ B-MetricName
2 -X- _ I-MetricName
and -X- _ O
Rouge -X- _ B-MetricName
L -X- _ I-MetricName
score -X- _ O
of -X- _ O
the -X- _ O
text -X- _ O
generated -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
with -X- _ O
the -X- _ O
performance -X- _ O
produced -X- _ O
by -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
original -X- _ O
BART -X- _ B-MethodName
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
our -X- _ O
solution -X- _ O
integrating -X- _ O
signals -X- _ O
from -X- _ O
Google -X- _ O
( -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
S -X- _ I-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
our -X- _ O
solution -X- _ O
integrating -X- _ O
signals -X- _ O
from -X- _ O
Google -X- _ O
with -X- _ O
our -X- _ O
rank -X- _ O
- -X- _ O
aware -X- _ O
multi -X- _ O
- -X- _ O
head -X- _ O
cross -X- _ O
attention -X- _ O
( -X- _ O
BART -X- _ B-MethodName
- -X- _ I-MethodName
SR -X- _ I-MethodName
) -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
integrating -X- _ O
the -X- _ O
signals -X- _ O
from -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
can -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
generating -X- _ O
the -X- _ O
metadata -X- _ O
, -X- _ O
and -X- _ O
considering -X- _ O
the -X- _ O
ranking -X- _ O
of -X- _ O
the -X- _ O
search -X- _ O
results -X- _ O
can -X- _ O
further -X- _ O
lead -X- _ O
to -X- _ O
an -X- _ O
improvement -X- _ O
. -X- _ O
Setup -X- _ O
To -X- _ O
conduct -X- _ O
an -X- _ O
isolated -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
ILP -X- _ O
based -X- _ O
inference -X- _ O
, -X- _ O
in -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
generate -X- _ O
the -X- _ O
candidates -X- _ O
for -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
based -X- _ O
on -X- _ O
its -X- _ O
metadata -X- _ O
from -X- _ O
the -X- _ O
ground -X- _ O
truth -X- _ O
. -X- _ O
Concretely -X- _ O
, -X- _ O
we -X- _ O
assume -X- _ O
there -X- _ O
is -X- _ O
an -X- _ O
oracle -X- _ O
that -X- _ O
can -X- _ O
generate -X- _ O
the -X- _ O
metadata -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
context -X- _ O
for -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
directly -X- _ O
search -X- _ O
the -X- _ O
metadata -X- _ O
on -X- _ O
Google -X- _ O
, -X- _ O
and -X- _ O
fetch -X- _ O
its -X- _ O
top-5 -X- _ O
results -X- _ O
returned -X- _ O
as -X- _ O
candidates -X- _ O
for -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
our -X- _ O
inference -X- _ O
algorithm -X- _ O
is -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
correct -X- _ O
source -X- _ O
article -X- _ O
for -X- _ O
each -X- _ O
sentence -X- _ O
from -X- _ O
those -X- _ O
candidates -X- _ O
. -X- _ O
To -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ B-MetricName
recall -X- _ I-MetricName
of -X- _ O
source -X- _ O
articles -X- _ O
for -X- _ O
each -X- _ O
article -X- _ O
, -X- _ O
and -X- _ O
compare -X- _ O
it -X- _ O
with -X- _ O
results -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
baselines -X- _ O
, -X- _ O
including -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
simply -X- _ O
choosing -X- _ O
the -X- _ O
top-1 -X- _ O
article -X- _ O
from -X- _ O
the -X- _ O
results -X- _ O
returned -X- _ O
by -X- _ O
directly -X- _ O
searching -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
on -X- _ O
Google -X- _ O
( -X- _ O
SS1 -X- _ B-MethodName
) -X- _ O
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
choosing -X- _ O
the -X- _ O
top-1 -X- _ O
article -X- _ O
from -X- _ O
the -X- _ O
results -X- _ O
returned -X- _ O
by -X- _ O
searching -X- _ O
the -X- _ O
metadata -X- _ O
on -X- _ O
Google -X- _ O
( -X- _ O
MS1 -X- _ B-MethodName
) -X- _ O
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
our -X- _ O
proposed -X- _ O
solution -X- _ O
, -X- _ O
which -X- _ O
conducts -X- _ O
ILP -X- _ O
inference -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
from -X- _ O
the -X- _ O
search -X- _ O
results -X- _ O
returned -X- _ O
by -X- _ O
searching -X- _ O
the -X- _ O
metadata -X- _ O
on -X- _ O
Google -X- _ O
( -X- _ O
MS -X- _ O
- -X- _ O
ILP -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
have -X- _ O
a -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
the -X- _ O
performance -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
report -X- _ O
two -X- _ O
upper -X- _ O
bounds -X- _ O
. -X- _ O
The -X- _ O
first -X- _ O
one -X- _ O
is -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
the -X- _ O
mean -X- _ B-HyperparameterName
recall -X- _ I-HyperparameterName
of -X- _ O
the -X- _ O
results -X- _ O
by -X- _ O
directly -X- _ O
searching -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
on -X- _ O
Google -X- _ O
( -X- _ O
SS -X- _ B-MethodName
- -X- _ I-MethodName
UB -X- _ I-MethodName
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
one -X- _ O
is -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
the -X- _ O
mean -X- _ O
recall -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
by -X- _ O
directly -X- _ O
searching -X- _ O
the -X- _ O
meta -X- _ O
- -X- _ O
data -X- _ O
on -X- _ O
Google -X- _ O
( -X- _ O
MS -X- _ B-MethodName
- -X- _ I-MethodName
UB -X- _ I-MethodName
) -X- _ O
. -X- _ O
To -X- _ O
compute -X- _ O
the -X- _ O
upper -X- _ O
bounds -X- _ O
, -X- _ O
if -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
articles -X- _ O
returned -X- _ O
by -X- _ O
Google -X- _ O
is -X- _ O
correct -X- _ O
, -X- _ O
then -X- _ O
we -X- _ O
consider -X- _ O
the -X- _ O
sentence -X- _ O
is -X- _ O
correctly -X- _ O
assigned -X- _ O
. -X- _ O
Actually -X- _ O
, -X- _ O
they -X- _ O
are -X- _ O
equivalent -X- _ O
to -X- _ O
the -X- _ O
mean -X- _ O
recall -X- _ O
of -X- _ O
the -X- _ O
top-5 -X- _ O
results -X- _ O
, -X- _ O
since -X- _ O
we -X- _ O
only -X- _ O
request -X- _ O
Google -X- _ O
for -X- _ O
its -X- _ O
top-5 -X- _ O
search -X- _ O
results -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
performance -X- _ O
in -X- _ O
Figure -X- _ O
6 -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
figure -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
mean -X- _ B-MetricName
recall -X- _ I-MetricName
of -X- _ O
SS1 -X- _ O
is -X- _ O
only -X- _ O
0.067 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
even -X- _ O
its -X- _ O
upper -X- _ O
bound -X- _ O
SS -X- _ B-MethodName
- -X- _ I-MethodName
UB -X- _ I-MethodName
can -X- _ O
only -X- _ O
achieve -X- _ O
0.15 -X- _ B-MetricValue
, -X- _ O
which -X- _ O
reveals -X- _ O
that -X- _ O
directly -X- _ O
searching -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
on -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
to -X- _ O
find -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
is -X- _ O
not -X- _ O
feasible -X- _ O
. -X- _ O
Using -X- _ O
the -X- _ O
metadata -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
article -X- _ O
to -X- _ O
search -X- _ O
can -X- _ O
improve -X- _ O
the -X- _ O
mean -X- _ B-MetricName
recall -X- _ I-MetricName
to -X- _ O
around -X- _ O
0.3 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
considering -X- _ O
the -X- _ O
relatedness -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
by -X- _ O
ILP -X- _ O
can -X- _ O
further -X- _ O
improve -X- _ O
it -X- _ O
to -X- _ O
around -X- _ O
0.37 -X- _ B-MetricValue
. -X- _ O
It -X- _ O
demonstrates -X- _ O
that -X- _ O
the -X- _ O
ILP -X- _ O
inference -X- _ O
is -X- _ O
useful -X- _ O
for -X- _ O
capturing -X- _ O
the -X- _ O
relatedness -X- _ O
between -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
result -X- _ O
has -X- _ O
been -X- _ O
very -X- _ O
close -X- _ O
to -X- _ O
the -X- _ O
mean -X- _ B-MetricName
recall -X- _ I-MetricName
of -X- _ O
its -X- _ O
top-5 -X- _ O
results -X- _ O
( -X- _ O
MS -X- _ B-MethodName
- -X- _ I-MethodName
UB -X- _ I-MethodName
) -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
the -X- _ O
upper -X- _ O
bound -X- _ O
of -X- _ O
the -X- _ O
performance -X- _ O
that -X- _ O
the -X- _ O
inference -X- _ O
can -X- _ O
achieve -X- _ O
with -X- _ O
searching -X- _ O
by -X- _ O
metadata -X- _ O
. -X- _ O
Setup -X- _ O
In -X- _ O
this -X- _ O
experiment -X- _ O
, -X- _ O
we -X- _ O
issue -X- _ O
the -X- _ O
queries -X- _ O
generated -X- _ O
by -X- _ O
the -X- _ O
query -X- _ O
generation -X- _ O
module -X- _ O
to -X- _ O
Google -X- _ O
, -X- _ O
and -X- _ O
fetched -X- _ O
the -X- _ O
top-5 -X- _ O
results -X- _ O
returned -X- _ O
. -X- _ O
We -X- _ O
combine -X- _ O
these -X- _ O
results -X- _ O
with -X- _ O
the -X- _ O
top-5 -X- _ O
links -X- _ O
returned -X- _ O
by -X- _ O
searching -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
directly -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
candidate -X- _ O
pool -X- _ O
for -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
conduct -X- _ O
ILP -X- _ O
inference -X- _ O
to -X- _ O
assign -X- _ O
the -X- _ O
candidate -X- _ O
to -X- _ O
each -X- _ O
sentence -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
mean -X- _ B-MetricName
recall -X- _ I-MetricName
of -X- _ O
Figure -X- _ O
6 -X- _ O
: -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
inferring -X- _ O
source -X- _ O
articles -X- _ O
for -X- _ O
each -X- _ O
article -X- _ O
, -X- _ O
MS -X- _ O
- -X- _ O
ILP -X- _ O
is -X- _ O
our -X- _ O
ILP -X- _ O
based -X- _ O
solution -X- _ O
, -X- _ O
and -X- _ O
MS -X- _ O
- -X- _ O
UB -X- _ O
is -X- _ O
the -X- _ O
best -X- _ O
possible -X- _ O
performance -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
achieved -X- _ O
when -X- _ O
the -X- _ O
candidates -X- _ O
are -X- _ O
the -X- _ O
top-5 -X- _ O
results -X- _ O
returned -X- _ O
by -X- _ O
searching -X- _ O
for -X- _ O
metadata -X- _ O
on -X- _ O
Google -X- _ O
. -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
, -X- _ O
varying -X- _ O
k -X- _ O
, -X- _ O
which -X- _ O
represents -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
the -X- _ O
links -X- _ O
we -X- _ O
returned -X- _ O
for -X- _ O
each -X- _ O
identified -X- _ O
sentence -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
finding -X- _ O
the -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
assignments -X- _ O
in -X- _ O
ILP -X- _ O
is -X- _ O
actually -X- _ O
relaxing -X- _ O
the -X- _ O
unique -X- _ O
solution -X- _ O
constraint -X- _ O
in -X- _ O
Eq -X- _ O
3 -X- _ O
to -X- _ O
be -X- _ O
∀i -X- _ O
, -X- _ O
j -X- _ O
x -X- _ O
j -X- _ O
i -X- _ O
= -X- _ O
k -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
the -X- _ O
problem -X- _ O
require -X- _ O
an -X- _ O
additional -X- _ O
significant -X- _ O
amount -X- _ O
of -X- _ O
time -X- _ O
to -X- _ O
solve -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
here -X- _ O
we -X- _ O
greedily -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
assignment -X- _ O
for -X- _ O
each -X- _ O
variable -X- _ O
as -X- _ O
an -X- _ O
approximate -X- _ O
top -X- _ O
- -X- _ O
k -X- _ O
solution -X- _ O
. -X- _ O
Results -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
7 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
when -X- _ O
k -X- _ O
= -X- _ O
3 -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
already -X- _ O
beaten -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
SS -X- _ B-MethodName
- -X- _ I-MethodName
UB -X- _ I-MethodName
reported -X- _ O
in -X- _ O
Figure -X- _ O
6 -X- _ O
, -X- _ O
which -X- _ O
reveals -X- _ O
that -X- _ O
the -X- _ O
candidates -X- _ O
found -X- _ O
by -X- _ O
the -X- _ O
queries -X- _ O
generated -X- _ O
by -X- _ O
our -X- _ O
query -X- _ O
generator -X- _ O
are -X- _ O
helpful -X- _ O
. -X- _ O
When -X- _ O
k -X- _ O
= -X- _ O
5 -X- _ O
, -X- _ O
the -X- _ O
mean -X- _ B-MetricName
recall -X- _ I-MetricName
can -X- _ O
achieve -X- _ O
around -X- _ O
0.21 -X- _ B-MetricValue
, -X- _ O
which -X- _ O
is -X- _ O
much -X- _ O
better -X- _ O
than -X- _ O
0.15 -X- _ B-MetricValue
, -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
achieved -X- _ O
by -X- _ O
searching -X- _ O
the -X- _ O
identified -X- _ O
sentence -X- _ O
directly -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
what -X- _ O
we -X- _ O
can -X- _ O
observe -X- _ O
in -X- _ O
the -X- _ O
figure -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
gap -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
MS -X- _ B-MethodName
- -X- _ I-MethodName
UB -X- _ I-MethodName
in -X- _ O
Figure -X- _ O
6 -X- _ O
. -X- _ O
This -X- _ O
may -X- _ O
result -X- _ O
from -X- _ O
the -X- _ O
insufficiency -X- _ O
of -X- _ O
the -X- _ O
query -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
implies -X- _ O
that -X- _ O
a -X- _ O
better -X- _ O
text -X- _ O
generation -X- _ O
model -X- _ O
may -X- _ O
be -X- _ O
necessary -X- _ O
to -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
think -X- _ O
is -X- _ O
an -X- _ O
interesting -X- _ O
topic -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O
Our -X- _ O
work -X- _ O
builds -X- _ O
on -X- _ O
earlier -X- _ O
work -X- _ O
on -X- _ O
Claim -X- _ B-TaskName
Provenance -X- _ I-TaskName
( -X- _ O
see -X- _ O
Section -X- _ O
2 -X- _ O
for -X- _ O
a -X- _ O
discussion -X- _ O
) -X- _ O
. -X- _ O
Beyond -X- _ O
that -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
below -X- _ O
additional -X- _ O
related -X- _ O
work -X- _ O
. -X- _ O
Fact -X- _ O
- -X- _ O
checking -X- _ O
Fact -X- _ O
- -X- _ O
checking -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
our -X- _ O
problem -X- _ O
, -X- _ O
since -X- _ O
there -X- _ O
is -X- _ O
usually -X- _ O
a -X- _ O
document -X- _ O
retrieval -X- _ O
step -X- _ O
to -X- _ O
find -X- _ O
articles -X- _ O
that -X- _ O
may -X- _ O
provide -X- _ O
evidence -X- _ O
in -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
solutions -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Thorne -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018;Nadeem -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Typically -X- _ O
, -X- _ O
the -X- _ O
input -X- _ O
of -X- _ O
fact -X- _ O
- -X- _ O
checking -X- _ O
is -X- _ O
a -X- _ O
single -X- _ O
claim -X- _ O
instead -X- _ O
of -X- _ O
an -X- _ O
article -X- _ O
, -X- _ O
therefore -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
directly -X- _ O
extend -X- _ O
their -X- _ O
solutions -X- _ O
to -X- _ O
our -X- _ O
problem -X- _ O
. -X- _ O
Even -X- _ O
though -X- _ O
fact -X- _ O
- -X- _ O
checking -X- _ O
may -X- _ O
find -X- _ O
various -X- _ O
evidentiary -X- _ O
articles -X- _ O
for -X- _ O
the -X- _ O
claim -X- _ O
, -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
we -X- _ O
are -X- _ O
looking -X- _ O
for -X- _ O
are -X- _ O
those -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
by -X- _ O
the -X- _ O
author -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
actually -X- _ O
a -X- _ O
specific -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
articles -X- _ O
that -X- _ O
fact -X- _ O
- -X- _ O
checking -X- _ O
targets -X- _ O
to -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
size -X- _ O
is -X- _ O
also -X- _ O
much -X- _ O
smaller -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
try -X- _ O
to -X- _ O
extract -X- _ O
the -X- _ O
metadata -X- _ O
of -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
to -X- _ O
support -X- _ O
a -X- _ O
better -X- _ O
search -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
considered -X- _ O
in -X- _ O
the -X- _ O
document -X- _ O
retrieval -X- _ O
step -X- _ O
of -X- _ O
fact -X- _ O
- -X- _ O
checking -X- _ O
. -X- _ O
Recommending -X- _ O
Citations -X- _ O
Recommending -X- _ O
citations -X- _ O
for -X- _ O
scholarly -X- _ O
articles -X- _ O
has -X- _ O
similarities -X- _ O
to -X- _ O
our -X- _ O
work -X- _ O
. -X- _ O
The -X- _ O
source -X- _ O
articles -X- _ O
we -X- _ O
are -X- _ O
looking -X- _ O
for -X- _ O
can -X- _ O
be -X- _ O
considered -X- _ O
as -X- _ O
the -X- _ O
citations -X- _ O
of -X- _ O
the -X- _ O
given -X- _ O
news -X- _ O
article -X- _ O
that -X- _ O
should -X- _ O
be -X- _ O
recommended -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
meaning -X- _ O
of -X- _ O
the -X- _ O
" -X- _ O
reference -X- _ O
" -X- _ O
is -X- _ O
different -X- _ O
in -X- _ O
these -X- _ O
two -X- _ O
problems -X- _ O
. -X- _ O
When -X- _ O
recommending -X- _ O
citations -X- _ O
for -X- _ O
a -X- _ O
paper -X- _ O
, -X- _ O
the -X- _ O
system -X- _ O
is -X- _ O
to -X- _ O
look -X- _ O
for -X- _ O
previous -X- _ O
works -X- _ O
that -X- _ O
are -X- _ O
related -X- _ O
to -X- _ O
the -X- _ O
arguments -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
paper -X- _ O
. -X- _ O
The -X- _ O
argument -X- _ O
was -X- _ O
created -X- _ O
by -X- _ O
the -X- _ O
author -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
criteria -X- _ O
of -X- _ O
the -X- _ O
recommendation -X- _ O
is -X- _ O
the -X- _ O
relatedness -X- _ O
. -X- _ O
While -X- _ O
inferring -X- _ O
provenance -X- _ O
is -X- _ O
to -X- _ O
do -X- _ O
reverse -X- _ O
engineering -X- _ O
to -X- _ O
the -X- _ O
given -X- _ O
article -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
find -X- _ O
the -X- _ O
articles -X- _ O
whose -X- _ O
information -X- _ O
or -X- _ O
claims -X- _ O
were -X- _ O
actually -X- _ O
used -X- _ O
when -X- _ O
the -X- _ O
author -X- _ O
was -X- _ O
writing -X- _ O
. -X- _ O
Technically -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
two -X- _ O
types -X- _ O
of -X- _ O
citation -X- _ O
recommendation -X- _ O
systems -X- _ O
( -X- _ O
Bhagavatula -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
One -X- _ O
is -X- _ O
called -X- _ O
local -X- _ O
( -X- _ O
Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012(Huang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
, -X- _ O
2015 -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
a -X- _ O
system -X- _ O
takes -X- _ O
a -X- _ O
few -X- _ O
sentences -X- _ O
( -X- _ O
and -X- _ O
an -X- _ O
optional -X- _ O
placeholder -X- _ O
for -X- _ O
the -X- _ O
candidate -X- _ O
citation -X- _ O
) -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
recommends -X- _ O
citations -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
sentences -X- _ O
. -X- _ O
Another -X- _ O
one -X- _ O
is -X- _ O
called -X- _ O
global -X- _ O
( -X- _ O
Kataria -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010;Ren -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014;Bhagavatula -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
that -X- _ O
is -X- _ O
, -X- _ O
a -X- _ O
system -X- _ O
takes -X- _ O
the -X- _ O
entire -X- _ O
article -X- _ O
( -X- _ O
and -X- _ O
its -X- _ O
meta -X- _ O
- -X- _ O
data -X- _ O
which -X- _ O
is -X- _ O
optional -X- _ O
) -X- _ O
as -X- _ O
input -X- _ O
and -X- _ O
recommends -X- _ O
cita -X- _ O
- -X- _ O
tions -X- _ O
for -X- _ O
the -X- _ O
paper -X- _ O
. -X- _ O
Our -X- _ O
solution -X- _ O
is -X- _ O
more -X- _ O
related -X- _ O
to -X- _ O
local -X- _ O
recommendation -X- _ O
systems -X- _ O
, -X- _ O
while -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
assume -X- _ O
we -X- _ O
can -X- _ O
access -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
articles -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
cited -X- _ O
and -X- _ O
have -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
represent -X- _ O
them -X- _ O
to -X- _ O
be -X- _ O
vectors -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
query -X- _ O
generator -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
different -X- _ O
with -X- _ O
previous -X- _ O
works -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
joint -X- _ O
inference -X- _ O
for -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
identified -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
article -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
actually -X- _ O
a -X- _ O
global -X- _ O
inference -X- _ O
. -X- _ O
We -X- _ O
propose -X- _ O
new -X- _ O
techniques -X- _ O
to -X- _ O
infer -X- _ O
fine -X- _ O
- -X- _ O
grained -X- _ O
provenance -X- _ O
for -X- _ O
an -X- _ O
article -X- _ O
that -X- _ O
contains -X- _ O
multiple -X- _ O
claims -X- _ O
; -X- _ O
this -X- _ O
is -X- _ O
important -X- _ O
for -X- _ O
a -X- _ O
critical -X- _ O
reader -X- _ O
to -X- _ O
understand -X- _ O
what -X- _ O
information -X- _ O
supports -X- _ O
the -X- _ O
article -X- _ O
he -X- _ O
/ -X- _ O
she -X- _ O
is -X- _ O
reading -X- _ O
and -X- _ O
what -X- _ O
its -X- _ O
origins -X- _ O
are -X- _ O
. -X- _ O
The -X- _ O
inference -X- _ O
consists -X- _ O
of -X- _ O
models -X- _ O
that -X- _ O
can -X- _ O
identify -X- _ O
the -X- _ O
sentences -X- _ O
that -X- _ O
refer -X- _ O
to -X- _ O
important -X- _ O
external -X- _ O
information -X- _ O
, -X- _ O
generate -X- _ O
the -X- _ O
metadata -X- _ O
that -X- _ O
can -X- _ O
make -X- _ O
it -X- _ O
more -X- _ O
likely -X- _ O
to -X- _ O
recall -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
using -X- _ O
a -X- _ O
search -X- _ O
engine -X- _ O
, -X- _ O
and -X- _ O
do -X- _ O
an -X- _ O
ILP -X- _ O
inference -X- _ O
to -X- _ O
jointly -X- _ O
determine -X- _ O
the -X- _ O
correct -X- _ O
source -X- _ O
articles -X- _ O
from -X- _ O
the -X- _ O
candidates -X- _ O
. -X- _ O
We -X- _ O
create -X- _ O
a -X- _ O
new -X- _ O
dataset -X- _ O
, -X- _ O
Politi -X- _ B-DatasetName
- -X- _ I-DatasetName
Prov -X- _ I-DatasetName
, -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
evaluation -X- _ O
on -X- _ O
it -X- _ O
demonstrates -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
each -X- _ O
component -X- _ O
, -X- _ O
and -X- _ O
shows -X- _ O
a -X- _ O
big -X- _ O
improvement -X- _ O
compared -X- _ O
with -X- _ O
the -X- _ O
baselines -X- _ O
of -X- _ O
finding -X- _ O
source -X- _ O
articles -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
problem -X- _ O
has -X- _ O
not -X- _ O
been -X- _ O
solved -X- _ O
yet -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
analysis -X- _ O
, -X- _ O
a -X- _ O
better -X- _ O
text -X- _ O
generation -X- _ O
model -X- _ O
would -X- _ O
further -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
it -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
revealed -X- _ O
in -X- _ O
the -X- _ O
experiments -X- _ O
that -X- _ O
the -X- _ O
gold -X- _ O
metadata -X- _ O
can -X- _ O
only -X- _ O
recall -X- _ B-MetricName
only -X- _ O
around -X- _ O
40 -X- _ B-MetricValue
% -X- _ I-MetricValue
of -X- _ O
the -X- _ O
source -X- _ O
articles -X- _ O
, -X- _ O
which -X- _ O
actually -X- _ O
becomes -X- _ O
a -X- _ O
bottleneck -X- _ O
. -X- _ O
Therefore -X- _ O
, -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
an -X- _ O
interesting -X- _ O
future -X- _ O
work -X- _ O
direction -X- _ O
to -X- _ O
explore -X- _ O
what -X- _ O
other -X- _ O
information -X- _ O
should -X- _ O
be -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
query -X- _ O
, -X- _ O
besides -X- _ O
the -X- _ O
target -X- _ O
metadata -X- _ O
, -X- _ O
so -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
recall -X- _ O
more -X- _ O
source -X- _ O
articles -X- _ O
. -X- _ O
Our -X- _ O
dataset -X- _ O
Politi -X- _ O
- -X- _ O
Prov -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
www.poli -X- _ O
tifact.com -X- _ O
. -X- _ O
The -X- _ O
executive -X- _ O
director -X- _ O
of -X- _ O
PolitiFact -X- _ O
, -X- _ O
based -X- _ O
at -X- _ O
the -X- _ O
Poynter -X- _ O
Institute -X- _ O
for -X- _ O
Media -X- _ O
Studies -X- _ O
, -X- _ O
granted -X- _ O
us -X- _ O
permission -X- _ O
to -X- _ O
use -X- _ O
their -X- _ O
data -X- _ O
for -X- _ O
this -X- _ O
research -X- _ O
and -X- _ O
to -X- _ O
make -X- _ O
the -X- _ O
new -X- _ O
dataset -X- _ O
available -X- _ O
. -X- _ O
The -X- _ O
collection -X- _ O
process -X- _ O
is -X- _ O
automatic -X- _ O
without -X- _ O
additional -X- _ O
manual -X- _ O
work -X- _ O
. -X- _ O
Our -X- _ O
collection -X- _ O
involves -X- _ O
fact -X- _ O
- -X- _ O
check -X- _ O
articles -X- _ O
with -X- _ O
sources -X- _ O
in -X- _ O
4 -X- _ O
topics -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
coronavirus -X- _ O
, -X- _ O
health -X- _ O
care -X- _ O
, -X- _ O
immigration -X- _ O
and -X- _ O
taxes -X- _ O
, -X- _ O
which -X- _ O
were -X- _ O
written -X- _ O
by -X- _ O
the -X- _ O
website -X- _ O
's -X- _ O
journalists -X- _ O
. -X- _ O
The -X- _ O
website -X- _ O
seeks -X- _ O
to -X- _ O
present -X- _ O
the -X- _ O
true -X- _ O
facts -X- _ O
, -X- _ O
unaffected -X- _ O
by -X- _ O
agenda -X- _ O
or -X- _ O
biases -X- _ O
, -X- _ O
but -X- _ O
journalists -X- _ O
set -X- _ O
their -X- _ O
own -X- _ O
opinions -X- _ O
aside -X- _ O
as -X- _ O
they -X- _ O
work -X- _ O
to -X- _ O
uphold -X- _ O
principles -X- _ O
of -X- _ O
independence -X- _ O
and -X- _ O
fairness -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
website -X- _ O
emphasizes -X- _ O
primary -X- _ O
sources -X- _ O
and -X- _ O
original -X- _ O
documentation -X- _ O
when -X- _ O
listing -X- _ O
sources -X- _ O
, -X- _ O
for -X- _ O
example -X- _ O
direct -X- _ O
access -X- _ O
to -X- _ O
government -X- _ O
reports -X- _ O
, -X- _ O
academic -X- _ O
studies -X- _ O
and -X- _ O
other -X- _ O
data -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
second -X- _ O
- -X- _ O
hand -X- _ O
sources -X- _ O
. -X- _ O
The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Aaron -X- _ O
Sharockman -X- _ O
, -X- _ O
the -X- _ O
executive -X- _ O
director -X- _ O
of -X- _ O
PolitiFact -X- _ O
, -X- _ O
for -X- _ O
kindly -X- _ O
granting -X- _ O
access -X- _ O
to -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
website -X- _ O
for -X- _ O
academic -X- _ O
research -X- _ O
. -X- _ O
This -X- _ O
work -X- _ O
is -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
the -X- _ O
Office -X- _ O
of -X- _ O
the -X- _ O
Director -X- _ O
of -X- _ O
National -X- _ O
Intelligence -X- _ O
( -X- _ O
ODNI -X- _ O
) -X- _ O
, -X- _ O
Intelligence -X- _ O
Advanced -X- _ O
Research -X- _ O
Projects -X- _ O
Activity -X- _ O
( -X- _ O
IARPA -X- _ O
) -X- _ O
, -X- _ O
via -X- _ O
IARPA -X- _ O
Contract -X- _ O
No -X- _ O
. -X- _ O
2019 -X- _ O
- -X- _ O
19051600006 -X- _ O
under -X- _ O
the -X- _ O
BETTER -X- _ O
Program -X- _ O
and -X- _ O
by -X- _ O
a -X- _ O
Google -X- _ O
Focused -X- _ O
Award -X- _ O
. -X- _ O

